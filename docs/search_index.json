[["index.html", "Aerial Imagery and Point Cloud Data for Slash Pile Quantification Section 1 Introduction 1.1 Objective 1.2 Data 1.3 Analysis Plan", " Aerial Imagery and Point Cloud Data for Slash Pile Quantification George Woolsey 14 January, 2026 Section 1 Introduction Code in support of “A General Method using UAS Data for Automated Slash Pile Detection and Quantification” Increasing active forest management activities generate non-commercial residues (slash) that are often aggregated into piles for disposal. However, pile burning is associated with increased operational costs and significant external environmental costs (Mott et al., 2021; Barker et al., 2025; Axlund et al., 2025), motivating the need for improved quantification and management. While remote sensing techniques using point clouds consistently offer improved pile quantification accuracy over traditional field methods (Trofymow et al., 2014; Guth et al., 2025), there is a lack of automated methods for simultaneously detecting and quantifying piles across an broad treatment extents. To overcome this we propose a geometry-based, rules-based framework that leverages the proven success of object segmentation frameworks in CWD (e.g. dos Santos et al., 2025) and tree detection (e.g. Tinkham &amp; Woolsey, 2024) and offers superior managerial relevance due to its inherent traceability and direct alignment with known pile construction parameters defined in silvicultural prescriptions. 1.1 Objective The objective of this study is to present a training-free, rules-based methodology for identifying slash piles from UAS data. The presented approach aims to enable high transferability by using user-defined geometric and size thresholds to identify pile candidates from aerial point cloud data, which can then be refined through a data fusion process incorporating spectral (i.e. RGB) data when available. 1.2 Data We have remote sensing data acquired from a UAS platform and accompanying ground truth data for four different study sites. For all study sites we have: Aerial RGB imagery captured by a UAS platform Aerial point cloud data generated by processing the UAS imagery using digital aerial photogrammetry (DAP) techniques (specifically, structure from motion [SfM]) Image-annotated slash pile perimeters digitized in a Geographic Information System (GIS) using field-collected point locations as a guide overlaid on the UAS-collected RGB imagery For the one study site only we have: * Field-collected slash pile point locations with height and diameter measurements Data from all study sites will be used to validate the slash pile detection methodology. Data from the study site with field-collected pile measurements will be used to test the slash pile quantification accuracies acheived by the proposed methodology. The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how the data was collected. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site. Site Name Pile Type Validation Data Type Unique Features &amp; Ecology Data Collection (UAS Platform &amp; Parameters) PSINF Mixed Conifer Site Hand Piles and smaller machine piles Image-annotated footprints and field-measured height and diameter Located in the Pike and San Isabel National Forest (PSINF) in CO, US. Mixed conifer stand with variable ground cover and canopy density. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. TRFO-BLM Pinyon-Juniper Site Hand Piles Image-annotated footprints based on field collected point locations Located on BLM land in CO, US. Arid environment with dry vegetation including standing dead pinyon-juniper. Piles are smaller, simpler, and hand-stacked. Freefly Astro with Sony ILX-LR1 (35mm lens). Altitude 243.84 m (terrain following), 85% forward and 80% side overlap. BHEF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Black Hills Experimental Forest (BHEF) in SD, US. Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected. DJI Phantom 4 Pro with 20 MP RGB sensor (8.8 mm lens). Altitude 80 m, 90% forward and 85% side overlap, 4 m/s speed. ARNF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Arapahoe and Roosevelt National Forest (ARNF) in CO, US. Ponderosa pine forest with a climate similar to PSINF. Machine piles are massive but more circular and regular. Less regeneration is expected. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. 1.3 Analysis Plan We will follow the general analysis outline in five distinct sections: Data Overview: We will detail the study sites, summarize the number of piles and the pile size based on available measurements, and review the RGB orthomosaic data Point Cloud Processing: We will demonstrate how to process the point cloud data to generate the required inputs for the propose pile detection method. Geometry-based Slash Pile Detection: We will detail the geometry-based slash pile detection method which uses user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-DAP point cloud data. Spectral Refinement Methodology: We will detail the complementary spectral refinement methodology which uses RGB data to filter the structurally-detected candidate piles. Structural-Only Methodology Evaluation: We will evaluate the accuracy of the structural-only methodology in terms of slash pile detection (F-score, Recall, Precision) across four distinct treatment units spanning unique prescriptions and forest types. Data Fusion Methodology Evaluation: We will evaluate the accuracy of the structural-plus-spectral data fusion methodology in terms of slash pile detection (F-score, Recall, Precision) when using spectral data to refine predictions. Sensitivity Analysis: Finally, we will perform a sensitivity analysis on the key user-defined parameters of the proposed method to systematically quantify the impact of each varied parameter on the stability and performance of the slash pile detection. "],["data-overview.html", "Section 2 Data Overview 2.1 Study Units Vector Data 2.2 Slash Pile Vector Data 2.3 RGB orthomosaic 2.4 Slash Pile RGB Imagery", " Section 2 Data Overview We will detail the study sites and summarize the number of piles and the pile size based on available measurements. Site Name Pile Type Validation Data Type Unique Features &amp; Ecology Data Collection (UAS Platform &amp; Parameters) PSINF Mixed Conifer Site Hand Piles and smaller machine piles Image-annotated footprints and field-measured height and diameter Located in the Pike and San Isabel National Forest (PSINF) in CO, US. Mixed conifer stand with variable ground cover and canopy density. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. TRFO-BLM Pinyon-Juniper Site Hand Piles Image-annotated footprints based on field collected point locations Located on BLM land in CO, US. Arid environment with dry vegetation including standing dead pinyon-juniper. Piles are smaller, simpler, and hand-stacked. Freefly Astro with Sony ILX-LR1 (35mm lens). Altitude 243.84 m (terrain following), 85% forward and 80% side overlap. BHEF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Black Hills Experimental Forest (BHEF) in SD, US. Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected. DJI Phantom 4 Pro with 20 MP RGB sensor (8.8 mm lens). Altitude 80 m, 90% forward and 85% side overlap, 4 m/s speed. ARNF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Arapahoe and Roosevelt National Forest (ARNF) in CO, US. Ponderosa pine forest with a climate similar to PSINF. Machine piles are massive but more circular and regular. Less regeneration is expected. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. Load the standard libraries we use to do work # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(ggnewscale) # new scale library(grDevices) # default graphics # spatial analysis library(terra) # raster library(sf) # simple features library(lwgeom) # advanced functions for spatial operations library(lidR) # lidar data library(rgl) # 3d plots library(cloud2trees) # the cloud2trees 2.1 Study Units Vector Data let’s load in all the vector data containing the study units we’ll combine the study unit boundaries for all sites to create a spatial data set that contains all units for plotting in a single map # read the data # stand boundary all_stand_boundary &lt;- dplyr::bind_rows( psinf_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , pj_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , bhef_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , arnf_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) ) %&gt;% dplyr::group_by(site) %&gt;% dplyr::summarise( geometry = sf::st_union(geometry) ) %&gt;% dplyr::ungroup() %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( site_area_m2 = sf::st_area(geometry) %&gt;% as.numeric() , site_area_ha = site_area_m2/10000 ) # sf::st_centroid() %&gt;% # sf::st_sf() %&gt;% Let’s map the study sites on a single map sites_pal &lt;- RColorBrewer::brewer.pal(n = nrow(all_stand_boundary), name = &quot;Dark2&quot;) # option to put satellite imagery as base layer of mapview maps mapview::mapviewOptions( homebutton = T # , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) , basemaps = c(&quot;OpenStreetMap&quot;, &quot;Esri.WorldImagery&quot;) ) # map it mapview::mapview( all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_centroid() , zcol=&quot;site&quot; , col.regions = sites_pal , cex = 8 , layer.name = &quot;study sites&quot; ) static map for printing let’s make a pretty image for use in the journal article. we’ll use the ggmap package to get a nice background map and do some transformation to actually work with the map. We’ll add a map scale using ggspatial library(ggmap) library(ggspatial) ######################################################################### ######################################################################### # Make each plot individually by landscape as solution to small multiples # this block defines function ######################################################################### ##################hack to align plots for ggmap ggmap_bbox_fn &lt;- function(map, my_crs=3857) { if (!inherits(map, &quot;ggmap&quot;)) stop(&quot;map must be a ggmap object&quot;) # Extract the bounding box (in lat/lon) from the ggmap to a numeric vector, # and set the names to what sf::st_bbox expects: map_bbox &lt;- setNames(unlist(attr(map, &quot;bb&quot;)), c(&quot;ymin&quot;, &quot;xmin&quot;, &quot;ymax&quot;, &quot;xmax&quot;)) # Convert the bbox to an sf polygon, transform it to 3857, # and convert back to a bbox (convoluted, but it works) bbox_3857 &lt;- st_bbox(st_transform(st_as_sfc(st_bbox(map_bbox, crs = 4326)), my_crs)) # Overwrite the bbox of the ggmap object with the transformed coordinates attr(map, &quot;bb&quot;)$ll.lat &lt;- bbox_3857[&quot;ymin&quot;] attr(map, &quot;bb&quot;)$ll.lon &lt;- bbox_3857[&quot;xmin&quot;] attr(map, &quot;bb&quot;)$ur.lat &lt;- bbox_3857[&quot;ymax&quot;] attr(map, &quot;bb&quot;)$ur.lon &lt;- bbox_3857[&quot;xmax&quot;] map } plt_crs &lt;- 3857 ######################################################################### ######################################################################### ######################################################################### my_ggmap_basemap &lt;- function(sf_data, zoom_level = 14, buffer_box = 2600, my_crs = plt_crs, scale_location = &quot;bl&quot;, my_maptype = &quot;stamen_terrain&quot;) { # # should zoom in? # zoom_level &lt;- 14 # 11 # # should buffer extend? # buffer_box &lt;- 2600 # 20000 # bounding box bb_temp &lt;- sf_data %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(crs=5070) %&gt;% sf::st_buffer(as.numeric(buffer_box)) %&gt;% sf::st_transform(crs=4326) %&gt;% # same as get_map return sf::st_bbox() # set bbox for get call bbox_temp &lt;- c( bottom = bb_temp[[2]] , top = bb_temp[[4]] , right = bb_temp[[3]] , left = bb_temp[[1]] ) hey_ggmap &lt;- ggmap::get_stadiamap( bbox = bbox_temp , zoom = zoom_level , maptype = my_maptype #&quot;stamen_terrain&quot; #&quot;stamen_toner_lite&quot; , crop = T ) # ggmap::ggmap(hey_ggmap) # apply align function hey_ggmap_aligned &lt;- ggmap_bbox_fn(hey_ggmap, my_crs) # Use the function # plot plt_basemap &lt;- ggmap::ggmap(hey_ggmap_aligned) + ggplot2::coord_sf( expand = FALSE ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , plot.title = ggplot2::element_blank() , strip.text = ggplot2::element_blank() , axis.title = ggplot2::element_blank() , axis.text = ggplot2::element_blank() , axis.ticks = ggplot2::element_blank() , panel.grid = ggplot2::element_blank() , plot.margin = ggplot2::margin(0, 0, 0, 0, &quot;cm&quot;) ) if(scale_location %in% c(&quot;bl&quot;, &quot;br&quot;, &quot;tr&quot;, &quot;tl&quot;)){ plt_basemap &lt;- plt_basemap + ggspatial::annotation_scale( location = scale_location , style = &quot;ticks&quot; , pad_x = unit(0.1, &quot;cm&quot;) , pad_y = unit(0.1, &quot;cm&quot;) ) } return(plt_basemap) } plot the fancy basemap with the points # get the basemap with our my_ggmap_basemap() plt_basemap &lt;- my_ggmap_basemap( sf_data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() , buffer_box = 190000 , zoom_level = 7 , my_maptype = &quot;stamen_terrain&quot; ) # plt_basemap # plot plt2_temp &lt;- plt_basemap + ggplot2::geom_sf( data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(fill = site) , size = 4.5 , inherit.aes = F , shape = 21 , color = &quot;gray88&quot; , fill = &quot;blue2&quot; ) + ggplot2::geom_sf_label( data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(label = stringr::str_wrap(site, width = 40)) , size = 2.5 , hjust = -0.055 , vjust = 0.4 , inherit.aes = F ) + ggplot2::scale_fill_manual(values = sites_pal) plt2_temp what is the area of the treatment unit boundaries we are looking over? all_stand_boundary %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(site, site_area_ha) %&gt;% dplyr::mutate( site_area_ha = scales::comma(site_area_ha, suffix = &quot; ha&quot;, accuracy = 0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Study site area&quot; , col.names = c( &quot;site&quot;, &quot;hectares&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 2.1: Study site area site hectares ARNF Ponderosa Pine Site 73.6 ha BHEF Ponderosa Pine Site 103.1 ha PSINF Mixed Conifer Site 17.5 ha TRFO-BLM Pinyon-Juniper Site 5.2 ha 2.2 Slash Pile Vector Data Image-annotated pile footprints at each study site were created in a GIS by outlining pile boundaries on the RGB orthomosaic and confirming the vertical structure using fine-resolution CHM data (e.g., 0.15m resolution). Field-collected points were used to ensure pile census completeness at the hand-pile study sites (PSINF Mixed Conifer Site and TRFO-BLM Pinyon-Juniper Site) to pinpoint piles that were otherwise challenging to delineate from the aerial imagery and CHM data alone. Across all sites, machine piles were easily distinguishable using the RGB and CHM data. Let’s load in those image-annotated pile polygons now for each study site. ####################################### # polygons annotated using RGB and field-collected points ####################################### ########################### # PSINF Mixed Conifer Site ########################### psinf_slash_piles_polys &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/manitou_pile_polys.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::ungroup() %&gt;% dplyr::mutate(treeID = dplyr::row_number()) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID, shape_leng, shape_area)) %&gt;% dplyr::mutate(site = &quot;PSINF Mixed Conifer Site&quot;) # points recorded in field psinf_slash_piles_points &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/SlashPiles.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_zm() %&gt;% sf::st_transform(sf::st_crs(psinf_slash_piles_polys)) %&gt;% dplyr::filter( !(objectid %in% c(43)) ) %&gt;% # duplicate field points dplyr::mutate(row_number = dplyr::row_number()) %&gt;% dplyr::select(-c(objectid)) %&gt;% dplyr::rename( height_ft = height , diameter_ft = diameter ) # update unit boundary to pile proj psinf_stand_boundary &lt;- psinf_stand_boundary %&gt;% sf::st_transform(sf::st_crs(psinf_slash_piles_polys)) # attach flag for spatial overlap with unit boundary psinf_slash_piles_polys &lt;- psinf_slash_piles_polys %&gt;% dplyr::left_join( psinf_slash_piles_polys %&gt;% sf::st_intersection(psinf_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # TRFO-BLM Pinyon-Juniper Site ########################### pj_slash_piles_polys &lt;- sf::st_read(&quot;../data/Dawson_Data/piles/pj_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID,id)) %&gt;% dplyr::filter(pile_id!=62) %&gt;% dplyr::mutate(site = &quot;TRFO-BLM Pinyon-Juniper Site&quot;) # points recorded in field # these piles were collected twice in the same location and have different measurements :\\ bad_pile_ids_temp &lt;- c( 142 , 146 , 99 , 96 , 50 ) pj_slash_piles_points &lt;- readr::read_csv(&quot;../data/Dawson_data/PJ_Piles_Unit_10.csv&quot;, progress = T, show_col_types = F) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% dplyr::mutate( orig_pile_id = readr::parse_number(name) ) %&gt;% dplyr::filter( !(orig_pile_id %in% bad_pile_ids_temp) ) %&gt;% sf::st_as_sf(coords = c(&quot;easting&quot;,&quot;northing&quot;), crs = 6342, remove = F) %&gt;% dplyr::select(orig_pile_id,name,height_m,width_m,easting,northing,latitude,longitude,code,description,elevation) %&gt;% sf::st_make_valid() %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_polys)) ## indexing PJ_Piles_Unit_10.csv [=============================] 2.15GB/s, eta: 0s # update unit boundary to pile proj pj_stand_boundary &lt;- pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_polys)) # attach flag for spatial overlap with unit boundary pj_slash_piles_polys &lt;- pj_slash_piles_polys %&gt;% dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_intersection(pj_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # BHEF Ponderosa Pine Site ########################### bhef_slash_piles_polys &lt;- sf::st_read(&quot;../data/BHEF_202306/piles/bhef_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% dplyr::mutate(site = &quot;BHEF Ponderosa Pine Site&quot;) # update unit boundary to pile proj bhef_stand_boundary &lt;- bhef_stand_boundary %&gt;% sf::st_transform(sf::st_crs(bhef_slash_piles_polys)) # attach flag for spatial overlap with unit boundary bhef_slash_piles_polys &lt;- bhef_slash_piles_polys %&gt;% dplyr::left_join( bhef_slash_piles_polys %&gt;% sf::st_intersection(bhef_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # ARNF Ponderosa Pine Site ########################### arnf_slash_piles_polys &lt;- sf::st_read(&quot;../data/ARNF_DiamondView_202510/arnf_diamond_view_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% dplyr::mutate(site = &quot;ARNF Ponderosa Pine Site&quot;) # update unit boundary to pile proj arnf_stand_boundary &lt;- arnf_stand_boundary %&gt;% sf::st_transform(sf::st_crs(arnf_slash_piles_polys)) # attach flag for spatial overlap with unit boundary arnf_slash_piles_polys &lt;- arnf_slash_piles_polys %&gt;% dplyr::left_join( arnf_slash_piles_polys %&gt;% sf::st_intersection(arnf_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) 2.2.1 Standardize Pile Data For the sites with field-collected point data, each point may not necessarily fall within the polygon boundary (e.g. due to misalignment between the imagery and point locations or slight inaccuracies in either the point or pile boundaries). So, we need to perform a matching process to tie the points to the polygons so that we get the height and diameter measured during the point collection attached to the polygons. to do this, we’ll use a two-stage process that first attaches the points data frame to polygons where points fall within, using a spatial intersection. It then finds and assigns the remaining, unjoined points to their nearest polygon. The final output includes all polygons from the original data, ensuring that every polygon is represented even if no points were matched. # function to perform a two-step spatial join # first matching points that fall inside polygons and # then assigning the remaining points to the nearest polygon # all original polygons are returned in the final output match_points_to_polygons &lt;- function( points_sf , polygons_sf , point_id , polygon_id ) { # check if point_id column exists in points_sf if (!point_id %in% names(points_sf)) { stop(paste0(&quot;column &#39;&quot;, point_id, &quot;&#39; not found in points_sf.&quot;)) } # check if polygon_id column exists in polygons_sf if (!polygon_id %in% names(polygons_sf)) { stop(paste0(&quot;column &#39;&quot;, polygon_id, &quot;&#39; not found in polygons_sf.&quot;)) } # 1. ensure the crs are the same. if (sf::st_crs(points_sf) != sf::st_crs(polygons_sf)) { points_sf &lt;- sf::st_transform(points_sf, sf::st_crs(polygons_sf)) } # 2. Perform a standard spatial join for points within polygons. # Use an inner join (`left = FALSE`) to get only points that fall inside. points_within &lt;- sf::st_join( x = points_sf , y = polygons_sf , join = sf::st_intersects , left = FALSE ) # 3. Identify points that were not matched in the first step. matched_points_ids &lt;- points_within[[point_id]] unmatched_points &lt;- points_sf[!points_sf[[point_id]] %in% matched_points_ids, ] if (nrow(unmatched_points) &gt; 0) { # 4. For the remaining points, find the index of the nearest polygon. nearest_polygon_index &lt;- sf::st_nearest_feature(unmatched_points, polygons_sf) # 5. Extract the nearest polygons and join their attributes to the unmatched points. nearest_polygons &lt;- polygons_sf[nearest_polygon_index, ] points_nearest &lt;- data.frame(unmatched_points, sf::st_drop_geometry(nearest_polygons)) # Preserve the geometry from the original unmatched points for the nearest matches. points_nearest &lt;- sf::st_set_geometry(points_nearest, sf::st_geometry(unmatched_points)) # 6. Combine the results from the &quot;points_within&quot; and &quot;points_nearest&quot; joins. combined_points &lt;- dplyr::bind_rows(points_within, points_nearest) } else { # If all points were matched in step 2. combined_points &lt;- points_within } # names diff cols_add &lt;- c( base::setdiff( names(combined_points) , names(polygons_sf) ) , polygon_id ) # 7. Perform a left join to ensure all original polygons are included in the final output. # Polygons without any matched points will have `NA` values for the point attributes. final_result &lt;- polygons_sf %&gt;% dplyr::left_join( combined_points %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(cols_add)) , by = polygon_id ) return(final_result) } we’ll also define a function to get the diameter of the polygon which we will use to extract diameter from our predicted segments to compare with the field-measured diameter values. we can also compare the field-measured diameter to the image-annotated diameter as a sanity check. let’s define a function to get polygon diameter that accurately reflects the measurement for potentially irregular shapes. we’ll calculate the diameter by finding the maximum distance across the footprint of the entire polygon ###___________________________________________### # calculate diameter of single polygon ###___________________________________________### # function to calculate the diamater of an sf polygon that is potentially irregularly shaped # using the distance between the farthest points st_calculate_diameter_polygon &lt;- function(polygon) { # get the convex hull ch &lt;- sf::st_convex_hull(polygon) # cast to multipoint then point to get individual vertices ch_points &lt;- sf::st_cast(ch, &#39;MULTIPOINT&#39;) %&gt;% sf::st_cast(&#39;POINT&#39;) # calculate the distances between all pairs of points distances &lt;- sf::st_distance(ch_points) # find the maximum distance, which is the diameter diameter &lt;- as.numeric(max(distances,na.rm=T)) return(diameter) } # apply st to sf data st_calculate_diameter &lt;- function(sf_data) { if(!inherits(sf_data,&quot;sf&quot;)){stop(&quot;st_calculate_diameter() requires polygon sf data&quot;)} if( !all( sf::st_is(sf_data, c(&quot;POLYGON&quot;,&quot;MULTIPOLYGON&quot;)) ) ){ stop(&quot;st_calculate_diameter() requires polygon sf data&quot;) } # get the geometry column name geom_col_name &lt;- attr(sf_data, &quot;sf_column&quot;) # calculate diameter # !!rlang::sym() unquotes the geometry column return_dta &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate(diameter_m = st_calculate_diameter_polygon( !!rlang::sym(geom_col_name) )) %&gt;% dplyr::ungroup() return(return_dta) } let’s apply our match_points_to_polygons() and st_calculate_diameter() functions For only the PSINF mixed conifer site, slash pile field measurements were taken by measuring the height and diameter (longest side of pile) using a laser hypsometer For volume estimation, we’ll model the ground truth slash piles as a paraboloid, specifically a parabolic dome, assuming a perfectly circular base and sides curved smoothly to a peak. Assuming a paraboloid shape is common for quantifying slash pile volume (Hardy 1996; Long &amp; Boston 2014) and may better represent the diverse shapes of real-world slash piles than assuming a conical or half-sphere form. A paraboloid can represent a variety of shapes including those that are taller and more conical, or flatter and more spread out, because it allows the measured height and width to influence the volume calculation independently. This makes the paraboloid potentially more robust for estimating volumes of piles with varying aspect ratios. the volume formula for a paraboloid is: \\[ V = \\frac{1}{8}\\pi \\cdot width^2 \\cdot height \\] # PSINF Mixed Conifer Site psinf_slash_piles_polys &lt;- match_points_to_polygons( points_sf = psinf_slash_piles_points , polygons_sf = psinf_slash_piles_polys , point_id = &quot;row_number&quot; , polygon_id = &quot;pile_id&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( # height field_height_m = height_ft*0.3048 , field_diameter_m = diameter_ft*0.3048 # *0.3048 or /3.281 to convert to m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() , field_gt_area_m2 = pi*field_radius_m^2 # volume ASSUMING PERFECT GEOMETRIC SHAPE :/ , image_gt_volume_m3 = (1/8) * pi * (image_gt_diameter_m^2) * field_height_m , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * field_height_m ) # TRFO-BLM Pinyon-Juniper Site pj_slash_piles_polys &lt;- match_points_to_polygons( points_sf = pj_slash_piles_points , polygons_sf = pj_slash_piles_polys , point_id = &quot;orig_pile_id&quot; , polygon_id = &quot;pile_id&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_calculate_diameter() %&gt;% dplyr::rename( image_gt_diameter_m = diameter_m , field_height_m = height_m ) %&gt;% # calculate area and volume dplyr::mutate( # height field_diameter_m = width_m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() , field_gt_area_m2 = pi*field_radius_m^2 # volume ASSUMING PERFECT GEOMETRIC SHAPE :/ , image_gt_volume_m3 = (1/8) * pi * (image_gt_diameter_m^2) * field_height_m , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * field_height_m ) # BHEF Ponderosa Pine Site bhef_slash_piles_polys &lt;- bhef_slash_piles_polys %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) # ARNF Ponderosa Pine Site arnf_slash_piles_polys &lt;- arnf_slash_piles_polys %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) 2.2.2 Pile Form Measurements let’s make some reusable functions to make the same tables throughout the analysis # aggregate agg_piles_temp &lt;- function(df) { df %&gt;% dplyr::filter(is_in_stand) %&gt;% # dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( dplyr::any_of(c(&quot;site&quot;, &quot;pile_type&quot;)) , tidyselect::contains(&quot;area_m2&quot;) | tidyselect::contains(&quot;diameter_m&quot;) | tidyselect::contains(&quot;height_m&quot;) # | tidyselect::contains(&quot;volume_m3&quot;) ) %&gt;% dplyr::summarise( dplyr::across( dplyr::where(~ is.character(.x) | is.factor(.x)) , .fns = dplyr::first ) , dplyr::across( dplyr::where(is.numeric) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) # , q10 = ~quantile(.x,na.rm=T,probs=0.1) # , q50 = ~quantile(.x,na.rm=T,probs=0.5) # , q90 = ~quantile(.x,na.rm=T,probs=0.9) # , min = ~min(.x,na.rm=T) # , max = ~max(.x,na.rm=T) , range = ~paste0( scales::comma(min(.x,na.rm=T), accuracy = 0.1) ,&quot;-&quot; , scales::comma(max(.x,na.rm=T), accuracy = 0.1) ) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() } # function to kableExtra kbl_form_sum_stats_wide &lt;- function(df, by_lab = &quot;&quot;) { df %&gt;% dplyr::mutate( n = scales::comma(n,accuracy=1) , dplyr::across( dplyr::where(is.numeric) , ~scales::comma(.x,accuracy=0.1) ) ) %&gt;% kableExtra::kbl( caption = paste0( &quot;Slash pile image-annotated and field-collected form measurements&quot; ,&quot;&lt;br&gt;&quot; , by_lab ) , col.names = c( &quot; &quot;, &quot;Piles&quot; , rep(c(&quot;Mean&quot;,&quot;Std Dev&quot;,&quot;Range&quot;), times = 4) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above( c( &quot; &quot;=2 , &quot;Image-Ann. Area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; = 3 , &quot;Image-Ann. Diam (m)&quot; = 3 , &quot;Field-Meas. Diam (m)&quot; = 3 , &quot;Field-Meas. Height (m)&quot; = 3 ) , escape = F ) %&gt;% kableExtra::column_spec(seq(2,14,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 2:14 , extra_css = &quot;font-size: 11px;&quot; , include_thead = T ) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) } ## for a single site kbl_form_sum_stats_long &lt;- function( pile_df , caption = &quot;Ground Truth Piles: summary statistics for form measurements&quot; ) { pile_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( tidyselect::contains(&quot;area_m2&quot;) | tidyselect::contains(&quot;diameter_m&quot;) | tidyselect::contains(&quot;height_m&quot;) | tidyselect::contains(&quot;volume_m3&quot;) ) %&gt;% dplyr::summarise( dplyr::across( dplyr::everything() , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% # dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c(n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% stringr::str_c( dplyr::case_when( stringr::str_detect(name,&quot;(field|image)&quot;) ~ paste0(&quot; (&quot;, stringr::str_extract(name,&quot;(field|image)&quot;), &quot;)&quot;) , T ~ &quot;&quot; ) ) %&gt;% stringr::str_replace(&quot;area&quot;, &quot;area m&lt;sup&gt;2&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;volume&quot;, &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;diameter&quot;, &quot;diameter m&quot;) %&gt;% stringr::str_replace(&quot;height&quot;, &quot;height m&quot;) %&gt;% stringr::str_to_sentence() ) %&gt;% # dplyr::count(metric) dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( # metric == &quot;gt_height_m&quot; ~ scales::comma(value,accuracy=0.1) T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::select(-c(min,max)) %&gt;% kableExtra::kbl( caption = caption , col.names = c( &quot;# piles&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) } summary statistics for the form measurements for all study sites agg_piles_temp( psinf_slash_piles_polys %&gt;% dplyr::select(-tidyselect::starts_with(&quot;field_gt_area&quot;)) ) %&gt;% dplyr::bind_rows( agg_piles_temp( pj_slash_piles_polys %&gt;% dplyr::select( -tidyselect::contains(&quot;field&quot;) , -tidyselect::contains(&quot;height&quot;) ) ) , agg_piles_temp(bhef_slash_piles_polys) , agg_piles_temp(arnf_slash_piles_polys) ) %&gt;% dplyr::select( site, n , tidyselect::starts_with(&quot;image_&quot;) , tidyselect::starts_with(&quot;field_&quot;) ) %&gt;% kbl_form_sum_stats_wide(by_lab = &quot;by study site&quot;) Table 2.2: Slash pile image-annotated and field-collected form measurementsby study site Image-Ann. Area (m2) Image-Ann. Diam (m) Field-Meas. Diam (m) Field-Meas. Height (m) Piles Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range PSINF Mixed Conifer Site 121 9.8 9.4 3.9-59.3 3.8 1.3 2.6-10.2 3.4 1.2 2.4-9.0 2.2 0.8 1.5-6.4 TRFO-BLM Pinyon-Juniper Site 277 10.6 3.2 4.1-25.3 4.2 0.6 2.6-6.4 NA NA NA NA NA NA BHEF Ponderosa Pine Site 26 199.9 85.8 76.0-408.7 21.0 6.5 13.3-38.0 NA NA NA NA NA NA ARNF Ponderosa Pine Site 19 409.0 97.1 221.5-593.1 25.9 3.6 18.4-32.9 NA NA NA NA NA NA All sites except PSINF have only mechanical or only hand piles whereas PSINF has both hand piles and mechanical piles. Let’s look at the summary statistics for the form measurements for only PSINF based on pile construction type psinf_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( -tidyselect::contains(&quot;volume_m3&quot;) , -tidyselect::starts_with(&quot;field_gt_area&quot;) , -c(site) ) %&gt;% dplyr::rename(pile_type = comment) %&gt;% dplyr::group_by(pile_type) %&gt;% agg_piles_temp() %&gt;% dplyr::select( pile_type, n , tidyselect::starts_with(&quot;image_&quot;) , tidyselect::starts_with(&quot;field_&quot;) ) %&gt;% kbl_form_sum_stats_wide(by_lab = &quot;PSINF Mixed Conifer Site by pile type&quot;) Table 2.3: Slash pile image-annotated and field-collected form measurementsPSINF Mixed Conifer Site by pile type Image-Ann. Area (m2) Image-Ann. Diam (m) Field-Meas. Diam (m) Field-Meas. Height (m) Piles Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Hand Pile 111 7.2 1.7 3.9-14.3 3.5 0.4 2.6-5.0 3.1 0.3 2.4-4.3 2.0 0.2 1.5-2.4 Mechanical Pile 10 38.3 12.7 21.3-59.3 8.0 1.3 5.9-10.2 7.2 1.1 5.5-9.0 4.4 1.2 2.4-6.4 2.2.3 Image-Annotation Comparison For only the PSINF site, let’s check the field-collected and image-annotated measurements of diameter which will serve as a good sanity check for our image-annotation process (assuming diameter was accurately measured in the field…might be a perilous assumption) psinf_slash_piles_polys %&gt;% dplyr::mutate(diff_diameter_m = image_gt_diameter_m - field_diameter_m) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = image_gt_diameter_m, y = field_diameter_m)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(ggplot2::aes(color = diff_diameter_m)) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(psinf_slash_piles_polys$field_diameter_m,na.rm=T), max(psinf_slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(psinf_slash_piles_polys$field_diameter_m,na.rm=T), max(psinf_slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::labs( x = &quot;image-annotated diameter (m)&quot;, y = &quot;field-collected diameter (m)&quot; , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = &quot;diameter (m) comparison&quot; ) + ggplot2::theme_light() the plot makes these values look very similar with the image-annotated diameter generally larger than the field-collected value. let’s check these using lm() lm_temp &lt;- lm(field_diameter_m ~ image_gt_diameter_m, data = psinf_slash_piles_polys) summary(lm_temp) ## ## Call: ## lm(formula = field_diameter_m ~ image_gt_diameter_m, data = psinf_slash_piles_polys) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.18985 -0.16525 0.01416 0.16807 1.76883 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.13522 0.09891 1.367 0.174 ## image_gt_diameter_m 0.86403 0.02436 35.471 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3593 on 119 degrees of freedom ## (66 observations deleted due to missingness) ## Multiple R-squared: 0.9136, Adjusted R-squared: 0.9129 ## F-statistic: 1258 on 1 and 119 DF, p-value: &lt; 2.2e-16 Our slope of 0.86 is close to 1 and, along with our high R-squared value of 91%, indicate our image- and field-measured diameters are well-calibrated let’s use a paired t-test to determine if the mean difference (MD) between the field-measured diameter and the image-annotated diameter is statistically significant (i.e. significantly different from zero) # is the mean difference between the two diameters significantly different from zero ttest_temp &lt;- t.test( psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) , psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) and psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) ## t = -10.563, df = 120, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -0.4583169 -0.3136208 ## sample estimates: ## mean difference ## -0.3859688 the mean difference (MD) is -0.39 m (field-measured minus image-annotated value). also, the p-value of 0.00001 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where image-annotated diameter is larger than the field-measured diameter is statistically significant and not due to random chance 2.3 RGB orthomosaic Orthomosaic tif files from UAS flight imagery were created in the photogrammetry software (e.g. Agisoft Metashape). Each of our study sites have RGB data available covering the study area extent. We’re going to standardize the raster resolution of these RGB data across study sites. The RGB orthomosaics created from UAS photogrammetry processing generally have very fine resolutions of 4 cm or finer and we will standardize the data to make it slightly more coarse (6 cm) to reduce the computational processing burden. my_rgb_res_m &lt;- 0.06 2.3.1 PSINF Mixed Conifer Site load the original data #### read RGB data keep only RGB psinf_rgb_rast &lt;- terra::rast( file.path( &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , &quot;P4Pro_06_17_2021_half_half_optimal_transparent_mosaic_group1.tif&quot; ) ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(psinf_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(psinf_rgb_rast) ## [1] 0.02632 0.02632 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ## function to change the resolution of RGB change_res_fn &lt;- function( r , my_res=1 , m = &quot;bilinear&quot; # , ofile = tempfile(fileext = &quot;.tif&quot;) , ofile = NULL ){ if(terra::res(r)[1] == my_res){ return(r) }else{ r2 &lt;- r terra::res(r2) &lt;- my_res if(!inherits(ofile,&quot;character&quot;)){ r2 &lt;- terra::resample(r, r2, method = m) }else{ r2 &lt;- terra::resample(r, r2, method = m, filename=ofile, overwrite = T) } return(r2) } } ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/PFDP_Data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;psinf_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- psinf_rgb_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size psinf_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , psinf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... psinf_rgb_rast &lt;- change_res_fn(psinf_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ psinf_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } # terra::res(psinf_rgb_rast) # terra::plotRGB(bhef_rgb_rast, stretch = &quot;lin&quot;) make a function to plot the RGB imagery as a background for ggplot2 plots. ggplot2 offers capabilities to build multi-layered, publication-quality figures by stacking multiple vector overlays on an RGB background. however, it can be computationally expensive since it requires the conversion to a data frame first. # make a function to plot these detected crowns with rgb data ortho_plt_fn &lt;- function(rgb_rast, stand, add_stand = F, buffer = 10, plt_lwd = 1, plt_line_col = &quot;black&quot;){ if(!inherits(rgb_rast,&quot;SpatRaster&quot;)){stop(&quot;rgb_rast must be terra SpatRaster data&quot;)} if(terra::nlyr(rgb_rast)&lt;3){stop(&quot;rgb_rast must have 3 layers with RGB data&quot;)} if(!inherits(stand,&quot;sf&quot;) &amp;&amp; !inherits(stand,&quot;sfc&quot;)){stop(&quot;stand must be sf data&quot;)} # crop crp_rgb_rast_temp &lt;- rgb_rast %&gt;% terra::crop( stand %&gt;% dplyr::ungroup() %&gt;% sf::st_union() %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(buffer) %&gt;% sf::st_transform(terra::crs(rgb_rast)) %&gt;% terra::vect() ) # convert raster to a data frame and create hex colors # ?grDevices::rgb rgb_df_temp &lt;- crp_rgb_rast_temp %&gt;% terra::as.data.frame(xy = TRUE) %&gt;% dplyr::rename( red = 3, green = 4, blue = 5 ) %&gt;% dplyr::mutate( # rows that have missing color data is_missing = is.na(red) | is.na(green) | is.na(blue) # hex using 0s for NAs to avoid grDevices::rgb error , hex_col = grDevices::rgb( ifelse(is_missing, 0, red) , ifelse(is_missing, 0, green) , ifelse(is_missing, 0, blue) , maxColorValue = 255 ) # back to NA , hex_col = ifelse(is_missing, as.character(NA), hex_col) ) %&gt;% dplyr::select(-c(is_missing)) # plt plt &lt;- ggplot2::ggplot() + # add rgb base map ggplot2::geom_tile(data = rgb_df_temp, mapping = ggplot2::aes(x = x, y = y, fill = hex_col), color = NA) + # use identity scale so the hex codes are used directly ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::coord_sf(expand = F) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; ) # add stand if(add_stand){ # overlay polygons plt &lt;- plt + # ggplot2::geom_sf(data = polys, fill = NA, color = &quot;red&quot;, linewidth = 0.5) + ggplot2::geom_sf( data = stand %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% sf::st_transform(terra::crs(rgb_rast)) , fill = NA , color = plt_line_col , lwd = plt_lwd , inherit.aes = F ) } return(plt) } test our plotting function on a zoomed-in portion of the study area ortho_plt_fn( psinf_rgb_rast , psinf_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (blue) terra::plotRGB(psinf_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 2.3.2 TRFO-BLM Pinyon-Juniper Site load the original data #### read RGB data keep only RGB pj_rgb_rast &lt;- terra::rast( # &quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/Ortho/BLM_CO_SWDF_DawsonFuelsTreatment_Ortho_202504.tif&quot; &quot;../data/dawson_data/dawson_rgb.tif&quot; ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(pj_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(pj_rgb_rast) ## [1] 0.025883 0.025883 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/dawson_data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;pj_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- pj_rgb_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size pj_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , pj_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... pj_rgb_rast &lt;- change_res_fn(pj_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ pj_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } test our ggplot2 plotting function on a zoomed-in portion of the study area ortho_plt_fn( pj_rgb_rast , pj_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (blue) terra::plotRGB(pj_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 2.3.3 BHEF Ponderosa Pine Site load the original data. for this site, the orthomosaics are split across multiple files. we’ll read in each, align the resolutions, and use terra::moasaic() to combine ############################################################### # compile RGB raster ############################################################### rgb_dir_temp &lt;- &quot;F:/UAS_Collections/BHEF_202306&quot; # where is the raw las and rgb data? dir_temp &lt;- &quot;../data/BHEF_202306/&quot; # where do you want to save processed data to? rgb_fnm_temp &lt;- file.path(dir_temp,&quot;bhef_rgb.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # read list of orthos ortho_list_temp &lt;- list.files( rgb_dir_temp , pattern = &quot;.*(_RGB|_RBG)\\\\.(tif|tiff)$&quot; , full.names = T, recursive = T ) %&gt;% purrr::map(function(x){terra::rast(x)}) ## apply the change_res_fn ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.04)}) ######## mosaic the raster list bhef_rgb_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works , filename = rgb_fnm_temp , overwrite = T ) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) %&gt;% terra::subset(c(1,2,3)) } # rename bands names(bhef_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(bhef_rgb_rast) ## [1] 0.04 0.04 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/BHEF_202306/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;bhef_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- bhef_rgb_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size bhef_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... bhef_rgb_rast &lt;- change_res_fn(bhef_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (blue) terra::plotRGB(bhef_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 2.3.4 ARNF Ponderosa Pine Site load the original data #### read RGB data keep only RGB arnf_rgb_rast &lt;- terra::rast( &quot;f:/UAS_Collections/ARNF_DiamondView_202510/DiamondPeak_Switchblade_transparent_mosaic_group1.tif&quot; ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(arnf_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(arnf_rgb_rast) ## [1] 0.02101 0.02101 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;arnf_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- arnf_rgb_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size arnf_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... arnf_rgb_rast &lt;- change_res_fn(arnf_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ arnf_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } test our ggplot2 plotting function on a zoomed-in portion of the study area ortho_plt_fn( arnf_rgb_rast , arnf_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (blue) terra::plotRGB(arnf_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 2.4 Slash Pile RGB Imagery let’s look at the RGB imagery and pile locations. we’ll make a panel of plots for each pile at each study site and place a one square meter box in the middle of each pile to distinguish size plt_fn_temp &lt;- function(vect, rgb){ # get vector d &lt;- vect %&gt;% dplyr::slice(1) %&gt;% sf::st_transform(terra::crs(rgb)) # make a box sqm &lt;- d %&gt;% sf::st_centroid() %&gt;% sf::st_buffer( sqrt(1/4) ## numerator = desired plot size in m2 , endCapStyle = &quot;SQUARE&quot; ) %&gt;% dplyr::mutate(dummy=1) # buff buff &lt;- dplyr::case_when( d$image_gt_diameter_m &lt; 4 ~ 4 , d$image_gt_diameter_m &gt; 10 ~ 2.5 , T ~ d$image_gt_diameter_m*(2/3) ) # plt ortho_plt_fn( rgb_rast = rgb , stand = sf::st_union(d, sqm) , buffer = buff , add_stand = F ) + ggplot2::geom_sf(data = sqm, fill = NA, color = &quot;white&quot;, inherit.aes = F) + ggplot2::geom_sf(data = d, fill = NA, lwd = 1, color = &quot;blue&quot;, inherit.aes = F) + ggplot2::labs( subtitle = base::bquote( &quot;pile area: &quot; ~ .(scales::comma(d$image_gt_area_m2, accuracy = 0.1)) ~ m^2 ) ) + ggplot2::theme( plot.subtitle = ggplot2::element_text(hjust = 0.5, size = 7) , plot.title = ggplot2::element_text(hjust = 0.5, size = 8) ) } # plot largest, smallest, and median samp_plt_fn_temp &lt;- function(piles, ortho) { min_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_min(n = 1, order_by = image_gt_area_m2, na_rm = T, with_ties = F) , rgb = ortho ) + ggplot2::labs(title = &quot;smallest&quot;) med_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_min( n = 1 , order_by = abs(image_gt_area_m2 - median(image_gt_area_m2, na.rm = TRUE)) , na_rm = T, with_ties = F ) , rgb = ortho ) + ggplot2::labs(title = &quot;median&quot;) max_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_max(n = 1, order_by = image_gt_area_m2, na_rm = T, with_ties = F) , rgb = ortho ) + ggplot2::labs(title = &quot;largest&quot;) # combine patchwork::wrap_plots( list(min_temp, med_temp, max_temp) , ncol = 3 ) } 2.4.1 PSINF Mixed Conifer Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference psinf_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = psinf_slash_piles_polys, ortho = psinf_rgb_rast) psinf_samp_plt_fn_temp 2.4.2 TRFO-BLM Pinyon-Juniper Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference pj_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = pj_slash_piles_polys, ortho = pj_rgb_rast) pj_samp_plt_fn_temp 2.4.3 BHEF Ponderosa Pine Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference bhef_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = bhef_slash_piles_polys, ortho = bhef_rgb_rast) bhef_samp_plt_fn_temp 2.4.4 ARNF Ponderosa Pine Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference arnf_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = arnf_slash_piles_polys, ortho = arnf_rgb_rast) arnf_samp_plt_fn_temp 2.4.5 All patchwork::wrap_plots( patchwork::wrap_elements( psinf_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;PSINF Mixed Conifer Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( pj_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;TRFO-BLM Pinyon-Juniper Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( bhef_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;BHEF Ponderosa Pine Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( arnf_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;ARNF Ponderosa Pine Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , ncol = 1 ) "],["ptcld_process.html", "Section 3 Point Cloud Processing 3.1 Process Raw Point Cloud 3.2 Clean Up", " Section 3 Point Cloud Processing We’ll use the cloud2trees package to perform all preprocessing of point cloud data which includes: ground classification and noise removal raster data (DTM and CHM) generation point cloud height normalization All of this can be accomplished using the cloud2trees::cloud2raster() function. After generating these products from the raw point cloud we’ll perform object segmentation to attempt to detect slash piles from the CHM which we’ll generate by setting the minimum height to zero (essentially a digital surface model [DSM] with the ground removed). To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation or DBSCAN (Density-Based Spatial Clustering of Applications with Noise), for example. Both of these methods are common in segmenting individual trees and coarse woody debris from CHM data. 3.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data. For each site we’ll generate a fine-resolution (0.1 m) CHM data set which can be aggregated to coarser resolution for sensitivity testing. Fine resolution CHM data would include granular details which may be important for delineating smaller slash piles while more coarse resolution data may help smooth out noise in the data to reduce false positive pile detections and potentially better represent the form of the actual piles # set chm res my_chm_res_m &lt;- 0.1 3.1.1 PSINF Mixed Conifer Site look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/PFDP_Data/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) las_dir_temp &lt;- &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## type : terrestrial ## density : 375.4 points/m² ## num. files : 1 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees psinf_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.25 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.25m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine psinf_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM psinf_cloud2raster_ans$dtm_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM psinf_cloud2raster_ans$chm_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.1.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid. we’ll make some functions to use for the different study areas plt_rast_fn &lt;- function( rn , df , rast , my_title = &quot;&quot; , vopt = &quot;viridis&quot; , lim = NULL , buff = 10 ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(terra::crs(rast)) # convert rast to df comp_st &lt;- rast %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(buff) %&gt;% terra::vect() ) %&gt;% terra::as.data.frame(xy = T) %&gt;% dplyr::rename(f=3) # ggplot comp_temp &lt;- ggplot2::ggplot() + ggplot2::geom_tile(data = comp_st, ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;blue&quot;, lwd = 0.4) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , subtitle = my_title ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) if(!is.null(lim)){ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt, limits = lim) }else{ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt) } plt_temp &lt;- comp_temp return(list(&quot;plt&quot;=plt_temp,&quot;d&quot;=d_temp)) } # plt_rast_fn(rn = 9, df = psinf_slash_piles_polys, rast = psinf_cloud2raster_ans$dtm_rast, vopt = &quot;viridis&quot;) # combine 3 plt_rast_combine &lt;- function( rn , df , dtm_rast , dtm_rast_vopt = &quot;viridis&quot; , chm_rast , chm_rast_vopt = &quot;plasma&quot; , rgb_rast , buffer = 10 ) { # composite 1 ans1 &lt;- plt_rast_fn( rn = rn , df = df , rast = dtm_rast , my_title = &quot;DTM&quot; , vopt = dtm_rast_vopt , buff = buffer ) # composite 2 ans2 &lt;- plt_rast_fn( rn = rn , df = df , rast = chm_rast , my_title = &quot;CHM&quot; , vopt = chm_rast_vopt , buff = buffer ) # plt rgb rgb_temp &lt;- ortho_plt_fn( rgb_rast = rgb_rast , stand =ans1$d , buffer = buffer , add_stand = F ) + ggplot2::geom_sf(data = ans1$d, fill = NA, color = &quot;blue&quot;, lwd = 0.3) # combine r &lt;- patchwork::wrap_plots(list(rgb_temp,ans1$plt,ans2$plt), nrow = 1) return(r) } # plt_rast_combine( # rn = 11 # , df = psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) # , dtm_rast = psinf_cloud2raster_ans$dtm_rast # , chm_rast = psinf_cloud2raster_ans$chm_rast # , rgb_rast = psinf_rgb_rast # ) use this handy plotting function for some piles # add pile locations plt_list_rast_temp &lt;- 1:sum(psinf_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(psinf_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = psinf_cloud2raster_ans$dtm_rast , chm_rast = psinf_cloud2raster_ans$chm_rast , rgb_rast = psinf_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) a few things are noteworthy in these examples: Piles are clearly visible in some areas of the DTM but less visible in other areas Piles are delineated in the CHM but with varying degrees of definition based on surrounding terrain and pile structure The DTM and CHM were rarely impacted by shadows in the RGB imagery It is interesting to see coarse woody debris occasionally visible in the CHM 3.1.2 TRFO-BLM Pinyon-Juniper Site for this site, the full point cloud data we have covers a much larger extent than the treatment unit used for this study. we will therefore crop point cloud to a buffered area of interest so that we limit the amount of data processed ############################################################### # read/crop point cloud ############################################################### # output dir for clipped las las_dir_temp &lt;- &quot;../data/Dawson_Data/point_cloud&quot; if(!dir.exists(las_dir_temp)){dir.create(las_dir_temp, showWarnings = F)} # do it if not already done if(dplyr::coalesce(length(list.files(las_dir_temp)),0)&lt;1){ # this reads the metadata from all files in the folder, not the points themselves. las_ctg_temp &lt;- lidR::readLAScatalog(&quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/PointCloud/Tiles/&quot;) las_ctg_temp cloud2trees:::check_las_ctg_empty(las_ctg_temp) # set ctg opts lidR::opt_select(las_ctg_temp) &lt;- &quot;xyzainrcRGBNC&quot; lidR::opt_progress(las_ctg_temp) &lt;- T # write generated results to disk storage rather than keeping everything in memory. This option can be activated with opt_output_files() lidR::opt_output_files(las_ctg_temp) &lt;- paste0(normalizePath(las_dir_temp),&quot;/&quot;, &quot;_{XLEFT}_{YBOTTOM}&quot;) # label outputs based on coordinates lidR::opt_filter(las_ctg_temp) &lt;- &quot;-drop_duplicates&quot; # clip the point cloud using the polygon and write to a new file # the lidR::opt_output_files is key to writing the output to disk without loading the entire clipped result into memory. clip_las_ctg_temp &lt;- lidR::clip_roi( las = las_ctg_temp , geometry = pj_stand_boundary %&gt;% sf::st_buffer(100) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% sf::st_transform(sf::st_crs(las_ctg_temp)) ) }else{ clip_las_ctg_temp &lt;- lidR::readLAScatalog(las_dir_temp) } # clip_las_ctg_temp # clip_las_ctg_temp$filename look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/Dawson_Data/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) # las_dir_temp &lt;- las_dir_temp # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 2) ## extent : 707813.6, 708409.9, 4193155, 4193638 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83(2011) / UTM zone 12N ## area : 288106.3 m² ## points : 163.84 million points ## type : terrestrial ## density : 568.7 points/m² ## density : 568.7 pulses/m² ## num. files : 1 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees pj_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine pj_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM pj_cloud2raster_ans$dtm_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( pj_stand_boundary %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM pj_cloud2raster_ans$chm_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( pj_stand_boundary %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.2.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(pj_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(pj_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = pj_cloud2raster_ans$dtm_rast , chm_rast = pj_cloud2raster_ans$chm_rast , rgb_rast = pj_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.1.3 BHEF Ponderosa Pine Site for this site, the point cloud files are dispersed across different folders. so, we’ll manually specify which files to use. look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/BHEF_202306/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) # las_dir_temp &lt;- &quot;where/are/the/pointcloud&quot; las_flist_temp &lt;- c( &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit1and3Processing.files/BHEF_202306_Unit1and3_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit2Processing.files/BHEF_202306_Unit2_laz.laz&quot; , list.files( &quot;F:\\\\UAS_Collections\\\\BHEF_202306\\\\00good_simplified_point_clouds_reduced_overlap&quot; , pattern = &quot;.*\\\\.(laz|las)$&quot; , full.names = TRUE, recursive = T ) ) # read header with catalog lidR::readLAScatalog(las_flist_temp) ## class : LAScatalog (v1.2 format 2) ## extent : 608234, 610968.2, 4888216, 4889418 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83 / UTM zone 13N ## area : 3.48 km² ## points : 1.42 billion points ## type : airborne ## density : 408 points/m² ## density : 408 pulses/m² ## num. files : 7 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees bhef_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_flist_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine bhef_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM bhef_cloud2raster_ans$dtm_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM bhef_cloud2raster_ans$chm_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.3.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(bhef_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(bhef_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = bhef_cloud2raster_ans$dtm_rast , chm_rast = bhef_cloud2raster_ans$chm_rast , rgb_rast = bhef_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.1.4 ARNF Ponderosa Pine Site look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; # where do you want to save processed data to? out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) las_dir_temp &lt;- &quot;F:/UAS_Collections/ARNF_DiamondView_202510/point_cloud_high_density&quot; # where is the raw las # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 455073.8, 456582.3, 4535127, 4536067 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1.24 km² ## points : 1.37 billion points ## type : airborne ## density : 1102.8 points/m² ## density : 39.9 pulses/m² ## num. files : 44 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees arnf_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine arnf_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM arnf_cloud2raster_ans$dtm_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM arnf_cloud2raster_ans$chm_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.4.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(arnf_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(arnf_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = arnf_cloud2raster_ans$dtm_rast , chm_rast = arnf_cloud2raster_ans$chm_rast , rgb_rast = arnf_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.2 Clean Up going forward, we only need the CHM data, so we can drop the DTM data from our session "],["geom_detect.html", "Section 4 Geometry-based Slash Pile Detection 4.1 Demonstration Area 4.2 Segmentation Methods 4.3 Candidate Shape Refinement and Area filtering 4.4 Candidate Geometric filtering 4.5 Structural Metrics from CHM 4.6 Final Shape Refinement 4.7 Pile Detection Function", " Section 4 Geometry-based Slash Pile Detection In this section, we will demonstrate the geometry-based slash pile detection method which relies upon user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-DAP point cloud data. Since this is only a demonstration of the method, we will work with only a sample area from one of the study sites which we know includes slash piles. Full evaluation of the methodology will be performed later in the analysis. We’ll attempt to detect slash piles using raster-based methods with the CHM. These raster-based approaches are simple and efficient but rasterization simplifies/removes some of the rich 3D information in the point cloud. However, raster-based approaches for detecting individual trees in forest stands and coarse woody debris are common. Here is a section from the draft manuscript: These geometry-based approaches are supported by the demonstrated successes of object segmentation frameworks for both CWD and individual trees, which consistently provide high detection and quantification accuracy by utilizing rules to define expected target object morphology. Beyond their technical performance, the geometry-based methods utilizing a set of rules offer some key advantages. The inherent traceability of these methods ensures that reporting for regulatory oversight is more transparent and easier to describe compared to the “black box” nature of many model-based approaches. Geometry-based frameworks also do not rely on training datasets and can directly align with the explicit pile construction parameters which are generally known by land managers through silvicultural prescriptions. To address the current lack of automated methods for simultaneously detecting and quantifying slash piles from aerial remote sensing data, our objective in this work is to present a geometry-based approach that uses rules and user-defined thresholds applied to geometric features (such as area, shape, and height) to identify and quantify slash piles from UAS-DAP point cloud data. Geometric, rules-based object detection methods offer advantages over model-based approaches, primarily because they eliminate the need for extensive training data which might be limited in it’s transferability to unseen conditions. Models are often considered “black boxes” but rules-based methods rely on the inherent physical properties of the target objects themselves. This transparency allows for a high degree of interpretability as every segmentation result can be traced back to specific geometric constraints. Furthermore, this approach aligns perfectly with the expertise of land managers, as the input parameters like minimum height and area thresholds are the physical metrics commonly used in forest inventories and silvicultural prescriptions. By using these intuitive thresholds, the method becomes accessible to managers who possess a good understanding of the landscape they manage. To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation or DBSCAN (Density-Based Spatial Clustering of Applications with Noise). Both of these methods are common in segmenting individual trees and coarse woody debris from CHM data. 4.1 Demonstration Area we’ll focus on an example area that is outside of the study unit boundary but was captured in our UAS data acquisition of the area. This demonstration area also included slash piles which were annotated in the same manner as previously described but did not have height and diameter measurements taken in the field. # boundary aoi_boundary &lt;- psinf_slash_piles_polys %&gt;% dplyr::filter( !is_in_stand &amp; pile_id %in% c(53,52,63,20,17,11,6) ) %&gt;% sf::st_union() %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(1.3, joinStyle = &quot;MITRE&quot;) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(dummy=1) # psinf_slash_piles_polys %&gt;% # # dplyr::filter(pile_id == 195) %&gt;% # machine # # dplyr::filter(pile_id == 74) %&gt;% # hand # dplyr::filter(pile_id == 71) %&gt;% # hand # # arnf_slash_piles_polys %&gt;% # # dplyr::filter(pile_id == 14) %&gt;% # sf::st_centroid() %&gt;% # sf::st_buffer( # # sqrt(9600/4) ## numerator = desired plot size in m2 # sqrt(4500/4) ## numerator = desired plot size in m2 # , endCapStyle = &quot;SQUARE&quot; # ) %&gt;% # dplyr::mutate(dummy=1) we cropped this section from our original RGB processing, so we’ll get it now dir_temp &lt;- &quot;../data/PFDP_Data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;aoi_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ #### read RGB data keep only RGB aoi_rgb_rast &lt;- terra::rast( file.path( &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , &quot;P4Pro_06_17_2021_half_half_optimal_transparent_mosaic_group1.tif&quot; ) ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(aoi_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(4) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... aoi_rgb_rast &lt;- change_res_fn(crop_rgb_rast_temp, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) aoi_rgb_rast &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T ) }else{ aoi_rgb_rast &lt;- terra::rast(rgb_fnm_temp) aoi_rgb_rast &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T ) } # terra::res(aoi_rgb_rast) # terra::plotRGB(aoi_rgb_rast, stretch = &quot;lin&quot;) we cropped this section from our original CHM processing, so we’ll get it now dir_temp &lt;- &quot;../data/PFDP_Data/&quot; chm_fnm_temp &lt;- file.path(dir_temp,&quot;aoi_chm_rast.tif&quot;) # what should the compiled chm be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(chm_fnm_temp)){ #### read CHM aoi_chm_rast &lt;- terra::rast( file.path( dir_temp , &quot;point_cloud_processing_delivery_chm0.1m&quot; , &quot;chm_0.1m.tif&quot; ) ) %&gt;% terra::subset(1) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(4) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T , filename = chm_fnm_temp , overwrite = TRUE ) aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T ) }else{ aoi_chm_rast &lt;- terra::rast(chm_fnm_temp) aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T ) } # terra::res(aoi_chm_rast) # terra::plot(aoi_chm_rast) get the piles that intersect with our AOI boundary # piles aoi_slash_piles_polys &lt;- psinf_slash_piles_polys %&gt;% dplyr::inner_join( psinf_slash_piles_polys %&gt;% sf::st_intersection(aoi_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) , by = &quot;pile_id&quot; ) # aoi_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(is_in_stand) # ggplot base aoi_plt_ortho &lt;- ortho_plt_fn(rgb_rast = aoi_rgb_rast, stand = aoi_boundary, buffer = 3) # aoi_plt_ortho look at the demonstration area (plots using ggplot2 for maximum customization) here is the CHM of the example area. can you pick out the slash piles? plt_aoi_chm &lt;- function(chm) { chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(mapping = ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;) + ggplot2::labs(fill = &quot;CHM (m)&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) } plt_aoi_chm(aoi_chm_rast) here is the RGB of the example area. can you pick out the slash piles? aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) we’ll add on the ground truth piles in blue on the RGB. how many did you find? be honest. aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) would you have done better if you had both the CHM and RGB data? plt_aoi_chm_rgb &lt;- function(chm) { aoi_plt_ortho + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.4 , inherit.aes = F ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;) + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::theme(legend.position = &quot;none&quot;) } plt_aoi_chm_rgb(aoi_chm_rast) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) 4.2 Segmentation Methods Our slash pile detection approach will align with the land manager knowledge of physical metrics of slash pile form which are commonly used in forest inventories and silvicultural prescriptions. We’ll start with input parameters like height and area thresholds. the first step in this approach is to isolate the lower “slice” of the CHM based on a maximum height threshold defined by the upper limit of the expected slash pile height. the expected height range to search for slash piles should be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion we’ll set a maximum height threshold (max_ht_m) which filters the CHM to only include raster cells lower than this threshold. we’ll also set a lower height limit (min_ht_m) based on the expected slash pile height for use later in removing candidate segments that are shorter than this lower limit. # set the max and min expected pile height max_ht_m &lt;- 4 min_ht_m &lt;- 0.5 # lower CHM slice aoi_chm_rast_slice &lt;- terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F) plot the lower slice, notice how the CHM height scale has changed plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) already, it looks like the piles should be distinguishable objects from this data our rules-based pile detection methodology will also rely on area thresholds to define a search space and filter candidate segments. like height, we’ll also set a minimum (min_area_m2) and maximum (max_area_m2) pile 2D area (in square meters) to search and filter for valid candidate objects. As with the height, these thresholds should be set based on the pile construction prescription or estimates or sample measurements from field visits. # set the max and min expected pile area min_area_m2 &lt;- 2 # Two standard US parking spaces, typically measuring 9 feet by 18 feet, # are roughly equivalent to 30.25 square meters. Each space is approximately 15.125 square meters. # 15.125*3 max_area_m2 &lt;- 50 to summarize, the size-based thresholds of our geometric, rules-based approach for detecting slash piles from CHM data are: max_ht_m : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific “slice” of the data, ignoring anything taller than a typical pile. min_ht_m : numeric. The minimum height (in meters) a detected pile must reach to be considered valid. min_area_m2 : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid. max_area_m2 : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid. 4.2.1 Overview of Methods The two primary segmentation methods we’ll test are watershed segmentation and DBSCAN. Watershed segmentation, which we’ll implement with lidR::watershed(), is a raster-based technique that treats a CHM as a topographic surface where height values are inverted to create basins. The algorithm identifies local maxima as “seeds” and expands them until they reach a boundary or “watershed” line. This method requires a tolerance parameter (tol) which defines “the minimum height of the object…between its highest point (seed) and the point where it contacts another object…If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. Tolerance should be chosen according to the range of x.” An extent parameter (ext) is used to define the search window for object seeds. The DBSCAN algorithm, which we’ll implement with dbscan::dbscan(), is typically a point-based clustering algorithm that groups points based on their spatial density but DBSCAN can also be applied to raster data by converting the raster cells into a 2D point set using the cell centroids. The algorithm relies on an epsilon parameter (eps), which defines the search radius around a point, and a minimum points parameter (minPts), which sets the threshold for how many neighbors must exist within that radius to form a core cluster. Dynamically defining these parameters is critical for the usability and scalability of the method because it removes the guesswork typically required when moving between different datasets. For example, point clouds can vary in point density depending on the flight altitude or sensor, and rasters can vary in resolution. If parameters are kept static, a model tuned for a specific data structure or target object will be suboptimal for different data. We can link the segmentation algorithm parameters directly to the input data structure and the expected target object size so that the method automatically recalibrates itself. In applying a similar, rules-based methodology for coarse woody debris detection from point cloud data, dos Santos et al. (2025) recommend setting algorithm parameters based on minimum expected object size to be detected and point density. We developed dynamic logic to automatically bridge the gap between the expectation of the target object form (height and area thresholds) and the representation of the object in the data by using geometric ratios. For watershed segmentation, the tolerance (tol) is scaled to the height range of the target objects to ensure sensitivity to the vertical variability. The extent (ext) is calculated by converting the physical radius of the smallest expected object into a pixel count based on the raster resolution. For DBSCAN, the epsilon parameter (eps) is calculated to bridge the average gap between points (or the distance between raster cell centroids) but is capped to prevent the merging of adjacent objects. The minimum points (minPts) parameter is scaled by the ratio of the search area (eps) to the total object area, ensuring that a cluster only forms if the local point density is representative of a valid target object. Method Parameter Parameter Description Our Dynamic Logic (R-style pseudo-code) Logic Explanation Why our dynamic logic works Watershed tol Minimum height difference to distinguish objects. (max_ht_m - min_ht_m) * 0.50 Sets the vertical threshold at 50% of the target’s defined Z search space. Prevents over-segmentation by requiring vertical “valleys” to be significant relative to the target’s height. Watershed ext Radius of the search window for detecting seeds. max(1, round((target_radius_m * 0.5) / rast_res_m)) Uses 50% of the target radius as the search window, converted to pixels with a 1-pixel minimum. Maintains a consistent physical search area regardless of raster resolution, ensuring seeds are centered on objects. DBSCAN eps Maximum distance to consider points as neighbors. min(1.5 * (1/sqrt(pts_per_m2)), (target_radius_m * 0.5 * 0.5)) Selects the smaller of 1.5-times the point spacing or 50% of the effective radius (25% of target radius). Ensures the point-search stays localized, effectively preventing separate objects from “bridging” together. DBSCAN minPts Minimum points required to form a cluster core. round((min_area_m2 * pts_per_m2) * (eps^2 / (target_radius_m^2))) Scales total expected points by the ratio of the search circle area to the total target area. Dynamically adjusts the density threshold based on the search radius, allowing for consistent detection across varying data densities. let’s define a function to get these parameters based on the user-defined size thresholds and the input data description # function to get segmentation parameters get_segmentation_params &lt;- function( min_ht_m , max_ht_m , min_area_m2 , max_area_m2 , pts_per_m2 = NULL , rast_res_m = NULL ){ # check for missing required values if (missing(max_ht_m) || missing(min_ht_m) || missing(min_area_m2) || missing(max_area_m2)) { stop(&quot;all geometric constraints (max_ht_m, min_ht_m, min_area_m2, max_area_m2) must be defined.&quot;) } # geometric param validation if (max_ht_m &lt;= min_ht_m) { stop(&quot;max_ht_m must be greater than min_ht_m.&quot;) } if (max_area_m2 &lt;= min_area_m2) { stop(&quot;max_area_m2 must be greater than min_area_m2.&quot;) } if (min_ht_m &lt; 0 || min_area_m2 &lt; 0) { stop(&quot;height and area constraints must be positive values.&quot;) } # data structure validation and calculation if (is.null(pts_per_m2) &amp;&amp; is.null(rast_res_m)) { stop(&quot;must provide either &#39;pts_per_m2&#39; (pts/m2) or &#39;rast_res_m&#39; (m/pixel).&quot;) } # calculate and validate data str values if (is.null(pts_per_m2)) { if (rast_res_m &lt;= 0) stop(&quot;rast_res_m must be a positive value.&quot;) pts_per_m2 &lt;- 1 / (rast_res_m^2) } if (is.null(rast_res_m)) { if (pts_per_m2 &lt;= 0) stop(&quot;pts_per_m2 must be a positive value.&quot;) rast_res_m &lt;- 1 / sqrt(pts_per_m2) } ################################################ # lidR::watershed / EBImage::watershed ################################################ # lidR::watershed `tol` # set based on the height range height_range &lt;- max_ht_m - min_ht_m # scale it to increase the sensitivity to distinguish smaller objects tol_val &lt;- height_range * 0.5 # lidR::watershed `ext` # use half the radius of the minimum object to increase sensitivity # this helps prevent merging nearby objects (under-segmentation) target_radius_m &lt;- sqrt(min_area_m2 / pi) effective_radius_m &lt;- target_radius_m * 0.5 ext_val &lt;- max(1, round(effective_radius_m / rast_res_m)) ################################################ # dbscan::dbscan ################################################ # dbscan::dbscan `eps` (epsilon) # [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) recommended to set this value based: # &quot;on the minimum cluster size to be detected and point density&quot; # start by scaling based on point spacing (1.5x average distance between points). spacing &lt;- 1 / sqrt(pts_per_m2) connectivity_eps &lt;- 1.5 * spacing # eps should not exceed 50% of the minimum object radius # to avoid merging separate objects into one cluster. max_allowable_eps &lt;- effective_radius_m * 0.5 # cap eps by the object size constraint eps_val &lt;- min(connectivity_eps, max_allowable_eps) # dbscan::dbscan `minPts` # based on expected points within the epsilon neighborhood area # get expected number of points in an object of min_area_m2 expected_pts_in_min_object &lt;- min_area_m2 * pts_per_m2 # ensure a core point is surrounded by a density of points based on min_area_m2 size at point density # scale the total expected points of the minimum object # by the ratio of the epsilon-neighborhood area to the total minimum object area # to ensure a core point meets the expected density of the target object pts_ratio_calc &lt;- expected_pts_in_min_object * (eps_val^2 / target_radius_m^2) min_pts_val &lt;- max( 5 # don&#39;t go any lower than the dbscan::dbscan() default , round(pts_ratio_calc) ) # return return(list( data_summary = list(pts_per_m2 = pts_per_m2, rast_res_m = rast_res_m), watershed = list(tol = tol_val, ext = ext_val), dbscan = list(eps = eps_val, minPts = min_pts_val) )) } let’s test our get_segmentation_params() function using the size threshold parameters we defined above: max_ht_m, min_ht_m, min_area_m2, max_area_m2 and we can get the raster resolution directly from our input CHM # get_segmentation_params get_segmentation_params_ans &lt;- get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(aoi_chm_rast_slice)[1] ) # huh? dplyr::glimpse(get_segmentation_params_ans) ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 100 ## ..$ rast_res_m: num 0.1 ## $ watershed :List of 2 ## ..$ tol: num 1.75 ## ..$ ext: num 4 ## $ dbscan :List of 2 ## ..$ eps : num 0.15 ## ..$ minPts: num 7 we can see how these parameters change if the CHM resolution changes get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = 0.5 ) %&gt;% dplyr::glimpse() ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 4 ## ..$ rast_res_m: num 0.5 ## $ watershed :List of 2 ## ..$ tol: num 1.75 ## ..$ ext: num 1 ## $ dbscan :List of 2 ## ..$ eps : num 0.199 ## ..$ minPts: num 5 and we can see how these parameters change using our CHM data but change the expected minimum pile 2D area get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = 22 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(aoi_chm_rast_slice)[1] ) %&gt;% dplyr::glimpse() ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 100 ## ..$ rast_res_m: num 0.1 ## $ watershed :List of 2 ## ..$ tol: num 1.75 ## ..$ ext: num 13 ## $ dbscan :List of 2 ## ..$ eps : num 0.15 ## ..$ minPts: num 7 the table summarizes how our rules-based approach creates dynamic parameters for use in watershed and DBSCAN segmentation. The height parameters manage vertical noise, the area parameters manage horizontal separation, and the data resolution parameters ensure the math stays consistent regardless of data density (raster resolution or point cloud point density). Dynamic Parameter Impact of Height (max_ht_m / min_ht_m) Impact of Target Area (min_area_m2) Impact of Data Structure (rast_res_m / pts_per_m2) Watershed tol Direct Driver: Sets the vertical threshold at 50% of the target’s defined Z search space. None: Vertical tolerance is independent of horizontal footprint. None: Vertical sensitivity is independent of horizontal resolution. Watershed ext None: Horizontal search window is independent of vertical range. Geometric Baseline: Defines the physical radius used to scale the search window at a 1:2 ratio. Spatial Divider: Converts the physical radius into a pixel count using rast_res_m with a 1-pixel minimum. DBSCAN eps None: Point-to-point connectivity is independent of height. Physical Cap: Limits search distance to 50% of the effective radius (25% of target radius) to ensure separation. Connectivity Anchor: Sets the search radius at 1.5-times the spacing derived from pts_per_m2 to maintain tight clusters. DBSCAN minPts None: Required point mass is independent of vertical range. Total Mass Baseline: Defines the total expected points for the smallest valid target. Density Multiplier: Calculates the local point count requirement relative to the pts_per_m2 value. sim_df_temp &lt;- tidyr::crossing( rast_res_m = seq(0.1, 1.3, by = 0.1) , min_area_m2 = seq(1, 50, length.out = 33) ) %&gt;% dplyr::mutate( # Call the pre-defined function directly to ensure logic alignment params = purrr::map2( rast_res_m, min_area_m2, ~ get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = .y , max_area_m2 = .y * 5 , rast_res_m = .x ) ) # Extract values into individual columns for plotting , ext = purrr::map_dbl(params, ~ .x$watershed$ext) , eps = purrr::map_dbl(params, ~ .x$dbscan$eps) , min_pts = purrr::map_dbl(params, ~ .x$dbscan$minPts) ) # # Pivot to long format for faceted plotting # tidyr::pivot_longer( # cols = c(ext, eps, min_pts), # names_to = &quot;parameter&quot;, # values_to = &quot;value&quot; # ) # sim_df_temp %&gt;% dplyr::glimpse() # plot p1_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = ext)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;Watershed: `ext` (pixels)&quot;, fill = &quot;pixels&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) p2_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = eps)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;DBSCAN: `eps` (meters)&quot;, fill = &quot;meters&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) p3_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = min_pts)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;DBSCAN: `minPts` (count)&quot;, fill = &quot;count&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) # 5. Combine using patchwork (p1_temp + p2_temp + p3_temp) + patchwork::plot_annotation( title = &quot;Dynamic Watershed and DBSCAN Parameter Definition&quot; , subtitle = &quot;across raster resolution and minimum target area gradients&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10),plot.subtitle = ggplot2::element_text(size = 8)) ) + patchwork::plot_layout(ncol = 3) 4.2.2 Watershed Segmentation Demonstration let’s go through the watershed segmentation process using lidR::watershed() which is based on the bioconductor package EBIimage # ?EBImage::watershed watershed_segs &lt;- lidR::watershed( chm = aoi_chm_rast_slice # th_tree = Threshold below which a pixel cannot be a tree. Default is 2. , th_tree = 0.01 # tol = minimum height of the object in the units of image intensity between its highest point (seed) # and the point where it contacts another object (checked for every contact pixel). # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. # Tolerance should be chosen according to the range of x , tol = get_segmentation_params_ans$watershed$tol # max_ht_m-min_ht_m # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. # Higher value smoothes out small objects. , ext = get_segmentation_params_ans$watershed$ext # 1 )() the result is a raster with cells segmented and given a unique identifier # this is a raster watershed_segs ## class : SpatRaster ## size : 1237, 768, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 499310.2, 499387, 4317735, 4317858 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## varname : aoi_chm_rast ## name : focal_mean ## min value : 1 ## max value : 105 each value should be a unique “segment” which we can refine based on rules of expected size and shape of piles terra::freq(watershed_segs) %&gt;% dplyr::slice_sample(n = 10) ## layer value count ## 1 1 43 8 ## 2 1 72 45 ## 3 1 44 9 ## 4 1 84 112 ## 5 1 29 2303 ## 6 1 7 80 ## 7 1 60 1539 ## 8 1 42 4 ## 9 1 48 576 ## 10 1 91 64 where the “value” is the segment identifier and the count is the number of raster cells assigned to that segment how many predicted segments are there? terra::freq(watershed_segs) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() ## [1] 105 let’s plot the raster return from the watershed segmentation watershed_segs %&gt;% terra::as.factor() %&gt;% terra::plot( col = c( viridis::turbo(n = terra::minmax(watershed_segs)[2]) # , viridis::viridis(n = floor(terra::minmax(watershed_segs)[2]/3)) # , viridis::cividis(n = floor(terra::minmax(watershed_segs)[2]/3)) ) %&gt;% sample() , legend = F , axes = F ) plot the watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice…we are getting close. 4.2.3 DBSCAN Segmentation Demonstration let’s go through the DBSCAN segmentation process using dbscan::dbscan() which uses a kd-tree for efficient processing. As an aside, the RANN package enables KD-tree searching/processing using the X and Y coordinates of the entire point cloud to build the tree which is a super-fast way to find the x number of near neighbors for each point in an input dataset (see RANN::nn2()). because the DBSCAN process is a point-based clustering algorithm that groups points based on their spatial density we need to convert the raster cells into a 2D point set using the cell centroids first ## XY df xy_df_temp &lt;- aoi_chm_rast_slice %&gt;% # na.rm = T ensures we only process cells with CHM data terra::as.data.frame(xy = T, na.rm = T) %&gt;% dplyr::rename( X=x,Y=y , f=3 ) %&gt;% dplyr::select(X,Y) # huh? xy_df_temp %&gt;% dplyr::glimpse() ## Rows: 20,669 ## Columns: 2 ## $ X &lt;dbl&gt; 499330.2, 499330.4, 499330.5, 499330.2, 499330.4, 499330.5, 499330.2… ## $ Y &lt;dbl&gt; 4317856, 4317856, 4317856, 4317856, 4317856, 4317856, 4317856, 43178… # ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=&quot;.&quot;) now, we can apply the dbscan::dbscan() function using the parameters we identified using our dynamic process defined in get_segmentation_params() # get_segmentation_params_ans %&gt;% dplyr::glimpse() # ?dbscan::dbscan dbscan_ans_temp &lt;- dbscan::dbscan( x = xy_df_temp # eps primarily controls the spatial extent of a cluster, # as it defines how far points can be from each other to be considered part of the same dense region. , eps = get_segmentation_params_ans$dbscan$eps # minPts primarily controls the minimum density of a cluster, # as it dictates how many points must be packed together within that eps radius. , minPts = get_segmentation_params_ans$dbscan$minPts ) # huh? dbscan_ans_temp %&gt;% str() ## List of 5 ## $ cluster : int [1:20669] 1 1 1 1 1 1 1 1 1 2 ... ## $ eps : num 0.15 ## $ minPts : num 7 ## $ metric : chr &quot;euclidean&quot; ## $ borderPoints: logi TRUE ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;dbscan_fast&quot; &quot;dbscan&quot; the result is a vector with a cluster identifier for each point we provided to the algorithm identical( length(dbscan_ans_temp$cluster) , nrow(xy_df_temp) ) ## [1] TRUE add the cluster identifier to the XY point data # add the cluster to the data xy_df_temp$cluster &lt;- dbscan_ans_temp$cluster # what? xy_df_temp %&gt;% dplyr::count(cluster) %&gt;% dplyr::arrange(desc(n)) %&gt;% head() ## cluster n ## 1 87 2398 ## 2 100 2303 ## 3 101 1821 ## 4 93 1754 ## 5 92 1539 ## 6 3 775 to maintain processing consistency with the watershed result, we’ll rasterize the XY data back to the original CHM grid. this will result in a raster with cells segmented and given the unique identifier. Note: the cells/segments classified as noise from the dbscan::dbscan() algorithm are marked with a cluster identifier as “0”…we’ll remove these prior to rasterizing # fill the rast with the cluster values dbscan_segs &lt;- terra::rasterize( x = xy_df_temp %&gt;% dplyr::filter(cluster!=0) %&gt;% sf::st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;), crs = terra::crs(aoi_chm_rast_slice), remove = F) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(cluster) %&gt;% terra::vect() , y = aoi_chm_rast_slice , field = &quot;cluster&quot; ) the result is a raster with cells segmented and given a unique identifier # this is a raster dbscan_segs ## class : SpatRaster ## size : 1237, 768, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 499310.2, 499387, 4317735, 4317858 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## varname : aoi_chm_rast ## name : last ## min value : 1 ## max value : 108 each value should be a unique “segment” which we can refine based on rules of expected size and shape of piles terra::freq(dbscan_segs) %&gt;% dplyr::arrange(desc(count)) %&gt;% head() ## layer value count ## 1 1 87 2398 ## 2 1 100 2303 ## 3 1 101 1821 ## 4 1 93 1754 ## 5 1 92 1539 ## 6 1 3 775 where the “value” is the segment identifier and the count is the number of raster cells assigned to that segment (compare to the count of the segmented points above ;) how many predicted segments are there? terra::freq(dbscan_segs) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() ## [1] 108 let’s plot the raster of the dbscan segmentation dbscan_segs %&gt;% terra::as.factor() %&gt;% terra::plot( col = c( viridis::turbo(n = terra::minmax(dbscan_segs)[2]) ) %&gt;% sample() , legend = F , axes = F ) plot the watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice…we are getting close. 4.2.4 Comparison of Candidate Segments we’ll start by converting the candidate segments to polygons # watershed_segs watershed_segs_poly &lt;- watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs dbscan_segs_poly &lt;- dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) count the number of unique candidate segments from each method and summarize the area covered by all segments dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments = scales::comma(segments,accuracy=1) , area = scales::comma(area,accuracy=0.01) ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&quot; , col.names = c( &quot;method&quot;, &quot;candidate segments&quot;, &quot;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.1: Demonstration area candidate segments by method method candidate segments area (m2) watershed 105 206.69 DBSCAN 108 205.81 notice the dbscan segments cover a smaller area because noise points are identified and removed as part of the algorithm. in the next stage of our method, we’ll include additional noise removal applied to both methodologies. In fact, all processing will be the same from here forward for both segementation methodologies. 4.2.5 Segmentation Function let’s make a function to perform either the watershed (lidR::watershed()) or DBSCAN (dbscan::dbscan()) segmentation given an input CHM raster, target height range, and target area range. the output will include a raster and sf polygons of the candidate segments ############################################################################ # DBSCAN function # to align input of raster and output of raster as in lidR::watershed() # this enables dbscan, typically a point-based method, # to be implemented with raster input data by using cell centroids ############################################################################ get_segs_dbscan &lt;- function( chm_rast , eps , minPts ) { ######################## # check raster ######################## # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } # first layer only if(terra::nlyr(chm_rast)&gt;1){warning(&quot;...only using first layer of raster stack for segmentation&quot;)} chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) # na check if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } ######################## # get cell centroids as points ######################## ## XY df xy_df_temp &lt;- chm_rast %&gt;% # na.rm = T ensures we only process cells with CHM data terra::as.data.frame(xy = T, na.rm = T) %&gt;% dplyr::rename( X=x,Y=y , f=3 ) %&gt;% dplyr::select(X,Y) # huh? # xy_df_temp %&gt;% dplyr::glimpse() # ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=&quot;.&quot;) if(nrow(xy_df_temp)==0){stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;)} ######################## # dbscan::dbscan() ######################## # ?dbscan::dbscan dbscan_ans_temp &lt;- dbscan::dbscan( x = xy_df_temp # eps primarily controls the spatial extent of a cluster, # as it defines how far points can be from each other to be considered part of the same dense region. , eps = eps # minPts primarily controls the minimum density of a cluster, # as it dictates how many points must be packed together within that eps radius. , minPts = minPts ) # ensure the result is a vector with a `cluster` identifier for each point we provided to the algorithm if( !identical( length(dbscan_ans_temp$cluster) , nrow(xy_df_temp) ) ){ stop(&quot;dbscan::dbscan() length mismatch&quot;) } # add the cluster identifier to the XY point data xy_df_temp$cluster &lt;- dbscan_ans_temp$cluster # # what? # xy_df_temp %&gt;% # dplyr::count(cluster) %&gt;% # dplyr::arrange(desc(n)) %&gt;% # head() if( nrow( xy_df_temp %&gt;% dplyr::filter(cluster!=0) ) == 0 ){ stop(&quot;dbscan::dbscan() result is all noise based on &#39;eps&#39; and &#39;minPts&#39;. try adjusting these parameters.&quot;) } ######################## # back to raster data ######################## # to maintain processing consistency with the watershed result # we&#39;ll rasterize the XY data back to the original CHM grid # this will result in a raster with cells segmented and given the unique identifier. # *Note*: the cells/segments classified as noise from the `dbscan::dbscan()` # algorithm are marked with a cluster identifier as &quot;0&quot;...we&#39;ll remove these prior to rasterizing # fill the rast with the cluster values dbscan_segs &lt;- terra::rasterize( x = xy_df_temp %&gt;% dplyr::filter(cluster!=0) %&gt;% sf::st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;), crs = terra::crs(chm_rast), remove = F) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(cluster) %&gt;% terra::vect() , y = chm_rast , field = &quot;cluster&quot; ) %&gt;% setNames(&quot;cluster&quot;) # the result is a raster with cells segmented and given a unique identifier # this is a raster # dbscan_segs return(dbscan_segs) } # # ?dbscan::dbscan # get_segs_dbscan(aoi_chm_rast_slice, minPts = 5, eps = 1) %&gt;% # terra::as.factor() %&gt;% # terra::plot(legend = F, col = grDevices::rainbow(n=111) %&gt;% sample() ) ############################################################################ # intermediate function to check string method ############################################################################ # check the `method` argument check_segmentation_method &lt;- function(method) { if(!inherits(method,&quot;character&quot;)){stop(&quot;no method&quot;)} # clean method method &lt;- dplyr::coalesce(method, &quot;&quot;) %&gt;% tolower() %&gt;% stringr::str_squish() %&gt;% unique() # potential methods pot_methods &lt;- c(&quot;watershed&quot;, &quot;dbscan&quot;) %&gt;% unique() find_method &lt;- paste(pot_methods, collapse=&quot;|&quot;) # can i find one? which_methods &lt;- stringr::str_extract_all(string = method, pattern = find_method) %&gt;% unlist() %&gt;% unique() # make sure at least one is selected n_methods_not &lt;- base::setdiff( pot_methods , which_methods ) %&gt;% length() if(n_methods_not&gt;=length(pot_methods)){ stop(paste0( &quot;`method` parameter must be one of:\\n&quot; , &quot; &quot; , paste(pot_methods, collapse=&quot;, &quot;) )) }else{ return(which_methods) } } # check_segmentation_method(c(&quot;watershed&quot;, &quot;dbscn&quot;, &quot;dbsca&quot;)) # check_segmentation_method(&quot;dbscn&quot;) ############################################################################ # intermediate function to convert rast to polygon ############################################################################ rast_to_poly &lt;- function(rast){ # ?terra::as.polygons rast %&gt;% terra::subset(1) %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) } ############################################################################ # full segmentation function # given an input CHM raster, target height range, and target area range. # the output will include a raster and `sf` polygons of the candidate segments # automatically adjusts segmentation method parameters using get_segmentation_params() ############################################################################ get_segmentation_candidates &lt;- function( chm_rast , method = &quot;watershed&quot; # &quot;watershed&quot; or &quot;dbscan&quot; , min_ht_m , max_ht_m , min_area_m2 , max_area_m2 ){ ######################## # threshold checks ######################## max_ht_m &lt;- max_ht_m[1] min_ht_m &lt;- min_ht_m[1] min_area_m2 &lt;- min_area_m2[1] max_area_m2 &lt;- max_area_m2[1] if( (is.na(tryCatch(as.numeric(max_ht_m), error = function(e) NA)) || identical(as.numeric(max_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_ht_m), error = function(e) NA)) || identical(as.numeric(min_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || identical(as.numeric(max_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || identical(as.numeric(min_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) || !(as.numeric(max_ht_m) &gt; as.numeric(min_ht_m)) || !(as.numeric(max_area_m2) &gt; as.numeric(min_area_m2)) || as.numeric(max_ht_m)&lt;0 || as.numeric(min_ht_m)&lt;0 || as.numeric(min_area_m2)&lt;0 || as.numeric(max_area_m2)&lt;0 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_ht_m`,`max_ht_m`,`min_area_m2`,`max_area_m2` are not valid numbers, or the conditions max_area_m2&gt;min_area_m2 or max_ht_m&gt;min_ht_m are not met.&quot;) }else{ max_ht_m &lt;- as.numeric(max_ht_m)[1] min_ht_m &lt;- as.numeric(min_ht_m)[1] min_area_m2 &lt;- as.numeric(min_area_m2)[1] max_area_m2 &lt;- as.numeric(max_area_m2)[1] } ######################## # check raster ######################## # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } # first layer only if(terra::nlyr(chm_rast)&gt;1){warning(&quot;...only using first layer of raster stack for segmentation&quot;)} chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) # na check if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } ######################## # check method ######################## check_segmentation_method_ans &lt;- check_segmentation_method(method = method) if(length(check_segmentation_method_ans)&gt;1){ warning( paste0( &quot;...using only &quot;, check_segmentation_method_ans[1], &quot; method for segmentation&quot;) ) } check_segmentation_method_ans &lt;- check_segmentation_method_ans[1] ######################## # slice CHM ######################## # lower CHM slice slice_chm_rast &lt;- terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F) # na check if( as.numeric(terra::global(slice_chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(slice_chm_rast) ){ stop(&quot;Input &#39;chm_rast&#39; has no values at or below &#39;max_ht_m&#39; value&quot;) } ######################## # get_segmentation_params ######################## # get_segmentation_params seg_params_ans &lt;- get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(slice_chm_rast)[1] ) # # huh? # dplyr::glimpse(seg_params_ans) ######################## # segmentation ######################## if(check_segmentation_method_ans==&quot;watershed&quot;){ # ?EBImage::watershed segs_rast &lt;- lidR::watershed( chm = slice_chm_rast # th_tree = Threshold below which a pixel cannot be a tree. Default is 2. , th_tree = 0.01 # tol = minimum height of the object in the units of image intensity between its highest point (seed) # and the point where it contacts another object (checked for every contact pixel). # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. # Tolerance should be chosen according to the range of x , tol = seg_params_ans$watershed$tol # max_ht_m-min_ht_m # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. # Higher value smoothes out small objects. , ext = seg_params_ans$watershed$ext # 1 )() # match names of get_segs_dbscan() names(segs_rast) &lt;- &quot;cluster&quot; }else if(check_segmentation_method_ans==&quot;dbscan&quot;){ segs_rast &lt;- get_segs_dbscan( chm_rast = slice_chm_rast , eps = seg_params_ans$dbscan$eps , minPts = seg_params_ans$dbscan$minPts ) }else{ stop(&quot;incorrect method selected&quot;) } # na check if( as.numeric(terra::global(segs_rast, fun = &quot;isNA&quot;)) == terra::ncell(segs_rast) ){ warning(&quot;no segmentation candidates detected&quot;) } ######################## # rast to poly ######################## segs_sf &lt;- rast_to_poly(segs_rast) ######################## # return ######################## return(list( segs_rast = segs_rast , segs_sf = segs_sf , slice_chm_rast = slice_chm_rast , seg_mthd_params = seg_params_ans )) } # get_segmentation_candidates( # chm_rast = aoi_chm_rast # , method = &quot;dbscan&quot; # , min_ht_m = 1 # , max_ht_m = 4 # , min_area_m2 = 1.5^2 # , max_area_m2 = 55 # ) our get_segmentation_candidates() is the workhorse of our methodology. it includes all input data and parameter (e.g. height, area thresholds) checks and includes the following processing steps: CHM Height Filtering: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a “slice” of the CHM. Segmentation Method Setup: Applies the dynamic parameter logic used in the Watershed or DBSCAN segmentation method. This logic ensures scale-invariant object detection by maintaining constant proportions between the algorithm search windows and the physical dimensions of the target object. This dynamic approach allows the method parameters to adapt automatically to the input data resolution so that the resulting candidate segments remain spatially consistent with target objects. Candidate Segmentation: Watershed or DBSCAN segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form. 4.3 Candidate Shape Refinement and Area filtering to better align the segmentation results with real-world pile construction we’ll now simplify candidate segments composed of multiple separate parts representing a single identified feature (i.e. “multi-polygon” candidate segments. We’ll simplify these segments by retaining only the largest contiguous portion using cloud2trees functionality. Because slash piles are constructed as distinct, isolated objects to prevent tree mortality during burning, this refinement step isolates the primary candidate body to eliminate detached noise and ensure each segment represents a discrete physical object before area-based filtering using the candidate segment polygons, apply the cloud2trees::simplify_multipolygon_crowns() function which keeps only the largest part of multi-polygon geometries and works for all sf polygon data (even though the term “crowns” is in the name) # watershed_segs watershed_segs_poly &lt;- watershed_segs_poly %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # dbscan_segs dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) we’ll have the same number of unique candidate segments from each method but the area covered by those segments will now be smaller dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments = scales::comma(segments,accuracy=1) , area = scales::comma(area,accuracy=0.01) ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method after removing noise polygon parts&quot; , col.names = c( &quot;method&quot;, &quot;candidate segments&quot;, &quot;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.2: Demonstration area candidate segments by method after removing noise polygon parts method candidate segments area (m2) watershed 105 204.84 DBSCAN 108 205.81 now we’ll remove all candidate segments that do not meet the area criteria based on the user-defined minimum and maximum area thresholds st_filter_area &lt;- function(sf_data, min_area_m2, max_area_m2) { # check input data if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # check thresholds min_area_m2 &lt;- min_area_m2[1] max_area_m2 &lt;- max_area_m2[1] if( (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || identical(as.numeric(max_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || identical(as.numeric(min_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) || !(as.numeric(max_area_m2) &gt; as.numeric(min_area_m2)) || as.numeric(min_area_m2)&lt;0 || as.numeric(max_area_m2)&lt;0 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_area_m2`,`max_area_m2` are not valid numbers, or the condition max_area_m2&gt;min_area_m2 not met.&quot;) }else{ min_area_m2 &lt;- as.numeric(min_area_m2)[1] max_area_m2 &lt;- as.numeric(max_area_m2)[1] } # return return( sf_data %&gt;% dplyr::ungroup() %&gt;% # area filter dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_xxxx,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_xxxx,0) &lt;= max_area_m2 ) %&gt;% dplyr::select(-c(area_xxxx)) ) } apply our st_filter_area() function # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) how many candidate segments were removed? dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , new_segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment area&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.3: Demonstration area candidate segments by methodfiltered by segment area method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -81.9% 105 19 178.37 DBSCAN -82.4% 108 19 178.37 4.3.1 Watershed Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice…we are getting closer. 4.3.2 DBSCAN Segmentation plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice…we are getting closer. 4.3.3 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) interesting. 4.4 Candidate Geometric filtering slash piles are man-made objects typically constructed into common geometric forms in 2D (e.g. circular base) and 3D space (e.g. paraboloid) to facilitate efficient construction and burning Hardy 1996. Our method leverages these traits by applying independent geometric filters to refine candidate segments. First, we apply a regularity filter to remove candidates with irregularly-shaped bases. Then, an independent circularity filter removes candidates that do not meet expectations for round bases (typical of hand piles). By keeping these filters independent, the our method is flexible and allows users to prioritize generally regular shapes (e.g. circular or rectangular) or apply the circularity filter as an additional filtering step when circular pile bases are expected. 4.4.1 Shape Irregularity: Convexity Our first shape irregularity filter compares the convex hull of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the convexity ratio or “solidity” of the shape (Glasbey and Horgan 1995) by: \\[\\frac{\\text{Area of Polygon}}{\\text{Area of Convex Hull}}\\] This approach is effective for identifying polygons with deep indents, holes, or branching. A perfectly convex shape like a circle, square, or triangle will have a convexity of 1.0 (because they have no indents) and as shapes become more irregular (or concave) the convexity drops toward 0. Convexity is is not sensitive to the overall elongation of a shape as a long, thin rectangle is technically convex and would have a ratio of 1.0, despite being irregular in its proportions. let’s create a convex hull of the candidate segments for comparison and convexity calculation # convex hulls of segments # watershed_segs_poly watershed_segs_poly_chull &lt;- watershed_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs_poly dbscan_segs_poly_chull &lt;- dbscan_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) compare the convex hull shape to the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly_chull, mapping=ggplot2::aes(color=&quot;convex hull&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;brown&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly_chull, mapping=ggplot2::aes(color=&quot;convex hull&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;brown&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) patchwork::wrap_plots(list(p1_temp,p2_temp)) now, we’ll calculate the convexity ratio for each remaining candidate segment # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::mutate(poly_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( watershed_segs_poly_chull %&gt;% dplyr::mutate(chull_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, chull_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( convexity_ratio = poly_area_m2/chull_area_m2 ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::mutate(poly_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( dbscan_segs_poly_chull %&gt;% dplyr::mutate(chull_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, chull_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( convexity_ratio = poly_area_m2/chull_area_m2 ) what is the convexity ratio for the remaining candidate segments in our demonstration area? # watershed_segs_poly watershed_segs_poly$convexity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.7517 0.8944 0.9096 0.9047 0.9304 0.9423 # dbscan_segs_poly dbscan_segs_poly$convexity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.7517 0.8944 0.9096 0.9047 0.9304 0.9423 plot the convexity of the candidate segments using the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = watershed_segs_poly , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = dbscan_segs_poly , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) patchwork::wrap_plots( list(p1_temp,p2_temp) , guides = &quot;collect&quot; , ) &amp; ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 7) ) finally, let’s filter the candidate segments with a user-defined expectation of shape irregularity on the 0-100% scale applied to the convexity ratio # # min required overlap between the predicted pile and the convex hull of the predicted pile min_convexity_ratio &lt;- 0.8 what proportion of the remaining segments were filtered using this shape irregularity filter dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( watershed_segs_poly %&gt;% nrow() , dbscan_segs_poly %&gt;% nrow() ) , new_segments = c( watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% nrow() , dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment convexity&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.4: Demonstration area candidate segments by methodfiltered by segment convexity method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -5.3% 19 18 173.98 DBSCAN -5.3% 19 18 173.98 actually apply the filter ;) # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) 4.4.1.1 Watershed Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) 4.4.1.2 DBSCAN Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) 4.4.1.3 Convexity Filter Function let’s make a function to ingest a spatial data frame and return polygons filtered for irregularity using this convex hull process st_convexity_filter &lt;- function( sf_data # min required overlap between the polygon and the convex hull of the polygon , min_convexity_ratio = 0.7 ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # convex hulls of segments poly_chull &lt;- sf_data %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() # dplyr::filter(sf::st_is_valid(.)) # compare areas if(nrow(poly_chull)!=nrow(sf_data)){ stop(&quot;could not make valid convex hulls from provided polygon data&quot;) }else{ area_comp &lt;- sf_data %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::bind_cols( poly_chull %&gt;% dplyr::mutate(chull_area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::select(chull_area_xxxx) %&gt;% sf::st_drop_geometry() ) %&gt;% dplyr::mutate( convexity_ratio = area_xxxx/chull_area_xxxx ) %&gt;% dplyr::filter( convexity_ratio &gt;= min_convexity_ratio ) %&gt;% dplyr::select(-c(area_xxxx,chull_area_xxxx)) return(area_comp) } } # dbscan_segs_poly$convexity_ratio %&gt;% summary() # dbscan_segs_poly %&gt;% # st_convexity_filter(min_convexity_ratio = 0.9) %&gt;% # dplyr::pull(convexity_ratio) %&gt;% # summary() 4.4.2 Shape Irregularity: Circularity Our second shape irregularity filter compares the minimum bounding circle of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the circularity ratio sometimes referred to as the Reock Compactness Score (Reock 1961) of the shape by: \\[\\frac{\\text{Area of Polygon}}{\\text{Area of Minumum Bounding Circle}}\\] This approach is used to measure how closely a shape is spread around its central point (dispersion) with a perfect circle receiving a score of 1.0 while long, thin shapes (like downed tree boles) will have low values approaching the lower limit of 0. This metric penalizes any shape that does not fill it’s circumcircle (i.e. the smallest circle that contains the polygon). For context, a perfect square has a circularity ratio of \\(\\frac{2}{\\pi}\\approx 0.637\\) while an equilateral triangle has a ratio of \\(\\frac{3\\sqrt{3}}{4\\pi}\\approx 0.414\\) let’s create the minimum bounding circle of the candidate segments using lwgeom::st_minimum_bounding_circle() # MBC of segments # watershed_segs_poly watershed_segs_poly_mbc &lt;- watershed_segs_poly %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs_poly dbscan_segs_poly_mbc &lt;- dbscan_segs_poly %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) compare the MBC shape to the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly_mbc, mapping=ggplot2::aes(color=&quot;min. bounding circle&quot;) , fill = NA, lwd = 1.5 ) + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;brown&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly_mbc, mapping=ggplot2::aes(color=&quot;min. bounding circle&quot;) , fill = NA, lwd = 1.5 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;brown&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) patchwork::wrap_plots(list(p1_temp,p2_temp)) now, we’ll calculate the circularity ratio for each remaining candidate segment # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::inner_join( watershed_segs_poly_mbc %&gt;% dplyr::mutate(mbc_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, mbc_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( circularity_ratio = poly_area_m2/mbc_area_m2 ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::inner_join( dbscan_segs_poly_mbc %&gt;% dplyr::mutate(mbc_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, mbc_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( circularity_ratio = poly_area_m2/mbc_area_m2 ) what is the circularity ratio for the remaining candidate segments in our demonstration area? # watershed_segs_poly watershed_segs_poly$circularity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4773 0.6465 0.6801 0.6836 0.7321 0.7991 # dbscan_segs_poly dbscan_segs_poly$circularity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4773 0.6465 0.6801 0.6836 0.7321 0.7991 plot the circularity of the candidate segments using the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = watershed_segs_poly , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = dbscan_segs_poly , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) patchwork::wrap_plots( list(p1_temp,p2_temp) , guides = &quot;collect&quot; , ) &amp; ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 7) ) finally, let’s filter the candidate segments with a user-defined expectation of shape circularity on the 0-100% scale applied to the circularity ratio # # min required overlap between the predicted pile and the MBC of the predicted pile min_circularity_ratio &lt;- 0.6 what proportion of the remaining segments were filtered using this shape circularity filter dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( watershed_segs_poly %&gt;% nrow() , dbscan_segs_poly %&gt;% nrow() ) , new_segments = c( watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% nrow() , dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment circularity&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.5: Demonstration area candidate segments by methodfiltered by segment circularity method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -5.6% 18 17 169.03 DBSCAN -5.6% 18 17 169.03 actually apply the filter ;) # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) 4.4.2.1 Watershed Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) 4.4.2.2 DBSCAN Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) 4.4.2.3 Circularity Filter Function let’s make a function to ingest a spatial data frame and return polygons filtered for irregularity using this minimum bounding circle process st_circularity_filter &lt;- function( sf_data # min required overlap between the polygon and the minimum bounding circle of the polygon , min_circularity_ratio = 0.6 ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # minimum bounding circle of segments poly_mbc &lt;- sf_data %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() # dplyr::filter(sf::st_is_valid(.)) # compare areas if(nrow(poly_mbc)!=nrow(sf_data)){ stop(&quot;could not make valid minimum bounding circle from provided polygon data&quot;) }else{ area_comp &lt;- sf_data %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::bind_cols( poly_mbc %&gt;% dplyr::mutate(mbc_area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::select(mbc_area_xxxx) %&gt;% sf::st_drop_geometry() ) %&gt;% dplyr::mutate( circularity_ratio = area_xxxx/mbc_area_xxxx ) %&gt;% dplyr::filter( circularity_ratio &gt;= min_circularity_ratio ) %&gt;% dplyr::select(-c(area_xxxx,mbc_area_xxxx)) return(area_comp) } } # dbscan_segs_poly$circularity_ratio %&gt;% summary() # dbscan_segs_poly %&gt;% # st_circularity_filter(min_circularity_ratio = 0.7) %&gt;% # dplyr::pull(circularity_ratio) %&gt;% # summary() 4.4.2.4 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot now that we have removed candidate segments that 1) do not meet the area thresholds; 2) do not meet the convexity ratio threshold; and 3) do not meet the circularity ratio threshold # watershed_segs_poly %&gt;% dplyr::glimpse() # dbscan_segs_poly %&gt;% dplyr::glimpse() ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) after all of that, the results of the two methods are the same for this particular demonstration area 4.5 Structural Metrics from CHM We’ll use the CHM raster to calculate area, height, and volume for each candidate pile to reflect the irregular pile footprints and elevation profiles that better represent real-world objects than assuming perfect geometric shapes like traditional pile measurement methods (Long and Boston, 2014; Trofymow et al., 2014; Guth et al., 2025) Candidate slash pile structural metrics are derived from the CHM raster using zonal statistics to aggregate cell-level raster data within the boundaries of each pile. To ensure geodetic accuracy, an area raster is generated (terra::cellSize()) which accounts for minute variations in pixel area caused by the curvature of the Earth and the coordinate reference system. This area raster is then used as input for volume calculation, where it is multiplied by the CHM height values to create a volume raster. Summing the individual volume of every pixel within the candidate pile footprint yields the total pile volume with each cell in the volume raster treated as a rectangular prism with height from the CHM and base area from the area raster. Pile area is calculated by summing the area raster values within the candidate pile boundary and pile height is determined by the maximum CHM pixel value. we’ll make a function to use polygon sf data and an input CHM raster to perform these calculations and return the data with metrics attached ######################################################################################## ## calculate raster-based area, height, and volume using zonal stats ######################################################################################## get_structural_metrics &lt;- function( sf_data , chm_rast # , sf_id = NA ) { # check polygons if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must include `sf` data object in &#39;sf_data&#39;&quot;)} if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } sf_data &lt;- sf_data %&gt;% dplyr::ungroup() # check raster # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } # # check id # if(!inherits(sf_id, &quot;character&quot;)){ # # stop(&quot;must include &#39;sf_id&#39; as the unique identifier&quot;) # sf_data &lt;- sf_data %&gt;% # dplyr::mutate(idxxxxx = dplyr::row_number()) # sf_id &lt;- &quot;idxxxxx&quot; # }else{ # if( !any( stringr::str_equal(names(sf_data), sf_id) ) ){ # stop(paste0(&quot;could not locate &#39;&quot;,sf_id,&quot;&#39; in sf_data&quot;)) # } # } # check overlap # Returns TRUE if any part of the vector geometry intersects the raster extent if( !any(terra::is.related( x = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , y = terra::ext(chm_rast) , relation = &quot;intersects&quot; )) ){ stop(&quot;Input &#39;sf_data&#39; does not overlap with &#39;chm_rast&#39;&quot;) } ################################# # area, volume of each cell ################################# area_rast_temp &lt;- terra::cellSize(chm_rast) names(area_rast_temp) &lt;- &quot;area_m2&quot; # area_rast_temp %&gt;% terra::plot() # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes vol_rast_temp &lt;- area_rast_temp*chm_rast names(vol_rast_temp) &lt;- &quot;volume_m3&quot; # vol_rast_temp %&gt;% terra::plot() ################################# # zonal stats ################################# # sum area within each segment to get the total area area_df_temp &lt;- terra::zonal( x = area_rast_temp , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;sum&quot;, na.rm = T ) %&gt;% setNames(&quot;area_m2&quot;) %&gt;% dplyr::mutate(area_m2 = dplyr::na_if(area_m2, NaN)) # area_df_temp %&gt;% dplyr::glimpse() # sum volume within each segment to get the total volume vol_df_temp &lt;- terra::zonal( x = vol_rast_temp , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;sum&quot;, na.rm = T ) %&gt;% setNames(&quot;volume_m3&quot;) %&gt;% dplyr::mutate(volume_m3 = dplyr::na_if(volume_m3, NaN)) # vol_df_temp %&gt;% dplyr::glimpse() # max ht within each segment to get the max ht ht_df_temp &lt;- terra::zonal( x = chm_rast , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;max&quot;, na.rm = T ) %&gt;% setNames(&quot;max_height_m&quot;) %&gt;% dplyr::mutate(max_height_m = dplyr::na_if(max_height_m, NaN)) ################################# # attach to sf ################################# if( !identical( nrow(sf_data) , nrow(area_df_temp) , nrow(vol_df_temp) , nrow(ht_df_temp) ) ){ stop(&quot;unable to find data in raster for given vectors&quot;) } ret_dta &lt;- sf_data %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;area_m2&quot; , &quot;volume_m3&quot; , &quot;max_height_m&quot; , &quot;volume_per_area&quot; ))) %&gt;% dplyr::bind_cols( area_df_temp , vol_df_temp , ht_df_temp ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) # ret_dta &lt;- sf_data %&gt;% # purrr::reduce( # list(sf_data, area_df_temp, vol_df_temp, ht_df_temp) # , dplyr::left_join # , by = sf_id # ) %&gt;% # dplyr::mutate( # volume_per_area = volume_m3/area_m2 # ) return( list( sf_data = ret_dta , area_rast = area_rast_temp , volume_rast = vol_rast_temp ) ) } # get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% # dplyr::glimpse() # get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = arnf_chm_rast) %&gt;% # dplyr::glimpse() 4.5.1 Structural Rasters we can quickly look at the area raster that was used for the volume calculation get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;area_rast&quot;) %&gt;% terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = &quot;area (m2)&quot;) and we can quickly look at the volume raster get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;volume_rast&quot;) %&gt;% terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = &quot;volume (m3)&quot;) # terra::plot( # aoi_slash_piles_polys %&gt;% # sf::st_transform(terra::crs(aoi_chm_rast_slice)) %&gt;% # terra::vect() # , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 # ) the volume raster mirrors the CHM but with volume as the cell value instead of height aoi_chm_rast_slice %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;CHM (m)&quot;) 4.5.2 Demonstration Candidate Segment Metrics we’ll use our get_structural_metrics() with the height-filtered CHM to compute the structural metrics for the candidate piles # watershed_segs_poly watershed_segs_poly &lt;- get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we already have area so we&#39;ll drop the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) # dbscan_segs_poly dbscan_segs_poly &lt;- get_structural_metrics(sf_data = dbscan_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we already have area so we&#39;ll drop the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) what did we get back? watershed_segs_poly %&gt;% dplyr::glimpse() ## Rows: 17 ## Columns: 10 ## $ pred_id &lt;dbl&gt; 29, 47, 48, 49, 50, 53, 59, 60, 61, 62, 63, 66, 67, … ## $ chull_area_m2 &lt;dbl&gt; 25.320, 5.055, 6.175, 5.605, 8.350, 6.275, 5.370, 17… ## $ convexity_ratio &lt;dbl&gt; 0.9095577, 0.9297725, 0.9327935, 0.9277431, 0.894610… ## $ mbc_area_m2 &lt;dbl&gt; 33.030222, 6.234503, 8.698236, 7.481425, 11.587181, … ## $ circularity_ratio &lt;dbl&gt; 0.6972402, 0.7538693, 0.6622032, 0.6950548, 0.644678… ## $ area_m2 &lt;dbl&gt; 23.048435, 4.703762, 5.764611, 5.204163, 7.475979, 5… ## $ volume_m3 &lt;dbl&gt; 31.446938, 4.081403, 4.177804, 3.642817, 4.954234, 4… ## $ max_height_m &lt;dbl&gt; 3.566, 2.559, 2.355, 2.352, 2.350, 2.175, 1.823, 1.7… ## $ volume_per_area &lt;dbl&gt; 1.3643850, 0.8676890, 0.7247329, 0.6999813, 0.662687… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499373.9 4317743,..., POLYGON ((49… plot the metrics of pile area, height, and volume # p1_temp &lt;- p_fn_temp &lt;- function(dta,fill_col,col_nm=latex2exp::TeX(&quot;area $\\\\textrm{m}^2$&quot;),pal=&quot;Oranges&quot;){ ggplot2::ggplot(data = dta) + ggplot2::geom_sf( mapping=ggplot2::aes(fill=.data[[fill_col]]) # mapping=ggplot2::aes(fill={{fill_col}}) , color = NA ) + ggplot2::geom_sf_text( # mapping=ggplot2::aes(label=scales::comma({{fill_col}}, accuracy=0.1)) mapping=ggplot2::aes(label=scales::comma(.data[[fill_col]], accuracy=0.1)) , vjust = 1, hjust = -0.9, size = 2.5 ) + ggplot2::scale_fill_distiller(palette = pal, name = col_nm, direction = 1) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) } # lists pal_temp &lt;- c(&quot;Blues&quot;,&quot;Purples&quot;,&quot;Greens&quot;) nm_temp &lt;- c( latex2exp::TeX(&quot;area $\\\\textrm{m}^2$&quot;) , latex2exp::TeX(&quot;volume $\\\\textrm{m}^3$&quot;) , &quot;height m&quot; ) col_temp &lt;- c( &quot;area_m2&quot; , &quot;volume_m3&quot; , &quot;max_height_m&quot; ) # watershed ws_p_temp &lt;- 1:length(col_temp) %&gt;% purrr::map( \\(x) p_fn_temp( watershed_segs_poly , fill_col = col_temp[x] , col_nm = nm_temp[x] , pal = pal_temp[x] ) ) # dbscan db_p_temp &lt;- 1:length(col_temp) %&gt;% purrr::map( \\(x) p_fn_temp( dbscan_segs_poly , fill_col = col_temp[x] , col_nm = nm_temp[x] , pal = pal_temp[x] ) ) p1_temp &lt;- patchwork::wrap_plots( ws_p_temp ) + patchwork::plot_annotation( title = &quot;watershed&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14)) ) p2_temp &lt;- patchwork::wrap_plots( db_p_temp ) + patchwork::plot_annotation( title = &quot;dbscan&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14)) ) patchwork::wrap_plots( list( patchwork::wrap_elements( p1_temp ) , patchwork::wrap_elements( p2_temp ) ) , nrow = 2 ) after all of that, the results of the two methods are the same for this particular demonstration area 4.6 Final Shape Refinement In the final stage, we generate convex hulls for the segments to smooth the blocky, pixelated edges inherent in raster data (which can look like they were generated in Minecraft). Any segments with overlapping convex hulls are then removed to help filter out false detections which may be groups of small trees or shrubs. This step is intended to reflect real-world conditions where distinct slash piles are constructed with enough spacing to remain spatially independent rather than overlapping. Finally, we’ll apply one more filter for the area and height thresholds. ############################################################################### # make a function to remove overlapping polygons from a sf data frame ############################################################################### st_remove_overlaps &lt;- function(sf_data) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } if(nrow(sf_data)&lt;=1){return(sf_data)} # combine all touching polygons and keep the ones that overlap multiple from the original polygons comb_temp &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% sf::st_union(by_feature = F) %&gt;% sf::st_cast(&quot;POLYGON&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% sf::st_set_crs(sf::st_crs(sf_data)) %&gt;% dplyr::mutate(new_id = dplyr::row_number()) %&gt;% dplyr::select(new_id) # identify overlaps overlap_temp &lt;- comb_temp %&gt;% sf::st_intersection(sf_data) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::group_by(new_id) %&gt;% dplyr::summarise(n_orig = dplyr::n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(n_orig&gt;=2) %&gt;% dplyr::pull(new_id) if(length(overlap_temp)==0){return(sf_data)} # just get the overlaps comb_temp &lt;- comb_temp %&gt;% dplyr::filter(new_id %in% overlap_temp) %&gt;% sf::st_union() # remove all input polygons from the original data that have any overlaps return(sf::st_difference(sf_data,comb_temp)) } take the convex hull and apply our st_remove_overlaps() function to the remaining candidate segments. Finally, we filter for area based on the smoothed shape # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %&gt;% # filter for height dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %&gt;% # filter for height dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # dbscan_segs_poly %&gt;% dplyr::glimpse() 4.6.1 Watershed Segmentation plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice 4.6.2 DBSCAN Segmentation plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;brown&quot;, lwd = 0.8 ) nice 4.6.3 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) exactly the same let’s see how many segments were originally detected using each method and how many we are left with after our filtering for shape irregularity, pile area and height expectations, circularity, and potential overlaps after smoothing? dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , new_segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) # area , old_area = c( terra::cellSize(watershed_segs) %&gt;% terra::crop(watershed_segs,mask=T) %&gt;% terra::global(fun=&quot;sum&quot;, na.rm=T) %&gt;% as.numeric() , terra::cellSize(dbscan_segs) %&gt;% terra::crop(dbscan_segs,mask=T) %&gt;% terra::global(fun=&quot;sum&quot;, na.rm=T) %&gt;% as.numeric() ) , new_area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments_pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area_pct_removed = scales::percent((new_area-old_area)/old_area, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;area&quot;), ~scales::comma(.x,accuracy=0.1)) ) %&gt;% dplyr::select( method ,tidyselect::ends_with(&quot;_segments&quot;), segments_pct_removed ,tidyselect::ends_with(&quot;_area&quot;), area_pct_removed ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;final candidate segments fully filtered for size and geometric expectations&quot; , col.names = c( &quot;method&quot; , &quot;orig. candidate&lt;br&gt;segments&quot;, &quot;final&lt;br&gt;segments&quot;, &quot;% candidates&lt;br&gt;removed&quot; , &quot;orig. candidate&lt;br&gt;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot;, &quot;final&lt;br&gt;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot;, &quot;% area&lt;br&gt;removed&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.6: Demonstration area candidate segments by methodfinal candidate segments fully filtered for size and geometric expectations method orig. candidatesegments finalsegments % candidatesremoved orig. candidatearea (m2) finalarea (m2) % arearemoved watershed 105 17 -83.8% 206.9 186.6 -9.8% DBSCAN 108 17 -84.3% 206.0 186.6 -9.4% wow that is a lot of filtering, but it looks like the result for this demonstration area is decently accurate (we’ll perform full validation of the method later). That is, there are no false positive predictions (commission errors) and few false negative predictions (omission errors) 4.7 Pile Detection Function The rule-based method for slash pile detection using CHM raster data we reviewed above generally follows this outline: CHM Generation: A Canopy Height Model (CHM) is generated from the point cloud data. The CHM is generated by removing the ground surface effectively representing a Digital Surface Model (DSM) without ground, ensuring all values are heights above bare earth. CHM Height Filtering: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a “slice” of the CHM. Segmentation Method Setup: Applies the dynamic parameter logic used in the Watershed or DBSCAN segmentation method. This logic ensures scale-invariant object detection by maintaining constant proportions between the algorithm search windows and the physical dimensions of the target object. This dynamic approach allows the method parameters to adapt automatically to the input data resolution so that the resulting candidate segments remain spatially consistent with target objects. Candidate Segmentation: Watershed or DBSCAN segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form. Shape Refinement &amp; Area Filtering: To align segmentation results with real-world pile construction, we simplify candidate segments by retaining only their largest contiguous portion to eliminate detached noise and ensure each feature represents a discrete physical object. The results are then filtered based on the area expectations. Shape Irregularity: Convexity Filtering: Candidate pile locations are filtered to remove highly irregular shapes by assessing their overlap with their convex hull. This process removes irregular objects like branched tree crowns or segments with holes while allowing solid, regular shapes (e.g. circles, rectangles, triangles) to pass. Circularity Filtering: A circularity filter is applied to measure a shape’s dispersion by dividing the candidate polygon area by the area of its minimum bounding circle. This second-stage shape irregularity filter targets the round bases typical of manual construction by penalizing elongated or non-circular shapes that do not adequately fill their circumcircle. Final Shape Refinement &amp; Overlap Removal: Lastly, segments are smoothed using their convex hull to remove the “blocky” raster edges (like they were made in Minecraft). Overlapping convex hull shapes are then removed to prevent false positives from clustered small trees or shrubs, ensuring singular pile detections. Let’s package all of the steps we demonstrated when formulating the methodology into a single function which can possibly be integrated into the cloud2trees package. The parameters are defined as follows: min_ht_m : numeric. The minimum height (in meters) a detected pile must reach to be considered valid. max_ht_m : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific “slice” of the data, ignoring anything taller than a typical pile. min_area_m2 : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid. max_area_m2 : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid. min_convexity_ratio : numeric. A value between 0 and 1 that controls how strict the filtering is for regularly shaped piles. A value of 1 means only piles that are perfectly smooth and rounded, with no dents or inward curves are kept (e.g. perfect square, rectangle, circle, triangle). A value of 0 allows for both perfectly regular and very irregular shapes. This filter works alongside min_circularity_ratio to identify slash piles based on expected morphology. min_circularity_ratio : numeric. A value between 0 and 1 that controls how strict the filtering is for circular pile shapes. Setting it to 1 means only piles that are perfectly circular are kept. A value of 0 allows for a wide range of shapes, including very circular and non-circular ones (like long, straight lines). For context, a perfect square has a circularity ratio of \\(\\frac{2}{\\pi}\\approx 0.637\\) while an equilateral triangle has a ratio of \\(\\frac{3\\sqrt{3}}{4\\pi}\\approx 0.414\\). This filter works alongside min_convexity_ratio to identify slash piles based on expected morphology. smooth_segs : logical. Setting this option to TRUE will: 1) smooth out the “blocky” edges of detected piles (which can look like they were made in Minecraft) by using their overall shape; and 2) remove any detected piles that overlap significantly with other smoothed piles to help ensure each detection is a single slash pile, not a cluster of objects like small trees or shrubs. # detect funciton slash_pile_detect &lt;- function( chm_rast , seg_method = &quot;watershed&quot; #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , min_ht_m # set the min expected pile height , max_ht_m # set the max expected pile height , min_area_m2 # set the min expected pile area , max_area_m2 # set the max expected pile area #### convexity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity if desired , min_convexity_ratio # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required overlap between the candidate pile segment polygon and the minimum bounding circle of the polygon , min_circularity_ratio #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) { # checks if(!inherits(smooth_segs, &quot;logical&quot;) || is.na(smooth_segs)){stop(&quot;define `smooth_segs` as logical&quot;)} ######################## # shape irregularity checks ######################## min_convexity_ratio &lt;- min_convexity_ratio[1] min_circularity_ratio &lt;- min_circularity_ratio[1] if( (is.na(tryCatch(as.numeric(min_convexity_ratio), error = function(e) NA)) || identical(as.numeric(min_convexity_ratio), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_convexity_ratio), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_circularity_ratio), error = function(e) NA)) || identical(as.numeric(min_circularity_ratio), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_circularity_ratio), error = function(e) NA))) || as.numeric(min_convexity_ratio)&lt;0 || as.numeric(min_convexity_ratio)&gt;1 || as.numeric(min_circularity_ratio)&lt;0 || as.numeric(min_circularity_ratio)&gt;1 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_convexity_ratio`,`min_circularity_ratio` are not valid numbers between 0 and 1.&quot;) } ######################################################################################## ## 1) Segmentation ######################################################################################## get_segmentation_candidates_ans &lt;- get_segmentation_candidates( chm_rast = chm_rast , method = seg_method , min_ht_m = min_ht_m , max_ht_m = max_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 ) # get results individual objects segs_rast &lt;- get_segmentation_candidates_ans$segs_rast segs_sf &lt;- get_segmentation_candidates_ans$segs_sf slice_chm_rast &lt;- get_segmentation_candidates_ans$slice_chm_rast # seg_mthd_params &lt;- get_segmentation_candidates_ans$seg_mthd_params if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_ht_m`,`max_ht_m`,`min_area_m2`,`max_area_m2`&quot; )) } ######################################################################################## ## 2) shape refinement and area filtering ######################################################################################## # to better align the segmentation results with real-world pile construction we&#39;ll now # simplify candidate segments composed of multiple separate parts representing a single identified feature (i.e. &quot;multi-polygon&quot; candidate segments. # We&#39;ll simplify these segments by retaining only the largest contiguous portion using `cloud2trees` functionality. # Because slash piles are constructed as distinct, isolated objects to prevent tree mortality during burning, this refinement step isolates the primary # candidate body to eliminate detached noise and ensure each segment represents a discrete physical object before area-based filtering segs_sf &lt;- segs_sf %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) %&gt;% # area filtering st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_area_m2`,`max_area_m2`&quot; )) } ######################################################################################## ## 3) convexity filtering ######################################################################################## # let&#39;s first filter out segments that have holes in them # or are very irregularly shaped by comparing the area of the polygon and convex hull # min_convexity_ratio = min required overlap between the predicted pile and the convex hull of the predicted pile if(min_convexity_ratio&gt;0){ # apply the convexity filtering on the polygons segs_sf &lt;- st_convexity_filter( sf_data = segs_sf # min required overlap between the polygon and the convex hull of the polygon , min_convexity_ratio = min_convexity_ratio ) } # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and `min_convexity_ratio` expectations&quot; , &quot;\\n try adjusting `min_convexity_ratio` &quot; )) } ######################################################################################## ## 4) circularity filtering ######################################################################################## # let&#39;s apply a minimum bounding circle algorithm to remove non-circular segments from the remaining segments if(min_circularity_ratio&gt;0){ # apply the circularity filtering on the polygons segs_sf &lt;- st_circularity_filter( sf_data = segs_sf # min required overlap between the polygon and the minimum bounding circle of the polygon , min_circularity_ratio = min_circularity_ratio ) } # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and `min_circularity_ratio` expectations&quot; , &quot;\\n try adjusting `min_circularity_ratio` &quot; )) } ######################################################################################## ## 5) calculate CHM-based structural metrics for the candidate piles ######################################################################################## # we&#39;ll use our `get_structural_metrics()` with the height-filtered CHM to compute the structural metrics for the candidate piles segs_sf &lt;- get_structural_metrics( sf_data = segs_sf , chm_rast = slice_chm_rast ) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we may already have area so we&#39;ll use only the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;trouble getting the structural metrics&quot; , &quot;\\n try adjusting .... something &quot; )) } # filter for height segs_sf &lt;- segs_sf %&gt;% dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_ht_m`,`max_ht_m`&quot; )) } ######################################################################################## ## 6) shape refinement &amp; overlap removal ######################################################################################## # use the convex hull shapes of our remaining segments. # This helps to smooth out the often &#39;blocky&#39; edges of raster-based segments # , which can look like they were generated in Minecraft. # Additionally, by removing any segments with overlapping convex hull shapes, # we can likely reduce false detections that are actually groups of small trees or shrubs, # ensuring our results represent singular slash piles. if(smooth_segs){ # take the convex hull and apply our `st_remove_overlaps()` function to the remaining candidate segments. # Finally, we filter for area based on the smoothed shape segs_sf &lt;- segs_sf %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected after removing overlapping final segments&quot; , &quot;\\n try with `smooth_segs = F`&quot; )) } } # calculate diameter segs_sf &lt;- st_calculate_diameter(segs_sf) # return return(list( segs_sf = segs_sf , seg_mthd_params = get_segmentation_candidates_ans$seg_mthd_params , slice_chm_rast = get_segmentation_candidates_ans$slice_chm_rast )) } remove all other parameters and objects that might have the same name as in this function since we used the framework outlined above to define this (fantastic?) beast of a function remove( min_ht_m, max_ht_m , min_area_m2, max_area_m2 , min_convexity_ratio , min_circularity_ratio , get_segmentation_params_ans , dbscan_segs_poly, watershed_segs_poly , dbscan_segs, watershed_segs , dbscan_segs_poly_chull, dbscan_segs_poly_mbc , watershed_segs_poly_chull, watershed_segs_poly_mbc , aoi_chm_rast_slice ) gc() let’s test this real quick on our example area slash_pile_detect_watershed_ans_temp &lt;- slash_pile_detect( chm_rast = aoi_chm_rast , seg_method = &quot;watershed&quot; , min_ht_m = 1.5 , max_ht_m = 5 , min_area_m2 = 1.5^2 , max_area_m2 = 50 , min_convexity_ratio = 0.7 , min_circularity_ratio = 0.5 ) the slash_pile_detect() function returns: segs_sf: the segments that passed all size and geometric expectations for target slash piles seg_mthd_params: the dynamic parameters used in the Watershed or DBSCAN segmentation method slice_chm_rast: the height-filtered CHM slice used to segment candidate slash piles # what did we get? slash_pile_detect_watershed_ans_temp %&gt;% dplyr::glimpse() ## List of 3 ## $ segs_sf : sf [15 × 9] (S3: sf/tbl_df/tbl/data.frame) ## ..$ pred_id : num [1:15] 48 59 60 61 62 65 70 71 72 73 ... ## ..$ convexity_ratio : num [1:15] 0.91 0.93 0.933 0.928 0.895 ... ## ..$ circularity_ratio: num [1:15] 0.697 0.754 0.662 0.695 0.645 ... ## ..$ area_m2 : num [1:15] 25.32 5.05 6.17 5.61 8.35 ... ## ..$ volume_m3 : num [1:15] 34.55 4.39 4.48 3.92 5.53 ... ## ..$ max_height_m : num [1:15] 3.57 2.56 2.36 2.35 2.35 ... ## ..$ volume_per_area : num [1:15] 1.364 0.868 0.725 0.7 0.663 ... ## ..$ geometry :sfc_POLYGON of length 15; first list element: List of 1 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## ..$ diameter_m : num [1:15] 6.45 2.82 3.33 3.09 3.84 ... ## ..- attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## ..- attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;pred_id&quot; &quot;convexity_ratio&quot; &quot;circularity_ratio&quot; &quot;area_m2&quot; ... ## $ seg_mthd_params:List of 3 ## ..$ data_summary:List of 2 ## .. ..$ pts_per_m2: num 100 ## .. ..$ rast_res_m: num 0.1 ## ..$ watershed :List of 2 ## .. ..$ tol: num 1.75 ## .. ..$ ext: num 4 ## ..$ dbscan :List of 2 ## .. ..$ eps : num 0.15 ## .. ..$ minPts: num 7 ## $ slice_chm_rast :S4 class &#39;SpatRaster&#39; [package &quot;terra&quot;] let’s check out the height-filtered CHM “slice” slash_pile_detect_watershed_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;filtered CHM (m)&quot;) let’s overlay the final candidate segments (brown) and the actual piles (blue) on the raw, un-filtered CHM aoi_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;CHM (m) and demonstration piles&quot;) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 2.5 ) how do the form quantification measurements look? p1_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = area_m2)) + ggplot2::scale_fill_distiller(palette = &quot;Blues&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p2_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = volume_m3)) + ggplot2::scale_fill_distiller(palette = &quot;Purples&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p3_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = max_height_m)) + ggplot2::scale_fill_distiller(palette = &quot;Greens&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p4_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = diameter_m)) + ggplot2::scale_fill_distiller(palette = &quot;PuRd&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) (p1_temp + p2_temp) / (p3_temp + p4_temp) "],["data_fusion.html", "Section 5 Data Fusion 5.1 RGB Indices 5.2 Demonstration Pile Spectral Summary 5.3 Candidate Polygon Spectral Filtering Function 5.4 Data Fusion Method Demonstration", " Section 5 Data Fusion We’ll demonstrate our approach that uses both aerial point cloud-generated CHM data (for structural information) and RGB imagery (for spectral information) which is a data fusion approach. In the prior section, we demonstrated our geometric, rules-based slash pile detection approach. Our data fusion approach identify initial candidate slash piles based on their structural form using this geometric, rules-based method and then integrates the RGB imagery to filter these candidates spectrally. This data fusion methodology leverages the complementary strengths of both data types, using 3D geometry (or “2.5D” as CHM is sometimes referred to) for initial object segmentation and spectral data to refine detections by using thresholds defined to identify green biomass and rock and soil features for exclusion. we’ll continue using the same demonstration area for this walkthrough as introduced in the prior section 5.1 RGB Indices In the HSI (Hue, Saturation, Intensity) model (Judd, 1940), Saturation and Intensity describe the grade of purity of the colour and the light intensity, respectively, while Hue describes the colour itself in the form of an angle between 0 degress and 360 degress, where 0 degress means red, 60 degress means yellow, 120 degress means green and 180 degress means cyan. Derived from Hue, the Green Area (GA) index is defined as the percentage of green pixels in the image (Hue range from 60 degrees to 180 degrees). Two alternative models to HSI (CIELab and CIELuv) are defined according to the International Commission of Illumination (http://www.cie.co.at). In the CIELab model, the a* component represents the green to red range, . The b* component defines the blue to yellow range, where more positive values are closer to a pure yellow, and more negative ones are closer to pure blue. We limited our data fusion approach to methods that could be implemented using RGB data only since most common UAS systems do not include additional spectral information (e.g. NIR) beyond these visible wavelenghts. Many RGB-based indices correlate strongly with indices derived from multispectral data especially measurements related to leaf area (Santini et al. 2019). We calculate spectral indices that utilize only RGB information including: Green Red Vegetation Index (GRVI) which is also referred to as the Normalized Green-Red Difference Index (NGRDI), Red Green Ratio Index (RGRI), Visible Band-Difference Vegetation Index (VDVI), Excess Green-minus-Red Index (ExGR) and a* are calculated for each candidate segment, and thresholds are applied to remove those exhibiting high greenness. The threshold method of separation between plants and background using RGB data is a common approach (Kior et al. 2024). The CIELAB color model is a standard, perceptually uniform color model which encompasses all human vision and can be used as an alternative to the RGB space in the analysis of color images for distinguising vegetation (Cheng et al. 2001; Kior et al. 2024). The CIELAB (L*a*b*) model is based on human vision, using L* for lightness (0-100), a* for green-red (towards red if a* &gt; 0, towards green if a* &lt; 0), and b* for blue-yellow (towards yellow if b* &gt; 0, towards blue if b* &lt; 0). Studies have used the a* component to perform vegetation segmentation and health (Rigon et al. 2016; Riehle et al. 2020) and in the discrimination of wood products (Moya et al. 2012; Amaral Reis et al. 2023). A common challenge with visible RGB spectral index-based methods is that the image brightness can influence calculations. The HSV color model (Hue, Saturation and Value) resolves challenges associated with image brightness by isolating the color distribution (i.e. the “hue” component) as a single object that is invariant to brightness with brightness (i.e. the “value” component) also isolated. In general the hue values of green vegetation vary from 50 to 150 degrees using a value range of 0-360 degrees (Yang et al. 2015; Luo et al. 2024). Index thresholds tested include those found to perform well in distinguishing green vegetation in previous research (Meyer &amp; Neto 2008; Motohka et al. 2010; Wang et al. 2025; Riehle et al. 2020; Johansen et al. 2019; Goodbody et al. 2017). Filtering candidate segments using spectral data will enhance our method’s ability to distinguish non-photosynthetic slash piles from living vegetation (e.g., small trees or shrubs) that might share similar structural profiles. While RGB vegetation indices are good for separating green biomass, differentiating between various shades of brown, black, and white of non-vegetated surfaces like slash piles, rocks, and bare soil can be more challenging. Many common rock-forming minerals are “spectrally featureless” in the visible range, often appearing pale grey to white (Harris et al. 2010). These achromatic features are difficult to distinguish from dead wood which can appear spectrally similar especially woody debris that has been sunbleached (xxx). As such, we focus the spectral refinement of candidate slash piles on indices that separate living vegetation from dead vegetation or background soil and rocks; acknowledging that our spectral filtering method will retain large boulders or rock outcroppings that appear structurally similar to slash piles based on the geometric and size expectations determined in the structural candidate segmentation step. We’ll test the spectral indices listed in the table below that rely only on RGB data and have threshold values identified in the literature to distinguish green vegetation from dead/senescent vegetation and background soil or rock. For the thresholds meant to identify green vegetation we’ll use the inverted threshold to keep candidate slash piles. Here are the thresholds represented in the literature: Index Likely Crop Likely Tree Likely Shrub Likely Wood / Diseased Trees Source GRVI x &gt; 0.0 x &gt; 0.0 x &gt; 0.0 Motohka et al. 2010; Goodbody et al. 2017; Johansen et al. 2019 RGRI x &lt; 0.63 x &lt; 0.70 x &lt; 0.52 Wang et al. 2025 VDVI x &gt; 0.06 x &gt; 0.04 x &gt; 0.03 Wang et al. 2025 ExGR x &gt; 0.0 x &gt; 0.0 x &gt; 0.0 Meyer &amp; Neto 2008; Riehle et al. 2020 a* x &lt; -5 – 0 x &gt; 2 – 10 Moya et al. 2012; Rigon et al. 2016; Riehle et al. 2020; Amaral Reis et al. 2023 Hue 50 &lt; x &lt; 150 0 &lt; x &lt; 26 Yang et al. 2015; Luo et al. 2024 For these formulas, \\(R\\), \\(G\\), and \\(B\\) represent the raw pixel values for the Red, Green, and Blue bands, respectively. For indices that use normalized values, \\(r\\), \\(g\\), and \\(b\\) are defined as: \\(r = \\frac{R}{R+G+B}\\) \\(g = \\frac{G}{R+G+B}\\) \\(b = \\frac{B}{R+G+B}\\) Name Acronym Description Recommended Formula / Method Potential Range Green-Red Vegetation Index GRVI Detects vegetation greenness using a normalized difference \\(\\frac{G - R}{G + R}\\) -1 to 1 Red-Green Ratio Index RGRI Compares red to green intensity to estimate plant pigment changes \\(\\frac{R}{G}\\) 0 to \\(\\infty\\) Visible-band Difference Index VDVI Index for extracting vegetation from complex backgrounds \\(\\frac{2G - R - B}{2G + R + B}\\) -1 to 1 Excess Green-minus-Red ExGR Linear index for discriminating plants from soil/background \\(3g - 2.4r - b\\) -3.4 to 3 CIE a-star (Green-Red) a* Perceptually uniform green-to-red axis grDevices::convertColor(..., to=\"Lab\") -128 to 127 Hue Hue The dominant “color type” angle on the color wheel that ensures consistent values regardless of illumination terra::colorize(x, to=\"hsv\") 0 to 1 (or 0–360 degrees) 5.1.1 Spectral Index Functions Although there are dedicated R packages to calculate various spectral indicies (e.g. RStoolbox [Muller et al. 2025]), we’ll make our own to ensure data quality checks and to limit the spectral indices to those highlighted above. # check raster bands and extract rgb layers check_raster_bands &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(rast, &quot;RasterStack&quot;) || inherits(rast, &quot;RasterBrick&quot;) ){ rast &lt;- terra::rast(rast) }else if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;rast&#39; must be a SpatRaster from the `terra` package&quot;) } # check if band indices are valid num_bands &lt;- terra::nlyr(rast) # let 999999 be a cheat code cheat_code &lt;- 999999 if( ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &gt; num_bands ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &gt; num_bands ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &gt; num_bands ) || ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &lt; 1 ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &lt; 1 ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &lt; 1 ) || length(unique(c(red_band_idx,green_band_idx,blue_band_idx)))!=3 ){ stop(&quot;Invalid band index provided. Band indices must correspond to existing, unique layers in the raster object.&quot;) } # extract bands if(red_band_idx!=cheat_code){ R &lt;- rast[[red_band_idx]] }else{ R &lt;- rast[[1]] } if(green_band_idx!=cheat_code){ G &lt;- rast[[green_band_idx]] }else{ G &lt;- rast[[1]] } if(blue_band_idx!=cheat_code){ B &lt;- rast[[blue_band_idx]] }else{ B &lt;- rast[[1]] } return(list(R = R, G = G, B = B)) } # check_raster_bands(ortho_rast, red_band_idx=1, green_band_idx=3, blue_band_idx = 999999) # convert RGB to HSV color space spectral_rgb_to_hsv &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { # check bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # convert to RGB rgb_rast &lt;- terra::RGB(x = c(R,G,B), value = 1:3) # ?terra::colorize # convert to HSV (returns layers: h, s, v) hsv_rast &lt;- terra::colorize(rgb_rast, to = &quot;hsv&quot;) # names names(hsv_rast) &lt;- c(&quot;hue&quot;, &quot;saturation&quot;, &quot;brightness&quot;) # scale only the hue layer to 360 # hsv_rast$hue &lt;- hsv_rast$hue*360 return(hsv_rast) } # convert RGB to CIELab color space # ?grDevices::convertColor spectral_rgb_to_lab &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx, max_dn = 255) { # check bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B rgb_rast &lt;- c(R,G,B) # values as a matrix (vectorized) normalized to max 255 val vals &lt;- terra::values(rgb_rast) / max_dn # conversion on the matrix lab_vals &lt;- grDevices::convertColor(vals, from = &quot;sRGB&quot;, to = &quot;Lab&quot;) # new SpatRaster using original str and replace values lab_rast &lt;- terra::rast(rgb_rast, nlyrs = 3) terra::values(lab_rast) &lt;- lab_vals names(lab_rast) &lt;- c(&quot;L&quot;, &quot;a&quot;, &quot;b&quot;) return(lab_rast) } # calculate green red vegetation index (GRVI) # (G - R) / (G + R) spectral_index_grvi &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G grvi &lt;- (G - R) / (G + R) names(grvi) &lt;- &quot;grvi&quot; return(grvi) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # red green ratio index (RGRI) # R/G spectral_index_rgri &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G rgri &lt;- R/G names(rgri) &lt;- &quot;rgri&quot; return(rgri) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # calculate visible band-difference vegetation index (VDVI) # (2G - R - B) / (2G + R + B) spectral_index_vdvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B vdvi &lt;- (2 * G - R - B) / (2 * G + R + B) names(vdvi) &lt;- &quot;vdvi&quot; return(vdvi) } # spectral_index_vdvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate red green blue vegetation index (RGBVI) # (G^2 - (B * R)) / (G^2 + (B * R)) spectral_index_rgbvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B rgbvi &lt;- (G^2 - (B * R)) / (G^2 + (B * R)) names(rgbvi) &lt;- &quot;rgbvi&quot; return(rgbvi) } # spectral_index_rgbvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excess green (ExG) # (2G - R - B) / (R + G + B) (using normalized RGB values) # 2G - R - B (using raw values, then normalized by sum of R+G+B) spectral_index_exg &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exg &lt;- (2 * g_norm - r_norm - b_norm) names(exg) &lt;- &quot;exg&quot; return(exg) } # spectral_index_exg(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate brightness index (BI) # sqrt((R^2 + G^2 + B^2) / 3) spectral_index_bi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B bi &lt;- sqrt((R^2 + G^2 + B^2) / 3) # normalize to 0-1 range max_brightness = max( terra::minmax(R)[2] , terra::minmax(G)[2] , terra::minmax(B)[2] , na.rm = T ) bi &lt;- bi/max_brightness names(bi) &lt;- &quot;bi&quot; return(bi) } # spectral_index_bi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excessive red (ExR) # 1.4r - g, where r and g are normalized RGB values. spectral_index_exr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx){ bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb exr &lt;- (1.4 * r_norm - g_norm) names(exr) &lt;- &quot;exr&quot; return(exr) } #&#39; calculate excess green-excess red (ExGR) #&#39; 3g - 2.4r - b, where r, g, b are normalized RGB values. #&#39; equivalent to ExG - ExR. spectral_index_exgr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exgr &lt;- (3 * g_norm - 2.4 * r_norm - b_norm) names(exgr) &lt;- &quot;exgr&quot; return(exgr) } # calculate saturation (SAT) # (max(R,G,B) - min(R,G,B)) / max(R,G,B) spectral_index_saturation &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B max_rgb &lt;- max(R, G, B, na.rm = T) min_rgb &lt;- min(R, G, B, na.rm = T) sat &lt;- (max_rgb - min_rgb) / max_rgb names(sat) &lt;- &quot;sat&quot; return(sat) } # spectral_index_saturation(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate all indices calculate_all_rgb_indices &lt;- function(raster_obj, red_band_idx, green_band_idx, blue_band_idx) { # call individual index functions grvi_layer &lt;- spectral_index_grvi(raster_obj, red_band_idx, green_band_idx) rgri_layer &lt;- spectral_index_rgri(raster_obj, red_band_idx, green_band_idx) vdvi_layer &lt;- spectral_index_vdvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) rgbvi_layer &lt;- spectral_index_rgbvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exg_layer &lt;- spectral_index_exg(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exr_layer &lt;- spectral_index_exr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exgr_layer &lt;- spectral_index_exgr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # bi_layer &lt;- spectral_index_bi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # sat_layer &lt;- spectral_index_saturation(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # color spaces: HSV hsv_rast &lt;- spectral_rgb_to_hsv(raster_obj, red_band_idx, green_band_idx, blue_band_idx) names(hsv_rast) &lt;- paste0(&quot;hsv_&quot;, names(hsv_rast), recycle0 = T) hsv_hue &lt;- hsv_rast$hsv_hue hsv_saturation &lt;- hsv_rast$hsv_saturation hsv_brightness &lt;- hsv_rast$hsv_brightness # color spaces: CEILab Lab_rast &lt;- spectral_rgb_to_lab(raster_obj, red_band_idx, green_band_idx, blue_band_idx) names(Lab_rast) &lt;- paste0(&quot;Lab_&quot;, names(Lab_rast), recycle0 = T) Lab_L &lt;- Lab_rast$Lab_L Lab_a &lt;- Lab_rast$Lab_a Lab_b &lt;- Lab_rast$Lab_b # stack all calculated indices into a single spatraster all_indices &lt;- c( grvi_layer , rgri_layer , vdvi_layer , rgbvi_layer , exg_layer , exr_layer , exgr_layer # , bi_layer # , sat_layer , hsv_hue , hsv_saturation , hsv_brightness , Lab_L , Lab_a , Lab_b ) return(all_indices) } let’s test this calculate_all_rgb_indices() function with our orthomosaic # calculate_all_rgb_indices all_rgb_indices_rast &lt;- calculate_all_rgb_indices(aoi_rgb_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) what did we get? # huh? all_rgb_indices_rast %&gt;% names() ## [1] &quot;grvi&quot; &quot;rgri&quot; &quot;vdvi&quot; &quot;rgbvi&quot; ## [5] &quot;exg&quot; &quot;exr&quot; &quot;exgr&quot; &quot;hsv_hue&quot; ## [9] &quot;hsv_saturation&quot; &quot;hsv_brightness&quot; &quot;Lab_L&quot; &quot;Lab_a&quot; ## [13] &quot;Lab_b&quot; we’ll limit to the indices we have thresholds for all_rgb_indices_rast &lt;- all_rgb_indices_rast %&gt;% terra::subset( c( &quot;grvi&quot; , &quot;rgri&quot; , &quot;vdvi&quot; , &quot;exgr&quot; , &quot;Lab_a&quot; , &quot;hsv_hue&quot; ) ) let’s plot all of those indices for the entire extent of our orthomoasic # plot terra::plot( all_rgb_indices_rast , nc = 3 # , nr = 3 , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F # , col = grDevices::gray.colors(n=111) ) we can also look at the correlation between the different indices # investigate correlation among covariates all_rgb_indices_rast %&gt;% terra::pairs( maxcells = min(11111, terra::ncell(all_rgb_indices_rast)*.01) ) many of these spectral indices are highly (even perfectly) correlated, meaning they provide redundant information. however, the index thresholds were determined independently for the most highly correlated values so we retain them for our voting system filtering methodology since the combination of the index with the unique index provides unique identification functionality. summary stats of these indices over our example area all_rgb_indices_rast %&gt;% terra::summary(size = min(11111, terra::ncell(all_rgb_indices_rast)*.01)) ## grvi rgri vdvi exgr ## Min. :-0.27500 Min. :0.5890 Min. :-0.166224 Min. :-0.57562 ## 1st Qu.:-0.04377 1st Qu.:0.9607 1st Qu.:-0.016255 1st Qu.:-0.19027 ## Median :-0.02054 Median :1.0419 Median :-0.004388 Median :-0.15605 ## Mean :-0.01061 Mean :1.0267 Mean : 0.011658 Mean :-0.12931 ## 3rd Qu.: 0.02003 3rd Qu.:1.0916 3rd Qu.: 0.024418 3rd Qu.:-0.09614 ## Max. : 0.25861 Max. :1.7586 Max. : 0.320572 Max. : 0.54519 ## NA&#39;s :11 NA&#39;s :11 NA&#39;s :11 NA&#39;s :11 ## Lab_a hsv_hue ## Min. :-31.14243 Min. :0.000029 ## 1st Qu.: -1.54772 1st Qu.:0.061810 ## Median : 1.03632 Median :0.126905 ## Mean : 0.04067 Mean :0.251398 ## 3rd Qu.: 3.41652 3rd Qu.:0.293970 ## Max. : 15.66249 Max. :0.999958 ## NA&#39;s :11 NA&#39;s :11 the terra::colorize() function produces Hue values normalized to the [0, 1] range; we can convert these normalized values to the [0, 360] range: (all_rgb_indices_rast$hsv_hue*360) %&gt;% terra::plot(main=&quot;Hue [0,360] range&quot;, axes = F, mar = c(0,0,2,0)) here is a plot of the different spectral indices (high values are brighter, low values are darker) on our example area we were working with in the last section with the demonstration piles in blue all_rgb_indices_rast %&gt;% terra::plot( nc = 3 , col = grDevices::gray.colors(111, start = 0, end = 1) , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F , fun = function(){ lines(terra::vect(aoi_boundary), col=&quot;black&quot;, lwd=2) # add a second vector outline (blue) lines( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , col = &quot;blue&quot;, lwd = 1.3) } ) for a refresher, here is the demonstration RGB image with the image annotated piles (blue) terra::plotRGB(aoi_rgb_rast) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.3 ) 5.1.2 Spectral Index of Polygons we now need a function to crop the raster with all spectral indices given a polygon input data and return the spectral index values as columns attached to the polygon extract_rast_values &lt;- function(sf_data, rast, fun_agg = mean) { # checks if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } if(!is.function(fun_agg)) { stop(&quot;Argument `fun_agg` must be a function (e.g., mean, median, sum).&quot;) } # crs sf_data &lt;- sf_data %&gt;% sf::st_transform(terra::crs(rast)) # extract values for each layer within each polygon extracted_values &lt;- terra::extract( x = rast , y = sf_data , fun = fun_agg , na.rm = TRUE ) # clean data fun_name &lt;- deparse(substitute(fun_agg)) extracted_values &lt;- extracted_values %&gt;% dplyr::select(-ID) %&gt;% dplyr::rename_with( ~ paste0( &quot;rast_&quot; # , fun_name ### if we want to have custom output depending on the fun_agg , &quot;agg&quot; , &quot;_&quot; , .x , recycle0 = TRUE ) ) # Merge the extracted values back to the original sf data frame # The row order is preserved by terra::extract, so a direct cbind is safe # if no rows were dropped due to spatial mismatch. # For robustness, we can explicitly join by row ID if needed, but for simple cases, cbind works. # Assuming sf_data has a unique ID column or row order is stable: sf_data_with_indices &lt;- sf_data %&gt;% dplyr::bind_cols(extracted_values) return(sf_data_with_indices) } 5.2 Demonstration Pile Spectral Summary let’s calculate the various spectral indices on our demonstration slash pile polygons by getting the median value within the bounds of the pile # extract_rast_values rgb_indices_df &lt;- extract_rast_values(aoi_slash_piles_polys, rast = all_rgb_indices_rast, fun_agg = median) %&gt;% # convert hue to 0-360 dplyr::rename(rast_agg_hsv_hue_01=rast_agg_hsv_hue) %&gt;% dplyr::mutate(rast_agg_hsv_hue = rast_agg_hsv_hue_01*360) rgb_indices_df %&gt;% dplyr::glimpse() ## Rows: 17 ## Columns: 27 ## $ pile_id &lt;dbl&gt; 3, 4, 5, 6, 11, 13, 17, 19, 20, 21, 22, 23, 24, 29… ## $ site &lt;chr&gt; &quot;PSINF Mixed Conifer Site&quot;, &quot;PSINF Mixed Conifer S… ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F… ## $ comment &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ height_ft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ diameter_ft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ xcoord &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ ycoord &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ refcorner &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ row_number &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499341.7 4317759,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 6.469934, 6.867876, 6.387723, 6.589466, 5.482888, … ## $ field_height_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_diameter_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_area_m2 &lt;dbl&gt; 25.166539, 32.028082, 22.928349, 26.261937, 20.184… ## $ field_gt_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ rast_agg_grvi &lt;dbl&gt; -0.032770754, -0.028380480, -0.052833877, -0.04832… ## $ rast_agg_rgri &lt;dbl&gt; 1.0677621, 1.0584189, 1.1115620, 1.1015627, 1.0571… ## $ rast_agg_vdvi &lt;dbl&gt; -0.01948794, -0.02056626, -0.02798897, -0.02466490… ## $ rast_agg_exgr &lt;dbl&gt; -0.1868011, -0.1832732, -0.2167072, -0.2087036, -0… ## $ rast_agg_Lab_a &lt;dbl&gt; 3.3675173, 3.2561641, 4.2656566, 4.0006617, 3.0351… ## $ rast_agg_hsv_hue_01 &lt;dbl&gt; 0.8723564, 0.8332400, 0.6569343, 0.7332149, 0.5626… ## $ rast_agg_hsv_hue &lt;dbl&gt; 314.0483, 299.9664, 236.4963, 263.9574, 202.5427, … # quick summary rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% summary() ## rast_agg_grvi rast_agg_rgri rast_agg_vdvi rast_agg_exgr ## Min. :-0.052834 Min. :0.8950 Min. :-0.03551 Min. :-0.2167 ## 1st Qu.:-0.028380 1st Qu.:0.9855 1st Qu.:-0.02799 1st Qu.:-0.1833 ## Median :-0.018569 Median :1.0378 Median :-0.02057 Median :-0.1694 ## Mean :-0.009339 Mean :1.0209 Mean :-0.02271 Mean :-0.1688 ## 3rd Qu.: 0.007320 3rd Qu.:1.0584 3rd Qu.:-0.01693 3rd Qu.:-0.1533 ## Max. : 0.055409 Max. :1.1116 Max. :-0.01214 Max. :-0.1203 ## rast_agg_Lab_a rast_agg_hsv_hue_01 rast_agg_hsv_hue ## Min. :0.3379 Min. :0.5626 Min. :202.5 ## 1st Qu.:0.8788 1st Qu.:0.6205 1st Qu.:223.4 ## Median :2.2162 Median :0.7208 Median :259.5 ## Mean :2.1987 Mean :0.7153 Mean :257.5 ## 3rd Qu.:3.2562 3rd Qu.:0.8054 3rd Qu.:289.9 ## Max. :4.2657 Max. :0.9026 Max. :324.9 let’s plot it # pivot agg_df_temp &lt;- rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::select(-rast_agg_hsv_hue_01) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;rast_agg_&quot;) %&gt;% stringr::str_to_upper()) # plot ggplot2::ggplot() + ggplot2::geom_density( data = agg_df_temp , mapping = ggplot2::aes(x = value, fill = name) , color = NA, alpha = 0.8 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=median(value,na.rm=T)) , mapping = ggplot2::aes(xintercept = value, color = &quot;median&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=0.025)) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=(1-0.025))) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::scale_fill_viridis_d(option = &quot;turbo&quot;, begin = 0.1, end = 0.9, alpha = 0.7) + # ggplot2::scale_fill_brewer(palette = &quot;Set2&quot;) + ggplot2::scale_color_manual(values = c(&quot;gray22&quot;,&quot;gray&quot;,&quot;gray&quot;)) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(8)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 3 , scales = &quot;free&quot; ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() ) + ggplot2::guides(fill = &quot;none&quot;) that’s interesting. compare those values with the thresholds identified in the research listed in the table above here is a plot of the median value of the different spectral indices (high values are brighter, low values are darker) within the bounds of the pile on our example area we were working with in the last section polys_temp &lt;- rgb_indices_df %&gt;% sf::st_transform(sf::st_crs(aoi_boundary)) %&gt;% dplyr::select(pile_id, tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;rast_agg_hsv_hue_01&quot; ))) %&gt;% tidyr::pivot_longer(cols = tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::mutate(name = stringr::str_remove(name,&quot;rast_agg_&quot;)) # # dplyr::filter(name==&quot;grvi&quot;) %&gt;% # ggplot2::ggplot() + # ggplot2::geom_sf(mapping=ggplot2::aes(fill=value)) + # ggplot2::facet_wrap(facets=dplyr::vars(name)) + # ggplot2::theme_void() + # ggplot2::theme(legend.position = &quot;top&quot;) # rast clip rast_temp &lt;- all_rgb_indices_rast %&gt;% terra::crop(aoi_boundary %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) %&gt;% terra::mask(aoi_boundary %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) # plot list plt_list_temp &lt;- # names(all_rgb_indices_rast) %&gt;% &quot;hsv_hue&quot; %&gt;% # sample(6) %&gt;% purrr::map( \\(x) ggplot2::ggplot() + ggplot2::geom_tile( data = rast_temp[[x]] %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x = x, y = y, fill = f) , alpha = 0.9 ) + ggplot2::geom_sf( data = aoi_boundary , color = &quot;black&quot;, fill = NA, lwd = 0.8 ) + ggplot2::geom_sf( data = polys_temp %&gt;% dplyr::filter(name == x) # , mapping = ggplot2::aes(fill=value) , color = &quot;blue&quot;, lwd = 0.6 ) + ggrepel::geom_text_repel( data = polys_temp %&gt;% dplyr::filter(name == x) %&gt;% sf::st_point_on_surface() %&gt;% dplyr::mutate( x_coord = sf::st_coordinates(.)[, 1] , y_coord = sf::st_coordinates(.)[, 2] ) , mapping = ggplot2::aes( x = x_coord , y = y_coord , label = dplyr::case_when( name == &quot;hsv_hue&quot; ~ scales::comma(value, accuracy=1) , T ~ scales::comma(value, accuracy=0.01) ) , fontface = &quot;bold&quot; ) , nudge_x = 0.5 # initial horizontal nudge , nudge_y = -0.2 # initial vertical nudge , size = 2.2, color = &quot;blue&quot; , force = 1 , box.padding = 0.3 # Increase padding to push labels further away # , point.padding = 0.7 # Ensure distance from the original point , min.segment.length = 0.5 # Minimum length of the connecting line segment , segment.color = NA ) + ggplot2::scale_fill_distiller(palette = &quot;Greys&quot;) + # ggplot2::scale_fill_gradientn(colors = grDevices::gray.colors(111, start = 0, end = 1)) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( fill = x , subtitle = x ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; , plot.subtitle = ggplot2::element_text(size = 11, face = &quot;bold&quot;, hjust = 0.5) ) ) # plt_list_temp # patchwork patchwork::wrap_plots( plt_list_temp , ncol = 3 ) 5.2.1 Voting System let’s consider a voting system approach for filtering candidate slash piles using the multiple spectral indices. a voting system could allow for a more robust and nuanced decision than relying on a single index. let’s make a highly specialized function using the data returned by out extract_rast_values() function ########################################################## #### function to validate threshold vector or list pair ########################################################## validate_thresholds_fn &lt;- function(th_list) { # input is a list or a numeric vector if (!is.list(th_list) &amp;&amp; !is.numeric(th_list)) { stop(&quot;Validation Error: Input must be a list of pairs or a single numeric vector pair.&quot;) } # to a list to standardize the purrr::map iteration items_to_check &lt;- if(is.list(th_list)){ th_list }else{ list(th_list) } # validate logic on each pair purrr::map(items_to_check, function(x) { # numeric type if (!is.numeric(x)) { stop(&quot;Validation Error: Threshold elements must be numeric.&quot;) } # length is exactly 2 if (length(x) != 2) { stop(paste(&quot;Validation Error: Pair must have exactly 2 values. Found length:&quot;, length(x))) } # order (lower &lt; upper) if (x[1] &gt;= x[2]) { stop(paste0(&quot;Validation Error: Lower limit must be smaller than upper limit. Found: [&quot;, x[1], &quot;, &quot;, x[2], &quot;]&quot;)) } }) # 4. If all checks passed (no stop triggered), return the original input return(th_list) } ########################################################## # function to filter a data frame by a list pair and column ########################################################## filter_by_thresholds_fn &lt;- function(df, target_col, th_list) { # col exists? if (!(target_col %in% names(df))) { stop(paste0(&quot;Column &#39;&quot;, target_col, &quot;&#39; not found in the data frame&quot;)) } # validate the thresholds using previous function valid_th &lt;- validate_thresholds_fn(th_list) # thresholds to a list if a single vector was provided th_pairs &lt;- if(is.list(valid_th)){ valid_th }else{ list(valid_th) } # use purrr::map to create a list of logical vectors (one for each pair) # then reduce them with &#39;|&#39; so any row hitting any range is kept df %&gt;% dplyr::mutate( is_inrange = purrr::map(th_pairs, function(x) { dplyr::between(.data[[target_col]], x[1], x[2]) }) %&gt;% purrr::reduce(`|`) %&gt;% as.integer() ) # dplyr::filter( # purrr::map( # th_pairs # , function(x) { # dplyr::between(.data[[target_col]], x[1], x[2]) # } # ) %&gt;% # purrr::reduce(`|`) # ) } # filter_by_thresholds_fn( # rgb_indices_df # , target_col = &quot;rast_agg_hsv_hue&quot; # # , th_list = c(275,Inf) # , th_list = list(c(0,210), c(275,Inf)) # # , th_list = c(275,207) # ) %&gt;% # ggplot2::ggplot(aes(x=rast_agg_hsv_hue,y=0,color=as.factor(is_inrange))) + ggplot2::geom_jitter() # # filter_by_thresholds_fn( # rgb_indices_df # , target_col = &quot;rast_agg_hsv_hue&quot; # # , th_list = c(275,Inf) # , th_list = list(c(0,210), c(275,Inf)) # # , th_list = c(275,207) # ) %&gt;% # dplyr::glimpse() # voting system rgb_indices_threshold_voting &lt;- function( rgb_indices_df # define ranges to *keep* piles , th_grvi = c(-Inf,0) , th_rgri = c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_vdvi = c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_exgr = c(-Inf,0) , th_a = c(-5+0.001,Inf) , th_hue = list(c(0,50-0.001), c(150+0.001,Inf)) ){ # checks if(!inherits(rgb_indices_df, &quot;data.frame&quot;)){ stop(&quot;Input `rgb_indices_df` must be an data.frame.&quot;) } # names agg_cols &lt;- c(&quot;rast_agg_grvi&quot;,&quot;rast_agg_exgr&quot;,&quot;rast_agg_rgri&quot;,&quot;rast_agg_vdvi&quot;,&quot;rast_agg_Lab_a&quot;,&quot;rast_agg_hsv_hue&quot;) # &quot;rast_agg_rgbvi&quot;, nm_diff &lt;- base::setdiff( agg_cols , names(rgb_indices_df) ) if(length(nm_diff)&gt;0){ stop(paste0(&quot;required variables missing:\\n&quot;, &quot;... &quot;, paste(nm_diff, collapse = &quot;, &quot;) )) } # thresholds safe_validate_thresholds_fn &lt;- purrr::safely(validate_thresholds_fn) # th_grvi chk_grvi &lt;- safe_validate_thresholds_fn(th_grvi) if(is.null(chk_grvi$result)){ stop(paste0(&quot;Input `th_grvi`: &quot;, chk_grvi$error)) } # th_rgri chk_rgri &lt;- safe_validate_thresholds_fn(th_rgri) if(is.null(chk_rgri$result)){ stop(paste0(&quot;Input `th_rgri`: &quot;, chk_rgri$error)) } # th_vdvi chk_vdvi &lt;- safe_validate_thresholds_fn(th_vdvi) if(is.null(chk_vdvi$result)){ stop(paste0(&quot;Input `th_vdvi`: &quot;, chk_vdvi$error)) } # th_exgr chk_exgr &lt;- safe_validate_thresholds_fn(th_exgr) if(is.null(chk_exgr$result)){ stop(paste0(&quot;Input `th_exgr`: &quot;, chk_exgr$error)) } # th_a chk_a &lt;- safe_validate_thresholds_fn(th_a) if(is.null(chk_a$result)){ stop(paste0(&quot;Input `th_a`: &quot;, chk_a$error)) } # th_hue chk_hue &lt;- safe_validate_thresholds_fn(th_hue) if(is.null(chk_hue$result)){ stop(paste0(&quot;Input `th_hue`: &quot;, chk_hue$error)) } # get rid of columns we&#39;ll create rgb_indices_df &lt;- rgb_indices_df %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;is_inrange&quot; , &quot;inrange_th_grvi&quot; , &quot;inrange_th_rgri&quot; , &quot;inrange_th_vdvi&quot; , &quot;inrange_th_exgr&quot; , &quot;inrange_th_a&quot; , &quot;inrange_th_hue&quot; ))) # check threshold ret_df &lt;- rgb_indices_df %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_grvi&quot;, th_list = th_grvi) %&gt;% dplyr::rename(inrange_th_grvi=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_rgri&quot;, th_list = th_rgri) %&gt;% dplyr::rename(inrange_th_rgri=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_vdvi&quot;, th_list = th_vdvi) %&gt;% dplyr::rename(inrange_th_vdvi=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_exgr&quot;, th_list = th_exgr) %&gt;% dplyr::rename(inrange_th_exgr=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_Lab_a&quot;, th_list = th_a) %&gt;% dplyr::rename(inrange_th_a=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_hsv_hue&quot;, th_list = th_hue) %&gt;% dplyr::rename(inrange_th_hue=is_inrange) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( inrange_th_votes = sum( dplyr::c_across(tidyselect::starts_with(&quot;inrange_th_&quot;)) , na.rm = T ) %&gt;% dplyr::coalesce(0) ) %&gt;% ungroup() #return return(ret_df) } let’s look at the columns we get from our rgb_indices_threshold_voting() function rgb_indices_df &lt;- rgb_indices_threshold_voting(rgb_indices_df=rgb_indices_df) # huh? rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% summary() ## inrange_th_grvi inrange_th_rgri inrange_th_vdvi inrange_th_exgr inrange_th_a ## Min. :0.0000 Min. :1 Min. :1 Min. :1 Min. :1 ## 1st Qu.:0.0000 1st Qu.:1 1st Qu.:1 1st Qu.:1 1st Qu.:1 ## Median :1.0000 Median :1 Median :1 Median :1 Median :1 ## Mean :0.7059 Mean :1 Mean :1 Mean :1 Mean :1 ## 3rd Qu.:1.0000 3rd Qu.:1 3rd Qu.:1 3rd Qu.:1 3rd Qu.:1 ## Max. :1.0000 Max. :1 Max. :1 Max. :1 Max. :1 ## inrange_th_hue inrange_th_votes ## Min. :1 Min. :5.000 ## 1st Qu.:1 1st Qu.:5.000 ## Median :1 Median :6.000 ## Mean :1 Mean :5.706 ## 3rd Qu.:1 3rd Qu.:6.000 ## Max. :1 Max. :6.000 notice the “Mean” value in the summary above is the proportion of demonstration piles that successfully met the spectral index threshold criteria (i.e. piles to be “kept”). it looks like the GRVI threshold was most unaligned with these demonstration piles, something we anticipated by looking at the distributions above compared the threshold value recommended in the literature for detecting green vegetation. let’s look at the proportional distribution of demonstration piles meeting the threshold by individual spectral index rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::filter(name!=&quot;VOTES&quot;) %&gt;% dplyr::count(name,value) %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate( pct = n/sum(n) , value = factor(value, levels = 0:1, labels = c(&quot;outside threshold&quot;,&quot;within threshold&quot;), ordered = T) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 3, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;magma&quot;, begin = 0.3, end = 0.7) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 2 ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) and let’s look at the distribution of demonstration piles based on the number of individual spectral index thresholds met. we’ll use this count as our voting system. dplyr::tibble(value=0:6) %&gt;% dplyr::left_join( rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_votes&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::count(name,value) , by = dplyr::join_by(value) ) %&gt;% dplyr::mutate( n = dplyr::coalesce(n,0) , pct = n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) , value = factor(value) , cum_pct = cumsum(pct) , cum_pct_lab = scales::percent(cum_pct,accuracy=0.1) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 4, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;mako&quot;, direction=-1) + ggplot2::scale_y_continuous( labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.15)) ) + ggplot2::labs( y = &quot;&quot;, x = &quot;spectral index threshold votes&quot;, fill = &quot;&quot; , subtitle = &quot;distribution of demonstration piles meeting spectral index thresholds&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) we can use this spectral index voting system to filter candidate slash piles with a user-defined parameter which defines the sensitivity of filtering based on the spectral information. For example, a value of “6” would heavily weight the spectral information in determining which piles to keep while a value of “1” would put less weight on the spectral data. 5.3 Candidate Polygon Spectral Filtering Function let’s put all of this together to define a function that takes as input: 1) a spatial data frame of candidate polygons; 2) a raster with RGB spectral data; 3) user-defined spectral weighting (voting system) polygon_spectral_filtering &lt;- function( sf_data , rgb_rast # define the band index , red_band_idx , green_band_idx , blue_band_idx # spectral weighting , spectral_weight = 3 # return unfiltered or filtered , filter_return = T ) { if(!inherits(filter_return,&quot;logical&quot;)){ stop(&quot;Input `filter_return` should be logical: T to filter return based on the `spectral_weight` or F to return the full `sf_data`&quot;) } # ### could make these parameters # th_grvi &lt;- c(-Inf,0) # th_rgri &lt;- c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper # th_vdvi &lt;- c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper # th_exgr &lt;- c(-Inf,0) # th_a &lt;- c(-5+0.001,Inf) # th_hue &lt;- list(c(0,50-0.001), c(150+0.001,Inf)) # checks if(!inherits(rgb_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } spectral_weight &lt;- as.numeric(spectral_weight) if( filter_return &amp;&amp; ( is.na(spectral_weight) || is.null(spectral_weight) || is.nan(spectral_weight) || !(spectral_weight %in% c(0:6)) ) ){ stop(&quot;Input `spectral_weight` must be a number between 0 (no filtering based on spectral) and 6 (highest weighting of spectral data)&quot;) } # if you don&#39;t want to do it, then why do it? if( filter_return &amp;&amp; dplyr::coalesce(spectral_weight,0)==0 ){ return(sf_data) } ################################################## # calculate_all_rgb_indices ################################################## all_rgb_indices_rast &lt;- calculate_all_rgb_indices( raster_obj = rgb_rast , red_band_idx = red_band_idx , green_band_idx = green_band_idx , blue_band_idx = blue_band_idx ) ################################################## # limit to the indices we have thresholds for ################################################## some_rgb_indices_rast &lt;- all_rgb_indices_rast %&gt;% terra::subset( c( &quot;grvi&quot; , &quot;rgri&quot; , &quot;vdvi&quot; , &quot;exgr&quot; , &quot;Lab_a&quot; , &quot;hsv_hue&quot; ) ) ################################################## # extract_rast_values ################################################## rgb_indices_df &lt;- extract_rast_values( sf_data = sf_data %&gt;% dplyr::ungroup() , rast = some_rgb_indices_rast , fun_agg = median ) ################################################## # rgb_indices_threshold_voting ################################################## rgb_indices_df &lt;- rgb_indices_threshold_voting( rgb_indices_df=rgb_indices_df # , th_grvi = th_grvi # , th_rgri = th_rgri # , th_vdvi = th_vdvi # , th_exgr = th_exgr # , th_a = th_a # , th_hue = th_hue ) ################################################## # filtering ################################################## if(filter_return){ rgb_indices_df &lt;- rgb_indices_df %&gt;% dplyr::filter(inrange_th_votes&gt;=spectral_weight) } # return return(list( segs_sf = rgb_indices_df , rgb_indices_rast = all_rgb_indices_rast )) } # polygon_spectral_filtering( # sf_data = slash_piles_polys # , rgb_rast = ortho_rast # , red_band_idx = 1 # , green_band_idx = 2 # , blue_band_idx = 3 # , spectral_weight = 4 # ) %&gt;% # nrow() # # dplyr::glimpse() # nrow(slash_piles_polys) 5.4 Data Fusion Method Demonstration we previously worked through an example where we identified candidate slash piles based on their structural form using our raster-based segmentation approach. we’re going to use that demonstration area, apply the slash_pile_detect() function to detect candidate slash piles from the CHM data based on expected size and geometric properties, and then integrate the spectral filtering method we defined above. for this demonstration, we’ll use the DBSCAN segmentation method with slightly less strict size and geometric thresholds than we used in the previous section # structurally predicted from chm slash_pile_detect_dbscan_ans_temp &lt;- slash_pile_detect( chm_rast = aoi_chm_rast , seg_method = &quot;dbscan&quot; , min_ht_m = 1 , max_ht_m = 5 , min_area_m2 = 1.5 , max_area_m2 = 50 , min_convexity_ratio = 0.4 , min_circularity_ratio = 0.3 ) let’s overlay the structural candidate segments (brown) and the actual piles (blue) on the raw, un-filtered CHM aoi_chm_rast %&gt;% # slash_pile_detect_dbscan_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), mar = c(0,0,0,0)) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_dbscan_ans_temp$segs_sf %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 2.5 ) now overlay the structural candidate segments (brown) and the actual piles (blue) on the RGB aoi_rgb_rast %&gt;% terra::plotRGB(axes = F, mar = c(0,0,0,0), stretch = &quot;lin&quot;) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_dbscan_ans_temp$segs_sf %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 2.5 ) notice there are lower portions of trees that are proposed as candidate segments given our less strict size and geometric filters Remember, our data fusion method uses the spectral data strictly as a final filter or quality check on the structurally-detected candidate piles, meaning it neither adds new piles nor alters the shape or location of the candidates. As a result, if the structural detection step missed a pile (false negative or omission), the spectral data won’t go back and fix it. The only changes we can expect by including spectral data in our data fusion approach is a trade-off: we can either improve our precision by successfully removing detections that aren’t actually piles (commissions or false positives), or we run the risk of mistakenly filtering out real piles (true positives) if their spectral signature happens to look unusual, which would unfortunately lower our recall. let’s apply our spectral filtering method to the set of structurally-detected piles but we’ll leave the return unfiltered (filter_return=F) so that we can see which candidate piles would have been filtered and why depending on the spectral_weight setting which defines how many of the six spectral thresholds must be met for a candidate pile to be retained given filter_return=T # names(aoi_rgb_rast) slash_pile_detect_spec_filt_temp &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_dbscan_ans_temp$segs_sf , rgb_rast = aoi_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # leave return unfiltered , filter_return = F ) what did we get? # huh? slash_pile_detect_spec_filt_temp %&gt;% dplyr::glimpse() ## List of 2 ## $ segs_sf : sf [20 × 22] (S3: sf/tbl_df/tbl/data.frame) ## ..$ pred_id : num [1:20] 3 4 19 32 35 36 37 40 51 60 ... ## ..$ convexity_ratio : num [1:20] 0.931 0.929 0.938 0.9 0.928 ... ## ..$ circularity_ratio: num [1:20] 0.671 0.73 0.477 0.641 0.733 ... ## ..$ area_m2 : num [1:20] 8.33 6.18 5.28 5.51 8.06 ... ## ..$ volume_m3 : num [1:20] 6.66 3.13 5.52 3.25 4.45 ... ## ..$ max_height_m : num [1:20] 1.73 1.15 2.58 1.5 1.53 ... ## ..$ volume_per_area : num [1:20] 0.799 0.506 1.047 0.589 0.553 ... ## ..$ geometry :sfc_POLYGON of length 20; first list element: List of 1 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## ..$ diameter_m : num [1:20] 3.83 3.14 3.63 3.14 3.54 ... ## ..$ rast_agg_grvi : num [1:20] -0.0119 -0.0409 0.0237 0.0274 0.0542 ... ## ..$ rast_agg_rgri : num [1:20] 1.024 1.085 0.954 0.947 0.897 ... ## ..$ rast_agg_vdvi : num [1:20] -0.0189 -0.0238 0.0105 -0.0344 -0.0292 ... ## ..$ rast_agg_exgr : num [1:20] -0.1669 -0.2005 -0.0956 -0.1472 -0.1196 ... ## ..$ rast_agg_Lab_a : num [1:20] 1.861 3.781 -0.722 0.778 0.337 ... ## ..$ rast_agg_hsv_hue : num [1:20] 0.716 0.899 0.399 0.63 0.613 ... ## ..$ inrange_th_grvi : int [1:20] 1 1 0 0 0 0 0 1 0 1 ... ## ..$ inrange_th_rgri : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_vdvi : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_exgr : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_a : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_hue : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_votes : num [1:20] 6 6 5 5 5 5 5 6 5 6 ... ## ..- attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## ..- attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA NA ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:21] &quot;pred_id&quot; &quot;convexity_ratio&quot; &quot;circularity_ratio&quot; &quot;area_m2&quot; ... ## $ rgb_indices_rast:S4 class &#39;SpatRaster&#39; [package &quot;terra&quot;] how many piles would be removed if we set a spectral_weight of “5” which requires five of the six spectral thresholds to be met for a candidate pile to be retained # how many piles were removed? nrow(slash_pile_detect_spec_filt_temp$segs_sf)- nrow(slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5)) ## [1] 1 # what proportion were removed? scales::percent( ( nrow(slash_pile_detect_spec_filt_temp$segs_sf)- nrow(slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5)) )/nrow(slash_pile_detect_spec_filt_temp$segs_sf) , accuracy=0.1 ) ## [1] &quot;5.0%&quot; let’s highlight the spectrally filtered segments (orange) with the candidate segments that were retained by the spectral filtering (brown) and the actual piles (blue) on the raw, un-filtered CHM aoi_chm_rast %&gt;% # slash_pile_detect_dbscan_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), mar = c(0,0,0,0)) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5) %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 2.5 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&lt;5) %&gt;% terra::vect() , add = T, border = &quot;orangered&quot;, col = NA, lwd = 2.5 ) now let’s highlight the spectrally filtered segments (orange) with the candidate segments that were retained by the spectral filtering (brown) and the actual piles (blue) on the RGB aoi_rgb_rast %&gt;% terra::plotRGB(axes = F, mar = c(0,0,0,0), stretch = &quot;lin&quot;) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 2.5 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&lt;5) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;orangered&quot;, col = NA, lwd = 2.5 ) in this demonsration area, the spectral filtering of our data fusion approach successfully filtered the structurally detected candidate piles that were clearly lower parts of trees (clearly green in the RGB). however, the spectral filtering failed to remove some false positive predictions that were in shadowed in the RGB imagery. a positive result, though, was that the spectral filtering stage did not remove any true positive predictions. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
