[["index.html", "Aerial Imagery and Point Cloud Data for Slash Pile Quantification Section 1 Introduction 1.1 Objective 1.2 Data 1.3 Analysis Plan", " Aerial Imagery and Point Cloud Data for Slash Pile Quantification George Woolsey 13 November, 2025 Section 1 Introduction Code in support of “Aerial Imagery and Point Cloud Data for Slash Pile Quantification” 1.1 Objective The objective of this study is to demonstrate the use of aerial point cloud data (from SfM photogrammetry) and RGB imagery to identify and quantify slash piles. 1.2 Data We have remote sensing data acquired from a UAS platform and accompanying ground truth data for four different study sites. For all study sites we have: Aerial RGB imagery captured by a UAS platform Aerial point cloud data generated by processing the UAS imagery using structure from motion (SfM) photogrammetry techniques Image-annotated slash pile perimeters digitized in a Geographic Information System (GIS) using field-collected point locations as a guide overlaid on the UAS-collected RGB imagery For the training study site only we have: * Field-collected slash pile point locations with height and diameter measurements Data from the training study site will be used to build and test the slash pile detection and quantification framework. Data from the other study sites will be used to validate the method based on learnings from the training data testing and analysis. The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how the data was collected. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site. Site Name Pile Type Data Use Unique Features &amp; Ecology Data Collection PSINF Ponderosa Pine Training Site Mostly Hand Piles (some smaller machine piles) Training Located in the Pike and San Isabel National Forest (PSINF). Ponderosa pine stand with mixed ground cover and varying canopy density. insert data collection summary TRFO-BLM Pinyon-Juniper Validation Site Hand Piles Validation Located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM). Arid environment with dry vegetation appearing less green including standing dead pinyon-juniper vegetation. Piles are smaller, simpler, and hand-stacked. insert data collection summary BHEF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Black Hills Experimental Forest (BHEF). Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected based on local precipitation and typical regrowth response. insert data collection summary ARNF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Arapahoe and Roosevelt National Forest (ARNF). Ponderosa pine forest with a climate similar to the training site and drier than BHEF. Piles are massive but more circular and regular. Less regeneration is expected due to more recent treatment and drier climate. insert data collection summary 1.3 Analysis Plan This project progressed through several phases to develop and validate a rigorous rules-based methodology for slash pile detection using UAS-collected data. The following summarizes the analysis project upon completion. Phase 1: Methodology Development and Sensitivity Testing This phase involved using ground truth data to perform sensitivity testing on the rules-based detection methodology. We first demonstrated a structural-only method, which uses a CHM raster generated from aerial point cloud data to identify candidate piles based on structural metrics like height, area, and shape. This method can be used when spectral data is unavailable. We then demonstrated a data fusion approach, which builds on the structural method by integrating spectral data as an additional filtering step. This approach takes the structurally-detected candidates and filters out potential false positive predictions by applying a set of spectral index thresholds. We then performed parameter sensitivity testing to systematically vary parameterizations on both approaches and quantify the resulting changes in detection and form quantification accuracy. This sensitivity testing provided a set of individual point estimates of detection accuracy (F-score) and quantification accuracy (e.g. RMSE and MAPE) for each parameter combination tested. These point estimates then served as the input dataset for subsequent statistical modeling to quantify the influence of parameters and input data on accuracy. Phase 2: Statistical Modeling Following sensitivity testing, a Bayesian Generalized Linear Model (GLM) was used to build a statistical framework for understanding the methodology’s performance. Unlike the sensitivity testing, which generate a range of detection and quantification accuracies based on parameter combinations tested, the statistical modeling does not calculate accuracy itself but instead uses these point estimates as dependent variables to statistically model the functional relationship between the tested detection parameters and the resulting accuracy. This provided a principled way to understand uncertainty and the complex interactions between parameters by providing posterior distributions for each parameter estimate rather than simple point estimates as obtained via sensitivity testing. This statistical modeling enabled the quantification of Bayesian credible intervals, which provide a direct measure of the uncertainty in each relationship, and allowed us to explicitly model interactions between parameters (e.g., the combined effect of CHM resolution and spectral data). Understanding these relationships and their associated uncertainty is critical for making more informed and confident decisions about the method’s optimal settings. Phase 3: Method Validation The final phase of this study involves three validation sites to assess the methodology’s real-world generalizability and transferability. Crucially, our detection methodology’s parameter setup (i.e. size, shape, and spectral filters) will be adjusted for each validation site based on its unique treatment and pile construction prescription, mimicking real-life application where optimal settings vary by implementation and forest type. "],["training-data.html", "Section 2 Training Data 2.1 Site Introduction 2.2 Slash Pile Vector Data 2.3 RGB orthomosaic 2.4 Study area imagery 2.5 Point Cloud Data 2.6 Check out one pile", " Section 2 Training Data 2.1 Site Introduction The PSINF ponderosa pine training site is located within the Pike and San Isabel National Forest in Colorado, featuring a characteristic ponderosa pine ecosystem. This site contains a mix of both smaller machine piles and primarily hand-stacked slash piles, representing a spectrum of typical slash pile construction techniques. For this and all other study sites, data were collected via Uncrewed Aircraft Systems (UAS), specifically capturing RGB data to produce two main products via Structure-from-Motion (SfM) processing: an RGB orthomosaic and an SfM point cloud. The data from this site was designated for full methodology development and parameter training of our slash pile detection and quantification workflow. All structural, size, and spectral filters were iteratively tuned using this site to establish the baseline configuration. We also have vector data including ground-truth slash pile point locations with field-measured values of pile height and diameter and image-annotated slash pile perimeters (i.e. polygons). This training data will be used in the development and statistical testing of the methodologies. Load the standard libraries we use to do work # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(corrplot) # correlation plots library(ggnewscale) # new scale library(rayshader) # Visualize Data in 2D and 3D # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data library(rgl) # 3d plots library(cloud2trees) # the cloud2trees library(glcm) # textures of rasters # modelling library(brms) library(tidybayes) 2.2 Slash Pile Vector Data Slash pile field measurements were taken by measuring the height and diameter (longest side of pile) using a laser hypsometer For volume estimation, we’ll model the ground truth slash piles as a paraboloid, specifically a parabolic dome, assuming a perfectly circular base and sides curved smoothly to a peak. Assuming a paraboloid shape is common for quantifying slash pile volume (Hardy 1996; Long &amp; Boston 2014) and may better represent the diverse shapes of real-world slash piles than assuming a conical or half-sphere form. A paraboloid can represent a variety of shapes including those that are taller and more conical, or flatter and more spread out, because it allows the measured height and width to influence the volume calculation independently. This makes the paraboloid potentially more robust for estimating volumes of piles with varying aspect ratios. the volume formula for a paraboloid is: \\[ V = \\frac{1}{8}\\pi \\cdot width^2 \\cdot height \\] # polygons annotated using RGB and field-collected points slash_piles_polys &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/manitou_pile_polys.shp&quot; # &quot;f:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles_Polygons.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::ungroup() %&gt;% dplyr::mutate(treeID = dplyr::row_number()) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID, shape_leng, shape_area)) # slash_piles_polys %&gt;% dplyr::glimpse() # points recorded in field slash_piles_points &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/SlashPiles.shp&quot; # &quot;f:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_zm() %&gt;% sf::st_transform(sf::st_crs(slash_piles_polys)) %&gt;% dplyr::filter( !(objectid %in% c(43)) ) %&gt;% # duplicate field points dplyr::mutate(row_number = dplyr::row_number()) %&gt;% dplyr::select(-c(objectid)) %&gt;% dplyr::rename( height_ft = height , diameter_ft = diameter ) # stand boundary stand_boundary &lt;- sf::st_read(&quot;../data/PFDP_Data/Tree_Data/GIS/PFDP_Boundary.shp&quot;, quiet = T) %&gt;% sf::st_transform(sf::st_crs(slash_piles_polys)) %&gt;% sf::st_union() what is the area of the treatment unit boundaries we are looking over? stand_boundary %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.1) ## [1] &quot;17.5 ha&quot; that’s great let’s check this on the map # mapview::mapview(slash_piles_points, zcol = &quot;comment&quot;, layer.name = &quot;slash piles&quot;) mapview::mapview( stand_boundary , color = &quot;black&quot; , lwd = 1 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE , layer.name = &quot;stand boundary&quot; ) + # mapview::mapview(slash_piles_polys, zcol = &quot;is_in_stand&quot;, layer.name = &quot;&#39;in&#39; slash piles&quot;) + mapview::mapview(slash_piles_polys, col.regions = &quot;navy&quot;, col = NA, layer.name = &quot;pile polys&quot;, legend = FALSE) + mapview::mapview(slash_piles_points, cex = 2, col.regions = &quot;gold&quot;, color = &quot;gold&quot;, layer.name = &quot;pile points&quot;) because each point does not necessarily fall within the polygon boundary (e.g. due to misalignment between the imagery and point locations or slight inaccuracies in either the point or pile boundaries) we need to perform a matching process to tie the points to the polygons so that we get the height and diameter measured during the point collection attached to the polygons. to do this, we’ll use a two-stage process that first attaches the points data frame to polygons where points fall within, using a spatial intersection. It then finds and assigns the remaining, unjoined points to their nearest polygon. The final output includes all polygons from the original data, ensuring that every polygon is represented even if no points were matched. # function to perform a two-step spatial join # first matching points that fall inside polygons and # then assigning the remaining points to the nearest polygon # all original polygons are returned in the final output match_points_to_polygons &lt;- function( points_sf , polygons_sf , point_id , polygon_id ) { # check if point_id column exists in points_sf if (!point_id %in% names(points_sf)) { stop(paste0(&quot;column &#39;&quot;, point_id, &quot;&#39; not found in points_sf.&quot;)) } # check if polygon_id column exists in polygons_sf if (!polygon_id %in% names(polygons_sf)) { stop(paste0(&quot;column &#39;&quot;, polygon_id, &quot;&#39; not found in polygons_sf.&quot;)) } # 1. ensure the crs are the same. if (sf::st_crs(points_sf) != sf::st_crs(polygons_sf)) { points_sf &lt;- sf::st_transform(points_sf, sf::st_crs(polygons_sf)) } # 2. Perform a standard spatial join for points within polygons. # Use an inner join (`left = FALSE`) to get only points that fall inside. points_within &lt;- sf::st_join( x = points_sf , y = polygons_sf , join = sf::st_intersects , left = FALSE ) # 3. Identify points that were not matched in the first step. matched_points_ids &lt;- points_within[[point_id]] unmatched_points &lt;- points_sf[!points_sf[[point_id]] %in% matched_points_ids, ] if (nrow(unmatched_points) &gt; 0) { # 4. For the remaining points, find the index of the nearest polygon. nearest_polygon_index &lt;- sf::st_nearest_feature(unmatched_points, polygons_sf) # 5. Extract the nearest polygons and join their attributes to the unmatched points. nearest_polygons &lt;- polygons_sf[nearest_polygon_index, ] points_nearest &lt;- data.frame(unmatched_points, sf::st_drop_geometry(nearest_polygons)) # Preserve the geometry from the original unmatched points for the nearest matches. points_nearest &lt;- sf::st_set_geometry(points_nearest, sf::st_geometry(unmatched_points)) # 6. Combine the results from the &quot;points_within&quot; and &quot;points_nearest&quot; joins. combined_points &lt;- dplyr::bind_rows(points_within, points_nearest) } else { # If all points were matched in step 2. combined_points &lt;- points_within } # 7. Perform a left join to ensure all original polygons are included in the final output. # Polygons without any matched points will have `NA` values for the point attributes. final_result &lt;- polygons_sf %&gt;% dplyr::left_join( sf::st_drop_geometry(combined_points) , by = polygon_id ) return(final_result) } we’ll also define a function to get the diameter of the polygon which we will use to extract diameter from our predicted segments to compare with the field-measured diameter values. we can also compare the field-measured diameter to the image-annotated diameter as a sanity check. let’s define a function to get polygon diameter that accurately reflects the measurement for potentially irregular shapes. we’ll calculate the diameter by finding the maximum distance across the footprint of the entire polygon ###___________________________________________### # calculate diameter of single polygon ###___________________________________________### # function to calculate the diamater of an sf polygon that is potentially irregularly shaped # using the distance between the farthest points st_calculate_diameter_polygon &lt;- function(polygon) { # get the convex hull ch &lt;- sf::st_convex_hull(polygon) # cast to multipoint then point to get individual vertices ch_points &lt;- sf::st_cast(ch, &#39;MULTIPOINT&#39;) %&gt;% sf::st_cast(&#39;POINT&#39;) # calculate the distances between all pairs of points distances &lt;- sf::st_distance(ch_points) # find the maximum distance, which is the diameter diameter &lt;- as.numeric(max(distances,na.rm=T)) return(diameter) } # apply st to sf data st_calculate_diameter &lt;- function(sf_data) { if(!inherits(sf_data,&quot;sf&quot;)){stop(&quot;st_calculate_diameter() requires polygon sf data&quot;)} if( !all( sf::st_is(sf_data, c(&quot;POLYGON&quot;,&quot;MULTIPOLYGON&quot;)) ) ){ stop(&quot;st_calculate_diameter() requires polygon sf data&quot;) } # get the geometry column name geom_col_name &lt;- attr(sf_data, &quot;sf_column&quot;) # calculate diameter # !!rlang::sym() unquotes the geometry column return_dta &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate(diameter_m = st_calculate_diameter_polygon( !!rlang::sym(geom_col_name) )) %&gt;% dplyr::ungroup() return(return_dta) } let’s apply our match_points_to_polygons() and st_calculate_diameter() functions # nrow(slash_piles_polys) # let&#39;s do it slash_piles_polys &lt;- match_points_to_polygons( points_sf = slash_piles_points , polygons_sf = slash_piles_polys , point_id = &quot;row_number&quot; , polygon_id = &quot;pile_id&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( # height height_m = height_ft*0.3048 , field_diameter_m = diameter_ft*0.3048 # *0.3048 or /3.281 to convert to m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() , field_gt_area_m2 = pi*field_radius_m^2 # volume ASSUMING PERFECT GEOMETRIC SHAPE :/ , image_gt_volume_m3 = (1/8) * pi * ( (sqrt(image_gt_area_m2/pi)*2)^2 ) * height_m # (1/8) * pi * (shape_length^2) * max_height_m # (sqrt(image_gt_area_m2/pi)*2) = diameter assuming of circle covering same area , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * height_m # (1/8) * pi * (shape_length^2) * max_height_m ) # check if the pile is in the stand boundary slash_piles_polys &lt;- slash_piles_polys %&gt;% dplyr::mutate( is_in_stand = pile_id %in% (slash_piles_polys %&gt;% sf::st_intersection(stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(pile_id)) ) what? slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 187 ## Columns: 19 ## $ pile_id &lt;dbl&gt; 3, 4, 5, 6, 8, 11, 13, 15, 16, 17, 19, 20, 21, 22,… ## $ comment &lt;chr&gt; NA, NA, NA, NA, &quot;Mechanical Pile&quot;, NA, NA, NA, NA,… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ height_ft &lt;dbl&gt; NA, NA, NA, NA, 14.0, NA, NA, NA, NA, NA, NA, NA, … ## $ diameter_ft &lt;dbl&gt; NA, NA, NA, NA, 22.0, NA, NA, NA, NA, NA, NA, NA, … ## $ xcoord &lt;dbl&gt; NA, NA, NA, NA, 1019078, NA, NA, NA, NA, NA, NA, N… ## $ ycoord &lt;dbl&gt; NA, NA, NA, NA, 4334862, NA, NA, NA, NA, NA, NA, N… ## $ refcorner &lt;chr&gt; NA, NA, NA, NA, &quot;G4&quot;, NA, NA, NA, NA, NA, NA, NA, … ## $ row_number &lt;int&gt; NA, NA, NA, NA, 93, NA, NA, NA, NA, NA, NA, NA, NA… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499341.7 4317759,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 6.469934, 6.867876, 6.387723, 6.589466, 7.595808, … ## $ height_m &lt;dbl&gt; NA, NA, NA, NA, 4.2672, NA, NA, NA, NA, NA, NA, NA… ## $ field_diameter_m &lt;dbl&gt; NA, NA, NA, NA, 6.7056, NA, NA, NA, NA, NA, NA, NA… ## $ field_radius_m &lt;dbl&gt; NA, NA, NA, NA, 3.3528, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_area_m2 &lt;dbl&gt; 25.166539, 32.028082, 22.928349, 26.261937, 28.909… ## $ field_gt_area_m2 &lt;dbl&gt; NA, NA, NA, NA, 35.315484, NA, NA, NA, NA, NA, NA,… ## $ image_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, 61.682109, NA, NA, NA, NA, NA, NA,… ## $ field_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, 75.34912, NA, NA, NA, NA, NA, NA, … ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FA… summary statistics for the form measurements kbl_form_sum_stats &lt;- function( pile_df , caption = &quot;Ground Truth Piles: summary statistics for form measurements&quot; ) { pile_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( tidyselect::contains(&quot;height_m&quot;) | tidyselect::contains(&quot;diameter_m&quot;) | tidyselect::contains(&quot;area_m2&quot;) | tidyselect::contains(&quot;volume_m3&quot;) ) %&gt;% dplyr::summarise( dplyr::across( dplyr::everything() , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c(n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% stringr::str_c( dplyr::case_when( stringr::str_detect(name,&quot;(field|image)&quot;) ~ paste0(&quot; (&quot;, stringr::str_extract(name,&quot;(field|image)&quot;), &quot;)&quot;) , T ~ &quot;&quot; ) ) %&gt;% stringr::str_replace(&quot;area&quot;, &quot;area m&lt;sup&gt;2&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;volume&quot;, &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;diameter&quot;, &quot;diameter m&quot;) %&gt;% stringr::str_replace(&quot;height&quot;, &quot;height m&quot;) %&gt;% stringr::str_to_sentence() ) %&gt;% # dplyr::count(metric) dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( # metric == &quot;gt_height_m&quot; ~ scales::comma(value,accuracy=0.1) T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::select(-c(min,max)) %&gt;% kableExtra::kbl( caption = caption , col.names = c( &quot;# piles&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) } kbl_form_sum_stats( slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) , caption = &quot;Ground Truth Piles: summary statistics for form measurements&lt;br&gt;ponderosa pine training site&quot; ) Table 2.1: Ground Truth Piles: summary statistics for form measurementsponderosa pine training site # piles Metric Mean Std Dev q 10% Median q 90% Range 121 Height m 2.2 0.8 1.7 2.0 2.3 1.5—6.4 Diameter m (image) 3.8 1.3 3.0 3.5 4.5 2.6—10.2 Diameter m (field) 3.4 1.2 2.8 3.1 4.0 2.4—9.0 Area m2 (image) 9.8 9.4 5.6 7.1 11.9 3.9—59.3 Area m2 (field) 10.5 10.2 6.2 7.6 12.3 4.7—63.1 let’s check the field-collected and image-annotated measurements of diameter which will serve as a good sanity check for our image-annotation process (assuming diameter was accurately measured in the field…might be a perilous assumption) slash_piles_polys %&gt;% dplyr::mutate(diff_diameter_m = image_gt_diameter_m - field_diameter_m) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = image_gt_diameter_m, y = field_diameter_m)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(ggplot2::aes(color = diff_diameter_m)) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(slash_piles_polys$field_diameter_m,na.rm=T), max(slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(slash_piles_polys$field_diameter_m,na.rm=T), max(slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::labs( x = &quot;image-annotated diameter (m)&quot;, y = &quot;field-collected diameter (m)&quot; , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = &quot;diameter (m) comparison&quot; ) + ggplot2::theme_light() the plot makes these values look very similar with the image-annotated diameter generally larger than the field-collected value. let’s check these using lm() lm_temp &lt;- lm(field_diameter_m ~ image_gt_diameter_m, data = slash_piles_polys) summary(lm_temp) ## ## Call: ## lm(formula = field_diameter_m ~ image_gt_diameter_m, data = slash_piles_polys) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.18985 -0.16525 0.01416 0.16807 1.76883 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.13522 0.09891 1.367 0.174 ## image_gt_diameter_m 0.86403 0.02436 35.471 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3593 on 119 degrees of freedom ## (66 observations deleted due to missingness) ## Multiple R-squared: 0.9136, Adjusted R-squared: 0.9129 ## F-statistic: 1258 on 1 and 119 DF, p-value: &lt; 2.2e-16 Our slope of 0.86 is close to 1 and, along with our high R-squared value of 91%, indicate our image- and field-measured diameters are well-calibrated let’s check the field-collected and image-annotated measurements of volume and area. for both volume measurements, a paraboloid geometry is assumed for calculation with the image-annotated volume relying on the field-collected heights p1_temp &lt;- slash_piles_polys %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = image_gt_area_m2, y =field_gt_area_m2)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(ggplot2::aes(color = height_m)) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(slash_piles_polys$field_gt_area_m2,na.rm=T), max(slash_piles_polys$image_gt_area_m2,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(slash_piles_polys$field_gt_area_m2,na.rm=T), max(slash_piles_polys$image_gt_area_m2,na.rm=T) ) )) + ggplot2::labs( x = &quot;image-annotated area (m2)&quot;, y = &quot;field-collected area (m2)&quot; , color = &quot;height (m)&quot; , subtitle = &quot;area (m2) comparison&quot; ) + ggplot2::theme_light() p2_temp &lt;- slash_piles_polys %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = image_gt_volume_m3, y =field_gt_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(ggplot2::aes(color = height_m)) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(slash_piles_polys$field_gt_volume_m3,na.rm=T), max(slash_piles_polys$image_gt_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(slash_piles_polys$field_gt_volume_m3,na.rm=T), max(slash_piles_polys$image_gt_volume_m3,na.rm=T) ) )) + ggplot2::labs( x = &quot;image-annotated volume (m3)&quot;, y = &quot;field-collected volume (m3)&quot; , color = &quot;height (m)&quot; , subtitle = &quot;volume (m3) comparison&quot; ) + ggplot2::theme_light() patchwork::wrap_plots(list(p1_temp,p2_temp), guides = &quot;collect&quot;) &amp; ggplot2::theme(legend.position = &quot;bottom&quot;) even assuming a perfectly circular base for the area of the field-collected data (i.e. based on measured diameter), our image-annotated values are in-line with the field-collected data as we saw with the diameter comparison quick summary of these measurements slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(height_m, tidyselect::ends_with(&quot;area_m2&quot;), tidyselect::ends_with(&quot;volume_m3&quot;)) %&gt;% summary() ## height_m image_gt_area_m2 field_gt_area_m2 image_gt_volume_m3 ## Min. :1.524 Min. : 3.805 Min. : 4.670 Min. : 3.279 ## 1st Qu.:1.829 1st Qu.: 6.200 1st Qu.: 6.585 1st Qu.: 5.963 ## Median :1.981 Median : 7.107 Median : 7.591 Median : 7.088 ## Mean :2.179 Mean :10.808 Mean :10.486 Mean : 13.831 ## 3rd Qu.:2.134 3rd Qu.: 8.597 3rd Qu.: 8.829 3rd Qu.: 8.428 ## Max. :6.401 Max. :60.998 Max. :63.069 Max. :172.950 ## NA&#39;s :66 NA&#39;s :66 NA&#39;s :66 ## field_gt_volume_m3 ## Min. : 4.270 ## 1st Qu.: 6.615 ## Median : 7.527 ## Mean : 14.990 ## 3rd Qu.: 8.746 ## Max. :183.080 ## NA&#39;s :66 2.3 RGB orthomosaic Orthomosaic tif files from the UAS flight imagery that were created in Agisoft Metashape are loaded and stitched together via terra::mosaic. # read list of orthos ortho_list_temp &lt;- list.files( &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , pattern = &quot;*\\\\.(tif|tiff)$&quot;, full.names = T)[] %&gt;% purrr::map(function(x){terra::rast(x)}) ortho_list_temp[[1]] %&gt;% terra::res() # terra::aggregate(20) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ####### ensure the resolution of the rasters matches # terra::res(ortho_list_temp[[1]]) ## function change_res_fn &lt;- function(r, my_res=1, m = &quot;bilinear&quot;){ r2 &lt;- r terra::res(r2) &lt;- my_res r2 &lt;- terra::resample(r, r2, method = m) return(r2) } ## apply the function ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.10)}) # terra::res(ortho_list_temp[[1]]) # ortho_list_temp[[1]] %&gt;% # terra::aggregate(2) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ######## mosaic the raster list ortho_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works ) names(ortho_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;alpha&quot;) # ortho_rast %&gt;% # terra::aggregate(4) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) make a function to plot the RGB imagery as a background for ggplot2 plots ###################################################################################### # function to plot ortho + stand ###################################################################################### ortho_plt_fn = function(my_ortho_rast = ortho_rast, stand = las_ctg_dta %&gt;% sf::st_union() %&gt;% sf::st_as_sf(), buffer = 20){ # convert to stars ortho_st &lt;- my_ortho_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( stand %&gt;% sf::st_buffer(buffer) %&gt;% terra::vect() ) %&gt;% # terra::aggregate(fact = 2, fun = &quot;mean&quot;, na.rm = T) %&gt;% stars::st_as_stars() # convert to rgb ortho_rgb &lt;- stars::st_rgb( ortho_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.005, 0.995) , stretch = &quot;percent&quot; ) # ggplot plt_rgb &lt;- ggplot2::ggplot() + stars::geom_stars(data = ortho_rgb[]) + ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; ) + ggplot2::theme_void() # return(plt_rgb) # combine all plot elements plt_combine = plt_rgb + # geom_sf( # data = stand # , alpha = 0 # , lwd = 1.5 # , color = &quot;gray22&quot; # ) + ggplot2::theme( legend.position = &quot;top&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = ggplot2::margin(0,0,0,0) , legend.text = ggplot2::element_text(size = 8) , legend.title = ggplot2::element_text(size = 8) , legend.key = ggplot2::element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = ggplot2::element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = ggplot2::element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) return(plt_combine) } plot an example slash pile RGB image stand_temp &lt;- slash_piles_polys %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% dplyr::slice(1) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # check it with the ortho ortho_plt_fn(stand = stand_temp) ggsave(&quot;../data/pile_rgb.jpeg&quot;, height = 5, width = 5) 2.3.1 Example ratio-based index While hyperspectral image data enables more detailed analysis by capturing a broader spectral range than RGB imagery, we can still perform robust analysis using spectral data in the visible range let’s define a general function for a ratio based (e.g. vegetation) index spectral_index_fn &lt;- function(rast, layer1, layer2) { bk &lt;- rast[[layer1]] bi &lt;- rast[[layer2]] vi &lt;- (bk - bi) / (bk + bi) return(vi) } The Green-Red Vegetation Index (GRVI) uses the reflectance of green and red bands to assess vegetation health and identify ground cover types. The formula is GRVI = (green - red) / (green + red). Higher GRVI values indicate healthy vegetation, while negative values suggest soils, and values near zero may indicate water or snow. grvi_rast &lt;- spectral_index_fn(rast = ortho_rast, layer1 = 2, layer2 = 1) names(grvi_rast) &lt;- c(&quot;grvi&quot;) terra::plot(grvi_rast, col = harrypotter::hp(n=100, option = &quot;Slytherin&quot;)) let’s check the GRVI for a ground truth pile # check it with the ortho grvi_rast %&gt;% terra::crop(stand_temp %&gt;% sf::st_buffer(20)) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = f), color = NA) + scale_fill_gradient2(low = &quot;black&quot;, high = &quot;forestgreen&quot;) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 10, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 8, hjust = 0.5, face = &quot;italic&quot;) ) ggsave(&quot;../data/pile_grvi.jpeg&quot;, height = 5, width = 5) 2.4 Study area imagery let’s look at the RGB imagery and pile locations # get the base plot plt_rgb_ortho &lt;- ortho_plt_fn( stand = slash_piles_points %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(50) %&gt;% sf::st_transform(terra::crs(ortho_rast)) ) # add pile locations plt_rgb_ortho + ggplot2::geom_sf( data = slash_piles_points %&gt;% sf::st_transform(terra::crs(ortho_rast)) , ggplot2::aes() # size = diameter , shape = 1 , color = &quot;firebrick&quot; ) + ggplot2::theme(legend.position = &quot;none&quot;) notice these are point measurements of plot locations and the points are not precisely in the center of the pile. notice also there are piles in the imagery that were not measured (e.g. upper-left corner) we created image-annotated pile polygons using the RBG and field-collected pile location data to compare against our predicted slash pile segments using an intersection over union (IoU) approach let’s make a panel of plots for each pile p_fn_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , crs = terra::crs(ortho_rast) ) { # scale the buffer based on the largest d &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(field_diameter_m)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt ortho_plt_fn(stand=d) + ggplot2::geom_sf(data = d, fill = NA, color = &quot;firebrick&quot;) + ggplot2::labs( subtitle = paste0( tolower(d$comment) , &quot;\\ndiam. = &quot; , scales::comma(d$field_diameter_m, accuracy = 0.1) # , &quot;, ht. = &quot; # , scales::comma(d$height, accuracy = 0.1) ) ) } # add pile locations plt_list_rgb &lt;- 1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))) %&gt;% purrr::map(p_fn_temp) plot tiles patchwork::wrap_plots( sample( plt_list_rgb, size = as.integer(nrow(slash_piles_points)/3)) , ncol = 5 ) ggsave(&quot;../data/pile_tiles_rgb.jpeg&quot;, height = 10.5, width = 8) a challenge in using the spectral data to identify slash piles will be to develop a spectral-based method that can account for the different lighting conditions in the imagery (e.g. piles in shadows or under tree crowns). this different lighting may have also influenced the point cloud generation 2.5 Point Cloud Data Let’s check out the point cloud data we got using UAS-SfM methods # directory with the downloaded .las|.laz files f_temp &lt;- &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # system.file(package = &quot;lidR&quot;, &quot;extdata&quot;, &quot;Megaplot.laz&quot;) # is there data? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;) %&gt;% length() ## [1] 1 # what files are in here? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;)[1] ## [1] &quot;P4Pro_06_17_2021_half_half_optimal_group1_densified_point_cloud.las&quot; what information does lidR read from the catalog? las_ctg &lt;- lidR::readLAScatalog(f_temp) # set the processing options lidR::opt_progress(las_ctg) &lt;- F lidR::opt_filter(las_ctg) &lt;- &quot;-drop_duplicates&quot; lidR::opt_select(las_ctg) &lt;- &quot;xyziRGB&quot; # huh? las_ctg ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## type : terrestrial ## density : 375.4 points/m² ## num. files : 1 that’s a lot of points…can an ordinary laptop handle it? we’ll find out. We’ll plot our point cloud data tiles real quick to orient ourselves las_ctg %&gt;% purrr::pluck(&quot;data&quot;) %&gt;% mapview::mapview(popup = F, layer.name = &quot;point cloud tile&quot;) 2.6 Check out one pile las_temp &lt;- lidR::clip_roi( las_ctg # biggest mechanical , slash_piles_polys %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% dplyr::slice(1) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(lidR::st_crs(las_ctg)) ) what did we get? las_temp@data %&gt;% dplyr::glimpse() ## Rows: 181,073 ## Columns: 7 ## $ X &lt;dbl&gt; 499807.3, 499807.3, 499807.3, 499807.3, 499807.3, 499807.3, … ## $ Y &lt;dbl&gt; 4317993, 4317992, 4317983, 4317983, 4317993, 4317989, 431799… ## $ Z &lt;dbl&gt; 2711.213, 2711.567, 2713.496, 2713.221, 2711.405, 2712.323, … ## $ Intensity &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ R &lt;int&gt; 40448, 33024, 37632, 40192, 17152, 42496, 41472, 39168, 5068… ## $ G &lt;int&gt; 37632, 31232, 35584, 36864, 16384, 38912, 37632, 37376, 5273… ## $ B &lt;int&gt; 33280, 26112, 29184, 31744, 10752, 34304, 32256, 33792, 5145… plot a sample las_temp %&gt;% lidR::plot( color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) make a gif library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_z.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_z&quot;, dir = &quot;../data/&quot;) rgl::close3d() } library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_rgb.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;RGB&quot;, bg = &quot;white&quot;, legend = F ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_rgb&quot;, dir = &quot;../data/&quot;) rgl::close3d() } "],["method-evaluation.html", "Section 3 Method Evaluation 3.1 Instance Matching 3.2 Detection Accuracy Metrics 3.3 Quantification Accuracy Metrics", " Section 3 Method Evaluation This section is entirely devoted to detailing the methods and defining analysis functions for instance matching and the calculation of overall prediction performance assessment metrics. Field-measured slash piles will be used as the ground truth data to perform a confusion matrix-based validation accuracy assessment of the methods. Instance matching compares predictions to the ground truth data to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions). Aggregation of the instance matching results allows us to calculate overall performance assessment metrics to determine overall detection accuracy and, in the case of our slash pile analysis, form quantification accuracy. detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified 3.1 Instance Matching Puliti et al. (2023, p. 14) provide guidance on performing “instance segmentation evaluation” to assess the ability of a method to correctly identify and delineate individual tree crown instances compared ground truth data. We’ll use this same methodology to test our slash pile identification approach. The first step in performing any instance segmentation evaluation is to match the point cloud reference and predicted instance IDs. To do this, it is necessary to define whether a prediction is correct. Here we adopt a method Wielgosz et al. (2023) proposed for matching tree instance IDs from two point clouds with reference and predicted instance IDs, respectively. Given a reference and a predicted point cloud with two separate sets of instances, the tree instances are iteratively matched in descending order from the tallest to the shortest trees by using the following algorithm: Find the tallest tree in the reference data; Find the tree in the predicted instances that have the largest intersection over union (IoU) with the tree selected in the previous step; if the IoU is &lt;0.5: the predicted tree is considered an error, and thus no reference instance ID is available; if the IoU is ≥0.5: the tree is considered a correct match, and assign reference instance ID label to the predicted tree; Add to collection (dictionary) of predicted tree instances with IDs matching the reference instance IDs. Following the initial matching of reference and predicted instance IDs, the evaluation can be done on the tree level to evaluate detection, omission, and commission rates (which can be used to calculate precision, recall, and the F-score metric) # check the data check_gt_str &lt;- function( gt_inst , gt_id = &quot;pile_id&quot; , predictions , pred_id = &quot;pred_pile_id&quot; ) { if( !inherits(gt_inst,&quot;sf&quot;)){stop(&quot;ground truth must be spatial `sf` data with a single record&quot;)} if( !inherits(predictions,&quot;sf&quot;) ){stop(&quot;predictions must be spatial `sf` data&quot;)} if( !identical(sf::st_crs(gt_inst),sf::st_crs(predictions)) ){stop(&quot;`sf` data should have same crs projection&quot;)} if( is.null(gt_id) || is.na(gt_id) || !inherits(gt_id, &quot;character&quot;) || stringr::str_trim(gt_id) == &quot;&quot; ){ stop(&quot;ground truth data must contain `gt_id` column&quot;) } if( is.null(pred_id) || is.na(pred_id) || !inherits(pred_id, &quot;character&quot;) || stringr::str_trim(pred_id) == &quot;&quot; ){ stop(&quot;ground truth data must contain `pred_id` column&quot;) } if( !(names(gt_inst) %&gt;% stringr::str_equal(gt_id) %&gt;% any()) ){stop(&quot;ground truth data must contain `gt_id` column&quot;)} # get rid of gt_id if it exists in the predictions and is not the key if( (names(predictions) %&gt;% stringr::str_equal(gt_id) %&gt;% any() ) &amp;&amp; (gt_id!=pred_id) ){ predictions &lt;- predictions %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , gt_id ))) } # rename it if gt_id==pred_id if( (names(predictions) %&gt;% stringr::str_equal(gt_id) %&gt;% any() ) &amp;&amp; (gt_id==pred_id) ){ predictions &lt;- predictions %&gt;% dplyr::rename_with( .cols = dplyr::all_of(gt_id) , .fn = function(x){&quot;prediction_idxxx&quot;} ) pred_id &lt;- &quot;prediction_idxxx&quot; }else if( !(names(predictions) %&gt;% stringr::str_equal(pred_id) %&gt;% any()) ){ stop(&quot;predictions data must contain `pred_id` column&quot;) } return(list( predictions = predictions , pred_id = pred_id )) } # match the instance ground_truth_single_match &lt;- function( gt_inst , gt_id = &quot;pile_id&quot; , predictions , pred_id = &quot;pred_pile_id&quot; , min_iou_pct = 0.5 ) { # check it check_ans &lt;- check_gt_str( gt_inst = gt_inst , gt_id = gt_id , predictions = predictions , pred_id = pred_id ) if(nrow(gt_inst)!=1 ){stop(&quot;ground truth must be spatial `sf` data with a single record&quot;)} predictions &lt;- check_ans$predictions pred_id &lt;- check_ans$pred_id # intersection i_temp &lt;- sf::st_intersection(predictions,gt_inst) %&gt;% dplyr::mutate(i_area = sf::st_area(.) %&gt;% as.numeric()) if(nrow(i_temp)==0){return(NULL)} # union u_temp &lt;- i_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::inner_join(predictions %&gt;% sf::st_set_geometry(&quot;geom1&quot;), by = pred_id) %&gt;% dplyr::inner_join(gt_inst %&gt;% sf::st_set_geometry(&quot;geom2&quot;) %&gt;% dplyr::select(dplyr::all_of(gt_id)), by = gt_id) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( u_area = sf::st_union(geom1, geom2) %&gt;% sf::st_area() %&gt;% as.numeric() ) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(geom1,geom2)) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( iou = dplyr::case_when( is.na(u_area) | is.nan(u_area) ~ NA , T ~ dplyr::coalesce(i_area,0)/u_area ) ) %&gt;% dplyr::filter(!is.na(iou) &amp; iou&gt;=min_iou_pct) if(nrow(u_temp)==0){return(NULL)} # return return( u_temp %&gt;% # pick the highest iou dplyr::arrange(desc(iou)) %&gt;% dplyr::slice(1) %&gt;% # column clean dplyr::select(dplyr::all_of( c( gt_id, &quot;i_area&quot;, &quot;u_area&quot;, &quot;iou&quot; , base::setdiff( names(predictions) , c(&quot;geometry&quot;, &quot;geom&quot;, gt_id, &quot;i_area&quot;, &quot;u_area&quot;, &quot;iou&quot;) ) ) )) ) } let’s generate some fake predictions to test predictions_temp &lt;- slash_piles_polys %&gt;% dplyr::slice_sample(prop = 0.7) %&gt;% sf::st_centroid() %&gt;% dplyr::mutate(rand=as.integer(runif(n=dplyr::n(), min = 1, max = 3))) %&gt;% dplyr::select(rand,pile_id) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( geometry = sf::st_buffer(geometry, rand) ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::bind_rows( sf::st_sample( slash_piles_polys %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() , size = 33 , type = &quot;random&quot; ) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(rand=as.integer(runif(n=dplyr::n(), min = 1, max = 6))) %&gt;% dplyr::select(rand) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( geometry = sf::st_buffer(geometry, rand) ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) ) %&gt;% dplyr::mutate(pred_id = dplyr::row_number() %&gt;% as.character()) %&gt;% dplyr::select(pred_id,pile_id) # storing the pile_id so we know which ones might be matches check out the fake predictions compared to the ground truth pile footprints ggplot2::ggplot() + ggplot2::geom_sf(data = slash_piles_polys, mapping = ggplot2::aes(color = &quot;ground truth&quot;), fill = NA) + ggplot2::geom_sf(data = predictions_temp, mapping = ggplot2::aes(color = &quot;fake predictions&quot;), fill = NA) + ggplot2::scale_color_manual(values=c(&quot;brown&quot;,&quot;blue&quot;)) + ggplot2::labs(color=&quot;&quot;) + ggplot2::theme_void() test for a single ground truth instance ground_truth_single_match( gt_inst = slash_piles_polys %&gt;% dplyr::filter(pile_id==purrr::discard(predictions_temp$pile_id, is.na)[1]) , gt_id = &quot;pile_id&quot; , predictions = predictions_temp , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.01 ) ## # A tibble: 1 × 5 ## pile_id i_area u_area iou pred_id ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 67 10.6 13.2 0.799 1 now we need to make a function that matches the instances iteratively allowing for only a single match from the predictions (i.e. one prediction can only go to one ground truth instance), and returns all instances labeled as true positive (correctly matched with a prediction), commission (predictions which do not match a ground truth instance; false positive), or omission (ground truth instances for which no predictions match; false negative) ground_truth_prediction_match &lt;- function( # ground_truth should be sorted already ground_truth , gt_id = &quot;pile_id&quot; # predictions just needs treeID , predictions , pred_id = &quot;pred_pile_id&quot; , min_iou_pct = 0.5 ) { # check it check_ans &lt;- check_gt_str( gt_inst = ground_truth , gt_id = gt_id , predictions = predictions , pred_id = pred_id ) predictions &lt;- check_ans$predictions pred_id &lt;- check_ans$pred_id # set up a blank data frame return_df &lt;- dplyr::tibble( i_area = as.numeric(NA) , u_area = as.numeric(NA) , iou = as.numeric(NA) ) %&gt;% dplyr::bind_cols( ground_truth %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(gt_id)) %&gt;% dplyr::slice(0) ) %&gt;% dplyr::bind_cols( predictions %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::slice(0) ) %&gt;% dplyr::relocate(tidyselect::starts_with(gt_id)) # save names to select nms_temp &lt;- names(return_df) # start with tallest tree and match to get true positives for (i in 1:nrow(ground_truth)) { match_temp &lt;- ground_truth_single_match( gt_inst = ground_truth %&gt;% dplyr::slice(i) , gt_id = gt_id , predictions = predictions %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::anti_join(return_df,by=pred_id) , pred_id = pred_id , min_iou_pct = min_iou_pct ) # add to return if(!is.null(match_temp)){ return_df &lt;- return_df %&gt;% dplyr::bind_rows(match_temp %&gt;% dplyr::select(nms_temp)) } match_temp &lt;- NULL } # label tps return_df &lt;- return_df %&gt;% dplyr::mutate(match_grp = &quot;true positive&quot;) # add omissions return_df &lt;- return_df %&gt;% dplyr::bind_rows( ground_truth %&gt;% sf::st_drop_geometry() %&gt;% dplyr::anti_join(return_df,by=gt_id) %&gt;% dplyr::select(dplyr::all_of(gt_id)) %&gt;% dplyr::mutate(match_grp = &quot;omission&quot;) ) # add commissions return_df &lt;- return_df %&gt;% dplyr::bind_rows( predictions %&gt;% sf::st_drop_geometry() %&gt;% dplyr::anti_join(return_df,by=pred_id) %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::mutate(match_grp = &quot;commission&quot;) ) # make match_grp factor return_df &lt;- return_df %&gt;% dplyr::mutate( match_grp = factor( match_grp , ordered = T , levels = c( &quot;true positive&quot; , &quot;commission&quot; , &quot;omission&quot; ) ) %&gt;% forcats::fct_rev() ) # return if(nrow(return_df)==0){ warning(&quot;no records found for ground truth to predition matching&quot;) return(NULL) }else{ return(return_df) } } let’s see how we did given the full list of fake predictions and ground truth data ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::arrange(desc(field_diameter_m)) # this is so the algorithm starts with the largest , gt_id = &quot;pile_id&quot; , predictions = predictions_temp , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.1 ) # huh? ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 223 ## Columns: 6 ## $ pile_id &lt;dbl&gt; 197, 189, 132, 111, 131, 42, 144, 169, 180, 128, 136, 135, 6… ## $ i_area &lt;dbl&gt; 12.560629, 12.560629, 12.011957, 11.787696, 11.131328, 3.048… ## $ u_area &lt;dbl&gt; 38.611505, 30.782327, 14.863479, 12.670969, 12.691045, 3.986… ## $ iou &lt;dbl&gt; 0.3253079, 0.4080468, 0.8081524, 0.9302916, 0.8771009, 0.764… ## $ pred_id &lt;chr&gt; &quot;36&quot;, &quot;115&quot;, &quot;54&quot;, &quot;112&quot;, &quot;110&quot;, &quot;84&quot;, &quot;109&quot;, &quot;42&quot;, &quot;61&quot;, &quot;8… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive, true positive, … how did our predictions do for this test example? # what did we get? ground_truth_prediction_match_ans %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate(pct = (n/sum(n)) %&gt;% scales::percent(accuracy=0.1)) ## # A tibble: 3 × 3 ## match_grp n pct ## &lt;ord&gt; &lt;int&gt; &lt;chr&gt; ## 1 omission 60 26.9% ## 2 commission 36 16.1% ## 3 true positive 127 57.0% let’s look at that spatially pal_match_grp = c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= &quot;black&quot; #viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # plot it ggplot2::ggplot() + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.7 ) + ggplot2::geom_sf( data = predictions_temp %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 1.1 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme_void() + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.1136 ## 1st Qu.:0.4429 ## Median :0.5109 ## Mean :0.5240 ## 3rd Qu.:0.6081 ## Max. :0.9303 ## NA&#39;s :96 3.2 Detection Accuracy Metrics Detection accuracy metrics are calculated by aggregating raw TP, FP, and FN counts to quantify the method’s ability to find the piles. Aggregation of the instance matching allows us to evaluate omission rate (false negative rate or miss rate), commission rate (false positive rate), precision, recall (detection rate), and the F-score metric. As a reminder, true positive (\\(TP\\)) instances correctly match ground truth instances with a prediction, commission tree predictions do not match a ground truth tree (false positive; \\(FP\\)), and omissions are ground truth instances for which no predictions match (false negative; \\(FN\\)) \\[\\textrm{omission rate} = \\frac{FN}{TP+FN}\\] \\[\\textrm{commission rate} = \\frac{FP}{TP+FP}\\] \\[\\textrm{precision} = \\frac{TP}{TP+FP}\\] \\[\\textrm{recall} = \\frac{TP}{TP+FN}\\] \\[ \\textrm{F-score} = 2 \\times \\frac{\\bigl(precision \\times recall \\bigr)}{\\bigl(precision + recall \\bigr)} \\] let’s make a function to calculate these detection accuracy metrics based on aggregated TP, FP, and FN counts # first function takes df with cols tp_n, fp_n, and fn_n to calculate rates confusion_matrix_scores_fn &lt;- function(df) { df %&gt;% dplyr::mutate( omission_rate = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) == 0 ~ 0 # if there are no actual piles, there is nothing to miss , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 1 # every single actual pile was missed , dplyr::coalesce(fn_n,0) == 0 &amp; dplyr::coalesce(tp_n,0) &gt; 0 ~ 0 , T ~ fn_n/(tp_n+fn_n) ) # False Negative Rate or Miss Rate , commission_rate = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 0 # if no predictions are made, the model could not have made any commission errors , dplyr::coalesce(fp_n,0) == 0 &amp; dplyr::coalesce(tp_n,0) &gt; 0 ~ 0 , T ~ fp_n/(tp_n+fp_n) ) # False Positive Rate , precision = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 1 # if no predictions are made, the model made zero incorrect positive claims , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) &gt; 0 ~ 0 , T ~ tp_n/(tp_n+fp_n) ) , recall = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) == 0 ~ 1 # if there are no actual piles, there is nothing to miss , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 0 # every single actual pile was missed , T ~ tp_n/(tp_n+fn_n) ) , f_score = dplyr::case_when( dplyr::coalesce(precision,0) == 0 | dplyr::coalesce(recall,0) == 0 ~ 0 , T ~ 2 * ( (precision*recall)/(precision+recall) ) ) ) } test it ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate( match_grp = dplyr::case_match( match_grp , &quot;true positive&quot;~&quot;tp&quot; , &quot;commission&quot;~&quot;fp&quot; , &quot;omission&quot;~&quot;fn&quot; ) ) %&gt;% tidyr::pivot_wider( names_from = match_grp , values_from = c(n) , names_glue = &quot;{match_grp}_{.value}&quot; ) %&gt;% confusion_matrix_scores_fn() ## # A tibble: 1 × 8 ## fn_n fp_n tp_n omission_rate commission_rate precision recall f_score ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 60 36 127 0.321 0.221 0.779 0.679 0.726 3.3 Quantification Accuracy Metrics Quantification accuracy metrics such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified to prepare our results for analysis, we will develop a function that aggregates the single-pile-level data into a single record for each parameter combination. this function will calculate detection performance metrics such as F-score, precision, and recall (using the confusion_matrix_scores_fn() we defined above), as well as quantification accuracy metrics including Root Mean Squared Error (RMSE), Mean Error (ME), and Mean Absolute Percentage Error (MAPE) to assess the accuracy of our pile form measurements. this could be a valuable function for any future analysis comparing predictions to ground truth data. here are the quantification accuracy metric formulas: \\[ \\textrm{RMSE} = \\sqrt{ \\frac{ \\sum_{i=1}^{N} (y_{i} - \\hat{y_{i}})^{2}}{N}} \\] \\[ \\textrm{ME} = \\frac{ \\sum_{i=1}^{N} (\\hat{y_{i}} - y_{i})}{N} \\] \\[ \\textrm{MAPE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left| \\frac{y_{i} - \\hat{y_{i}}}{y_{i}} \\right| \\] Where \\(N\\) is equal to the total number of correctly matched piles, \\(y_i\\) is the ground truth measured value and \\(\\hat{y_i}\\) is the predicted value of \\(i\\) we could also calculate Relative RMSE (RRMSE) \\[ \\textrm{RRMSE} = \\frac{\\text{RMSE}}{\\bar{y}} \\times 100\\% \\] where, \\(\\bar{y}\\) represents the mean of the ground truth values. the interpretations of RMSE and RRMSE are: RMSE: Measures the average magnitude of the differences between predicted and the actual observed values, expressed in the same units as the metric. RRMSE: Expresses RMSE as a percentage of the mean of the observed values, providing a scale-independent measure to compare model accuracy across different datasets or models. for this analysis, we’ll show how to calculate RRMSE but we’ll only investigate MAPE Use MAPE when: You need an easily understandable metric for comparing prediction accuracy across different series or models with varying scales, particularly when zeros or near-zero actual values are not present in your data. Use RRMSE when: You need a metric that is more robust to small or zero actual values and you want to penalize larger errors more heavily due to the squaring of errors in its calculation. # aggregate results from ground_truth_prediction_match() agg_ground_truth_match &lt;- function(ground_truth_prediction_match_ans) { if(nrow(ground_truth_prediction_match_ans)==0){return(NULL)} if( !(names(ground_truth_prediction_match_ans) %&gt;% stringr::str_equal(&quot;match_grp&quot;) %&gt;% any()) ){stop(&quot;ground_truth_prediction_match_ans must contain `match_grp` column&quot;)} # check for difference columns (contains &quot;_diff&quot;) and calc rmse for only those to return a single line df with colums for each diff_rmse if( (ground_truth_prediction_match_ans %&gt;% dplyr::select(tidyselect::starts_with(&quot;diff_&quot;) | tidyselect::starts_with(&quot;pct_diff_&quot;)) %&gt;% ncol() )&gt;0 ){ # get rmse and mean difference/error for all columns with &quot;_diff&quot; but not &quot;pct_diff&quot; # get mape for all columns with &quot;pct_diff&quot; but not &quot;diff_&quot; rmse_df &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::select( tidyselect::starts_with(&quot;diff_&quot;) | tidyselect::starts_with(&quot;pct_diff_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything(), values_drop_na = T) %&gt;% dplyr::group_by(name) %&gt;% dplyr::summarise( sq = sum(value^2, na.rm = T) , mean = mean(value, na.rm = T) , sumabs = sum(abs(value), na.rm = T) , nomiss = sum(!is.na(value)) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( rmse = dplyr::case_when( dplyr::coalesce(nomiss,0)==0 ~ as.numeric(NA) , T ~ sqrt(sq/nomiss) ) , mape = dplyr::case_when( dplyr::coalesce(nomiss,0)==0 ~ as.numeric(NA) , T ~ sumabs/nomiss ) ) %&gt;% # NA nonsense values dplyr::mutate( mape = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ mape , T ~ as.numeric(NA) ) , rmse = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ as.numeric(NA) , T ~ rmse ) , mean = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ as.numeric(NA) , T ~ mean ) ) %&gt;% dplyr::select(name,rmse,mean,mape) %&gt;% tidyr::pivot_wider( names_from = name , values_from = c(rmse,mean,mape) , names_glue = &quot;{name}_{.value}&quot; ) %&gt;% # remove columns with NA in all rows dplyr::select( dplyr::where( ~!all(is.na(.x)) ) ) if( dplyr::coalesce(nrow(rmse_df),0)==0 || dplyr::coalesce(ncol(rmse_df),0)==0 ){ # empty df rmse_df &lt;- dplyr::tibble() } }else{ # empty df rmse_df &lt;- dplyr::tibble() } # count by match group agg &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate( match_grp = dplyr::case_match( match_grp , &quot;true positive&quot;~&quot;tp&quot; , &quot;commission&quot;~&quot;fp&quot; , &quot;omission&quot;~&quot;fn&quot; ) ) # true positive, false positive, false negative rates return_df &lt;- dplyr::tibble(match_grp = c(&quot;tp&quot;,&quot;fp&quot;,&quot;fn&quot;)) %&gt;% dplyr::left_join(agg, by = &quot;match_grp&quot;) %&gt;% dplyr::mutate(dplyr::across(.cols = c(n), .fn = ~dplyr::coalesce(.x,0))) %&gt;% tidyr::pivot_wider( names_from = match_grp , values_from = c(n) , names_glue = &quot;{match_grp}_{.value}&quot; ) # rates, precision, recall, f-score return_df &lt;- confusion_matrix_scores_fn(return_df) # add rmse if(nrow(rmse_df)&gt;0){ return_df &lt;- return_df %&gt;% dplyr::bind_cols(rmse_df) } # return return(return_df) } There is a lot going on in our agg_ground_truth_match() function but it’s application is straightforward enough: The minimum required input is a data frame of the raw instance matches with a column named match_grp which is string/factor with the levels “true positive”, “commission”, and “omission” as returned by the ground_truth_prediction_match() function Optionally, if the data contain columns with the prefix “diff_” the mean error (ME) is calculated for those columns with the return having the suffix “_mean” and the RMSE is calculated for those columns with the return having the suffix “_rmse” interpretation of the ME is enhanced if these “diff_” columns are calculated as the predicted value minus the actual value (e.g. pred_diameter_m - gt_diameter_m) Optionally, if the data contain columns with the prefix “pct_diff_” the mean absolute percent error (MAPE) is calculated for those columns with the return having the suffix “_mape” these “pct_diff_” columns are calculated as the actual value minus the predicted value divided by the actual value (e.g. (gt_diameter_m - pred_diameter_m)/gt_diameter_m) first, let’s look at the agg_ground_truth_match() return using an example minimum required input data frame of the raw instance matches with a column named match_grp which is string/factor with the levels “true positive”, “commission”, and “omission” dplyr::tibble( match_grp = c( rep(&quot;true positive&quot;, times = 9) , rep(&quot;commission&quot;, times = 2) , rep(&quot;omission&quot;, times = 4) ) ) %&gt;% agg_ground_truth_match() %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 8 ## $ tp_n &lt;dbl&gt; 9 ## $ fp_n &lt;dbl&gt; 2 ## $ fn_n &lt;dbl&gt; 4 ## $ omission_rate &lt;dbl&gt; 0.3076923 ## $ commission_rate &lt;dbl&gt; 0.1818182 ## $ precision &lt;dbl&gt; 0.8181818 ## $ recall &lt;dbl&gt; 0.6923077 ## $ f_score &lt;dbl&gt; 0.75 now, let’s look at the agg_ground_truth_match() output using our fake pile prediction instance match example made by our ground_truth_prediction_match() function as input. Before agg_ground_truth_match(), we’ll add area of the fake predicted piles and area of the ground truth piles to ensure we get RMSE, MAPE, and ME quantification accuracy metrics in the result # first, we&#39;ll add pile area from the respective spatial data ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # join on gt area data dplyr::left_join( slash_piles_polys %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(gt_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( predictions_temp %&gt;% dplyr::select(pred_id) %&gt;% dplyr::mutate(pred_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # agg_ground_truth_match() agg_ground_truth_match(ground_truth_prediction_match_ans) %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 11 ## $ tp_n &lt;dbl&gt; 127 ## $ fp_n &lt;dbl&gt; 36 ## $ fn_n &lt;dbl&gt; 60 ## $ omission_rate &lt;dbl&gt; 0.3208556 ## $ commission_rate &lt;dbl&gt; 0.2208589 ## $ precision &lt;dbl&gt; 0.7791411 ## $ recall &lt;dbl&gt; 0.6791444 ## $ f_score &lt;dbl&gt; 0.7257143 ## $ diff_area_m2_rmse &lt;dbl&gt; 9.738452 ## $ diff_area_m2_mean &lt;dbl&gt; 0.7120349 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.7468178 the agg_ground_truth_match() allows for multiple “diff_” and “pct_diff_” columns to aggregate quantification accuracy metrics for different measurements ground_truth_prediction_match_ans %&gt;% dplyr::mutate( # fake one pred_other_measurement = runif(n=dplyr::n(),min = 1, max = 11) , pred_other_measurement = ifelse(is.na(pred_id),NA,pred_other_measurement) # fake one , gt_other_measurement = runif(n=dplyr::n(),min = 3, max = 13) , gt_other_measurement = ifelse(is.na(pile_id),NA,gt_other_measurement) ) %&gt;% # calculate difference columns dplyr::mutate( diff_other_measurement = pred_other_measurement-gt_other_measurement , pct_diff_other_measurement = (gt_other_measurement-pred_other_measurement)/gt_other_measurement ) %&gt;% agg_ground_truth_match() %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 14 ## $ tp_n &lt;dbl&gt; 127 ## $ fp_n &lt;dbl&gt; 36 ## $ fn_n &lt;dbl&gt; 60 ## $ omission_rate &lt;dbl&gt; 0.3208556 ## $ commission_rate &lt;dbl&gt; 0.2208589 ## $ precision &lt;dbl&gt; 0.7791411 ## $ recall &lt;dbl&gt; 0.6791444 ## $ f_score &lt;dbl&gt; 0.7257143 ## $ diff_area_m2_rmse &lt;dbl&gt; 9.738452 ## $ diff_other_measurement_rmse &lt;dbl&gt; 4.41821 ## $ diff_area_m2_mean &lt;dbl&gt; 0.7120349 ## $ diff_other_measurement_mean &lt;dbl&gt; -1.915537 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.7468178 ## $ pct_diff_other_measurement_mape &lt;dbl&gt; 0.5199562 "],["ptcld_process.html", "Section 4 Point Cloud Processing and Pile Segmentation 4.1 Process Raw Point Cloud", " Section 4 Point Cloud Processing and Pile Segmentation To start, we’ll use the point cloud data alone to attempt to classify slash piles using structural signatures alone without additional spectral information. We’ll use the cloud2trees package to perform all preprocessing of point cloud data which includes: ground classification and noise removal raster data (DTM and CHM) generation point cloud height normalization All of this can be accomplished using the cloud2raster() function. After generating these products from the raw point cloud we’ll perform object segmentation to attempt to detect round, conical objects like slash piles from: 1) the normalized point cloud directly; 2) the CHM which we’ll generate by setting the minimum height to zero (essentially a digital surface model [DSM] with the ground removed). To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation in a bottom-up approach. Insert something from paper about bottom-up approach that uses a CHM “slice” near the ground. For slash piles, which are often irregular and may not have a distinct “treetop” equivalent, CHM-based methods might be less directly applicable unless the piles present a very clear, isolated conical or rounded form. Could use expected morphology of the slash piles (e.g. maximum height) based on prior research and/or the pile construction prescription. We won’t use the height normalized point cloud data in this project but future work could attempt to detect slash piles directly from the point cloud by using a clustering algorithm such as DBSCAN (Density-Based Spatial Clustering of Applications with Noise), for example. Section 5 builds and tests a raster-based watershed segmentation methodology Section 6 combines the raster-based watershed segmentation methodology with spectral information in a data fusion approach 4.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data # set chm res chm_res_m_temp &lt;- 0.2 dir_temp &lt;- paste0(&quot;../data/point_cloud_processing_delivery_chm&quot;,chm_res_m_temp,&quot;m&quot;) las_dir_temp &lt;- &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## type : terrestrial ## density : 375.4 points/m² ## num. files : 1 # do it if(!dir.exists(dir_temp)){ # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = &quot;../data&quot; , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.25 , chm_res_m = chm_res_m_temp , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = &quot;../data/point_cloud_processing_delivery&quot;, to = dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(dir_temp, &quot;dtm_0.25m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(dir_temp, paste0(&quot;chm_&quot;, chm_res_m_temp,&quot;m.tif&quot;)) ) # dtm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery_chm0.1m/dtm_0.25m.tif&quot;) # chm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery_chm0.1m/chm_0.1m.tif&quot;) # dtm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery_chm0.2m/dtm_0.5m.tif&quot;) # chm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery_chm0.2m/chm_0.2m.tif&quot;) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM cloud2raster_ans$dtm_rast %&gt;% terra::aggregate(fact = 2) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(axes = F) and CHM cloud2raster_ans$chm_rast %&gt;% terra::aggregate(fact = 2) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) 4.1.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid p_fn_temp &lt;- function( rn , df = slash_piles_polys , rast = cloud2raster_ans$dtm_rast , crs = terra::crs(cloud2raster_ans$dtm_rast) , my_title = &quot;&quot; , vopt = &quot;viridis&quot; , lim = NULL ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(field_diameter_m)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt classifier # convert to stars comp_st &lt;- rast %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(20) %&gt;% terra::vect() ) %&gt;% terra::as.data.frame(xy = T) %&gt;% dplyr::rename(f=3) # ggplot comp_temp &lt;- ggplot2::ggplot() + ggplot2::geom_tile(data = comp_st, ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;gray33&quot;, lwd = 0.4) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , subtitle = my_title ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) if(!is.null(lim)){ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt, limits = lim) }else{ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt) } plt_temp &lt;- comp_temp return(list(&quot;plt&quot;=plt_temp,&quot;d&quot;=d_temp)) } # p_fn_temp( # rn = 5 # # , lim = c(floor(terra::minmax(cloud2raster_ans$dtm_rast)[1]*0.98), floor(terra::minmax(cloud2raster_ans$dtm_rast)[2]*1.02)) # ) # p_fn_temp( # rn = 11 # , rast = cloud2raster_ans$chm_rast # , vopt = &quot;plasma&quot; # ) # combine 3 plt_combine_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , rast1 = cloud2raster_ans$dtm_rast , title1 = &quot;DTM&quot; , vopt1 = &quot;viridis&quot; , rast2 = cloud2raster_ans$chm_rast , title2 = &quot;CHM&quot; , vopt2 = &quot;plasma&quot; , crs = terra::crs(cloud2raster_ans$dtm_rast) ) { # composite 1 ans1 &lt;- p_fn_temp( rn = rn , df = df , rast = rast1 , my_title = title1 , crs = crs , vopt = vopt1 ) # composite 2 ans2 &lt;- p_fn_temp( rn = rn , df = df , rast = rast2 , my_title = title2 , crs = crs , vopt = vopt2 ) # plt rgb rgb_temp &lt;- ortho_plt_fn(my_ortho_rast = ortho_rast, stand =ans1$d) + ggplot2::geom_sf(data = ans1$d, fill = NA, color = &quot;white&quot;, lwd = 0.3) # combine r &lt;- ans1$plt + ans2$plt + rgb_temp return(r) } # plt_combine_temp(2) # add pile locations plt_list_rast_comp &lt;- sample(1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))),10) %&gt;% purrr::map(plt_combine_temp) # plt_list_rast_comp[[2]] combine the plots for a few piles patchwork::wrap_plots( plt_list_rast_comp , ncol = 2 ) ggplot2::ggsave(&quot;../data/pile_tiles_rast.jpeg&quot;, height = 8.5, width = 10.5) a few things are noteworthy in these examples: Piles are clearly visible in some areas of the DTM but less visible in other areas Piles are delineated in the CHM but with varying degrees of definition based on surrounding terrain and pile structure The DTM and CHM were rarely impacted by shadows in the RGB imagery It is interesting to see coarse woody debris occasionally visible in the CHM "],["raster_watershed.html", "Section 5 Structural Detection from CHM 5.1 Method Demonstration 5.2 Instance Matching 5.3 Watershed Pile Detection Function", " Section 5 Structural Detection from CHM We’ll first attempt to detect slash piles using raster-based methods with the DTM and CHM. These raster-based approaches are simple and efficient but can be limited in complex forest structures where piles might be occluded by overstory trees while rasterization simplifies/removes some of the rich 3D information in the point cloud. When used for individual tree detection (ITD) the watershed segmentation technique treats the CHM as a topographic surface, where local maxima represent tree tops and valleys represent crown boundaries. A “water source” is conceptually placed at each local lowest point, and the surface is “flooded.” Barriers are generated where different “water sources” meet, forming watershed lines that delineate individual tree crowns. two possible approaches for segmenting piles are to: 1) segment individual trees using a top-down approach and then use the canopy cover as a mask to then identify slash piles; 2) use a bottoms-up approach to perform slash pile segmentation on a lower “slice” of the CHM based on an expected maximum height of a pile we’ll first try the bottoms-up approach using a CHM slice with a user-defined maximum height which should be set based on the pile construction prescription or expectation from the treatment type. the first step in this approach is to isolate the lower slice of the CHM based on a maximum height threshold defined by the upper limit of the expected slash pile height. the expected height range to search for slash piles should be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion we’ll set a maximum height threshold which filters the CHM to only include raster cells lower than this threshold. we’ll also set a lower height limit based on the expected slash pile height for use later in removing candidate segments that are shorter than this lower limit. # set the max and min expected pile height max_ht_m &lt;- 4 min_ht_m &lt;- 0.5 # lower CHM slice cloud2raster_ans$chm_rast %&gt;% terra::clamp(upper = max_ht_m, lower = 0, values = F) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) already, it looks like the piles should be distinguishable objects from this data 5.1 Method Demonstration let’s run watershed segmentation using lidR::watershed() which is based on the bioconductor package EBIimage watershed_ans &lt;- lidR::watershed( chm = cloud2raster_ans$chm_rast %&gt;% terra::clamp(upper = max_ht_m, lower = 0, values = F) , th_tree = 0.1 )() # this is a raster watershed_ans ## class : SpatRaster ## size : 2740, 3473, 1 (nrow, ncol, nlyr) ## resolution : 0.2, 0.2 (x, y) ## extent : 499264.2, 499958.8, 4317599, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## varname : chm_0.2m ## name : focal_mean ## min value : 1 ## max value : 9892 each value should be a unique “segment” which we can refine based on rules of expected size and shape of piles terra::freq(watershed_ans) %&gt;% dplyr::slice_sample(n = 10) ## layer value count ## 1 1 6409 17 ## 2 1 2976 61 ## 3 1 4232 15 ## 4 1 2522 63 ## 5 1 2831 4 ## 6 1 6699 169 ## 7 1 6871 556 ## 8 1 7036 241 ## 9 1 7154 14 ## 10 1 3127 7 where the “value” is the segment identifier and the count is the number of raster cells assigned to that segment how many predicted segments are there? terra::freq(watershed_ans) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() ## [1] 9892 let’s plot the raster return from the watershed segmentation watershed_ans %&gt;% terra::plot( col = c( viridis::turbo(n = floor(terra::minmax(watershed_ans)[2]/3)) , viridis::viridis(n = floor(terra::minmax(watershed_ans)[2]/3)) , viridis::cividis(n = floor(terra::minmax(watershed_ans)[2]/3)) ) %&gt;% sample() , legend = F , axes = F ) plot it with the watershed segmented piles (brown) and the actual piles (blue) # plot it terra::plotRGB(ortho_rast, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) terra::plot( watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 1 ) nice…we are getting close. ideally, we want objects that: i) meet the height threshold over the entire surface of the segment (no doughnuts); ii) are not irregularly shaped (relatively few inward angles); iii) are circular in shape; and iv) meet an expected pile area threshold (minimum/maximum expected area) 5.1.1 Geometric filtering: Irregularity Filtering now let’s try to filter based on the geometric properties of the watershed-detected segments. we’ll make a convex hull of the polygons generated from a raster to smooth out the square edges and any inward curves or indentations, resulting in a boundary that’s always convex (no inward angles). using a convex hull we will be able to filter out: watershed detected segments that were actually lower branches of a tree. these will be shaped like a doughnut with circular shape but a hole in the center watershed detected segments that are irregularly shaped like coarse woody debris that was not organized into piles by humans let’s convert the watershed-detected segments from raster to vector data and create a convex hull of the shapes for comparison # vectors of segments watershed_ans_poly &lt;- watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # convex hulls of segments watershed_ans_poly_chull &lt;- watershed_ans_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) lets make an example area that we’ll use to demonstrate the filtering process of the watershed detected segments example_aoi &lt;- slash_piles_polys %&gt;% dplyr::filter(pile_id == 91) %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_buffer(55) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() # watershed_ans_poly %&gt;% # # dplyr::filter(pred_id==241) %&gt;% # dplyr::filter(pred_id==11916) %&gt;% # # dplyr::slice_sample(n = 1) %&gt;% # sf::st_bbox() %&gt;% # sf::st_as_sfc() %&gt;% # sf::st_buffer(55) # chm of example buff_temp &lt;- 7.3 example_aoi_chm &lt;- cloud2raster_ans$chm_rast %&gt;% terra::crop( example_aoi %&gt;% sf::st_buffer(buff_temp) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::mask( example_aoi %&gt;% sf::st_buffer(buff_temp) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) # list of examples pred_id_temp &lt;- watershed_ans_poly %&gt;% sf::st_intersection(example_aoi) %&gt;% dplyr::pull(pred_id) # plot it plt_ortho_example &lt;- ortho_plt_fn( my_ortho_rast = ortho_rast, stand = example_aoi , buffer = buff_temp ) here is the CHM of the example area. can you pick out the slash piles? example_aoi_chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(mapping = ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;) + ggplot2::labs(fill = &quot;CHM (m)&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) here is the RGB of the example area. can you pick out the slash piles? plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) we’ll add on the ground truth piles in blue on the RGB. how many did you find? be honest. plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) would you have done better if you had both the CHM and RGB data? plt_ortho_example + ggplot2::geom_tile( data = example_aoi_chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.4 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;) + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) now, we’ll plot our example watershed detected segments as vectors (brown) compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) notice how the watershed detected segments have “blocky” outlines since they were generated from the CHM raster let’s plot our example watershed detected segments as vectors (brown) and convex hull of the segments (orange) compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly_chull %&gt;% dplyr::filter(pred_id %in% pred_id_temp) , fill = NA, color = &quot;orangered&quot;, lwd = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) notice how the most irregularly-shaped predicted segments have much less overlap with the convex hull shapes than the more regularly shaped segments let’s filter out segments that have holes in them or are very irregularly shaped by comparing the area of the polygon and convex hull # min required overlap between the predicted pile and the convex hull of the predicted pile pct_chull_overlap &lt;- 0.7 # compare areas watershed_keep_overlaps_chull_pred_id &lt;- watershed_ans_poly %&gt;% dplyr::mutate(poly_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( watershed_ans_poly_chull %&gt;% dplyr::mutate(chull_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( pct_chull = poly_area_m2/chull_area_m2 ) %&gt;% dplyr::filter( pct_chull &gt;= pct_chull_overlap ) %&gt;% dplyr::pull(pred_id) let’s make a function to ingest a spatial data frame and return polygons filtered for irregularity using this convex hull process st_irregular_remove &lt;- function( sf_data # min required overlap between the predicted pile and the convex hull of the predicted pile , pct_chull_overlap = 0.7 ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;)) %&gt;% all()) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # convex hulls of segments poly_chull &lt;- sf_data %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() # dplyr::filter(sf::st_is_valid(.)) # compare areas if(nrow(poly_chull)!=nrow(sf_data)){ stop(&quot;could not make valid convex hulls from provided polygon data&quot;) }else{ area_comp &lt;- sf_data %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::bind_cols( poly_chull %&gt;% dplyr::mutate(chull_area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::select(chull_area_xxxx) %&gt;% sf::st_drop_geometry() ) %&gt;% dplyr::mutate( pct_chull = area_xxxx/chull_area_xxxx ) %&gt;% dplyr::filter( pct_chull &gt;= pct_chull_overlap ) %&gt;% dplyr::select(-c(area_xxxx,chull_area_xxxx)) return(area_comp) } } run it # run it watershed_keep_overlaps_chull_pred_id &lt;- watershed_ans_poly %&gt;% st_irregular_remove(pct_chull_overlap = pct_chull_overlap) %&gt;% dplyr::pull(pred_id) how many piles are remaining after this shape irregularity filtering? length(watershed_keep_overlaps_chull_pred_id) ## [1] 9163 now, we’ll look at which piles meet the minimum overlap threshold (black outline) between the segmented polygon and the convex hull and will be kept compared to those that did not meet the irregularity threshold (red) and will be removed p_temp &lt;- plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly_chull %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::mutate( meets_overlap = pred_id %in% watershed_keep_overlaps_chull_pred_id ) , ggplot2::aes(color = meets_overlap) , fill = NA, lwd = 0.6 ) + ggplot2::scale_color_manual(values = c(&quot;red&quot;,&quot;black&quot;)) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) p_temp let’s see which predictions we are left with after filtering for segment shape irregularity with based on the overlap with the convex hull plot the remaining example watershed detected segments as vectors (brown) compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) it looks like the filtering using convex hulls successfully removed most segments with irregular shapes and holes. following this, we’ll apply an area filter based on the expected minimum and maximum pile areas and then we will apply a circularity filter that uses least squares circle fitting to remove non-circular shapes. this expected area and geometric shape filtering is performed to ensure that only the most likely slash pile candidates are retained. 5.1.2 Area Filtering apply an area filter based on the minimum and maximum expected pile areas. in practice, the expected area range defined here would be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion ##### area thresholds min_area_m2 &lt;- 2 # Two standard US parking spaces, typically measuring 9 feet by 18 feet, # are roughly equivalent to 30.25 square meters. Each space is approximately 15.125 square meters. # 15.125*3 max_area_m2 &lt;- 50 # filter the remaining segments by area and st_irregular_remove removes irregular preds watershed_ans_poly &lt;- watershed_ans_poly %&gt;% # dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) %&gt;% st_irregular_remove(pct_chull_overlap = pct_chull_overlap) %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_xxxx,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_xxxx,0) &lt;= max_area_m2 ) %&gt;% dplyr::select(-c(area_xxxx)) how many piles are remaining after the shape irregularity filtering and area filtering? watershed_ans_poly %&gt;% nrow() ## [1] 1289 example of watershed detected segments as vectors (brown) filtered to remove irregular shapes and segments outside of the expected area thresholds; compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) it looks like we are on the right track. now we need to remove the remaining candidate segments that do not meet our expectations for having a circular base 5.1.3 Geometric filtering: Circularity Filtering now, let’s apply a circle-fitting algorithm to remove non-circular segments from the remaining segments Least squares circle fitting is a method to find the circle that best approximates a set of data points by minimizing the sum of the squared distances between the points and the circle. The lidR::fit_circle() function finds the best-fitting flat, horizontal circle for a group of 3D points, even if some of those points are messy or don’t quite fit. It determines the circle’s center and size, and also provides an “angular range” to show how much of a complete circle the points actually form, which is a more reliable measure than a simple error value (e.g. RMSE). The “angular range” tells you how much of a complete circle the points in the watershed-detected segment actually cover. Imagine drawing a circle, and then only having points along a part of its edge, here’s how to interpret it: 360 degrees suggests the points form a full, unbroken circle, like the base of a perfectly round slash pile. 180 degrees would mean the points only form a half-circle or a semi-circle. A smaller range (e.g., 90 degrees) indicates just a partial arc or a small curve. This can help us determine if a group of points truly represents a circular shape, which is useful for identifying objects like slash piles that are expected to have a round base. we’ll define a function to pass our sf polygon data of watershed detected segments and return a sf data of the fitted circles ########################## # 1) # function to return sf circle from xy center and radius in given crs # to handle return from common circle fitting algorithms ########################## point_xy_radius_to_circle_sf &lt;- function( center_x , center_y , radius , crs = NULL ) { if(is.null(crs)){stop(&quot;need a crs, guy&quot;)} # create a point geometry object center_point &lt;- sf::st_point(c(center_x, center_y)) # create an sf object from the point center_sf &lt;- sf::st_sf( data.frame( center_x = center_x , center_y = center_y , radius = radius ) , geometry = sf::st_sfc(center_point) , crs = crs ) # create the circle geometry by buffering the point circle_sf &lt;- sf::st_buffer(center_sf, dist = radius) return(circle_sf) } ########################## # 2) # function to generate 2d xy points from polygon feature # to pass to common circle fitting algorithms # !!! only works with a singular polygon at a time ########################## poly_to_points &lt;- function( sf_data , as_spatial = F # if set to F, returns xy dataframe; if T returns sf data , simplify_multipolygons = F # if set to T, multipolygons are simplified by keeping the largest segment ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # just work with the first if(nrow(sf_data)&gt;1){stop(&quot;this function only works with a single record at a time&quot;)} # simplify_multipolygons if(simplify_multipolygons){ sf_data &lt;- sf_data %&gt;% dplyr::mutate(treeID=1) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) } # get point coordinates xy_temp &lt;- sf_data %&gt;% sf::st_coordinates() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::select(x,y) %&gt;% dplyr::mutate(z=0) # as_spatial if(as_spatial){ xy_temp &lt;- xy_temp %&gt;% sf::st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;), crs = sf::st_crs(sf_data), remove = F) } return(xy_temp) } # watershed_ans_poly %&gt;% # dplyr::filter(pred_id %in% c(7717)) %&gt;% # # poly_to_points(as_spatial = T) %&gt;% # poly_to_points(as_spatial = F) %&gt;% # ggplot() + # # geom_sf() # geom_point(aes(x=x,y=y)) ########################## # 3) # function to combine poly_to_points, lidR::fit_circle, and point_xy_radius_to_circle_sf # !!! only works with a singular polygon at a time ########################## poly_circle_fit &lt;- function( poly # if set to T, multipolygons are simplified by keeping the largest segment , simplify_multipolygons = F # number of iterations for the RANSAC fitting algorithm , num_iterations = 100 # threshold value; points are considered inliers if their residuals are below this value , inlier_threshold = 0.01 ) { # poly_to_points poly_to_points_ans &lt;- poly_to_points(poly, as_spatial = F, simplify_multipolygons = simplify_multipolygons) # fit_circle fit_circle_ans &lt;- lidR::fit_circle( points = poly_to_points_ans %&gt;% as.matrix() # number of iterations for the RANSAC fitting algorithm , num_iterations = num_iterations # threshold value; points are considered inliers if their residuals are below this value , inlier_threshold = inlier_threshold ) # point_xy_radius_to_circle_sf ans &lt;- point_xy_radius_to_circle_sf( center_x = fit_circle_ans$center_x , center_y = fit_circle_ans$center_y , radius = fit_circle_ans$radius , crs = sf::st_crs(poly) ) # add other vars ans &lt;- ans %&gt;% dplyr::mutate( covered_arc_degree = fit_circle_ans$covered_arc_degree , percentage_inlier = fit_circle_ans$percentage_inlier , percentage_inside = fit_circle_ans$percentage_inside # , inliers = fit_circle_ans$inliers ) # return return(ans) } # watershed_ans_poly %&gt;% # dplyr::filter(pred_id == 7717) %&gt;% # poly_circle_fit() %&gt;% # ggplot() + geom_sf() + # geom_sf( # data = filtered_watershed_ans_poly %&gt;% dplyr::filter(pred_id == 7717) %&gt;% poly_to_points(as_spatial = T) # ) # watershed_ans_poly %&gt;% # dplyr::filter(pred_id == 7717) %&gt;% # poly_circle_fit() %&gt;% # dplyr::glimpse() ########################## # 4) # function to combine poly_to_points, lidR::fit_circle, and point_xy_radius_to_circle_sf # !!! only works with a singular polygon at a time ########################## sf_data_circle_fit &lt;- function(sf_data, num_iterations = 100) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # apply poly_circle_fit() to each row to get fitted circle sf data cf &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(id_xxx = dplyr::row_number()) %&gt;% dplyr::nest_by(id_xxx) %&gt;% dplyr::mutate( circle_fit = poly_circle_fit(poly = data, num_iterations=num_iterations) ) %&gt;% dplyr::pull(circle_fit) # combine with original data but drop original geom df &lt;- sf_data %&gt;% sf::st_drop_geometry() %&gt;% dplyr::bind_cols(cf) %&gt;% sf::st_as_sf(crs = sf::st_crs(sf_data)) # return return(df) } let’s apply the sf_data_circle_fit() function we just defined fits the best circle using lidR::fit_circle() to each watershed detected segment to get a spatial data frame with the best fitting circle for each segment # apply the sf_data_circle_fit() which takes each segment polygon, transforms it to points, and the fits the best circle set.seed(22) watershed_ans_poly_circle_fit &lt;- sf_data_circle_fit(watershed_ans_poly, num_iterations = 111) # what is this? watershed_ans_poly_circle_fit %&gt;% dplyr::glimpse() ## Rows: 1,289 ## Columns: 9 ## $ pred_id &lt;dbl&gt; 8, 12, 20, 24, 26, 32, 38, 47, 50, 52, 53, 54, 55, … ## $ pct_chull &lt;dbl&gt; 0.7577640, 0.7764706, 0.7197802, 0.8000000, 0.81012… ## $ center_x &lt;dbl&gt; 499944.3, 499739.9, 499720.8, 499778.0, 499780.8, 4… ## $ center_y &lt;dbl&gt; 4317698, 4317898, 4317853, 4318048, 4318065, 431761… ## $ radius &lt;dbl&gt; 1.144859e+00, 1.305153e+00, 1.612613e+00, 4.499848e… ## $ covered_arc_degree &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, … ## $ percentage_inlier &lt;dbl&gt; 0.22857143, 0.20000000, 0.12698413, 0.14583333, 0.2… ## $ percentage_inside &lt;dbl&gt; 0.57142857, 0.45714286, 0.50793651, 0.10416667, 0.6… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499945.4 4317698,..., POLYGON ((4… # watershed_ans_poly %&gt;% dplyr::glimpse() let’s check out the distribution of the metrics that quantify the fit of the circle watershed_ans_poly_circle_fit %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(covered_arc_degree,percentage_inlier,percentage_inside) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, fill = name)) + ggplot2::geom_density(color = NA) + ggplot2::facet_wrap(facets = ggplot2::vars(name), scales = &quot;free&quot;) + ggplot2::scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.2, end = 0.8, alpha = 0.8) + ggplot2::theme_light() + ggplot2::theme( axis.text.y = ggplot2::element_blank() , axis.text.x = ggplot2::element_text(angle = 90, vjust = 0.5) , axis.title.x = ggplot2::element_blank() , legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(color = &quot;black&quot;, size = 10) ) let’s look at the best fitting circles using the remaining piles from our example above example of watershed detected segments as vectors (brown) filtered to remove irregular shapes and segments outside of the expected area thresholds; best fitting circle of the segments (orange); compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly_circle_fit %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) %&gt;% dplyr::filter( as.numeric(sf::st_area(.)) &lt; (as.numeric(sf::st_area(example_aoi))*0.5) ) , fill = NA, color = &quot;orangered&quot;, lwd = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) the best fitting circles on the linear watershed detected segments are not very well fitting, we can filter using the intersection over union (IoU) between the circle and the predicted segment. we’ll use the IoU function we defined in this earlier section. watershed_circle_fit_iou &lt;- watershed_ans_poly$pred_id %&gt;% unique() %&gt;% purrr::map(\\(x) ground_truth_single_match( gt_inst = watershed_ans_poly %&gt;% dplyr::filter(pred_id == x) , gt_id = &quot;pred_id&quot; , predictions = watershed_ans_poly_circle_fit %&gt;% dplyr::filter(pred_id == x) %&gt;% dplyr::select(pred_id) %&gt;% dplyr::rename(circ_pred_id = pred_id) , pred_id = &quot;circ_pred_id&quot; , min_iou_pct = 0 ) ) %&gt;% dplyr::bind_rows() # what did we get? watershed_circle_fit_iou %&gt;% dplyr::glimpse() ## Rows: 1,279 ## Columns: 5 ## $ pred_id &lt;dbl&gt; 8, 12, 20, 24, 26, 32, 38, 47, 52, 53, 54, 55, 56, 57, 76… ## $ i_area &lt;dbl&gt; 2.28624273, 2.12113426, 3.82323811, 0.16347654, 2.5174554… ## $ u_area &lt;dbl&gt; 4.269565, 5.867885, 9.582808, 4.952362, 4.961554, 12.6693… ## $ iou &lt;dbl&gt; 0.535474346, 0.361481880, 0.398968460, 0.033009810, 0.507… ## $ circ_pred_id &lt;dbl&gt; 8, 12, 20, 24, 26, 32, 38, 47, 52, 53, 54, 55, 56, 57, 76… what is the distribution of IoU of the watershed segments and the best fit circle of those segments? watershed_circle_fit_iou %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = iou)) + ggplot2::geom_density(color = NA, fill = &quot;navy&quot;, alpha = 0.8) + ggplot2::labs( x = &quot;IoU of the watershed segments and the best fit circle&quot; ) + ggplot2::scale_x_continuous(labels = scales::percent) + ggplot2::theme_light() + ggplot2::theme( axis.text.y = ggplot2::element_blank() , legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(color = &quot;black&quot;, size = 10) ) let’s color our predicted segments by the IoU with the best fitting circle plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) %&gt;% dplyr::left_join(watershed_circle_fit_iou, by = &quot;pred_id&quot;) , mapping = ggplot2::aes(fill = iou) , alpha = 0.9 , lwd = 0 , color = NA ) + ggplot2::geom_sf( data = watershed_ans_poly_circle_fit %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) %&gt;% dplyr::filter( as.numeric(sf::st_area(.)) &lt; (as.numeric(sf::st_area(example_aoi))*0.5) ) , fill = NA, color = &quot;orangered&quot;, lwd = 0.6 ) + ggplot2::scale_fill_fermenter( n.breaks = 10 # 10 use 10 if can go full range 0-1 , palette = &quot;PuOr&quot; # &quot;BrBG&quot; , direction = 1 , limits = c(0,1) # use c(0,1) if can go full range 0-1 , labels = scales::percent , na.value = &quot;sienna4&quot; ) + ggplot2::labs(fill=&quot;IoU&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , legend.text = ggplot2::element_text(size = 6, angle = 90, vjust = 0.5) ) we’ll set a threshold for the minimum IoU to further filter for segments that are approximately round, this filter should remove linear objects from the watershed detections # min required IoU between the predicted pile and the best fit circle of the predicted pile pct_iou_circle_fit &lt;- 0.55 # compare iou watershed_keep_circle_fit_pred_id &lt;- watershed_circle_fit_iou %&gt;% dplyr::filter(iou&gt;=pct_iou_circle_fit) %&gt;% dplyr::pull(pred_id) how many piles are remaining after the shape irregularity filtering, area threshold filtering, and circle fitting filtering? length(watershed_keep_circle_fit_pred_id) ## [1] 578 let’s check out the remaining watershed detected piles after: 1) filtering out the irregularly shaped segments (filtered using the convex hull), 2) filtering for expected pile size, and 3) filtering out the non-circular segments (filtered using circle fitting) example of watershed detected segments as vectors (brown) filtered to remove irregular shapes, segments outside of the expected area thresholds, and non-circular segments; compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::filter(pred_id %in% watershed_keep_overlaps_chull_pred_id) %&gt;% dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) 5.1.4 Area and Volume from CHM We’ll use the CHM raster to calculate area, height, and volume for each candidate pile to reflect the irregular pile footprints and elevation profiles that better represent real-world objects than assuming perfect geometric shapes as is common for quantifying slash pile structure after we calculate the height of the pile based on the maximum height withing the lower CHM slice of the pile footprint, we will lastly apply our filter for the minimum expected pile height. this is the last filtering step to give us our final, structurally-detected slash pile prediction list ######################################## # use the remaining segments that meet the geometric and area filtering # to filter the watershed raster ######################################## smooth_watershed_ans &lt;- watershed_ans %&gt;% terra::mask( watershed_ans_poly %&gt;% #these are irregularity and area filtered already dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %&gt;% terra::vect() , updatevalue=NA ) names(smooth_watershed_ans) &lt;- &quot;pred_id&quot; ######################################## # mask the chm rast to these remaining segments ######################################## smooth_chm_rast &lt;- cloud2raster_ans$chm_rast %&gt;% terra::clamp(upper = max_ht_m, lower = 0, values = F) %&gt;% terra::mask(smooth_watershed_ans) # terra::plot(smooth_chm_rast) # now mask the watershed_ans raster to only keep cells that are in the originating CHM smooth_watershed_ans &lt;- smooth_watershed_ans %&gt;% terra::mask(smooth_chm_rast) # terra::plot(smooth_watershed_ans, col = viridis::turbo(555) %&gt;% sample(), legend = F) ######################################################################################## ## calculate raster-based area and volume ######################################################################################## # first, calculate the area of each cell area_rast &lt;- terra::cellSize(smooth_chm_rast) names(area_rast) &lt;- &quot;area_m2&quot; # area_rast %&gt;% terra::plot() # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes vol_rast &lt;- area_rast*smooth_chm_rast names(vol_rast) &lt;- &quot;volume_m3&quot; # vol_rast %&gt;% terra::plot() # sum area within each segment to get the total area area_df &lt;- terra::zonal(x = area_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # area_df %&gt;% dplyr::glimpse() # sum volume within each segment to get the total volume vol_df &lt;- terra::zonal(x = vol_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # vol_df %&gt;% dplyr::glimpse() # max ht within each segment to get the max ht ht_df &lt;- terra::zonal(x = smooth_chm_rast, z = smooth_watershed_ans, fun = &quot;max&quot;, na.rm = T) %&gt;% dplyr::rename(max_height_m=2) # let&#39;s convert the smoothed and filtered watershed-detected segments from raster to vector data # vectors of segments watershed_ans_poly &lt;- smooth_watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # add area and volume to our vector data # we&#39;ll do this with a slick trick to perform multiple joins succinctly using purrr::reduce watershed_ans_poly &lt;- purrr::reduce( list(watershed_ans_poly, area_df, vol_df, ht_df) , dplyr::left_join , by = &#39;pred_id&#39; ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_m2,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 &amp; dplyr::coalesce(max_height_m,0) &gt;= min_ht_m ) %&gt;% # do one more pass of the irregularity filtering st_irregular_remove(pct_chull_overlap = pct_chull_overlap) what did we do? watershed_ans_poly %&gt;% dplyr::glimpse() ## Rows: 577 ## Columns: 7 ## $ pred_id &lt;dbl&gt; 38, 55, 80, 89, 104, 121, 150, 151, 175, 233, 296, 313… ## $ area_m2 &lt;dbl&gt; 7.886308, 4.923938, 22.057642, 5.644515, 2.682145, 4.2… ## $ volume_m3 &lt;dbl&gt; 15.930993, 14.787953, 65.423964, 12.013256, 4.271128, … ## $ max_height_m &lt;dbl&gt; 3.999429, 3.999000, 3.998000, 3.998000, 3.998000, 3.99… ## $ volume_per_area &lt;dbl&gt; 2.020083, 3.003277, 2.966045, 2.128306, 1.592430, 1.11… ## $ pct_chull &lt;dbl&gt; 0.8509719, 0.8453608, 0.7118863, 0.8221574, 0.8993289,… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499303.8 4318063,..., POLYGON ((4998… how many piles are remaining after the shape irregularity filtering, area threshold filtering, and circle fitting filtering, and height filtering? nrow(watershed_ans_poly) ## [1] 577 let’s look at the remaining piles which have now been: 1) filtered to remove irregular shapes, 2) filtered based on the expected area threshold, 3) filtered to remove non-circular shapes, 4) filtered to remove piles that don’t meet the expected vertical dimensions (i.e. pile height) example of watershed detected segments as vectors (brown) filtered to remove irregular shapes, segments outside of the expected area and height thresholds, and non-circular segments; compared with the ground truth piles (blue) plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% pred_id_temp) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) 5.1.5 Shape Refinement As a final step, we’ll use the convex hull shapes of our remaining segments. This helps to smooth out the often “blocky” edges of raster-based segments, which can look like they were generated in Minecraft. Additionally, by removing any segments with overlapping convex hull shapes, we can likely reduce false detections that are actually groups of small trees or shrubs, ensuring our results represent singular slash piles. ############################################################################### # dissolve groups of touching or overlapping polygons using st_union and st_cast ############################################################################### st_combine_touching &lt;- function(polygons_sf) { # check if the input is an sf data frame if (!inherits(polygons_sf, &quot;sf&quot;)) { stop(&quot;Input &#39;polygons_sf&#39; must be an sf data frame.&quot;) } # check if the geometry type is either polygon or multipolygon geometry_types &lt;- sf::st_geometry_type(polygons_sf) if (!all(geometry_types %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input &#39;polygons_sf&#39; must contain only POLYGON or MULTIPOLYGON geometries.&quot;) } # union then pull out separate polys dissolved_sf &lt;- polygons_sf %&gt;% # 1. perform a full union to dissolve all contiguous polygons into a multipolygon. sf::st_union(by_feature = F) %&gt;% # 2. cast the multipolygon back to individual polygons, one for each component. sf::st_cast(&quot;POLYGON&quot;) %&gt;% # 3. return a new sf data frame with the dissolved components. sf::st_sf() %&gt;% # 4. ensure valid polygons sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # make id dplyr::mutate(id = dplyr::row_number()) return(dissolved_sf) } ############################################################################### # dissolve only contiguous, non-overlapping polygons and combine with others. ############################################################################### st_dissolve_and_combine &lt;- function(polygons_sf) { # Input checks if (!inherits(polygons_sf, &quot;sf&quot;)) stop(&quot;Input &#39;polygons_sf&#39; must be an sf data frame.&quot;) if (!all(sf::st_geometry_type(polygons_sf) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input &#39;polygons_sf&#39; must contain only POLYGON or MULTIPOLYGON geometries.&quot;) } # Identify touching and overlapping polygons using matrix operations touches_matrix &lt;- sf::st_touches(polygons_sf, polygons_sf, sparse = FALSE) overlaps_matrix &lt;- sf::st_overlaps(polygons_sf, polygons_sf, sparse = FALSE) # Exclude self-touching and self-overlapping relationships diag(touches_matrix) &lt;- FALSE diag(overlaps_matrix) &lt;- FALSE # Polygons that are part of a touching group (i.e., touch another polygon) touching_ids &lt;- which(rowSums(touches_matrix) &gt; 0) # Polygons that are part of an overlapping group (i.e., overlap another polygon) overlapping_ids &lt;- which(rowSums(overlaps_matrix) &gt; 0) # Polygons to be dissolved: only those that touch but do not overlap to_dissolve_ids &lt;- touching_ids[!touching_ids %in% overlapping_ids] # Polygons to remain as-is: isolated polygons and overlapping polygons to_keep_ids &lt;- unique(c(which(rowSums(touches_matrix) == 0 &amp; rowSums(overlaps_matrix) == 0), overlapping_ids)) # Separate the datasets to_dissolve_sf &lt;- polygons_sf[to_dissolve_ids, ] to_keep_sf &lt;- polygons_sf[to_keep_ids, ] # # Dissolve the contiguous, non-overlapping polygons # dissolved_sf &lt;- sf::st_union(to_dissolve_sf) # dissolved_cast &lt;- sf::st_cast(dissolved_sf, &quot;POLYGON&quot;) # dissolved_final &lt;- sf::st_sf(geometry = dissolved_cast) dissolved_final &lt;- st_combine_touching(to_dissolve_sf) # Combine the dissolved polygons with the remaining polygons final_result &lt;- dissolved_final %&gt;% dplyr::bind_rows( to_keep_sf %&gt;% dplyr::mutate(id = dplyr::row_number()) %&gt;% dplyr::select(id) ) %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # make id dplyr::mutate(id = dplyr::row_number()) return(final_result) } ############################################################################### # make a function to remove overlapping polygons from a sf data frame ############################################################################### st_remove_overlaps &lt;- function(sf_data) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;)) %&gt;% all()) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } if(nrow(sf_data)&lt;=1){return(sf_data)} # combine all touching polygons and keep the ones that overlap multiple from the original polygons comb_temp &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% sf::st_union(by_feature = F) %&gt;% sf::st_cast(&quot;POLYGON&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% sf::st_set_crs(sf::st_crs(sf_data)) %&gt;% dplyr::mutate(new_id = dplyr::row_number()) %&gt;% dplyr::select(new_id) # identify overlaps overlap_temp &lt;- comb_temp %&gt;% sf::st_intersection(sf_data) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::group_by(new_id) %&gt;% dplyr::summarise(n_orig = dplyr::n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(n_orig&gt;=2) %&gt;% dplyr::pull(new_id) if(length(overlap_temp)==0){return(sf_data)} # just get the overlaps comb_temp &lt;- comb_temp %&gt;% dplyr::filter(new_id %in% overlap_temp) %&gt;% sf::st_union() # remove from the original data return(sf::st_difference(sf_data,comb_temp)) } save this filtered data as our predictions # save this filtered data as our predictions predicted_watershed_piles_sf &lt;- watershed_ans_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() # attach a flag for those in stand predicted_watershed_piles_sf &lt;- predicted_watershed_piles_sf %&gt;% dplyr::mutate( is_in_stand = pred_id %in% (predicted_watershed_piles_sf %&gt;% sf::st_intersection(stand_boundary %&gt;% sf::st_transform(sf::st_crs(predicted_watershed_piles_sf))) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(pred_id)) ) let’s see how many segments were originally detected using the watershed method and how many we are left with after our filtering for shape irregularity, pile area and height expectations, circularity, and potential overlaps after smoothing? dplyr::tibble( n_segments = c( terra::freq(watershed_ans) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() , nrow(predicted_watershed_piles_sf) ) , which_segments = c(&quot;original segments&quot;, &quot;filtered segments&quot;) ) ## # A tibble: 2 × 2 ## n_segments which_segments ## &lt;int&gt; &lt;chr&gt; ## 1 9892 original segments ## 2 520 filtered segments wow that is a lot of filtering…but will it be enough? now let’s look at our final detected segments (brown) compared with the ground truth piles (blue) in the example area we have been looking at plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::filter(pred_id %in% pred_id_temp) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) that looks like it did what we wanted it to do, though note there are a false negative predictions (omission) and false positive predictions (commissions) in this example area as well as many true positive matches let’s look at the entire area again after applying this filter, plotting the remaining watershed segmented piles (brown) and the actual piles (blue) # plot it terra::plotRGB(ortho_rast, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) terra::plot( predicted_watershed_piles_sf %&gt;% terra::vect() , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA, lwd = 1 ) nice! let’s save these data predicted_watershed_piles_sf %&gt;% sf::st_write(&quot;../data/predicted_watershed_piles_sf.gpkg&quot;, append = F) watershed_ans_poly %&gt;% sf::st_write(&quot;../data/watershed_ans_poly.gpkg&quot;, append = F) 5.2 Instance Matching We didn’t “train” any model here, just developed a rules-based method for detecting piles from aerial point cloud data. As such, we can evaluate the methods performance on the “full” set of ground truth pile data. let’s see how we did given the list of predictions compared to the ground truth data using the instance matching process we outlined in this earlier section. 5.2.1 Example Area first, we’ll look at the example area that we have been working with ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% dplyr::arrange(desc(field_diameter_m)) , gt_id = &quot;pile_id&quot; , predictions = predicted_watershed_piles_sf %&gt;% dplyr::filter(pred_id %in% pred_id_temp) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) final plotting it pal_match_grp &lt;- c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= &quot;gray88&quot; #viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # plot it p_temp &lt;- plt_ortho_example + # ggplot2::ggplot() + ggplot2::geom_sf(data = example_aoi %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(watershed_ans_poly)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::filter(pred_id %in% pred_id_temp) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.8 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) p_temp 5.2.2 Full Study Area we’ll look at only predicted and ground truth piles that intersect with the unit boundary for our instance matching ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(predicted_watershed_piles_sf)) , gt_id = &quot;pile_id&quot; , predictions = predicted_watershed_piles_sf %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) let’s look at that spatially for the entire area # plot it ortho_plt_fn(my_ortho_rast = ortho_rast, stand = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), buffer = 10) + # ggplot2::ggplot() + ggplot2::geom_sf(data = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.3 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) ggplot2::ggsave(&quot;../data/watershed_pred_match.jpg&quot;, height = 8, width = 10.5) counts of instance matching results ground_truth_prediction_match_ans %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate(pct = (n/sum(n)) %&gt;% scales::percent(accuracy=0.1)) ## # A tibble: 3 × 3 ## match_grp n pct ## &lt;ord&gt; &lt;int&gt; &lt;chr&gt; ## 1 omission 13 5.5% ## 2 commission 115 48.7% ## 3 true positive 108 45.8% it looks like we did a really good job correctly predicting the location of actual piles (yellow) but that we incorrectly predicted pile locations at a relatively high rate. Our false positive predictions (i.e. commmissions) were frequently located in areas with quaking aspen (Populus tremuloides) which has many more short trees than the treated conifer areas. let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.5763 ## 1st Qu.:0.7836 ## Median :0.8228 ## Mean :0.8050 ## 3rd Qu.:0.8458 ## Max. :0.9284 ## NA&#39;s :128 5.2.2.1 Detection Accuracy we’ll aggregate the raw instance match data to calculate our detection accuracy metrics agg_ground_truth_match(ground_truth_prediction_match_ans) ## # A tibble: 1 × 8 ## tp_n fp_n fn_n omission_rate commission_rate precision recall f_score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 108 115 13 0.107 0.516 0.484 0.893 0.628 let’s plot our confusion matrix confusion_matrix_temp &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans) confusion_matrix_scores_temp &lt;- confusion_matrix_scores_fn(confusion_matrix_temp) # plot confusion_matrix_temp %&gt;% dplyr::select(tidyselect::ends_with(&quot;_n&quot;)) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( presence = ifelse(name %in% c(&quot;tp_n&quot;, &quot;fn_n&quot;),1,0) , estimate = ifelse(name %in% c(&quot;tp_n&quot;, &quot;fp_n&quot;),1,0) ) %&gt;% dplyr::mutate( is_false = as.factor(ifelse(presence!=estimate,1,0)) , presence_fact = factor(presence,levels = 0:1,labels = c(&quot;Observed Absent&quot;, &quot;Observed Present&quot;)) , estimate_fact = factor(estimate,levels = 0:1,labels = c(&quot;Predicted Absent&quot;, &quot;Predicted Present&quot;)) , pct = value/sum(value) ) %&gt;% ggplot(mapping = aes(y = estimate_fact, x = presence_fact)) + geom_tile(aes(fill = is_false), color = &quot;white&quot;,alpha=0.8) + geom_text(aes(label = scales::comma(value,accuracy=1)), vjust = 1,size = 8) + geom_text(aes(label = scales::percent(pct,accuracy=0.1)), vjust = 3.5, size=5) + scale_fill_manual(values= c(&quot;turquoise&quot;,&quot;tomato2&quot;)) + scale_x_discrete(position = &quot;top&quot;) + labs( y = &quot;Predicted&quot; , x = &quot;Observed&quot; , subtitle = paste0( &quot;True positive rate (recall) = &quot; , confusion_matrix_scores_temp$recall %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nPrecision (PPV) = &quot; , confusion_matrix_scores_temp$precision %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nF1-score = &quot; , confusion_matrix_scores_temp$f_score %&gt;% scales::percent(accuracy = 0.1) ) ) + theme_light() + theme( legend.position = &quot;none&quot; , panel.grid = element_blank() , plot.title = element_text(size = 9) , plot.subtitle = element_text(size = 9) ) 5.2.2.2 Quantification Accuracy let’s add structural measurements to our instance matching data first, we’ll review what structural information we already have for the predicted segments predicted_watershed_piles_sf %&gt;% dplyr::glimpse() ## Rows: 520 ## Columns: 8 ## $ pred_id &lt;dbl&gt; 38, 55, 80, 104, 150, 151, 175, 233, 296, 313, 327, 33… ## $ area_m2 &lt;dbl&gt; 7.886308, 4.923938, 22.057642, 2.682145, 18.614888, 4.… ## $ volume_m3 &lt;dbl&gt; 15.930993, 14.787953, 65.423964, 4.271128, 27.613173, … ## $ max_height_m &lt;dbl&gt; 3.999429, 3.999000, 3.998000, 3.998000, 3.997000, 3.99… ## $ volume_per_area &lt;dbl&gt; 2.020083, 3.003277, 2.966045, 1.592430, 1.483392, 2.51… ## $ pct_chull &lt;dbl&gt; 0.8509719, 0.8453608, 0.7118863, 0.8993289, 0.7591837,… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499303.2 4318059,..., POLYGON ((4998… ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE,… Our quantification accuracy evaluation will be restricted to measurements that were directly collected across both sites (i.e. training and validation site). The ground truth dataset only includes direct data for field-measured height, field-measured diameter, and image-annotated area (based on pile perimeters). Accuracy and error metrics, such as ME, RMSE, and MAPE, will be only calculated for these direct measurements. We exclude quantification accuracy metrics for derived values, such as volume, because the resulting value would not constitute a true “error”. Comparing our predicted volume to a volume that was not directly measured, but instead calculated using a geometric assumption (like assuming a perfectly circular base and paraboloid shape) would be inappropriate. This is because any resulting difference between the prediction and the ground truth would be a blend of three inseparable factors: the error of the remote-sensing prediction method, the error in the direct field measurements (diameter/height), and the error introduced by the geometric shape assumption. Reporting such combined errors would be misleading, as it would be impossible to isolate the true performance of our remote-sensing method alone. Instead, data involving these derived values (e.g., predicted volume versus the volume based on field measurements and a shape assumption) will be treated simply as data points for insight into the differences. Using geometric shape assumptions for estimating pile volume is the standard practice when implementing prescriptions or preparing for slash pile burning (Hardy 1996; Long &amp; Boston 2014). This comparison will help us understand the discrepancy between our irregularly shaped CHM-derived volume and the volume calculated assuming a perfectly circular base and paraboloid shape with field-measured height and diameter. This approach will still provide valuable context about the impact of the perfectly circular base and paraboloid geometric assumptions without falsely attributing the error of the simplified model to the remote-sensing method itself. tl;dr: we already have height and area for our predicted piles, we need to calculate diameter. we will not use volume of the ground truth piles to calculate the error in volume measurement of predicted piles because we did not directly measure volume of the ground truth piles. use our st_calculate_diameter() function to add diameter to the predicted piles predicted_watershed_piles_sf &lt;- st_calculate_diameter(predicted_watershed_piles_sf) # predicted_watershed_piles_sf %&gt;% dplyr::glimpse() now, we’ll add pile measurement data for both the ground truth and prediction data to our instance matched data. we’ll also calculate difference columns for the different measurements based on the formulas in this prior section # add pile measurement data ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # join on gt area data dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id, height_m, image_gt_area_m2, field_diameter_m) %&gt;% dplyr::rename( gt_height_m = height_m , gt_area_m2 = image_gt_area_m2 , gt_diameter_m = field_diameter_m ) , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( predicted_watershed_piles_sf %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, max_height_m, area_m2, diameter_m) %&gt;% dplyr::rename( pred_height_m = max_height_m , pred_area_m2 = area_m2 , pred_diameter_m = diameter_m ) , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( # area_m2 diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # height_m , diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m ) let’s check out the relationship between our predictions and the ground truth data df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::select( pile_id , (tidyselect::starts_with(&quot;pred_&quot;) | tidyselect::starts_with(&quot;gt_&quot;)) ) %&gt;% dplyr::select(-c(pred_id)) %&gt;% tidyr::pivot_longer(cols = -pile_id) %&gt;% dplyr::mutate( which_data = stringr::str_extract(name, &quot;^[^_]+&quot;) , name = stringr::str_remove(name, paste0(which_data,&quot;_&quot;)) ) %&gt;% tidyr::pivot_wider( names_from = which_data , values_from = value ) %&gt;% dplyr::mutate( name = dplyr::case_match( name , &quot;height_m&quot; ~ &quot;Height (m)&quot; , &quot;area_m2&quot; ~ &quot;Area (m2)&quot; , &quot;diameter_m&quot; ~ &quot;Diameter (m)&quot; ) ) plt_list_temp &lt;- unique(df_temp$name) %&gt;% purrr::map(function(x){ # get limit max_val &lt;- df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(name==x) %&gt;% dplyr::summarise(max_gt = max(gt,na.rm = T),max_pred = max(pred,na.rm = T)) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::pull(value) %&gt;% max(na.rm = T) plt &lt;- df_temp %&gt;% dplyr::filter(name==x) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = gt, y = pred)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(color = &quot;navy&quot;, size = 2, alpha = 0.9) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::facet_grid(cols = dplyr::vars(name)) + ggplot2::scale_x_continuous(limits = c(0,max_val), breaks = scales::breaks_extended(n=7)) + ggplot2::scale_y_continuous(limits = c(0,max_val), breaks = scales::breaks_extended(n=7)) + ggplot2::labs( x = &quot;ground truth&quot; , y = &quot;predicted&quot; ) + ggplot2::theme_light() + ggplot2::theme( strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) return(plt) }) patchwork::wrap_plots( plt_list_temp , ncol = 3 ) the method performed well at extracting the diameter of the pile when compared to the field-measured value with a slight overestimation overall. with respect to pile area, the method performed very well compared to the image-annotated pile perimeters but tended to under-predict area for the largest piles. the method’s height estimation was more variable in it’s accuracy when compared to the field-measured values and, on-average, performed well for the shorter and intermediate height piles but under-predicted pile height for the tallest piles, this suggests that we set our maximum height threshold too low (set at 4 for this demonstration) for these larger piles. let’s look closer at the difference in area for each pile spatially # look at this spatially ggplot2::ggplot() + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,diff_area_m2,pct_diff_area_m2) ) , mapping = ggplot2::aes(fill = pct_diff_area_m2) , color = NA ) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id) ) , fill = NA, color = &quot;blue&quot; ) + ggplot2::scale_fill_stepsn( n.breaks = 7 , colors = scales::pal_div_gradient()(seq(1, 0, length.out = 7)) , limits = c(-max(abs(fivenum(ground_truth_prediction_match_ans$pct_diff_area_m2))),max(abs(fivenum(ground_truth_prediction_match_ans$pct_diff_area_m2)))) , labels = scales::percent_format(accuracy = 1) , show.limits = T ) + ggplot2::labs(fill = &quot;% difference area&quot;) + ggplot2::theme_void() # and get a summary of the percent error summary(ground_truth_prediction_match_ans$pct_diff_area_m2) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## -0.47831 -0.07621 0.00767 0.00729 0.08151 0.42779 128 the ground truth, image-annotated area is well aligned with the predicted area for most piles (negative values indicate the predicted area is larger than the ground truth area and vice-versa) and let’s look at the distribution of the difference in area (m2) calculated as the predicted area minus the image-annotated area so that negative difference values mean our predictions were smaller and positive values mean our predictions were larger (this is opposite of our percent difference value) # plot the difference of the area ground_truth_prediction_match_ans %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = diff_area_m2) ) + ggplot2::geom_density(fill = &quot;gray&quot;, color = NA) + ggplot2::geom_vline(xintercept = median(ground_truth_prediction_match_ans$diff_area_m2,na.rm=T)) + ggplot2::annotate( &quot;text&quot;, x = median(ground_truth_prediction_match_ans$diff_area_m2,na.rm=T), y = 0 , label = paste(&quot;median:&quot;,scales::comma(median(ground_truth_prediction_match_ans$diff_area_m2,na.rm=T),accuracy=0.1),&quot;m2&quot;) , hjust = 1.01, vjust = 1 ) + ggplot2::labs(y=&quot;density&quot;,x=&quot;area difference (m2)&quot;, subtitle = &quot;Difference in area between predicted and image-annotated slash piles (m2)&quot;) + ggplot2::theme_light() + ggplot2::theme(axis.text.y = ggplot2::element_blank()) # ggplot2::geom_boxplot(outliers = F) O_O nice finally, we’ll aggregate the raw instance matches to calculate quantification accuracy metrics # agg_ground_truth_match() agg_ground_truth_match(ground_truth_prediction_match_ans) %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 17 ## $ tp_n &lt;dbl&gt; 108 ## $ fp_n &lt;dbl&gt; 115 ## $ fn_n &lt;dbl&gt; 13 ## $ omission_rate &lt;dbl&gt; 0.107438 ## $ commission_rate &lt;dbl&gt; 0.5156951 ## $ precision &lt;dbl&gt; 0.4843049 ## $ recall &lt;dbl&gt; 0.892562 ## $ f_score &lt;dbl&gt; 0.627907 ## $ diff_area_m2_rmse &lt;dbl&gt; 2.442577 ## $ diff_diameter_m_rmse &lt;dbl&gt; 0.7078588 ## $ diff_height_m_rmse &lt;dbl&gt; 0.655133 ## $ diff_area_m2_mean &lt;dbl&gt; -0.4566056 ## $ diff_diameter_m_mean &lt;dbl&gt; 0.4777459 ## $ diff_height_m_mean &lt;dbl&gt; -0.09372698 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1060726 ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.1708208 ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.1924974 our area predictions are not very good, we’ll have to check out if those image-annotated areas are accurate also, we can make a pretty table of these detection and quantification accuracy metrics agg_ground_truth_match(ground_truth_prediction_match_ans) %&gt;% # first select to arrange eval_metric dplyr::select( # detection f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( # detection f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) %&gt;% tidyr::pivot_longer( cols = c( f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% stringr::str_c( dplyr::case_when( stringr::str_detect(metric,&quot;(field|image)&quot;) ~ paste0(&quot; (&quot;, stringr::str_extract(metric,&quot;(field|image)&quot;), &quot;)&quot;) , T ~ &quot;&quot; ) ) %&gt;% stringr::str_replace(&quot;area&quot;, &quot;area m&lt;sup&gt;2&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;volume&quot;, &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;diameter&quot;, &quot;diameter m&quot;) %&gt;% stringr::str_replace(&quot;height&quot;, &quot;height m&quot;) %&gt;% stringr::str_to_sentence() , sorter = ifelse(pile_metric==&quot;Detection&quot;,0,1) ) %&gt;% dplyr::arrange(sorter, pile_metric, eval_metric) %&gt;% dplyr::select(pile_metric,eval_metric,value) %&gt;% kableExtra::kbl( caption = &quot;pile detection and form quantification accuracy metrics&quot; , col.names = c( &quot;.&quot;, &quot;&quot; , &quot;value&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 12) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 5.1: pile detection and form quantification accuracy metrics . value Detection F-score 63% Recall 89% Precision 48% Area m2 ME -0.46 RMSE 2.4 MAPE 11% Diameter m ME 0.48 RMSE 0.7 MAPE 17% Height m ME -0.09 RMSE 0.7 MAPE 19% remember, these metrics are just for a test case of the method we just outlined. we’re going to formalize this detection method and then explore different parameterizations of the method to determine a range of expected accuracies based on the input data and settings. 5.3 Watershed Pile Detection Function The rule-based method for slash pile detection using CHM raster data we reviewed above generally follows this outline: CHM Generation: A Canopy Height Model (CHM) is generated from the point cloud data. The CHM is generated by removing the ground surface effectively representing a Digital Surface Model (DSM) without ground, ensuring all values are heights above bare earth. CHM Height Filtering: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a “slice” of the CHM. A final step includes filtering candidate segments based on an expected minimum height threshold as well to remove any piles shorter than this expectation. Candidate Segmentation: Watershed segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form. First Irregularity Filtering: Candidate pile locations are initially filtered to remove highly irregular shapes by assessing their overlap with their convex hull (e.g. &gt;70% overlap). This step helps exclude lower tree branches (objects with holes in the lower CHM slice) and unorganized coarse woody debris. Area Filtering: A filter is applied based on the minimum and maximum expected pile areas. Circularity Filtering: A final geometric screen uses least squares circle fitting on each candidate pile, removing any that do not have a strong overlap (based on an Intersection over Union, or IoU, threshold) with the best-fit circle (e.g., &gt;50%). This removes non-circular features such as rectangular boulders and downed tree stems. Shape Refinement &amp; Overlap Removal: Lastly, segments are smoothed using their convex hull to remove the “blocky” raster edges (like they were made in Minecraft). Overlapping convex hull shapes are then removed to prevent false positives from clustered small trees or shrubs, ensuring singular pile detections. Let’s package all of the steps we demonstrated when formulating the methodology into a single function which can possibly be integrated into the cloud2trees package. The parameters are defined as follows: max_ht_m : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific “slice” of the data, ignoring anything taller than a typical pile. min_ht_m : numeric. The minimum height (in meters) a detected pile must reach to be considered valid. min_area_m2 : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid. max_area_m2 : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid. convexity_pct : numeric. A value between 0 and 1 that controls how strict the filtering is for regularly shaped piles. A value of 1 means only piles that are perfectly smooth and rounded, with no dents or inward curves are kept. A value of 0 allows for both perfectly regular and very irregular shapes. This filter works alongside circle_fit_iou_pct to refine the pile’s overall shape. circle_fit_iou_pct : numeric. A value between 0 and 1 that controls how the filtering is for circular pile shapes. Setting it to 1 means only piles that are perfectly circular are kept. A value of 0 allows for a wide range of shapes, including very circular and non-circular ones (like long, straight lines). smooth_segs : logical. Setting this option to TRUE will: 1) smooth out the “blocky” edges of detected piles (which can look like they were made in Minecraft) by using their overall shape; and 2) remove any detected piles that overlap significantly with other smoothed piles to help ensure each detection is a single slash pile, not a cluster of small trees or shrubs. # detect funciton slash_pile_detect_watershed &lt;- function( chm_rast #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = 4 # set the max expected pile height , min_ht_m = 0.5 # set the min expected pile height , min_area_m2 = 2 # set the min expected pile area , max_area_m2 = 50 # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.7 # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = 0.5 #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) { # checks if(!inherits(chm_rast,&quot;SpatRaster&quot;)){stop(&quot;`chm_rast` must be raster data with the class `SpatRaster` &quot;)} max_ht_m &lt;- max_ht_m[1] min_ht_m &lt;- min_ht_m[1] min_area_m2 &lt;- min_area_m2[1] max_area_m2 &lt;- max_area_m2[1] if( (is.na(tryCatch(as.numeric(max_ht_m), error = function(e) NA)) || identical(as.numeric(max_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_ht_m), error = function(e) NA)) || identical(as.numeric(min_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || identical(as.numeric(max_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || identical(as.numeric(min_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) || !(as.numeric(max_ht_m) &gt; as.numeric(min_ht_m)) || !(as.numeric(max_area_m2) &gt; as.numeric(min_area_m2)) || as.numeric(max_ht_m)&lt;0 || as.numeric(min_ht_m)&lt;0 || as.numeric(min_area_m2)&lt;0 || as.numeric(max_area_m2)&lt;0 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `max_ht_m`,`min_ht_m`,`min_area_m2`,`max_area_m2` are not valid numbers, or the conditions max_area_m2&gt;min_area_m2 or max_ht_m&gt;min_ht_m are not met.&quot;) }else{ max_ht_m &lt;- as.numeric(max_ht_m)[1] min_ht_m &lt;- as.numeric(min_ht_m)[1] min_area_m2 &lt;- as.numeric(min_area_m2)[1] max_area_m2 &lt;- as.numeric(max_area_m2)[1] } # just get the first layer and &quot;slice&quot; the raster based on the height threshold chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) %&gt;% terra::clamp(upper = max_ht_m, lower = 0, values = F) # could make this a parameter # could automatically adjust for raster cell size: # higher res (smaller cell size) get bigger ws, lower res (larger cell size) get smaller/no ws??? # get resolution which will be used to test against the minimum expected pile area chm_res &lt;- max(terra::res(chm_rast)[1:2],na.rm = T) ws_for_smooth &lt;- ws_for_smooth_fn(chm_res = chm_res, min_area_m2 = min_area_m2) # 3 # needs to be the same for the watershed seg and CHM smooth # search_area = (res^2) * (ws^2) ######################################################################################## ## 1) watershed segmentation ######################################################################################## # let&#39;s run watershed segmentation using `lidR::watershed()` which is based on the bioconductor package `EBIimage` # return is a raster with the first layer representing the identified watershed segments watershed_ans &lt;- lidR::watershed( chm = chm_rast , th_tree = min(0.1,min_ht_m) )() names(watershed_ans) &lt;- &quot;pred_id&quot; # vectors of segments watershed_ans_poly &lt;- watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # simplify multipolygons by keeping the largest polygon of each multipolygon dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) ######################################################################################## ## 2) irregularity filtering ######################################################################################## # let&#39;s first filter out segments that have holes in them # or are very irregularly shaped by comparing the area of the polygon and convex hull # convexity_pct = min required overlap between the predicted pile and the convex hull of the predicted pile if(convexity_pct&gt;0){ # apply the irregularity filtering on the polygons watershed_ans_poly &lt;- watershed_ans_poly %&gt;% st_irregular_remove(pct_chull_overlap = convexity_pct) } # check return if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and irregularity expectations&quot; , &quot;\\n try adjusting `convexity_pct` &quot; )) } ######################################################################################## ## 3) area filtering ######################################################################################## # filter out the segments that don&#39;t meet the size thresholds watershed_ans_poly &lt;- watershed_ans_poly %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::filter( dplyr::coalesce(area_xxxx,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_xxxx,0) &lt;= max_area_m2 ) %&gt;% dplyr::select(-c(area_xxxx)) ######################################################################################## ## 4) circularity filtering ######################################################################################## # let&#39;s apply a circle-fitting algorithm to remove non-circular segments from the remaining segments # let&#39;s apply the `sf_data_circle_fit()` function that # fits the best circle using `lidR::fit_circle()` to each watershed detected segment # to get a spatial data frame with the best fitting circle for each segment if(circle_fit_iou_pct==0){ watershed_keep_circle_fit_pred_id &lt;- unique(watershed_ans_poly$pred_id) }else{ # apply the sf_data_circle_fit() which takes each segment polygon, transforms it to points, and the fits the best circle watershed_ans_poly_circle_fit &lt;- sf_data_circle_fit(watershed_ans_poly) # filter using the intersection over union (IoU) between the circle and the predicted segment. # we&#39;ll use the IoU function we defined # we map over this to only compare the segment to it&#39;s own best circle fit...not all # we should consider doing this in bulk.....another day watershed_circle_fit_iou &lt;- watershed_ans_poly$pred_id %&gt;% unique() %&gt;% purrr::map(\\(x) ground_truth_single_match( gt_inst = watershed_ans_poly %&gt;% dplyr::filter(pred_id == x) , gt_id = &quot;pred_id&quot; , predictions = watershed_ans_poly_circle_fit %&gt;% dplyr::filter(pred_id == x) %&gt;% dplyr::select(pred_id) %&gt;% # keeping other columns causes error? dplyr::rename(circ_pred_id = pred_id) , pred_id = &quot;circ_pred_id&quot; , min_iou_pct = 0 # set to 0 just to return pct ) ) %&gt;% dplyr::bind_rows() # threshold for the minimum IoU to further filter for segments that are approximately round, # this filter should remove linear objects from the watershed detections # compare iou watershed_keep_circle_fit_pred_id &lt;- watershed_circle_fit_iou %&gt;% dplyr::filter(iou&gt;=circle_fit_iou_pct) %&gt;% dplyr::pull(pred_id) } if( identical(watershed_keep_circle_fit_pred_id, numeric(0)) || any(is.null(watershed_keep_circle_fit_pred_id)) || any(is.na(watershed_keep_circle_fit_pred_id)) || length(watershed_keep_circle_fit_pred_id)&lt;1 ){ stop(paste0( &quot;no segments detected using the given CHM and circularity expectations&quot; , &quot;\\n try adjusting `circle_fit_iou_pct` &quot; )) } ######################################################################################## ## 5) raster smoothing ######################################################################################## ######################################## # use the remaining segments that meet the geometric and area filtering # to smooth the watershed raster ######################################## smooth_watershed_ans &lt;- watershed_ans %&gt;% terra::mask( watershed_ans_poly %&gt;% #these are irregularity and area filtered already dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %&gt;% terra::vect() , updatevalue=NA ) if(dplyr::coalesce(ws_for_smooth,0)&gt;=3){ # smooths the raster using the majority value smooth_watershed_ans &lt;- smooth_watershed_ans %&gt;% terra::focal(w = ws_for_smooth, fun = &quot;modal&quot;, na.rm = T, na.policy = &quot;only&quot;) # only fill NA cells } names(smooth_watershed_ans) &lt;- &quot;pred_id&quot; ######################################## # mask the chm rast to these remaining segments and smooth to match the smoothing for the segments ######################################## smooth_chm_rast &lt;- chm_rast %&gt;% terra::mask(smooth_watershed_ans) if(dplyr::coalesce(ws_for_smooth,0)&gt;=3){ # smooths the raster to match the smoothing in the watershed segments smooth_chm_rast &lt;- smooth_chm_rast %&gt;% terra::focal(w = ws_for_smooth, fun = &quot;mean&quot;, na.rm = T, na.policy = &quot;only&quot;) #only for cells that are NA } # now mask the watershed_ans raster to only keep cells that are in the originating CHM smooth_watershed_ans &lt;- smooth_watershed_ans %&gt;% terra::mask(smooth_chm_rast) ######################################################################################## ## calculate raster-based area and volume ######################################################################################## # first, calculate the area of each cell area_rast &lt;- terra::cellSize(smooth_chm_rast) names(area_rast) &lt;- &quot;area_m2&quot; # area_rast %&gt;% terra::plot() # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes vol_rast &lt;- area_rast*smooth_chm_rast names(vol_rast) &lt;- &quot;volume_m3&quot; # vol_rast %&gt;% terra::plot() # sum area within each segment to get the total area area_df &lt;- terra::zonal(x = area_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # sum volume within each segment to get the total volume vol_df &lt;- terra::zonal(x = vol_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # max ht within each segment to get the max ht ht_df &lt;- terra::zonal(x = smooth_chm_rast, z = smooth_watershed_ans, fun = &quot;max&quot;, na.rm = T) %&gt;% dplyr::rename(max_height_m=2) # let&#39;s convert the smoothed and filtered watershed-detected segments from raster to vector data # vectors of segments watershed_ans_poly &lt;- smooth_watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # add area and volume to our vector data # we&#39;ll do this with a slick trick to perform multiple joins succinctly using purrr::reduce watershed_ans_poly &lt;- purrr::reduce( list(watershed_ans_poly, area_df, vol_df, ht_df) , dplyr::left_join , by = &#39;pred_id&#39; ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_m2,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 &amp; dplyr::coalesce(max_height_m,0) &gt;= min_ht_m ) %&gt;% # do one more pass of the irregularity filtering st_irregular_remove(pct_chull_overlap = convexity_pct) if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and expected size thresholds&quot; , &quot;\\n try adjusting `max_ht_m`, `min_area_m2`, `max_area_m2` &quot; )) } ######################################################################################## ## 4) shape refinement &amp; overlap removal ######################################################################################## # use the convex hull shapes of our remaining segments. # This helps to smooth out the often &#39;blocky&#39; edges of raster-based segments # , which can look like they were generated in Minecraft. # Additionally, by removing any segments with overlapping convex hull shapes, # we can likely reduce false detections that are actually groups of small trees or shrubs, # ensuring our results represent singular slash piles. if(smooth_segs){ ### ORIGINAL didn&#39;t combine touching segments first # return_dta &lt;- watershed_ans_poly %&gt;% # sf::st_convex_hull() %&gt;% # sf::st_simplify() %&gt;% # sf::st_make_valid() %&gt;% # dplyr::filter(sf::st_is_valid(.)) %&gt;% # dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %&gt;% # st_remove_overlaps() %&gt;% # # now we need to re-do the volume and area calculations # dplyr::mutate( # area_m2 = sf::st_area(.) %&gt;% as.numeric() # , volume_m3 = area_m2*volume_per_area # ) %&gt;% # dplyr::filter( # dplyr::coalesce(area_m2,0) &gt;= min_area_m2 # &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 # ) # combine polygons that share a common border but don&#39;t overlap comb_watershed_ans_poly &lt;- watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %&gt;% st_dissolve_and_combine() %&gt;% dplyr::rename(id_comb_xxx = id) # recalculate metrics agg_comb_watershed_ans_poly &lt;- comb_watershed_ans_poly %&gt;% sf::st_intersection( watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::group_by(id_comb_xxx) %&gt;% dplyr::summarise( area_m2 = sum(area_m2, na.rm = T) , volume_m3 = sum(volume_m3, na.rm = T) , max_height_m = max(max_height_m, na.rm = T) ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) # bring together comb_watershed_ans_poly &lt;- comb_watershed_ans_poly %&gt;% dplyr::inner_join(agg_comb_watershed_ans_poly, by = &quot;id_comb_xxx&quot;) %&gt;% dplyr::rename(pred_id = id_comb_xxx) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_m2,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 &amp; dplyr::coalesce(max_height_m,0) &gt;= min_ht_m ) %&gt;% # do one more pass of the irregularity filtering st_irregular_remove(pct_chull_overlap = convexity_pct) %&gt;% # simplify multipolygons dplyr::mutate(treeID=dplyr::row_number()) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # watershed_ans_poly %&gt;% dplyr::glimpse() # comb_watershed_ans_poly %&gt;% dplyr::glimpse() # apply st_convex_hull return_dta &lt;- comb_watershed_ans_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% dplyr::filter( dplyr::coalesce(area_m2,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 ) }else{ return_dta &lt;- watershed_ans_poly %&gt;% dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) } # calculate diameter return_dta &lt;- st_calculate_diameter(return_dta) # return return(return_dta) } ################################################# # intermediat functions ################################################# # rounds to nearest odd since ws for terra::focal() only takes odd round_to_nearest_odd &lt;- function(x) { rounded_int &lt;- round(x) # step 2: check if the rounded integer is already odd is_odd &lt;- (rounded_int %% 2 != 0) # step 3: for numbers that rounded to an even integer, find the nearest odd odd_down &lt;- rounded_int - 1 odd_up &lt;- rounded_int + 1 # calculate the absolute distances from the original number &#39;x&#39; dist_down &lt;- abs(x - odd_down) dist_up &lt;- abs(x - odd_up) # step 4: use ifelse for vectorized conditional logic result &lt;- ifelse( is_odd , rounded_int # if the initially rounded integer is odd, use it , ifelse( dist_down &lt; dist_up , odd_down # if odd_down is strictly closer , odd_up # if odd_up is closer or equidistant ) ) return(result) } # round_to_nearest_odd(c(2,2.2,1.5,0)) # find window size given res and min expected area ws_for_smooth_fn &lt;- function(chm_res,min_area_m2){ if(length(min_area_m2)&gt;1){stop(&quot;min_area_m2 must be a single numeric value&quot;)} # return dplyr::case_when( T ~ 0 ## all will be 0 so smoothing won&#39;t happen ###!!!!!! original attempt down here...just remove T ~ 0 !!!!!!### , (chm_res*3) &gt; (min_area_m2/2) ~ 0 # the minimum ws of 3 exceeds half of the expected area (coarse) , T ~ round( (min_area_m2/4) / chm_res ) %&gt;% round_to_nearest_odd() %&gt;% max(3) # has to be odd and at least 3 ) } # dplyr::tibble(res = seq(0.01,0.5,by=0.01)) %&gt;% # dplyr::rowwise() %&gt;% # dplyr::mutate( # ws = ws_for_smooth_fn(res, 2) # min_area_m2=2 # , area = ifelse(ws==0, res*res, # (res^2) * (ws^2)) # , area_prop = area/2 # min_area_m2=2 # ) %&gt;% # ggplot() + # # geom_line(aes(x=res,y=ws)) + # # geom_line(aes(x=res,y=area)) + # geom_line(aes(x=res,y=area_prop)) + # # scale_y_continuous(breaks = scales::breaks_extended(n=22)) + # scale_y_continuous(breaks = scales::breaks_extended(n=22), labels = scales::percent) + # scale_x_continuous(breaks = scales::breaks_extended(n=20)) let’s test this real quick on our example area # terra::plot(example_aoi_chm, axes = F, legend = F) # terra::plot( # example_aoi %&gt;% sf::st_transform(sf::st_crs(example_aoi_chm)) %&gt;% terra::vect() # , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 # ) slash_pile_detect_watershed_ans_temp &lt;- slash_pile_detect_watershed( chm_rast = example_aoi_chm , max_ht_m = 4.5 , min_ht_m = 0.5 , min_area_m2 = 2 , max_area_m2 = 50 , convexity_pct = 0.8 , circle_fit_iou_pct = 0.5 ) # what did we get? slash_pile_detect_watershed_ans_temp %&gt;% dplyr::glimpse() ## Rows: 34 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,… ## $ area_m2 &lt;dbl&gt; 4.12, 4.84, 8.28, 9.12, 8.76, 9.06, 7.64, 10.70, 8.42,… ## $ volume_m3 &lt;dbl&gt; 3.436257, 3.979143, 9.554492, 9.208540, 10.130051, 9.7… ## $ max_height_m &lt;dbl&gt; 4.460059, 4.264971, 2.684000, 2.520000, 2.418000, 2.36… ## $ volume_per_area &lt;dbl&gt; 0.8340429, 0.8221369, 1.1539241, 1.0097083, 1.1563985,… ## $ pct_chull &lt;dbl&gt; 0.8349515, 0.8429752, 0.9178744, 0.9122807, 0.9223744,… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499484 4317759, 4..., POLYGON ((4995… ## $ diameter_m &lt;dbl&gt; 3.162278, 3.052868, 3.605551, 3.720215, 3.544009, 3.72… how does it look overlaid on the CHM? terra::plot(example_aoi_chm, col = viridis::plasma(100), axes = F) terra::plot(slash_pile_detect_watershed_ans_temp %&gt;% terra::vect(),add = T, border = &quot;brown&quot;, col = NA, lwd = 3) how do the form quantification measurements look? p1_temp &lt;- slash_pile_detect_watershed_ans_temp %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = area_m2)) + ggplot2::scale_fill_distiller(palette = &quot;Blues&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p2_temp &lt;- slash_pile_detect_watershed_ans_temp %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = volume_m3)) + ggplot2::scale_fill_distiller(palette = &quot;BuGn&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p3_temp &lt;- slash_pile_detect_watershed_ans_temp %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = max_height_m)) + ggplot2::scale_fill_distiller(palette = &quot;YlOrBr&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) p4_temp &lt;- slash_pile_detect_watershed_ans_temp %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = diameter_m)) + ggplot2::scale_fill_distiller(palette = &quot;PuRd&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank()) (p1_temp + p2_temp) / (p3_temp + p4_temp) the volume per area ratio (volume_per_area) quantifies the “effective” height or depth of that volume relative to the area it occupies; this ratio may not be very useful for anything other than scaling estimates to relate a three-dimensional quantity (volume) to a two-dimensional quantity (area) "],["data_fusion.html", "Section 6 Data Fusion 6.1 RGB Indices 6.2 Ground Truth Pile Spectral Summary 6.3 Candidate Polygon Spectral Filtering Function 6.4 Data Fusion Example", " Section 6 Data Fusion We’ll now test and approach that uses both aerial point cloud data (for structural information) and RGB imagery (for spectral information) which is a data fusion approach. First, we’ll identify initial candidate slash piles based on their structural form using our raster-based watershed segmentation approach. Then, we’ll use the RGB imagery to filter these candidates spectrally: relevant RGB vegetation indices such as Green Red Vegetation Index (GRVI), Red Green Ratio Index (RGRI), Visible Band-Difference Vegetation Index (VDVI), Red Green Ratio Index (RGRI), Red Green Blue Vegetation Index (RGBVI), and Excess Green (ExG) are calculated for each candidate segment, and thresholds are applied to remove those exhibiting high greenness. Index thresholds tested include those found to perform well in distinguishing green vegetation in previous research (Motohka et al. 2010; Wang et al. 2025; Riehle et al. 2020). Filtering candidate segments using spectral data will enhance our method’s ability to distinguish non-photosynthetic slash piles from living vegetation (e.g., small trees or shrubs) that might share similar structural profiles. While RGB vegetation indices are good for separating green biomass, differentiating between various shades of brown, black, and white of non-vegetated surfaces like slash piles, rocks, and bare soil can be more challenging. Many common rock-forming minerals are “spectrally featureless” in the visible range, often appearing pale grey to white (Harris et al. 2010). As such, we will attempt to filter out very dark (black) or very light (white) boulders from the reddish-brown tones common of wood in slash piles using RGB indices that focus on overall brightness and color purity (Kior et al. 2024). The Brightness Index (BI) can help us exclude extremely dark (black; low BI) or bright (white; high BI) objects. Setting a minimum threshold for saturation (i.e. color purity) can remove achromatic features (like grey, black, or white objects that have very low saturation values close to 0) to help us isolate more chromatic (brown) slash piles. This data fusion methodology leverages the complementary strengths of both data types, using 3D geometry for initial object segmentation and 2D spectral data to refine detections by excluding green biomass and potential rock and soil features that appear very dark or very light, leading to more accurate slash pile identification. 6.1 RGB Indices For these formulas, \\(R\\), \\(G\\), and \\(B\\) represent the raw pixel values for the Red, Green, and Blue bands, respectively. For indices that use normalized values, \\(r\\), \\(g\\), and \\(b\\) are defined as: \\(r = \\frac{R}{R+G+B}\\) \\(g = \\frac{G}{R+G+B}\\) \\(b = \\frac{B}{R+G+B}\\) Green Red Vegetation Index (GRVI) \\[GRVI = \\frac{G - R}{G + R}\\] Red Green Ratio Index (RGRI) \\[RGRI = \\frac{R}{G}\\] Visible Band-Difference Vegetation Index (VDVI) \\[VDVI = \\frac{2G - R - B}{2G + R + B}\\] Red Green Blue Vegetation Index (RGBVI) \\[RGBVI = \\frac{G^2 - (B \\cdot R)}{G^2 + (B \\cdot R)}\\] Excess Green (ExG) \\[ExG = 2g - r - b = \\frac{2G - R - B}{R+G+B}\\] Excessive Red (ExR) \\[ExR = 1.4r - g = \\frac{1.4R - G}{R+G+B}\\] Excess Green-Excess Red (ExGR) \\[ExGR = 3g - 2.4r - b = \\frac{3G - 2.4R - B}{R+G+B}\\] Brightness Index (BI) \\[BI = \\sqrt{\\frac{R^2+G^2+B^2}{3}}\\] Saturation \\[Saturation = \\frac{\\max(R,G,B) - \\min(R,G,B)}{\\max(R,G,B)}\\] 6.1.1 Spectral Index Functions Although there are dedicated R packages to calculate various spectral indicies (e.g. RStoolbox [Muller et al. 2025]), we’ll make our own to ensure data quality checks and to limit the spectral indices to those highlighted above. # check raster bands and extract rgb layers check_raster_bands &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(rast, &quot;RasterStack&quot;) || inherits(rast, &quot;RasterBrick&quot;) ){ rast &lt;- terra::rast(rast) }else if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;rast&#39; must be a SpatRaster from the `terra` package&quot;) } # check if band indices are valid num_bands &lt;- terra::nlyr(rast) # let 999999 be a cheat code cheat_code &lt;- 999999 if( ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &gt; num_bands ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &gt; num_bands ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &gt; num_bands ) || ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &lt; 1 ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &lt; 1 ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &lt; 1 ) || length(unique(c(red_band_idx,green_band_idx,blue_band_idx)))!=3 ){ stop(&quot;Invalid band index provided. Band indices must correspond to existing, unique layers in the raster object.&quot;) } # extract bands if(red_band_idx!=cheat_code){ R &lt;- rast[[red_band_idx]] }else{ R &lt;- rast[[1]] } if(green_band_idx!=cheat_code){ G &lt;- rast[[green_band_idx]] }else{ G &lt;- rast[[1]] } if(blue_band_idx!=cheat_code){ B &lt;- rast[[blue_band_idx]] }else{ B &lt;- rast[[1]] } return(list(R = R, G = G, B = B)) } # check_raster_bands(ortho_rast, red_band_idx=1, green_band_idx=3, blue_band_idx = 999999) # calculate green red vegetation index (GRVI) # (G - R) / (G + R) spectral_index_grvi &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G grvi &lt;- (G - R) / (G + R) names(grvi) &lt;- &quot;grvi&quot; return(grvi) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # red green ratio index (RGRI) # R/G spectral_index_rgri &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G rgri &lt;- R/G names(rgri) &lt;- &quot;rgri&quot; return(rgri) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # calculate visible band-difference vegetation index (VDVI) # (2G - R - B) / (2G + R + B) spectral_index_vdvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B vdvi &lt;- (2 * G - R - B) / (2 * G + R + B) names(vdvi) &lt;- &quot;vdvi&quot; return(vdvi) } # spectral_index_vdvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate red green blue vegetation index (RGBVI) # (G^2 - (B * R)) / (G^2 + (B * R)) spectral_index_rgbvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B rgbvi &lt;- (G^2 - (B * R)) / (G^2 + (B * R)) names(rgbvi) &lt;- &quot;rgbvi&quot; return(rgbvi) } # spectral_index_rgbvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excess green (ExG) # (2G - R - B) / (R + G + B) (using normalized RGB values) # 2G - R - B (using raw values, then normalized by sum of R+G+B) spectral_index_exg &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exg &lt;- (2 * g_norm - r_norm - b_norm) names(exg) &lt;- &quot;exg&quot; return(exg) } # spectral_index_exg(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate brightness index (BI) # sqrt((R^2 + G^2 + B^2) / 3) spectral_index_bi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B bi &lt;- sqrt((R^2 + G^2 + B^2) / 3) # normalize to 0-1 range max_brightness = max( terra::minmax(R)[2] , terra::minmax(G)[2] , terra::minmax(B)[2] , na.rm = T ) bi &lt;- bi/max_brightness names(bi) &lt;- &quot;bi&quot; return(bi) } # spectral_index_bi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excessive red (ExR) # 1.4r - g, where r and g are normalized RGB values. spectral_index_exr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx){ bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb exr &lt;- (1.4 * r_norm - g_norm) names(exr) &lt;- &quot;exr&quot; return(exr) } #&#39; calculate excess green-excess red (ExGR) #&#39; 3g - 2.4r - b, where r, g, b are normalized RGB values. #&#39; equivalent to ExG - ExR. spectral_index_exgr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exgr &lt;- (3 * g_norm - 2.4 * r_norm - b_norm) names(exgr) &lt;- &quot;exgr&quot; return(exgr) } # calculate saturation (SAT) # (max(R,G,B) - min(R,G,B)) / max(R,G,B) spectral_index_saturation &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B max_rgb &lt;- max(R, G, B) min_rgb &lt;- min(R, G, B) sat &lt;- (max_rgb - min_rgb) / max_rgb names(sat) &lt;- &quot;sat&quot; return(sat) } # spectral_index_saturation(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate all indices calculate_all_rgb_indices &lt;- function(raster_obj, red_band_idx, green_band_idx, blue_band_idx) { # call individual index functions grvi_layer &lt;- spectral_index_grvi(raster_obj, red_band_idx, green_band_idx) rgri_layer &lt;- spectral_index_rgri(raster_obj, red_band_idx, green_band_idx) vdvi_layer &lt;- spectral_index_vdvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) rgbvi_layer &lt;- spectral_index_rgbvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exg_layer &lt;- spectral_index_exg(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exr_layer &lt;- spectral_index_exr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exgr_layer &lt;- spectral_index_exgr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) bi_layer &lt;- spectral_index_bi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) sat_layer &lt;- spectral_index_saturation(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # stack all calculated indices into a single spatraster all_indices &lt;- c( grvi_layer , rgri_layer , vdvi_layer , rgbvi_layer , exg_layer , exr_layer , exgr_layer , bi_layer , sat_layer ) return(all_indices) } let’s test this calculate_all_rgb_indices() function with our orthomosaic # calculate_all_rgb_indices all_rgb_indices_rast &lt;- calculate_all_rgb_indices(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) what did we get? # huh? all_rgb_indices_rast %&gt;% names() ## [1] &quot;grvi&quot; &quot;rgri&quot; &quot;vdvi&quot; &quot;rgbvi&quot; &quot;exg&quot; &quot;exr&quot; &quot;exgr&quot; &quot;bi&quot; &quot;sat&quot; let’s plot all of those indices for the entire extent of our orthomoasic # plot terra::plot( all_rgb_indices_rast , nc = 3 # , nr = 3 , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F ) we can also look at the correlation between the different indices # investigate correlation among covariates all_rgb_indices_rast %&gt;% terra::pairs( maxcells = min(11111, terra::ncell(all_rgb_indices_rast)*.01) ) many of these spectral indices are highly (even perfectly) correlated, meaning they provide redundant information. to streamline our method and ensure we utilize unique spectral insights for distinguishing slash piles from the surrounding terrain and other objects, we will select only one index from each correlated group. GRVI, RGRI, and ExR are highly correlated, as are VDVI, RGBVI, and ExG. we’ll choose one from each of these sets. here is a plot of the different spectral indices (high values are brighter, low values are darker) on our example area we were working with in the last section with the ground truth piles in blue all_rgb_indices_rast %&gt;% terra::crop(example_aoi %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) %&gt;% terra::mask(example_aoi %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) %&gt;% terra::plot( nc = 3 , col = grDevices::gray.colors(111, start = 0, end = 1) , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F , fun = function(){ lines(terra::vect(example_aoi), col=&quot;black&quot;, lwd=2) # add a second vector outline (blue) lines( slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% terra::vect() , col = &quot;blue&quot;, lwd = 1.3) } ) 6.1.2 Spectral Index of Polygons we now need a function to crop the raster with all spectral indices given a polygon input data and return the spectral index values as columns attached to the polygon extract_rast_values &lt;- function(sf_data, rast, fun_agg = mean) { # checks if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } if(!is.function(fun_agg)) { stop(&quot;Argument `fun_agg` must be a function (e.g., mean, median, sum).&quot;) } # crs sf_data &lt;- sf_data %&gt;% sf::st_transform(terra::crs(rast)) # extract values for each layer within each polygon extracted_values &lt;- terra::extract( x = rast , y = sf_data , fun = fun_agg , na.rm = TRUE ) # clean data fun_name &lt;- deparse(substitute(fun_agg)) extracted_values &lt;- extracted_values %&gt;% dplyr::select(-ID) %&gt;% dplyr::rename_with( ~ paste0( &quot;rast_&quot; # , fun_name ### if we want to have custom output depending on the fun_agg , &quot;agg&quot; , &quot;_&quot; , .x , recycle0 = TRUE ) ) # Merge the extracted values back to the original sf data frame # The row order is preserved by terra::extract, so a direct cbind is safe # if no rows were dropped due to spatial mismatch. # For robustness, we can explicitly join by row ID if needed, but for simple cases, cbind works. # Assuming sf_data has a unique ID column or row order is stable: sf_data_with_indices &lt;- sf_data %&gt;% dplyr::bind_cols(extracted_values) return(sf_data_with_indices) } # extract_rast_values(slash_piles_polys, rast = ortho_rast) %&gt;% dplyr::glimpse() 6.2 Ground Truth Pile Spectral Summary let’s calculate the various spectral indices on our ground truth slash pile polygons by getting the median value within the bounds of the pile # extract_rast_values rgb_indices_df &lt;- extract_rast_values(slash_piles_polys, rast = all_rgb_indices_rast, fun_agg = median) rgb_indices_df %&gt;% dplyr::glimpse() ## Rows: 187 ## Columns: 28 ## $ pile_id &lt;dbl&gt; 3, 4, 5, 6, 8, 11, 13, 15, 16, 17, 19, 20, 21, 22,… ## $ comment &lt;chr&gt; NA, NA, NA, NA, &quot;Mechanical Pile&quot;, NA, NA, NA, NA,… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ height_ft &lt;dbl&gt; NA, NA, NA, NA, 14.0, NA, NA, NA, NA, NA, NA, NA, … ## $ diameter_ft &lt;dbl&gt; NA, NA, NA, NA, 22.0, NA, NA, NA, NA, NA, NA, NA, … ## $ xcoord &lt;dbl&gt; NA, NA, NA, NA, 1019078, NA, NA, NA, NA, NA, NA, N… ## $ ycoord &lt;dbl&gt; NA, NA, NA, NA, 4334862, NA, NA, NA, NA, NA, NA, N… ## $ refcorner &lt;chr&gt; NA, NA, NA, NA, &quot;G4&quot;, NA, NA, NA, NA, NA, NA, NA, … ## $ row_number &lt;int&gt; NA, NA, NA, NA, 93, NA, NA, NA, NA, NA, NA, NA, NA… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499341.7 4317759,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 6.469934, 6.867876, 6.387723, 6.589466, 7.595808, … ## $ height_m &lt;dbl&gt; NA, NA, NA, NA, 4.2672, NA, NA, NA, NA, NA, NA, NA… ## $ field_diameter_m &lt;dbl&gt; NA, NA, NA, NA, 6.7056, NA, NA, NA, NA, NA, NA, NA… ## $ field_radius_m &lt;dbl&gt; NA, NA, NA, NA, 3.3528, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_area_m2 &lt;dbl&gt; 25.166539, 32.028082, 22.928349, 26.261937, 28.909… ## $ field_gt_area_m2 &lt;dbl&gt; NA, NA, NA, NA, 35.315484, NA, NA, NA, NA, NA, NA,… ## $ image_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, 61.682109, NA, NA, NA, NA, NA, NA,… ## $ field_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, 75.34912, NA, NA, NA, NA, NA, NA, … ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FA… ## $ rast_agg_grvi &lt;dbl&gt; -0.032584086, -0.028242828, -0.052384051, -0.04705… ## $ rast_agg_rgri &lt;dbl&gt; 1.0673631, 1.0581273, 1.1105597, 1.0987591, 1.0457… ## $ rast_agg_vdvi &lt;dbl&gt; -0.01943105, -0.02085224, -0.02775876, -0.02476903… ## $ rast_agg_rgbvi &lt;dbl&gt; -0.03828319, -0.04091964, -0.05317091, -0.04778023… ## $ rast_agg_exg &lt;dbl&gt; -0.02574134, -0.02761107, -0.03667236, -0.03275494… ## $ rast_agg_exr &lt;dbl&gt; 0.16016840, 0.15627252, 0.17784675, 0.17298965, 0.… ## $ rast_agg_exgr &lt;dbl&gt; -0.1866028, -0.1835047, -0.2156208, -0.2073676, -0… ## $ rast_agg_bi &lt;dbl&gt; 0.48999473, 0.50380811, 0.41243017, 0.43621239, 0.… ## $ rast_agg_sat &lt;dbl&gt; 0.06838244, 0.06986231, 0.11602359, 0.09983881, 0.… # quick summary rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% summary() ## rast_agg_grvi rast_agg_rgri rast_agg_vdvi rast_agg_rgbvi ## Min. :-0.0523841 Min. :0.7814 Min. :-0.0380903 Min. :-0.066556 ## 1st Qu.:-0.0183949 1st Qu.:0.9919 1st Qu.:-0.0150468 1st Qu.:-0.028208 ## Median :-0.0051776 Median :1.0104 Median : 0.0060960 Median : 0.016233 ## Mean :-0.0007363 Mean :1.0030 Mean :-0.0001669 Mean : 0.002146 ## 3rd Qu.: 0.0040900 3rd Qu.:1.0375 3rd Qu.: 0.0138264 3rd Qu.: 0.028844 ## Max. : 0.1227404 Max. :1.1106 Max. : 0.0223162 Max. : 0.045439 ## rast_agg_exg rast_agg_exr rast_agg_exgr rast_agg_bi ## Min. :-0.0501504 Min. :0.03125 Min. :-0.21562 Min. :0.05521 ## 1st Qu.:-0.0199623 1st Qu.:0.13239 1st Qu.:-0.15365 1st Qu.:0.35286 ## Median : 0.0081446 Median :0.13834 Median :-0.13253 Median :0.47475 ## Mean :-0.0001212 Mean :0.13466 Mean :-0.13491 Mean :0.40386 ## 3rd Qu.: 0.0185206 3rd Qu.:0.15020 3rd Qu.:-0.11602 3rd Qu.:0.50461 ## Max. : 0.0299779 Max. :0.17785 Max. :-0.03701 Max. :0.61996 ## rast_agg_sat ## Min. :0.02616 ## 1st Qu.:0.06252 ## Median :0.07335 ## Mean :0.09759 ## 3rd Qu.:0.11510 ## Max. :0.36490 let’s plot it # pivot agg_df_temp &lt;- rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;rast_agg_&quot;) %&gt;% stringr::str_to_upper()) # plot ggplot2::ggplot() + ggplot2::geom_density( data = agg_df_temp , mapping = ggplot2::aes(x = value, fill = name) , color = NA, alpha = 0.8 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=median(value,na.rm=T)) , mapping = ggplot2::aes(xintercept = value, color = &quot;median&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=0.025)) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=(1-0.025))) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::scale_fill_viridis_d(option = &quot;turbo&quot;, begin = 0.1, end = 0.9, alpha = 0.7) + # ggplot2::scale_fill_brewer(palette = &quot;Set2&quot;) + ggplot2::scale_color_manual(values = c(&quot;gray22&quot;,&quot;gray&quot;,&quot;gray&quot;)) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(8)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 3 , scales = &quot;free&quot; ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() ) + ggplot2::guides(fill = &quot;none&quot;) that’s interesting. let’s see how those values compare with the thresholds identified in the research to identify green crops, trees, and shrubs using RGB spectral indicies Index Likely Crop Likely Tree Likely Shrub Source VDVI x &gt; 0.06 x &gt; 0.04 x &gt; 0.03 Wang et al. 2025 RGRI x &lt; 0.63 x &lt; 0.70 x &lt; 0.52 Wang et al. 2025 RGBVI x &gt; -20.0 x &gt; -22.0 x &gt; -18.0 Wang et al. 2025 ExG x &gt; 58.0 x &gt; 59.5 x &gt; 59.0 Wang et al. 2025 GRVI x &gt; 0.0 x &gt; 0.0 Motohka et al. 2010 ExGR x &gt; 0.0 x &gt; 0.0 x &gt; 0.0 Riehle et al. 2020 VDVI: setting a threshold to remove candidate slash piles with VDVI&gt;0.03 should work well RGRI: setting a threshold to remove candidate slash piles with RGRI&lt;0.70 should work well RGBVI: setting a threshold to remove candidate slash piles with RGBVI&gt;-18.0 should not work well There appears to be a mis-match between the range of values we calculated ([-1.00, 1.00]) and their range ([-50, 78]) ExG: setting a threshold to remove candidate slash piles with ExG&gt;59.5 should not work well There appears to be a mis-match between the range of values we calculated ([-1.00, 2.00]) and their range ([0, 150]) GRVI: setting a threshold to remove candidate slash piles with GRVI&gt;0.0 should work moderately well We may need to raise this threshold to remove candidate slash piles with GRVI&gt;0.05, for example ExGR: setting a threshold to remove candidate slash piles with ExGR&gt;0.0 should work well BI: setting a threshold to remove candidate slash piles that are extremely dark (BI&lt;0.10) or bright (BI&gt;0.90) should work well Saturation: setting a threshold to remove candidate slash piles that have low saturation values (SAT&lt;0.03) should work well Based on these thresholds identified in the literature and our objective to remove very highly correlated indices, we’ll proceed with the following five indices to refine the structurally detected candidate slash piles: RGRI VDVI ExGR BI Saturation (SAT) here is a plot of the median value of the different spectral indices (high values are brighter, low values are darker) within the bounds of the pile on our example area we were working with in the last section polys_temp &lt;- rgb_indices_df %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% dplyr::select(pile_id, tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% tidyr::pivot_longer(cols = tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::mutate(name = stringr::str_remove(name,&quot;rast_agg_&quot;)) # # dplyr::filter(name==&quot;grvi&quot;) %&gt;% # ggplot2::ggplot() + # ggplot2::geom_sf(mapping=ggplot2::aes(fill=value)) + # ggplot2::facet_wrap(facets=dplyr::vars(name)) + # ggplot2::theme_void() + # ggplot2::theme(legend.position = &quot;top&quot;) # rast clip rast_temp &lt;- all_rgb_indices_rast %&gt;% terra::crop(example_aoi %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) %&gt;% terra::mask(example_aoi %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) # plot list plt_list_temp &lt;- names(all_rgb_indices_rast) %&gt;% # sample(6) %&gt;% purrr::map( \\(x) ggplot2::ggplot() + ggplot2::geom_tile( data = rast_temp[[x]] %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x = x, y = y, fill = f) , alpha = 0.9 ) + ggplot2::geom_sf( data = example_aoi , color = &quot;black&quot;, fill = NA, lwd = 0.8 ) + ggplot2::geom_sf( data = polys_temp %&gt;% dplyr::filter(name == x) , mapping = ggplot2::aes(fill=value) , color = &quot;blue&quot;, lwd = 0.6 ) + # ggplot2::geom_sf_text( # data = polys_temp %&gt;% dplyr::filter(name == x) # , mapping = ggplot2::aes(label=scales::comma(value, accuracy=0.01), fontface = &quot;bold&quot;) # , size = 1.7, color = &quot;blue&quot; # , vjust = 0, hjust = 0.5 # ) + ggrepel::geom_text_repel( data = polys_temp %&gt;% dplyr::filter(name == x) %&gt;% sf::st_point_on_surface() %&gt;% dplyr::mutate( x_coord = sf::st_coordinates(.)[, 1] , y_coord = sf::st_coordinates(.)[, 2] ) , mapping = ggplot2::aes(x = x_coord, y = y_coord, label=scales::comma(value, accuracy=0.01), fontface = &quot;bold&quot;) , nudge_x = 0.5 # initial horizontal nudge , nudge_y = -0.2 # initial vertical nudge , size = 2.2, color = &quot;blue&quot; , force = 1 , box.padding = 0.3 # Increase padding to push labels further away # , point.padding = 0.7 # Ensure distance from the original point , min.segment.length = 0.5 # Minimum length of the connecting line segment , segment.color = NA ) + ggplot2::scale_fill_distiller(palette = &quot;Greys&quot;) + # ggplot2::scale_fill_gradientn(colors = grDevices::gray.colors(111, start = 0, end = 1)) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( fill = x , subtitle = x ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; , plot.subtitle = ggplot2::element_text(size = 11, face = &quot;bold&quot;, hjust = 0.5) ) ) # plt_list_temp # patchwork patchwork::wrap_plots( plt_list_temp , ncol = 3 ) 6.2.1 Voting System let’s consider a voting system approach for filtering candidate slash piles using the multiple spectral indices. a voting system could allow for a more robust and nuanced decision than relying on a single index. let’s make a highly specialized function using the data returned by out extract_rast_values() function rgb_indices_threshold_voting &lt;- function( rgb_indices_df # define ranges to *keep* piles , th_rgri = c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_vdvi = c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_exgr = c(-Inf,0) , th_bi = c(0.1,0.9) , th_sat = c(0.03,Inf) ){ # checks if(!inherits(rgb_indices_df, &quot;data.frame&quot;)){ stop(&quot;Input `rgb_indices_df` must be an data.frame.&quot;) } # names agg_cols &lt;- c(&quot;rast_agg_exgr&quot;,&quot;rast_agg_rgri&quot;,&quot;rast_agg_vdvi&quot;,&quot;rast_agg_bi&quot;,&quot;rast_agg_sat&quot;) # &quot;rast_agg_rgbvi&quot;, nm_diff &lt;- base::setdiff( agg_cols , names(rgb_indices_df) ) if(length(nm_diff)&gt;0){ stop(paste0(&quot;required variables missing:\\n&quot;, &quot;... &quot;, paste(nm_diff, collapse = &quot;, &quot;) )) } # thresholds if(length(th_exgr)!=2 || th_exgr[1]&gt;th_exgr[2]){ stop(&quot;Input `th_exgr` must be of length 2 as: c(lower,upper) defining the range of values to keep where lower&lt;=upper&quot;) } if(length(th_rgri)!=2 || th_rgri[1]&gt;th_rgri[2]){ stop(&quot;Input `th_rgri` must be of length 2 as: c(lower,upper) defining the range of values to keep where lower&lt;=upper&quot;) } if(length(th_vdvi)!=2 || th_vdvi[1]&gt;th_vdvi[2]){ stop(&quot;Input `th_vdvi` must be of length 2 as: c(lower,upper) defining the range of values to keep where lower&lt;=upper&quot;) } if(length(th_bi)!=2 || th_bi[1]&gt;th_bi[2]){ stop(&quot;Input `th_bi` must be of length 2 as: c(lower,upper) defining the range of values to keep where lower&lt;=upper&quot;) } if(length(th_sat)!=2 || th_sat[1]&gt;th_sat[2]){ stop(&quot;Input `th_sat` must be of length 2 as: c(lower,upper) defining the range of values to keep where lower&lt;=upper&quot;) } # get rid of columns we&#39;ll create rgb_indices_df &lt;- rgb_indices_df %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;inrange_th_exgr&quot; , &quot;inrange_th_rgri&quot; , &quot;inrange_th_vdvi&quot; , &quot;inrange_th_bi&quot; , &quot;inrange_th_sat&quot; ))) # check threshold ret_df &lt;- rgb_indices_df %&gt;% # dplyr::select(dplyr::all_of(agg_cols)) %&gt;% dplyr::mutate( inrange_th_exgr = ifelse( !is.na(rast_agg_exgr) &amp; rast_agg_exgr &gt;= th_exgr[1] &amp; rast_agg_exgr &lt;= th_exgr[2] , 1, 0 ) , inrange_th_rgri = ifelse( !is.na(rast_agg_rgri) &amp; rast_agg_rgri &gt;= th_rgri[1] &amp; rast_agg_rgri &lt;= th_rgri[2] , 1, 0 ) , inrange_th_vdvi = ifelse( !is.na(rast_agg_vdvi) &amp; rast_agg_vdvi &gt;= th_vdvi[1] &amp; rast_agg_vdvi &lt;= th_vdvi[2] , 1, 0 ) , inrange_th_bi = ifelse( !is.na(rast_agg_bi) &amp; rast_agg_bi &gt;= th_bi[1] &amp; rast_agg_bi &lt;= th_bi[2] , 1, 0 ) , inrange_th_sat = ifelse( !is.na(rast_agg_sat) &amp; rast_agg_sat &gt;= th_sat[1] &amp; rast_agg_sat &lt;= th_sat[2] , 1, 0 ) ) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( inrange_th_votes = sum( dplyr::c_across(tidyselect::starts_with(&quot;inrange_th_&quot;)) , na.rm = T ) %&gt;% dplyr::coalesce(0) ) %&gt;% ungroup() #return return(ret_df) } let’s look at the columns we get from our rgb_indices_threshold_voting() function rgb_indices_df &lt;- rgb_indices_threshold_voting(rgb_indices_df=rgb_indices_df) # huh? rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% summary() ## inrange_th_exgr inrange_th_rgri inrange_th_vdvi inrange_th_bi ## Min. :1 Min. :1 Min. :1 Min. :0.0000 ## 1st Qu.:1 1st Qu.:1 1st Qu.:1 1st Qu.:1.0000 ## Median :1 Median :1 Median :1 Median :1.0000 ## Mean :1 Mean :1 Mean :1 Mean :0.9358 ## 3rd Qu.:1 3rd Qu.:1 3rd Qu.:1 3rd Qu.:1.0000 ## Max. :1 Max. :1 Max. :1 Max. :1.0000 ## inrange_th_sat inrange_th_votes ## Min. :0.0000 Min. :4.00 ## 1st Qu.:1.0000 1st Qu.:5.00 ## Median :1.0000 Median :5.00 ## Mean :0.9947 Mean :4.93 ## 3rd Qu.:1.0000 3rd Qu.:5.00 ## Max. :1.0000 Max. :5.00 notice the “Mean” value in the summary above is the proportion of ground truth piles that successfully met the spectral index threshold criteria (i.e. piles to be “kept”). it looks like the SAT threshold was most unaligned with these ground truth piles, something we anticipated by looking at the distributions above compared the threshold value recommended in the literature for detecting green vegetation. let’s look at the proportional distribution of ground truth piles meeting the threshold by individual spectral index rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::filter(name!=&quot;VOTES&quot;) %&gt;% dplyr::count(name,value) %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate( pct = n/sum(n) , value = factor(value, levels = 0:1, labels = c(&quot;outside threshold&quot;,&quot;within threshold&quot;), ordered = T) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 3, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;magma&quot;, begin = 0.3, end = 0.7) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 2 ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) and let’s look at the distribution of ground truth piles based on the number of individual spectral index thresholds met. we’ll use this count as our voting system. dplyr::tibble(value=0:5) %&gt;% dplyr::left_join( rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_votes&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::count(name,value) , by = dplyr::join_by(value) ) %&gt;% dplyr::mutate( n = dplyr::coalesce(n,0) , pct = n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) , value = factor(value) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 4, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;mako&quot;, direction=-1) + ggplot2::scale_y_continuous( labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.15)) ) + ggplot2::labs( y = &quot;&quot;, x = &quot;spectral index threshold votes&quot;, color = &quot;&quot;, fill = &quot;&quot; , subtitle = &quot;distribution of ground truth piles meeting spectral index thresholds&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) we can use this spectral index voting system to filter candidate slash piles with a user-defined parameter which defines the sensitivity of filtering based on the spectral information. For example, a value of “5” would heavily weight the spectral information in determining which piles to keep while a value of “1” would put less weight on the spectral data. let’s see what some of those piles with the fewest votes look like on the imagery # filter for the plots with the fewest votes dta_temp &lt;- rgb_indices_df %&gt;% dplyr::filter(inrange_th_votes&lt;=4) %&gt;% dplyr::slice_sample(n=12) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # dta_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg&quot;)) %&gt;% summary() # plot on ortho plts_temp &lt;- 1:nrow(dta_temp) %&gt;% purrr::map(function(x){ dta &lt;- dta_temp %&gt;% dplyr::slice(x) dta &lt;- dta %&gt;% dplyr::bind_cols( dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::filter(name!=&quot;VOTES&quot; &amp; value == 0) %&gt;% dplyr::select(-value) %&gt;% tidyr::pivot_wider(values_from = name) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( lab = paste( dplyr::c_across(dplyr::everything()) , collapse = &quot;, &quot; ) ) %&gt;% dplyr::select(lab) ) ortho_plt_fn(my_ortho_rast = ortho_rast, stand =dta) + ggplot2::geom_sf(data = dta, fill = NA, color = &quot;white&quot;, lwd = 0.6) + ggplot2::labs(subtitle = paste0(&quot;Outside Threshold:\\n&quot;,dta$lab)) + ggplot2::theme(plot.subtitle = ggplot2::element_text(size = 9)) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) all of those piles would have been voted out based on SAT or BI since they are either in shadows or the dead wood appears very bright/white (perhaps we need to adjust those thresholds?). let’s see a summary of those spectral index values for these piles with the fewest votes dta_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(rast_agg_bi, rast_agg_sat) %&gt;% summary() ## rast_agg_bi rast_agg_sat ## Min. :0.05521 Min. :0.1229 ## 1st Qu.:0.06566 1st Qu.:0.1978 ## Median :0.07075 Median :0.2542 ## Mean :0.07154 Mean :0.2538 ## 3rd Qu.:0.07920 3rd Qu.:0.2985 ## Max. :0.08803 Max. :0.3649 6.3 Candidate Polygon Spectral Filtering Function let’s put all of this together to define a function that takes as input: 1) a spatial data frame of candidate polygons; 2) a raster with RGB spectral data; 3) user-defined spectral weighting (voting system) polygon_spectral_filtering &lt;- function( sf_data , rgb_rast # define the band index , red_band_idx , green_band_idx , blue_band_idx # spectral weighting , spectral_weight = 3 ) { ### could make these parameters th_rgri &lt;- c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper th_vdvi &lt;- c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper th_exgr = c(-Inf,0) th_bi &lt;- c(0.1,0.9) th_sat &lt;- c(0.03,Inf) # checks if(!inherits(rgb_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } spectral_weight &lt;- as.numeric(spectral_weight) if( !(spectral_weight %in% c(0:5)) ){ stop(&quot;Input `spectral_weight` must be a number between 0 (no filtering based on spectral) and 5 (highest weighting of spectral data)&quot;) } # if you don&#39;t want to do it, then why do it? if(spectral_weight==0){ return(sf_data) } ################################################## # calculate_all_rgb_indices ################################################## all_rgb_indices_rast &lt;- calculate_all_rgb_indices( raster_obj = rgb_rast , red_band_idx = red_band_idx , green_band_idx = green_band_idx , blue_band_idx = blue_band_idx ) ################################################## # extract_rast_values ################################################## rgb_indices_df &lt;- extract_rast_values( sf_data = sf_data %&gt;% dplyr::ungroup() , rast = all_rgb_indices_rast , fun_agg = median ) ################################################## # rgb_indices_threshold_voting ################################################## rgb_indices_df &lt;- rgb_indices_threshold_voting( rgb_indices_df=rgb_indices_df , th_rgri = th_rgri , th_vdvi = th_vdvi , th_exgr = th_exgr , th_bi = th_bi , th_sat = th_sat ) ################################################## # filtering ################################################## rgb_indices_df &lt;- rgb_indices_df %&gt;% dplyr::filter(inrange_th_votes&gt;=spectral_weight) # return return(rgb_indices_df) } # polygon_spectral_filtering( # sf_data = slash_piles_polys # , rgb_rast = ortho_rast # , red_band_idx = 1 # , green_band_idx = 2 # , blue_band_idx = 3 # , spectral_weight = 4 # ) %&gt;% # nrow() # # dplyr::glimpse() # nrow(slash_piles_polys) 6.4 Data Fusion Example we previously worked through an example where we identified candidate slash piles based on their structural form using our raster-based watershed segmentation approach. let’s go back to that example and see how the spectral filtering method we defined above impacts the results. first, load those example predictions # structurally predicted predicted_watershed_piles_sf &lt;- sf::st_read(&quot;../data/predicted_watershed_piles_sf.gpkg&quot;, quiet = T) # ortho plt # plot it buff_temp &lt;- 7.3 plt_ortho_example &lt;- ortho_plt_fn( my_ortho_rast = ortho_rast, stand = example_aoi , buffer = buff_temp ) here is a reminder of the structurally-detected segments (brown) compared with the ground truth piles (blue) in the example area we have been looking at plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::inner_join( predicted_watershed_piles_sf %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) Remember, our data fusion method uses the spectral data strictly as a final filter or quality check on the structurally-detected candidate piles, meaning it neither adds new piles nor alters the shape or location of the candidates. As a result, if the structural detection step missed a pile (false negative or omission), the spectral data won’t go back and fix it. The only changes we can expect by including spectral data in our data fusion approach is a trade-off: we can either improve our precision by successfully removing detections that aren’t actually piles (commissions or false positives), or we run the risk of mistakenly filtering out real piles (true positives) if their spectral signature happens to look unusual, which would unfortunately lower our recall. Different magnitude changes in these metrics will directly impact the overall accuracy measure of F-score. For example, a large gain in precision paired with only a small drop in recall will result in a net increase in the F-score, whereas a steep drop in recall will quickly negate any gains from improved precision. let’s apply our spectral filtering method to the full set of structurally-detected piles using a spectral_weight of “4” which requires four of the five spectral thresholds to be met for a candidate pile to be retained final_predicted_slash_piles &lt;- polygon_spectral_filtering( sf_data = predicted_watershed_piles_sf , rgb_rast = ortho_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = 4 ) what did we get? # huh? final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 342 ## Columns: 23 ## $ pred_id &lt;dbl&gt; 38, 80, 150, 233, 296, 335, 345, 403, 552, 595, 872, … ## $ area_m2 &lt;dbl&gt; 7.886308, 22.057642, 18.614888, 23.098474, 2.321857, … ## $ volume_m3 &lt;dbl&gt; 15.930993, 65.423964, 27.613173, 25.648945, 5.870187,… ## $ max_height_m &lt;dbl&gt; 3.999429, 3.998000, 3.997000, 3.994792, 3.992937, 3.9… ## $ volume_per_area &lt;dbl&gt; 2.0200827, 2.9660453, 1.4833918, 1.1104173, 2.5282292… ## $ pct_chull &lt;dbl&gt; 0.8509719, 0.7118863, 0.7591837, 0.8952676, 0.7204969… ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE,… ## $ rast_agg_grvi &lt;dbl&gt; 0.051901337, 0.053044260, 0.003640603, 0.067690785, 0… ## $ rast_agg_rgri &lt;dbl&gt; 0.9013190, 0.8992777, 0.9927452, 0.8732015, 0.9749513… ## $ rast_agg_vdvi &lt;dbl&gt; 0.07027040, -0.01708128, 0.03236633, 0.03398474, -0.0… ## $ rast_agg_rgbvi &lt;dbl&gt; 0.14096444, -0.02549687, 0.06923695, 0.07262199, -0.0… ## $ rast_agg_exg &lt;dbl&gt; 0.09594114, -0.02264607, 0.04362578, 0.04583218, -0.0… ## $ rast_agg_exr &lt;dbl&gt; 0.09521890, 0.08437340, 0.13648952, 0.07878246, 0.120… ## $ rast_agg_exgr &lt;dbl&gt; -0.001033881, -0.107019464, -0.088533181, -0.02634802… ## $ rast_agg_bi &lt;dbl&gt; 0.44347274, 0.04628512, 0.47422114, 0.14808661, 0.282… ## $ rast_agg_sat &lt;dbl&gt; 0.16817074, 0.23150009, 0.17257952, 0.15251648, 0.126… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((499303.2 4318059,..., POLYGON ((499… ## $ inrange_th_exgr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_rgri &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_vdvi &lt;dbl&gt; 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,… ## $ inrange_th_bi &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_sat &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_votes &lt;dbl&gt; 4, 4, 4, 4, 5, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 4,… # final_predicted_slash_piles %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::count(inrange_th_votes) how many piles were removed? # how many piles were removed? nrow(predicted_watershed_piles_sf)-nrow(final_predicted_slash_piles) ## [1] 178 # what proportion were removed? scales::percent( (nrow(predicted_watershed_piles_sf)-nrow(final_predicted_slash_piles))/nrow(predicted_watershed_piles_sf) , accuracy=0.1 ) ## [1] &quot;34.2%&quot; let’s check out the results of the spectral filtering for our example area p_temp &lt;- plt_ortho_example + ggplot2::geom_sf(data = example_aoi, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) , fill = NA, color = &quot;blue&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::inner_join( predicted_watershed_piles_sf %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # , fill = NA, color = &quot;brown&quot;, lwd = 0.6 , fill = &quot;brown&quot;, color = NA, lwd = 0, alpha = 0.6 ) + ggplot2::geom_sf( data = predicted_watershed_piles_sf %&gt;% dplyr::inner_join( predicted_watershed_piles_sf %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% dplyr::left_join( final_predicted_slash_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) %&gt;% dplyr::mutate(is_spectral_kept = T) ) %&gt;% dplyr::mutate(is_spectral_kept = dplyr::coalesce(is_spectral_kept,F)) , ggplot2::aes(color = is_spectral_kept) , fill = NA, lwd = 0.6 ) + ggplot2::scale_color_manual(values = c(&quot;red&quot;,&quot;black&quot;)) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) p_temp let’s look at the instance matching results for this example area # instance match ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::inner_join( final_predicted_slash_piles %&gt;% sf::st_transform(terra::crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # plot it p_temp &lt;- plt_ortho_example + # ggplot2::ggplot() + ggplot2::geom_sf(data = example_aoi %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::inner_join( slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = final_predicted_slash_piles %&gt;% dplyr::inner_join( final_predicted_slash_piles %&gt;% sf::st_transform(terra::crs(example_aoi)) %&gt;% sf::st_intersection(example_aoi) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.8 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) p_temp unfortunately, we didn’t remove as many false positive predictions as we would have liked for this example area but we did slightly improve our precision (by a count of one)…we’ll have to see how we did for the full ground truth set 6.4.1 Instance Matching let’s see how we did with the full data fusion predictions compared to the ground truth data using the instance matching process we outlined in this earlier section we’ll look at only predicted and ground truth piles that intersect with the unit boundary for our instance matching ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) let’s look at that spatially for the entire area # plot it ortho_plt_fn(my_ortho_rast = ortho_rast, stand = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), buffer = 10) + # ggplot2::ggplot() + ggplot2::geom_sf(data = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.3 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) ggplot2::ggsave(&quot;../data/datafusion_pred_match.jpg&quot;, height = 8, width = 10.5) we’ll aggregate the raw instance match data to calculate our detection accuracy metrics agg_ground_truth_match(ground_truth_prediction_match_ans) ## # A tibble: 1 × 8 ## tp_n fp_n fn_n omission_rate commission_rate precision recall f_score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 108 48 13 0.107 0.308 0.692 0.893 0.780 let’s plot our confusion matrix confusion_matrix_temp &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans) confusion_matrix_scores_temp &lt;- confusion_matrix_scores_fn(confusion_matrix_temp) # plot confusion_matrix_temp %&gt;% dplyr::select(tidyselect::ends_with(&quot;_n&quot;)) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( presence = ifelse(name %in% c(&quot;tp_n&quot;, &quot;fn_n&quot;),1,0) , estimate = ifelse(name %in% c(&quot;tp_n&quot;, &quot;fp_n&quot;),1,0) ) %&gt;% dplyr::mutate( is_false = as.factor(ifelse(presence!=estimate,1,0)) , presence_fact = factor(presence,levels = 0:1,labels = c(&quot;Observed Absent&quot;, &quot;Observed Present&quot;)) , estimate_fact = factor(estimate,levels = 0:1,labels = c(&quot;Predicted Absent&quot;, &quot;Predicted Present&quot;)) , pct = value/sum(value) ) %&gt;% ggplot(mapping = aes(y = estimate_fact, x = presence_fact)) + geom_tile(aes(fill = is_false), color = &quot;white&quot;,alpha=0.8) + geom_text(aes(label = scales::comma(value,accuracy=1)), vjust = 1,size = 8) + geom_text(aes(label = scales::percent(pct,accuracy=0.1)), vjust = 3.5, size=5) + scale_fill_manual(values= c(&quot;turquoise&quot;,&quot;tomato2&quot;)) + scale_x_discrete(position = &quot;top&quot;) + labs( y = &quot;Predicted&quot; , x = &quot;Observed&quot; , subtitle = paste0( &quot;True positive rate (recall) = &quot; , confusion_matrix_scores_temp$recall %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nPrecision (PPV) = &quot; , confusion_matrix_scores_temp$precision %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nF1-score = &quot; , confusion_matrix_scores_temp$f_score %&gt;% scales::percent(accuracy = 0.1) ) ) + theme_light() + theme( legend.position = &quot;none&quot; , panel.grid = element_blank() , plot.title = element_text(size = 9) , plot.subtitle = element_text(size = 9) ) you can compare these results to the results using the structural data only…wow, our data fusion approach noticeably improved the precision of our method’s predictions without negatively impacting recall, this effect combined to greatly improve our overall accuracy as measured by F-score "],["wshed_params_test.html", "Section 7 Sensitivity Testing Method 7.1 Workflow over parameter combinations", " Section 7 Sensitivity Testing Method In this section we introduce a slash pile detection workflow to perform parameter sensitivity testing to obtain a set of point estimates for both the detection and quantification accuracy metrics of the method. In the next section, we’ll use this workflow with different resolution CHM data as input to generate the data used for analysis to evaluate the method performance. Parameter sensitivity testing is a systematic process for evaluating how changes to the specific thresholds and settings within the detection methodology impact the final results. Since our method is rules-based and does not use training data, its performance is highly dependent on these manually defined parameters. The objective of this testing is to understand the robustness of the methodology and identify the optimal combination of settings that yields the best detection performance, balancing factors like detection rate (recall), accuracy of positive predictions (precision), and form quantification (e.g., height or diameter MAPE and RMSE). The primary objective of the sensitivity testing is to obtain a set of point estimates for both the detection and quantification accuracy metrics, which will then serve as the input dataset for subsequent statistical modeling to quantify the influence of parameters and input data on accuracy. Sensitivity testing is performed by repeatedly executing the entire rules-based detection method while systematically varying the values of one or more of its parameters (such as minimum area or maximum height) to generate a range of empirical results. The results of the sensitivity tests are individual point estimates of detection accuracy (F-score) and quantification accuracy (e.g. RMSE and MAPE) for each parameter combination. These sensitivity test results are distinct from the statistical modeling, which does not calculate accuracy itself but instead uses these point estimates as dependent variables to statistically model the functional relationship between the tested detection parameters and the resulting accuracy. This modeling approach will provide insight into the potentially complex interactions between the input data and parameter settings, while allowing us to generalize which parameter combinations optimize the methodology’s performance and to probabilistically quantify parameter influence while accounting for uncertainty. here are the general steps for sensitivity testing and statistical modeling that we’ll follow: Define Parameter Ranges and Increments: For each parameter in the rules-based method, determine a reasonable range of values to test and the step size for incrementing through that range. For example, if a threshold is currently 0.5, you might test from 0.3 to 0.7 in increments of 0.05. Automate the Detection Workflow: Create a script or automated process that can run the entire rules-based slash pile detection method using different combinations of these parameter values. Execute Tests: Run the automated workflow for each defined parameter combination. Collect Performance Metrics: For every run, calculate the key performance metrics against the ground truth data (e.g., recall, precision, F-score, and height/diameter MAPE). These calculated metrics will be used as the point estimates for our statistical models. Statistical Modeling: Models will be built with the detection and quantification accuracy metrics as the dependent variables. These models will provide insight into the complex relationships between different input data and parameter settings. They will be used to help visualize trends, identify sweet spots where performance is maximized, and understand trade-offs. For example, increasing recall might decrease precision, or one parameter change might be particularly impactful on form quantification accuracy. Select Optimal Parameters: Based on the statistical analysis and the specific goals of the project (e.g., maximizing detection accuracy versus maximizing overall accuracy F-score or maximizing form quantification accuracy), select the parameter set that provides the most desirable performance balance. 7.1 Workflow over parameter combinations let’s define parameter ranges and increments for our sensitivity testing and store them in a data frame param_combos_df &lt;- tidyr::crossing( max_ht_m = seq(from = 2, to = 5, by = 1) # set the max expected pile height (could also do a minimum??) , min_area_m2 = c(2) # fixed in workflow defined below so only use one value , max_area_m2 = seq(from = 10, to = 60, by = 10) # set the max expected pile area , convexity_pct = seq(from = 0.1, to = 0.9, by = 0.2) # min required overlap between the predicted pile and the convex hull of the predicted pile , circle_fit_iou_pct = seq(from = 0.1, to = 0.9, by = 0.2) ) %&gt;% dplyr::mutate(rn = dplyr::row_number()) %&gt;% dplyr::relocate(rn) # huh? param_combos_df %&gt;% dplyr::glimpse() ## Rows: 600 ## Columns: 6 ## $ rn &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ max_ht_m &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ min_area_m2 &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ max_area_m2 &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,… ## $ convexity_pct &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.3, 0… ## $ circle_fit_iou_pct &lt;dbl&gt; 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0… to automate the detection workflow we can simply map these combinations over our slash_pile_detect_watershed() function. however, that would result in us running the same watershed segmentation process repeatedly with the same settings. as such, let’s make a function to efficiently perform the detection workflow using the same watershed segmentation and circle fitting for use with the different filtering combinations. ######################################################################### # 1) # function to apply watershed seg over a list of max_ht_m # function to apply watershed segmentation over a list of different maximum height threshold (`max_ht_m`) which determines the &quot;slice&quot; of the CHM to use ######################################################################### chm_watershed_seg_fn &lt;- function(chm_rast,max_ht_m) { # get unique hts max_ht_m &lt;- unique(as.numeric(max_ht_m)) max_ht_m &lt;- max_ht_m[!is.na(max_ht_m)] if( dplyr::coalesce(length(max_ht_m),0)&lt;1 ){stop(&quot;could not detect `max_ht_m` parameter setting which should be numeric list&quot;)} # checks if(!inherits(chm_rast,&quot;SpatRaster&quot;)){stop(&quot;`chm_rast` must be raster data with the class `SpatRaster` &quot;)} # just get the first layer chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) # # first, calculate the area of each cell # area_rast &lt;- terra::cellSize(chm_rast) # names(area_rast) &lt;- &quot;area_m2&quot; # map over the max_ht_m to get the raster slice chm_ret_rast &lt;- max_ht_m %&gt;% purrr::map(\\(x) terra::clamp(chm_rast, upper = x, lower = 0, values = F) ) %&gt;% terra::rast() # name names(chm_ret_rast) &lt;- as.character(max_ht_m) # chm_ret_rast # chm_ret_rast %&gt;% terra::subset(1) %&gt;% terra::plot() # chm_ret_rast %&gt;% terra::subset(2) %&gt;% terra::plot() # chm_rast[[1]] # # map over the volume # # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes # vol_ret_rast &lt;- # 1:terra::nlyr(chm_ret_rast) %&gt;% # purrr::map(function(x){ # vol_rast &lt;- area_rast*chm_ret_rast[[x]] # names(vol_rast) &lt;- &quot;volume_m3&quot; # return(vol_rast) # }) %&gt;% # terra::rast() # # name # names(vol_ret_rast) &lt;- as.character(max_ht_m) # map over the watershed # let&#39;s run watershed segmentation using `lidR::watershed()` which is based on the bioconductor package `EBIimage` # return is a raster with the first layer representing the identified watershed segments ret_rast &lt;- 1:terra::nlyr(chm_ret_rast) %&gt;% purrr::map(\\(x) lidR::watershed( chm = chm_ret_rast[[x]] , th_tree = 0.1 )() ) %&gt;% terra::rast() # name names(ret_rast) &lt;- as.character(max_ht_m) # ret_rast # ret_rast %&gt;% terra::subset(1) %&gt;% terra::as.factor() %&gt;% terra::plot() # ret_rast %&gt;% terra::subset(2) %&gt;% terra::as.factor() %&gt;% terra::plot() return(list( chm_rast = chm_ret_rast # length = length(max_ht_m) # , area_rast = area_rast # length = 1 # , volume_rast = vol_ret_rast # length = length(max_ht_m) , watershed_rast = ret_rast # length = length(max_ht_m) )) } # xxx &lt;- chm_watershed_seg_fn( # cloud2raster_ans$chm_rast %&gt;% # terra::crop( # stand_boundary %&gt;% # dplyr::slice(1) %&gt;% # sf::st_buffer(-80) %&gt;% # sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% # terra::vect() # ) # ,c(4,5) # ) # xxx$chm_rast %&gt;% terra::subset( as.character(unique(c(4,5))[1]) ) %&gt;% terra::plot() # xxx$watershed_rast %&gt;% terra::subset( as.character(unique(c(4,5))[1]) ) %&gt;% terra::as.factor() %&gt;% terra::plot() # # xxx$volume_rast %&gt;% terra::subset( as.character(unique(c(4,5))[1]) ) %&gt;% terra::plot() # # xxx$area_rast[[1]] %&gt;% terra::minmax() # # xxx$area_rast %&gt;% terra::plot() ######################################################################### # 2) # now we need to define a function to apply the filters to the resulting watershed segmented rasters # based on a data frame of difference combinations of filters for irregularity using the comparison to the convex hull ######################################################################### param_combos_detect_convexity_fn &lt;- function( chm_watershed_seg_fn_ans #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = 4 # set the max expected pile height (could also do a minimum??) #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.7 # min required overlap between the predicted pile and the convex hull of the predicted pile ) { # extract individual elements from chm_watershed_seg_fn chm_rast &lt;- chm_watershed_seg_fn_ans$chm_rast %&gt;% terra::subset( as.character(unique(max_ht_m)[1]) ) watershed_ans &lt;- chm_watershed_seg_fn_ans$watershed_rast %&gt;% terra::subset( as.character(unique(max_ht_m)[1]) ) names(watershed_ans) &lt;- &quot;pred_id&quot; # checks if(!inherits(chm_rast,&quot;SpatRaster&quot;)){stop(&quot;`chm_rast` must be raster data with the class `SpatRaster` &quot;)} if(!inherits(watershed_ans,&quot;SpatRaster&quot;)){stop(&quot;`watershed_ans` must be raster data with the class `SpatRaster` &quot;)} ######################################################################################## ## convert to polys and area filters ######################################################################################## # let&#39;s convert the watershed-detected segments from raster to vector data # and create a convex hull of the shapes for comparison # vectors of segments watershed_ans_poly &lt;- watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) if(dplyr::coalesce(nrow(watershed_ans_poly),0)&lt;1){ return(NULL) } ######################################################################################## ## 2) irregularity filtering ######################################################################################## # let&#39;s first filter out segments that have holes in them # or are very irregularly shaped by comparing the area of the polygon and convex hull # convexity_pct = min required overlap between the predicted pile and the convex hull of the predicted pile if(convexity_pct&gt;0){ # apply the irregularity filtering on the polygons watershed_ans_poly &lt;- watershed_ans_poly %&gt;% st_irregular_remove(pct_chull_overlap = convexity_pct) } if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){ return(NULL) }else{ return(watershed_ans_poly %&gt;% dplyr::mutate(max_ht_m = max_ht_m, convexity_pct = convexity_pct)) } } # # just get the unique combinations needed for this param_combos_detect_convexity_fn function # param_combos_convexity_df &lt;- # param_combos_df %&gt;% # dplyr::filter(max_ht_m %in% as.numeric(names(xxx$chm_rast))) %&gt;% ## !!!!!!!!!!take this out # dplyr::distinct(max_ht_m,convexity_pct) # # apply this using our data frame to map over the combinations # ### takes ~40 mins # param_combos_detect_convexity_ans &lt;- # 1:nrow(param_combos_convexity_df) %&gt;% # sample(2) %&gt;% # purrr::map(\\(x) # param_combos_detect_convexity_fn( # chm_watershed_seg_fn_ans = xxx ## !!!!!!!!!!change this # , max_ht_m = param_combos_convexity_df$max_ht_m[x] # , convexity_pct = param_combos_convexity_df$convexity_pct[x] # ) # , .progress = T # ) %&gt;% # dplyr::bind_rows() # # param_combos_detect_convexity_ans %&gt;% dplyr::glimpse() # # param_combos_detect_convexity_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(max_ht_m,convexity_pct) # # param_combos_detect_convexity_ans %&gt;% # # dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # # sf::st_drop_geometry() %&gt;% # # dplyr::group_by(max_ht_m,convexity_pct) %&gt;% # # dplyr::summarise(dplyr::across(area_xxxx, list(min = min, max = max), .names = &quot;{.col}.{.fn}&quot;)) # # # now just join to filter for area # # expands to row unique by max_ht_m,convexity_pct,min_area_m2,max_area_m2,pred_id # param_combos_area &lt;- # param_combos_detect_convexity_ans %&gt;% # dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # dplyr::inner_join( # # add area ranges # param_combos_df %&gt;% # dplyr::distinct(max_ht_m,convexity_pct,min_area_m2,max_area_m2) # , by = dplyr::join_by( # max_ht_m, convexity_pct # , area_xxxx&gt;=min_area_m2 # , area_xxxx&lt;=max_area_m2 # ) # , relationship = &quot;many-to-many&quot; # ) # # dplyr::filter( # # area_xxxx&gt;=min_area_m2 # # , area_xxxx&lt;=max_area_m2 # # ) # param_combos_area %&gt;% dplyr::glimpse() # param_combos_area %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::group_by(max_ht_m,convexity_pct,min_area_m2,max_area_m2) %&gt;% # dplyr::summarise(dplyr::across(area_xxxx, list(min = min, max = max), .names = &quot;{.col}.{.fn}&quot;)) # # # geometries are unique by max_ht_m,pred_id # param_combos_area %&gt;% # dplyr::filter( # pred_id == param_combos_area$pred_id[111] # , max_ht_m == param_combos_area$max_ht_m[111] # ) %&gt;% # dplyr::mutate(lab = stringr::str_c(max_ht_m,convexity_pct,min_area_m2,max_area_m2, sep = &quot;:&quot;)) %&gt;% # ggplot() + geom_sf(aes(linetype = lab, color = lab),fill=NA) + facet_wrap(facets = dplyr::vars(lab)) + theme_void() # param_combos_area %&gt;% # dplyr::group_by(max_ht_m,pred_id) %&gt;% # dplyr::filter(dplyr::row_number()==1) %&gt;% # dplyr::select(max_ht_m,pred_id) %&gt;% # dplyr::ungroup() %&gt;% # # dplyr::glimpse() # ggplot() + geom_sf(aes(color = factor(max_ht_m)),fill=NA) + facet_wrap(facets = dplyr::vars(max_ht_m)) # unique_geometries_cf &lt;- sf_data_circle_fit( # param_combos_area %&gt;% # dplyr::group_by(max_ht_m,pred_id) %&gt;% # dplyr::filter(dplyr::row_number()==1) %&gt;% # dplyr::select(max_ht_m,pred_id) %&gt;% # dplyr::ungroup() # ) # unique_geometries_cf %&gt;% dplyr::glimpse() # function to smooth raster_smooth_smoother &lt;- function( chm_watershed_seg_fn_ans , max_ht_m = 4 , watershed_ans_poly , min_area_m2 = 2 ) { min_ht_m &lt;- 0.5 ## !!!!!!!!!!!!!!!! fixed for testing # extract individual elements from chm_watershed_seg_fn chm_rast &lt;- chm_watershed_seg_fn_ans$chm_rast %&gt;% terra::subset( as.character(unique(max_ht_m)[1]) ) watershed_ans &lt;- chm_watershed_seg_fn_ans$watershed_rast %&gt;% terra::subset( as.character(unique(max_ht_m)[1]) ) names(watershed_ans) &lt;- &quot;pred_id&quot; # checks if(!inherits(chm_rast,&quot;SpatRaster&quot;)){stop(&quot;`chm_rast` must be raster data with the class `SpatRaster` &quot;)} if(!inherits(watershed_ans,&quot;SpatRaster&quot;)){stop(&quot;`watershed_ans` must be raster data with the class `SpatRaster` &quot;)} chm_res &lt;- max(terra::res(chm_rast)[1:2],na.rm = T) ws_for_smooth &lt;- ws_for_smooth_fn(chm_res = chm_res, min_area_m2 = min_area_m2) # 3 # needs to be the same for the watershed seg and CHM smooth # search_area = (res^2) * (ws^2) ######################################################################################## ## 5) raster smoothing ######################################################################################## ######################################## # use the remaining segments that meet the geometric and area filtering # to smooth the watershed raster ######################################## smooth_watershed_ans &lt;- watershed_ans %&gt;% terra::mask( watershed_ans_poly %&gt;% #these are irregularity and area filtered already terra::vect() , updatevalue=NA ) if(dplyr::coalesce(ws_for_smooth,0)&gt;=3){ # smooths the raster using the majority value smooth_watershed_ans &lt;- smooth_watershed_ans %&gt;% terra::focal(w = ws_for_smooth, fun = &quot;modal&quot;, na.rm = T, na.policy = &quot;only&quot;) # only fill NA cells } names(smooth_watershed_ans) &lt;- &quot;pred_id&quot; ######################################## # mask the chm rast to these remaining segments and smooth to match the smoothing for the segments ######################################## smooth_chm_rast &lt;- chm_rast %&gt;% terra::mask(smooth_watershed_ans) if(dplyr::coalesce(ws_for_smooth,0)&gt;=3){ # smooths the raster to match the smoothing in the watershed segments smooth_chm_rast &lt;- smooth_chm_rast %&gt;% terra::focal(w = ws_for_smooth, fun = &quot;mean&quot;, na.rm = T, na.policy = &quot;only&quot;) #only for cells that are NA } # now mask the watershed_ans raster to only keep cells that are in the originating CHM smooth_watershed_ans &lt;- smooth_watershed_ans %&gt;% terra::mask(smooth_chm_rast) ######################################################################################## ## calculate raster-based area and volume ######################################################################################## # first, calculate the area of each cell area_rast &lt;- terra::cellSize(smooth_chm_rast) names(area_rast) &lt;- &quot;area_m2&quot; # area_rast %&gt;% terra::plot() # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes vol_rast &lt;- area_rast*smooth_chm_rast names(vol_rast) &lt;- &quot;volume_m3&quot; # vol_rast %&gt;% terra::plot() # sum area within each segment to get the total area area_df &lt;- terra::zonal(x = area_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # sum volume within each segment to get the total volume vol_df &lt;- terra::zonal(x = vol_rast, z = smooth_watershed_ans, fun = &quot;sum&quot;, na.rm = T) # max ht within each segment to get the max ht ht_df &lt;- terra::zonal(x = smooth_chm_rast, z = smooth_watershed_ans, fun = &quot;max&quot;, na.rm = T) %&gt;% dplyr::rename(max_height_m=2) # let&#39;s convert the smoothed and filtered watershed-detected segments from raster to vector data # vectors of segments watershed_ans_poly &lt;- smooth_watershed_ans %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% dplyr::mutate(treeID=pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # add area and volume to our vector data # we&#39;ll do this with a slick trick to perform multiple joins succinctly using purrr::reduce watershed_ans_poly &lt;- purrr::reduce( list(watershed_ans_poly, area_df, vol_df, ht_df) , dplyr::left_join , by = &#39;pred_id&#39; ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) %&gt;% dplyr::filter( dplyr::coalesce(max_height_m,0) &gt;= min_ht_m ) # # filter out the segments that don&#39;t meet the size thresholds # dplyr::filter( # dplyr::coalesce(area_m2,0) &gt;= min_area_m2 # &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 # ) %&gt;% # # do one more pass of the irregularity filtering # st_irregular_remove(pct_chull_overlap = convexity_pct) if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){ return(NULL) }else{ return(watershed_ans_poly) } } # function to do the whole thing param_combos_piles_detect_fn &lt;- function( chm , param_combos_df , smooth_segs = T , ofile = &quot;../data/param_combos_piles.gpkg&quot; ) { ######################################################################################## ## 1) chm slice and watershed segmentation ######################################################################################## # apply chm_watershed_seg_fn ### takes ~37 mins chm_watershed_seg_ans &lt;- chm_watershed_seg_fn(chm, max_ht_m = unique(param_combos_df$max_ht_m)) # # what did we get? # chm_watershed_seg_ans %&gt;% # terra::subset( as.character(unique(param_combos_df$max_ht_m)[3]) ) %&gt;% # terra::plot() ######################################################################################## ## 2) irregularity filter ######################################################################################## # just get the unique combinations needed for this param_combos_detect_convexity_fn function param_combos_convexity_df &lt;- param_combos_df %&gt;% dplyr::distinct(max_ht_m,convexity_pct) # apply this using our data frame to map over the combinations ### takes ~40 mins param_combos_detect_convexity_ans &lt;- 1:nrow(param_combos_convexity_df) %&gt;% purrr::map(\\(x) param_combos_detect_convexity_fn( chm_watershed_seg_fn_ans = chm_watershed_seg_ans , max_ht_m = param_combos_convexity_df$max_ht_m[x] , convexity_pct = param_combos_convexity_df$convexity_pct[x] ) , .progress = &quot;convexity filtering&quot; ) %&gt;% dplyr::bind_rows() # param_combos_detect_convexity_ans %&gt;% dplyr::glimpse() # param_combos_detect_convexity_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(max_ht_m,convexity_pct) # param_combos_detect_convexity_ans %&gt;% # dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::group_by(max_ht_m,convexity_pct) %&gt;% # dplyr::summarise(dplyr::across(area_xxxx, list(min = min, max = max), .names = &quot;{.col}.{.fn}&quot;)) ######################################################################################## ## 3) area filter ######################################################################################## # now just join to filter for area # expands to row unique by max_ht_m,convexity_pct,min_area_m2,max_area_m2,pred_id param_combos_area &lt;- param_combos_detect_convexity_ans %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( # add area ranges param_combos_df %&gt;% dplyr::distinct(max_ht_m,convexity_pct,min_area_m2,max_area_m2) , by = dplyr::join_by( max_ht_m, convexity_pct , area_xxxx&gt;=min_area_m2 , area_xxxx&lt;=max_area_m2 ) , relationship = &quot;many-to-many&quot; ) %&gt;% dplyr::select(-area_xxxx) # dplyr::filter( # area_xxxx&gt;=min_area_m2 # , area_xxxx&lt;=max_area_m2 # ) # param_combos_area %&gt;% dplyr::glimpse() # param_combos_area %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::group_by(max_ht_m,convexity_pct,min_area_m2,max_area_m2) %&gt;% # dplyr::summarise(dplyr::across(area_xxxx, list(min = min, max = max), .names = &quot;{.col}.{.fn}&quot;)) # !!!!!!!!!!!!!!!!!!!!!!geometries are unique by max_ht_m,pred_id!!!!!!!!!!!!!!!!!!!!!! # param_combos_area %&gt;% # dplyr::filter( # pred_id == param_combos_area$pred_id[111] # , max_ht_m == param_combos_area$max_ht_m[111] # ) %&gt;% # dplyr::mutate(lab = stringr::str_c(max_ht_m,convexity_pct,min_area_m2,max_area_m2, sep = &quot;:&quot;)) %&gt;% # ggplot() + geom_sf(aes(linetype = lab, color = lab),fill=NA) + facet_wrap(facets = dplyr::vars(lab)) + theme_void() # param_combos_area %&gt;% # dplyr::group_by(max_ht_m,pred_id) %&gt;% # dplyr::filter(dplyr::row_number()==1) %&gt;% # dplyr::select(max_ht_m,pred_id) %&gt;% # dplyr::ungroup() %&gt;% # # dplyr::glimpse() # ggplot() + geom_sf(aes(color = factor(max_ht_m)),fill=NA) + facet_wrap(facets = dplyr::vars(max_ht_m)) ######################################################################################## ## 4) circle filter ######################################################################################## # !!!!!!!!!!!!!!!!!!!!!!geometries are unique by max_ht_m,pred_id!!!!!!!!!!!!!!!!!!!!!! unique_geometries &lt;- param_combos_area %&gt;% dplyr::group_by(max_ht_m,pred_id) %&gt;% dplyr::filter(dplyr::row_number()==1) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(max_ht_m,pred_id) %&gt;% dplyr::mutate(record_id = dplyr::row_number()) # param_combos_detect_convexity_ans %&gt;% dplyr::glimpse() # and we&#39;ll apply the circle fitting to this spatial data # apply the sf_data_circle_fit() which takes each segment polygon, transforms it to points, and the fits the best circle unique_geometries_cf &lt;- sf_data_circle_fit(unique_geometries) # param_combos_detect_cf_ans %&gt;% sf::st_write(&quot;../data/param_combos_detect_cf_ans.gpkg&quot;) # param_combos_detect_cf_ans %&gt;% dplyr::glimpse() # nrow(param_combos_detect_cf_ans) # nrow(param_combos_detect_convexity_ans) # we&#39;ll use the IoU function we defined # we map over this to only compare the segment to it&#39;s own best circle fit...not all # we should consider doing this in bulk.....another day param_combos_detect_cf_iou &lt;- unique_geometries$record_id %&gt;% purrr::map(\\(x) ground_truth_single_match( gt_inst = unique_geometries %&gt;% dplyr::filter(record_id == x) , gt_id = &quot;record_id&quot; , predictions = unique_geometries_cf %&gt;% dplyr::filter(record_id == x) %&gt;% dplyr::select(record_id) %&gt;% # keeping other columns causes error? dplyr::rename(circ_record_id = record_id) , pred_id = &quot;circ_record_id&quot; , min_iou_pct = 0 # set to 0 just to return pct ) ) %&gt;% dplyr::bind_rows() # param_combos_detect_cf_iou %&gt;% dplyr::glimpse() ### now we need a function to map over all the different filters for circularity by combination of the other settings ### this is going to be highly custom to this particular task :\\ param_combos_circle_fit &lt;- param_combos_area %&gt;% # expands row to unique by max_ht_m,min_area_m2,max_area_m2,convexity_pct,circle_fit_iou_pct,pred_id dplyr::inner_join( param_combos_df , by = dplyr::join_by(max_ht_m,min_area_m2,max_area_m2,convexity_pct) , relationship = &quot;many-to-many&quot; ) %&gt;% # join unique geoms dplyr::inner_join( unique_geometries %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(max_ht_m,pred_id,record_id) , by = dplyr::join_by(max_ht_m,pred_id) ) %&gt;% # join circle fits dplyr::left_join( param_combos_detect_cf_iou %&gt;% dplyr::select(record_id,iou) , by = &quot;record_id&quot; ) %&gt;% dplyr::filter(dplyr::coalesce(iou,0)&gt;=circle_fit_iou_pct) ############################################################ # get unique sets of pred_id by height so we only need to smooth the raster for these sets ############################################################ rn_geom_lookup &lt;- param_combos_circle_fit %&gt;% sf::st_drop_geometry() %&gt;% dplyr::arrange(rn,max_ht_m,pred_id) %&gt;% dplyr::group_by(rn,max_ht_m) %&gt;% dplyr::summarise(preds = paste(sort(pred_id), collapse = &quot;_&quot;),n=dplyr::n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(max_ht_m,desc(n)) # now just get the unique sets by max_ht_m rn_geom_lookup &lt;- rn_geom_lookup %&gt;% dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::distinct(max_ht_m,preds) %&gt;% dplyr::mutate(set_id = dplyr::row_number()) , by = dplyr::join_by(max_ht_m,preds) ) %&gt;% dplyr::select(set_id,rn,max_ht_m) # rn_geom_lookup %&gt;% dplyr::glimpse() # now just get the unique max_ht_m and actual geoms geom_sets &lt;- param_combos_circle_fit %&gt;% dplyr::select(rn,max_ht_m,pred_id) %&gt;% dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::group_by(set_id) %&gt;% dplyr::filter(dplyr::row_number()==1) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(rn,set_id) , by = dplyr::join_by(rn) ) # dplyr::relocate(set_id) %&gt;% # dplyr::arrange(set_id,pred_id) %&gt;% # dplyr::glimpse() ######## ######################################################################################## ## 6) raster smooth ######################################################################################## geom_sets_smooth &lt;- geom_sets$set_id %&gt;% unique() %&gt;% purrr::map(\\(x) raster_smooth_smoother( chm_watershed_seg_fn_ans = chm_watershed_seg_ans , max_ht_m = (geom_sets %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(set_id==x) %&gt;% dplyr::slice(1) %&gt;% dplyr::pull(max_ht_m)) , watershed_ans_poly = geom_sets %&gt;% dplyr::filter(set_id==x) , min_area_m2 = min(param_combos_df$min_area_m2,na.rm=T) ##### this fixes the parameter # .......... so won&#39;t work if param_combos_df contains multiple values #ohwell...just don&#39;t test min_area_m2 ) %&gt;% dplyr::mutate( set_id = x , max_ht_m = (geom_sets %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(set_id==x) %&gt;% dplyr::slice(1) %&gt;% dplyr::pull(max_ht_m)) ) , .progress = &quot;smooth smoothing it&quot; ) %&gt;% dplyr::bind_rows() # geom_sets_smooth %&gt;% dplyr::glimpse() # ggplot() + # geom_sf( # data = geom_sets_smooth %&gt;% dplyr::filter(set_id == geom_sets_smooth$set_id[1]) # , fill = &quot;navy&quot; # , alpha = 0.8 # ) + # geom_sf( # data = geom_sets %&gt;% dplyr::filter(set_id == geom_sets_smooth$set_id[1]) # , fill = NA # , color = &quot;gold&quot; # ) + # theme_void() ######################################################################################## ## 6.3) second irregular filter ######################################################################################## # get set, convexity combinations to map over st_irregular_remove set_convexity_combo &lt;- rn_geom_lookup %&gt;% # add in convexity pct to get unique set_id, convexity dplyr::inner_join( param_combos_df %&gt;% dplyr::select(rn,convexity_pct) , by = &quot;rn&quot; ) %&gt;% dplyr::distinct(set_id,convexity_pct) # filter for convexity geom_sets_convexity &lt;- 1:nrow(set_convexity_combo) %&gt;% purrr::map(\\(x) st_irregular_remove( sf_data = geom_sets_smooth %&gt;% dplyr::filter(set_id==set_convexity_combo$set_id[x]) , pct_chull_overlap = set_convexity_combo$convexity_pct[x] ) %&gt;% dplyr::mutate( set_id = set_convexity_combo$set_id[x] , convexity_pct = set_convexity_combo$convexity_pct[x] ) , .progress = &quot;second irregularity filter&quot; ) %&gt;% dplyr::bind_rows() # row is unique by set_id,convexity_pct,pred_id # geom_sets_convexity %&gt;% dplyr::glimpse() # geom_sets_convexity %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(set_id,convexity_pct) ######################################################################################## ## 6.6) second area filter ######################################################################################## # filter for area message(&quot;expanding to final param combos.....&quot;) filtered_final &lt;- geom_sets_convexity %&gt;% dplyr::select(-c(max_ht_m)) %&gt;% # expand to full param_combos_df dplyr::inner_join( param_combos_df %&gt;% dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::select(rn,set_id) , by = &quot;rn&quot; ) , by = dplyr::join_by(set_id,convexity_pct) , relationship = &quot;many-to-many&quot; ) %&gt;% # filter for area dplyr::filter( dplyr::coalesce(area_m2,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_m2,0) &lt;= max_area_m2 ) %&gt;% dplyr::select(-c(set_id)) %&gt;% dplyr::relocate(names(param_combos_df)) # filtered_final %&gt;% dplyr::glimpse() ######################################################################################## ## 7) shape refinement &amp; overlap removal ######################################################################################## # use the convex hull shapes of our remaining segments. # This helps to smooth out the often &#39;blocky&#39; edges of raster-based segments # , which can look like they were generated in Minecraft. # Additionally, by removing any segments with overlapping convex hull shapes, # we can likely reduce false detections that are actually groups of small trees or shrubs, # ensuring our results represent singular slash piles. smooth_segs &lt;- T if(smooth_segs){ # smooth unique polygons message(&quot;shape refinement and diametering.....&quot;) ##### just work with unique polygons ##### geom_sets_smooth row is unique by: set_id,pred_id geom_sets_final &lt;- geom_sets_smooth %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;max_ht_m&quot; ))) %&gt;% # join to filter geoms dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::inner_join( filtered_final %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(rn,pred_id) , by = dplyr::join_by(rn) , relationship = &quot;one-to-many&quot; ) %&gt;% # just get the unique geoms now dplyr::distinct(set_id,pred_id) , by = dplyr::join_by(set_id,pred_id) , relationship = &quot;one-to-one&quot; ) %&gt;% # smooth sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # diameter dplyr::ungroup() %&gt;% st_calculate_diameter() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) # ##### geom_sets_final row is unique by: set_id,pred_id # geom_sets_final %&gt;% dplyr::glimpse() # ggplot() + # geom_sf( # # post smooth (should be slightly larger) # data = geom_sets_final %&gt;% dplyr::filter(set_id == geom_sets_final$set_id[1]) # , fill = &quot;navy&quot; # , alpha = 0.8 # , color = &quot;gray&quot; # , lwd = 0.2 # ) + # theme_void() # ggplot() + # geom_sf( # # post smooth (should be slightly larger) # data = geom_sets_final %&gt;% dplyr::filter(set_id == geom_sets_final$set_id[1]) # , fill = &quot;navy&quot; # , alpha = 0.8 # , color = &quot;gray&quot; # , lwd = 0.2 # ) + # geom_sf( # # pre-smooth # data = geom_sets %&gt;% dplyr::filter(set_id == geom_sets_final$set_id[1]) # , fill = NA # , color = &quot;gold&quot; # ) + # theme_void() # sf::st_read(&quot;c:/data/usfs/manitou_slash_piles/data/param_combos_piles_chm0.45m.gpkg&quot;) %&gt;% # dplyr::mutate(xxxarea_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::slice_sample(n=33333) %&gt;% # ggplot2::ggplot(mapping = ggplot2::aes(x = xxxarea_m2, y =area_m2)) + # ggplot2::geom_abline(lwd = 1) + # ggplot2::geom_point() + # ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + # ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + # ggplot2::theme_light() # ##### geom_sets_final row is unique by: set_id,pred_id # overlapping convex hull shapes are then removed to prevent false positives from clustered small trees or shrubs # have to map over this to do overlaps only on one set at a time geom_sets_final_olaps &lt;- geom_sets_final$set_id %&gt;% unique() %&gt;% purrr::map(\\(x) geom_sets_final %&gt;% dplyr::filter(set_id==x) %&gt;% st_remove_overlaps() ) %&gt;% dplyr::bind_rows() # ##### geom_sets_final_olaps row is unique by: set_id,pred_id # geom_sets_final %&gt;% dplyr::glimpse() # geom_sets_final_olaps %&gt;% dplyr::glimpse() # ggplot() + # geom_sf( # # post smooth (should be slightly larger) # data = geom_sets_final_olaps %&gt;% dplyr::filter(set_id == geom_sets_final_olaps$set_id[1]) # , fill = &quot;navy&quot; # , alpha = 0.8 # , color = &quot;gray&quot; # , lwd = 0.2 # ) + # geom_sf( # # pre-smooth # data = geom_sets_final %&gt;% dplyr::filter(set_id == geom_sets_final_olaps$set_id[1]) # , fill = NA # , color = &quot;gold&quot; # , lwd = 1 # ) + # theme_void() # join back to param_combos list final_ans &lt;- geom_sets_final_olaps %&gt;% # join to lookup # expands row to unique by set_id,rn,pred_id dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::select(rn,set_id) , by = dplyr::join_by(set_id) , relationship = &quot;many-to-many&quot; ) %&gt;% # join with filtered_final which have pred_id dplyr::inner_join( filtered_final %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(rn,pred_id) , by = dplyr::join_by(rn,pred_id) , relationship = &quot;one-to-one&quot; ) %&gt;% # add param_combos_df data dplyr::inner_join( param_combos_df , by = &quot;rn&quot; , relationship = &quot;many-to-one&quot; ) # nrow(filtered_final) # nrow(final_ans) # should be less }else{ message(&quot;diametering.....&quot;) ##### just work with unique polygons ##### geom_sets_smooth row is unique by: set_id,pred_id geom_sets_final &lt;- geom_sets_smooth %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;max_ht_m&quot; ))) %&gt;% # join to filter geoms dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::inner_join( filtered_final %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(rn,pred_id) , by = dplyr::join_by(rn) , relationship = &quot;one-to-many&quot; ) %&gt;% # just get the unique geoms now dplyr::distinct(set_id,pred_id) , by = dplyr::join_by(set_id,pred_id) , relationship = &quot;one-to-one&quot; ) %&gt;% # diameter dplyr::ungroup() %&gt;% st_calculate_diameter() # join back to param_combos list final_ans &lt;- geom_sets_final %&gt;% # join to lookup # expands row to unique by set_id,rn,pred_id dplyr::inner_join( rn_geom_lookup %&gt;% dplyr::select(rn,set_id) , by = dplyr::join_by(set_id) , relationship = &quot;many-to-many&quot; ) %&gt;% # join with filtered_final which have pred_id dplyr::inner_join( filtered_final %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(rn,pred_id) , by = dplyr::join_by(rn,pred_id) , relationship = &quot;one-to-one&quot; ) %&gt;% # add param_combos_df data dplyr::inner_join( param_combos_df , by = &quot;rn&quot; , relationship = &quot;many-to-one&quot; ) } if(stringr::str_length(ofile)&gt;1){ final_ans %&gt;% sf::st_write(ofile, append = F, quiet = T) } # return return(final_ans) } # param_combos_piles &lt;- # param_combos_df$rn %&gt;% # # sample(3) %&gt;% ## !!!!!!!!!!!!!!!!!!!! remove after testing # purrr::map(\\(x) # slash_pile_detect_watershed( # chm_rast = cloud2raster_ans$chm_rast # , max_ht_m = param_combos_df$max_ht_m[x] # , min_area_m2 = param_combos_df$min_area_m2[x] # , max_area_m2 = param_combos_df$max_area_m2[x] # , convexity_pct = param_combos_df$convexity_pct[x] # , circle_fit_iou_pct = param_combos_df$circle_fit_iou_pct[x] # ) %&gt;% # dplyr::mutate( # rn = param_combos_df$rn[x] # , max_ht_m = param_combos_df$max_ht_m[x] # , min_area_m2 = param_combos_df$min_area_m2[x] # , max_area_m2 = param_combos_df$max_area_m2[x] # , convexity_pct = param_combos_df$convexity_pct[x] # , circle_fit_iou_pct = param_combos_df$circle_fit_iou_pct[x] # ) # ) %&gt;% # dplyr::bind_rows() # param_combos_piles %&gt;% # sf::st_write(&quot;../data/param_combos_piles.gpkg&quot;, append = F) # # param_combos_piles &lt;- sf::st_read(&quot;../data/param_combos_piles.gpkg&quot;) 7.1.1 Test Workflow we’ll test our apply our function using a sample from the data frame of the parameter combinations f_temp &lt;- &quot;../data/testtest_param_combos_piles.gpkg&quot; if(!file.exists(f_temp)){ param_combos_piles &lt;- param_combos_piles_detect_fn( chm = cloud2raster_ans$chm_rast , param_combos_df = param_combos_df %&gt;% dplyr::slice_sample(n=17) , smooth_segs = T , ofile = f_temp ) # param_combos_piles %&gt;% dplyr::glimpse() # save it sf::st_write(param_combos_piles, f_temp, append = F, quiet = T) }else{ param_combos_piles &lt;- sf::st_read(f_temp, quiet = T) } what did we get? param_combos_piles %&gt;% dplyr::glimpse() ## Rows: 8,441 ## Columns: 14 ## $ pred_id &lt;dbl&gt; 418, 991, 1745, 2416, 2624, 2640, 3111, 3160, 3482,… ## $ area_m2 &lt;dbl&gt; 2.56, 3.76, 3.36, 2.52, 4.86, 7.92, 3.90, 3.12, 2.4… ## $ volume_m3 &lt;dbl&gt; 9.913314, 12.710141, 12.714443, 4.286529, 13.488759… ## $ max_height_m &lt;dbl&gt; 4.990000, 4.970000, 4.933000, 4.889250, 4.873667, 4… ## $ volume_per_area &lt;dbl&gt; 3.872388, 3.380357, 3.784060, 1.701004, 2.775465, 3… ## $ set_id &lt;int&gt; 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,… ## $ diameter_m &lt;dbl&gt; 2.163331, 2.690725, 2.720294, 2.000000, 3.440930, 4… ## $ rn &lt;int&gt; 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 4… ## $ max_ht_m &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, … ## $ min_area_m2 &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ max_area_m2 &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,… ## $ convexity_pct &lt;dbl&gt; 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0… ## $ circle_fit_iou_pct &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0… ## $ geom &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((499555 4317..., MULTIP… # param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(rn) %&gt;% dplyr::slice_head(n=6) # terra::plot(cloud2raster_ans$chm_rast, col = viridis::plasma(100), axes = F) # terra::plot(param_combos_piles %&gt;% dplyr::filter(rn==param_combos_piles$rn[2222]) %&gt;% terra::vect(),add = T, border = &quot;gray44&quot;, col = NA, lwd = 3) we should have predicted piles for each parameter combination tested so a row is unique by the combination of all of the variables in the param_combos_df data frame and the pile detected. we expect the number of piles detected to vary by these different parameter settings where the number of parameter settings should match the number of samples we selected. param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(rn) ## rn n ## 1 1 597 ## 2 13 331 ## 3 94 141 ## 4 173 149 ## 5 199 133 ## 6 246 190 ## 7 276 796 ## 8 313 575 ## 9 338 601 ## 10 361 984 ## 11 408 619 ## 12 423 203 ## 13 473 192 ## 14 508 733 ## 15 526 1169 ## 16 559 287 ## 17 588 741 which is equivalent to param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(max_ht_m,min_area_m2,max_area_m2,convexity_pct,circle_fit_iou_pct) ## max_ht_m min_area_m2 max_area_m2 convexity_pct circle_fit_iou_pct n ## 1 2 2 10 0.1 0.1 597 ## 2 2 2 10 0.5 0.5 331 ## 3 2 2 40 0.7 0.7 141 ## 4 3 2 10 0.9 0.5 149 ## 5 3 2 20 0.9 0.7 133 ## 6 3 2 40 0.9 0.1 190 ## 7 3 2 60 0.1 0.1 796 ## 8 4 2 10 0.5 0.5 575 ## 9 4 2 20 0.5 0.5 601 ## 10 4 2 30 0.5 0.1 984 ## 11 4 2 50 0.3 0.5 619 ## 12 4 2 50 0.9 0.5 203 ## 13 5 2 10 0.9 0.5 192 ## 14 5 2 30 0.3 0.5 733 ## 15 5 2 40 0.1 0.1 1169 ## 16 5 2 50 0.3 0.7 287 ## 17 5 2 60 0.5 0.5 741 7.1.2 Test Instance Matching let’s see how we did with the full data fusion predictions compared to the ground truth data using the instance matching process we outlined in this earlier section. here we validate the segments from these combinations against the ground truth data and we can map over the ground_truth_prediction_match() function to get true positive, false positive (commission), and false negative (omission) classifications for the predicted and ground truth piles f_temp &lt;- &quot;../data/testtest_param_combos_gt.csv&quot; if(!file.exists(f_temp)){ param_combos_gt &lt;- unique(param_combos_piles$rn) %&gt;% purrr::map(\\(x) ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) , gt_id = &quot;pile_id&quot; , predictions = param_combos_piles %&gt;% dplyr::filter(rn == x) %&gt;% dplyr::filter( pred_id %in% (param_combos_piles %&gt;% dplyr::filter(rn == x) %&gt;% sf::st_intersection( stand_boundary %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(pred_id)) ) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) %&gt;% dplyr::mutate(rn=x) ) %&gt;% dplyr::bind_rows() param_combos_gt %&gt;% readr::write_csv(f_temp, append = F, progress = F) }else{ param_combos_gt &lt;- readr::read_csv(f_temp, progress = F, show_col_types = F) } # huh? param_combos_gt %&gt;% dplyr::glimpse() # param_combos_gt %&gt;% dplyr::filter(pile_id==120) 7.1.3 Test Accuracy earlier, we defined a function (agg_ground_truth_match()) to prepare our results for analysis by developing a function that aggregates the single-pile-level data into a single record for each parameter combination. this function will calculate detection performance metrics such as F-score, precision, and recall (using the confusion_matrix_scores_fn() we defined above), as well as quantification accuracy metrics including Root Mean Squared Error (RMSE), Mean Error (ME), and Mean Absolute Percentage Error (MAPE) to assess the accuracy of our pile form measurements. this could be a valuable function for any future analysis comparing predictions to ground truth data. the agg_ground_truth_match() function looks for columns with the prefix “diff_” to calculate the mean error (ME) and the RMSE while columns with the prefix “pct_diff_” enable the function to calculate the mean absolute percent error (MAPE)…let’s make those columns # let&#39;s attach a flag to only work with piles that intersect with the stand boundary # and caclulate the &quot;diameter&quot; of the piles # add in/out to piles data param_combos_piles &lt;- param_combos_piles %&gt;% dplyr::left_join( param_combos_piles %&gt;% sf::st_intersection( stand_boundary %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(rn,pred_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand,F) ) # param_combos_piles %&gt;% dplyr::glimpse() # add it to validation param_combos_gt &lt;- param_combos_gt %&gt;% dplyr::mutate(pile_id = as.numeric(pile_id)) %&gt;% # add area of gt dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id,image_gt_area_m2,height_m,field_diameter_m) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( rn,pred_id ,is_in_stand , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2 , pred_height_m = max_height_m , pred_diameter_m = diameter_m ) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::case_when( is_in_stand == T ~ T , is_in_stand == F ~ F , match_grp == &quot;omission&quot; ~ T , T ~ F ) ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs , diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # what? # param_combos_gt %&gt;% dplyr::glimpse() now let’s apply the agg_ground_truth_match() function at the parameter combination level param_combos_gt_agg &lt;- unique(param_combos_gt$rn) %&gt;% purrr::map(\\(x) agg_ground_truth_match( param_combos_gt %&gt;% dplyr::filter( is_in_stand &amp; rn == x ) ) %&gt;% dplyr::mutate(rn = x) ) %&gt;% dplyr::bind_rows() %&gt;% # add in info on all parameter combinations dplyr::inner_join( param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct( rn,max_ht_m,min_area_m2,max_area_m2,convexity_pct,circle_fit_iou_pct ) , by = &quot;rn&quot; , relationship = &quot;one-to-one&quot; ) # what is this? param_combos_gt_agg %&gt;% dplyr::glimpse() ## Rows: 17 ## Columns: 23 ## $ tp_n &lt;dbl&gt; 83, 66, 116, 114, 78, 113, 94, 103, 95, 80, 7… ## $ fp_n &lt;dbl&gt; 33, 10, 156, 329, 53, 258, 138, 140, 14, 12, … ## $ fn_n &lt;dbl&gt; 38, 55, 5, 7, 43, 8, 27, 18, 26, 41, 45, 10, … ## $ omission_rate &lt;dbl&gt; 0.31404959, 0.45454545, 0.04132231, 0.0578512… ## $ commission_rate &lt;dbl&gt; 0.28448276, 0.13157895, 0.57352941, 0.7426636… ## $ precision &lt;dbl&gt; 0.7155172, 0.8684211, 0.4264706, 0.2573363, 0… ## $ recall &lt;dbl&gt; 0.6859504, 0.5454545, 0.9586777, 0.9421488, 0… ## $ f_score &lt;dbl&gt; 0.7004219, 0.6700508, 0.5903308, 0.4042553, 0… ## $ diff_area_m2_rmse &lt;dbl&gt; 0.9177856, 1.0318250, 2.7307986, 2.0816764, 1… ## $ diff_diameter_m_rmse &lt;dbl&gt; 0.5356816, 0.5909564, 0.8223519, 0.8535298, 0… ## $ diff_height_m_rmse &lt;dbl&gt; 0.4736971, 0.4941902, 0.7271534, 0.6431814, 0… ## $ diff_area_m2_mean &lt;dbl&gt; 0.4754762, 0.6257658, 0.6015038, 0.7216610, 0… ## $ diff_diameter_m_mean &lt;dbl&gt; 0.3976082, 0.4047071, 0.5242729, 0.5515058, 0… ## $ diff_height_m_mean &lt;dbl&gt; 0.026860245, -0.274133330, -0.116632762, 0.00… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1116297, 0.1209130, 0.1491131, 0.1503765, 0… ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.1512180, 0.1615222, 0.1834563, 0.1948854, 0… ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.1904217, 0.1385338, 0.2001751, 0.2095256, 0… ## $ rn &lt;dbl&gt; 473, 94, 276, 526, 13, 361, 313, 338, 246, 17… ## $ max_ht_m &lt;dbl&gt; 5, 2, 3, 5, 2, 4, 4, 4, 3, 3, 3, 5, 4, 5, 5, … ## $ min_area_m2 &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ max_area_m2 &lt;dbl&gt; 10, 40, 60, 40, 10, 30, 10, 20, 40, 10, 20, 6… ## $ convexity_pct &lt;dbl&gt; 0.9, 0.7, 0.1, 0.1, 0.5, 0.5, 0.5, 0.5, 0.9, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.5, 0.7, 0.1, 0.1, 0.5, 0.1, 0.5, 0.5, 0.1, … # param_combos_gt_agg %&gt;% readr::write_csv(&quot;c:/Users/georg/Downloads/param_combos_gt_agg.csv&quot;) # param_combos_gt_agg %&gt;% dplyr::select(f_score,precision,recall,tidyselect::ends_with(&quot;_n&quot;)) %&gt;% dplyr::mutate(gt_n=tp_n+fn_n) 7.1.3.1 Test Accuracy Insights lets’ make some plotting functions to glean some insight into the distribution of the accuracies obtained from our full set of sensitivity testing point estimates first, we’ll make a function to plot the distribution of F-score, Recall, and Precision values obtained in our sensitivity testing # this is a lot of work, so we&#39;re going to make it a function plt_detection_dist &lt;- function( df , my_subtitle = &quot;&quot; , show_rug = T ) { pal_eval_metric &lt;- c( RColorBrewer::brewer.pal(3,&quot;Oranges&quot;)[3] , RColorBrewer::brewer.pal(3,&quot;Greys&quot;)[3] , RColorBrewer::brewer.pal(3,&quot;Purples&quot;)[3] ) df_temp &lt;- df %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 ) %&gt;% factor( ordered = T , levels = 1:3 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) ) # plot # if(nrow(df)&lt;=15 &amp;&amp; (df_temp %&gt;% dplyr::count(metric,value) %&gt;% dplyr::pull(n) %&gt;% max())&gt;1 ){ if(nrow(df)&lt;=15){ # round df_temp &lt;- df_temp %&gt;% dplyr::mutate( value = round(value,2) ) # agg for median plotting xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , scales::percent(value,accuracy=1) ) ) # plot plt &lt;- df_temp %&gt;% dplyr::count(metric,value) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, fill = metric, color = metric) ) + ggplot2::geom_vline( data = xxxdf_temp , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + # ggplot2::geom_jitter(mapping = ggplot2::aes(y=-0.2), width = 0, height = 0.1) + # ggplot2::geom_boxplot(width = 0.1, color = &quot;black&quot;, fill = NA, outliers = F) + ggplot2::geom_segment( mapping = ggplot2::aes(y=n,yend=0) , lwd = 2, alpha = 0.8 ) + ggplot2::geom_point( mapping = ggplot2::aes(y=n) , alpha = 1 , shape = 21, color = &quot;gray44&quot;, size = 5 ) + ggplot2::geom_text( mapping = ggplot2::aes(y=n,label=n) , size = 2.5, color = &quot;white&quot; # , vjust = -0.01 ) + ggplot2::geom_text( data = xxxdf_temp , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5, color = &quot;black&quot; ) + # ggplot2::geom_rug() + ggplot2::scale_fill_manual(values = pal_eval_metric) + ggplot2::scale_color_manual(values = pal_eval_metric) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) # , limits = c(0,1) ) + ggplot2::scale_y_continuous(expand = ggplot2::expansion(mult = c(0, .1))) + ggplot2::facet_grid(cols = dplyr::vars(metric), scales = &quot;free&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) }else{ # agg for median plotting xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , scales::percent(value,accuracy=1) ) ) plt &lt;- df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, fill = metric, color = metric) ) + ggplot2::geom_density(color = NA, alpha = 0.9) + # ggplot2::geom_rug( # # # setting these makes the plotting more computationally intensive # # alpha = 0.5 # # , length = ggplot2::unit(0.01, &quot;npc&quot;) # ) + ggplot2::geom_vline( data = xxxdf_temp , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + ggplot2::geom_text( data = xxxdf_temp , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5, color = &quot;black&quot; ) + ggplot2::scale_fill_manual(values = pal_eval_metric) + ggplot2::scale_color_manual(values = pal_eval_metric) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) # , limits = c(0,1) ) + ggplot2::facet_grid(cols = dplyr::vars(metric), scales = &quot;free&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) if(show_rug){ plt &lt;- plt + ggplot2::geom_rug( # # setting these makes the plotting more computationally intensive # alpha = 0.5 # , length = ggplot2::unit(0.01, &quot;npc&quot;) ) } } return(plt) } that is a lot of plotting, try isolating the ggplot2::ggplot() command from the function to see what it does now plot the distribution of F-score, Recall, and Precision values obtained in our test sensitivity testing this is only a test plt_detection_dist(param_combos_gt_agg) we put in a special plot format if we only have a few observations (i.e. &lt;=15) this is only a test plt_detection_dist(param_combos_gt_agg %&gt;% dplyr::slice_sample(n=11)) neat. now, we’ll make a function to plot the distribution of MAPE, RMSE, and ME values obtained in our sensitivity testing. this one is a little more complex than the detection accuracy plotting because the values are on different scales (i.e. MAPE is a percentage value, RMSE is positive in the units of the measurement, and ME is positive or negative in the units of the measurement) # this is a lot of work, so we&#39;re going to make it a function plt_form_quantification_dist &lt;- function( df , my_subtitle = &quot;&quot; , show_rug = T ) { # reshape data to go long by evaluation metric df_temp &lt;- df %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( # label combining params lab = stringr::str_c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct, sep = &quot;:&quot;) %&gt;% forcats::fct_reorder(f_score) # %&gt;% forcats::fct_rev() ) %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct , lab # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area&quot; , &quot;Height&quot; , &quot;Diameter&quot; ) ) ) # plot # !!! we map over the ggplot function to allow for differnt formatting of the x axis # !!! and to allow for different axis ranges for each individual panel which is not possible when faceting plt_list_temp &lt;- # get factors in order df_temp %&gt;% dplyr::filter(eval_metric!=&quot;RRMSE&quot;) %&gt;% dplyr::count(eval_metric) %&gt;% pull(eval_metric) %&gt;% purrr::map(function(x, my_show_rug=show_rug){ if(nrow(df)&lt;=15){ df_temp &lt;- df_temp %&gt;% dplyr::filter(eval_metric==x) %&gt;% dplyr::mutate( value = dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ round(value,2) , T ~ round(value,1) ) ) # aggregate xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(pile_metric,eval_metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.1) , T ~ scales::comma(value,accuracy=0.1) ) ) ) # plot p &lt;- df_temp %&gt;% dplyr::count(eval_metric,pile_metric,value) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, fill = pile_metric, color = pile_metric) ) + ggplot2::geom_vline( data = xxxdf_temp , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + # ggplot2::geom_jitter(mapping = ggplot2::aes(y=-0.2), width = 0, height = 0.1) + # ggplot2::geom_boxplot(width = 0.1, color = &quot;black&quot;, fill = NA, outliers = F) + ggplot2::geom_segment( mapping = ggplot2::aes(y=n,yend=0) , lwd = 2, alpha = 0.8 ) + ggplot2::geom_point( mapping = ggplot2::aes(y=n) , alpha = 1 , shape = 21, color = &quot;gray44&quot;, size = 5 ) + ggplot2::geom_text( mapping = ggplot2::aes(y=n,label=n) , size = 2.5, color = &quot;white&quot; # , vjust = -0.01 ) + ggplot2::geom_text( data = xxxdf_temp , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5, color = &quot;black&quot; ) + # ggplot2::geom_rug() + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::scale_y_continuous(expand = ggplot2::expansion(mult = c(0, .33))) + ggplot2::facet_grid( cols = dplyr::vars(pile_metric), rows = dplyr::vars(eval_metric) , scales = &quot;free&quot; , switch = &quot;y&quot; # moves y facet label to left ) + ggplot2::labs(x = &quot;&quot;, y = &quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.placement = &quot;outside&quot; , strip.text.y = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y.left = ggplot2::element_text(angle = 0) , strip.background.y = ggplot2::element_rect(color = NA, fill = NA) , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 6.5) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() ) }else{ # aggregate xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(pile_metric,eval_metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.1) , T ~ scales::comma(value,accuracy=0.1) ) ) ) p &lt;- df_temp %&gt;% dplyr::filter(eval_metric==x) %&gt;% ggplot2::ggplot() + # ggplot2::geom_vline(xintercept = 0, color = &quot;gray&quot;) + ggplot2::geom_density(mapping = ggplot2::aes(x = value, fill = pile_metric), color = NA, alpha = 0.9) + # ggplot2::geom_rug(mapping = ggplot2::aes(x = value, color = pile_metric)) + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::geom_vline( data = xxxdf_temp %&gt;% dplyr::filter(eval_metric==x) , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + ggplot2::geom_text( data = xxxdf_temp %&gt;% dplyr::filter(eval_metric==x) , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5 ) + ggplot2::facet_grid( cols = dplyr::vars(pile_metric), rows = dplyr::vars(eval_metric) , scales = &quot;free&quot; , switch = &quot;y&quot; # moves y facet label to left ) + ggplot2::labs(x = &quot;&quot;, y = &quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.placement = &quot;outside&quot; , strip.text.y = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y.left = ggplot2::element_text(angle = 0) , strip.background.y = ggplot2::element_rect(color = NA, fill = NA) , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 6.5) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() ) if(my_show_rug){ p &lt;- p + ggplot2::geom_rug(mapping = ggplot2::aes(x = value, color = pile_metric)) } } if(x %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;)){ return(p+ggplot2::scale_x_continuous(labels = scales::percent_format(accuracy = 1))) }else{ return(p) } }) # combine # plt_list_temp patchwork::wrap_plots( plt_list_temp , ncol = 1 ) + patchwork::plot_annotation( # title = paste0(aoi_sf$study_site_lab, &quot; - ALS&quot;) subtitle = my_subtitle # paste0( # &quot;distribution of pile form quantification accuracy metrics for all&quot; # # , scales::percent(1-pct_rank_th_top,accuracy=1) # , &quot; (n=&quot; # , scales::comma(nrow(param_combos_gt_agg), accuracy = 1) # , &quot;) &quot; # , &quot;parameter combinations tested&quot; # ) # , caption = &quot;hey&quot; , theme = ggplot2::theme( plot.subtitle = ggplot2::element_text(size = 8) ) ) } now plot the distribution of F-score, Recall, and Precision values obtained in our test sensitivity testing this is only a test plt_form_quantification_dist(param_combos_gt_agg) we put in a special plot format if we only have a few observations (i.e. &lt;=15) this is only a test plt_form_quantification_dist(param_combos_gt_agg %&gt;% dplyr::slice_sample(n=11)) ok. "],["chm_sens_test.html", "Section 8 Sensitivity Testing Results 8.1 Process Raw Point Cloud 8.2 Structural Only: Parameter Testing 8.3 Data Fusion: Parameter Testing 8.4 Read Data for Analysis 8.5 Structural Only: Sensitivity Testing 8.6 Data Fusion: Sensitivity Testing 8.7 save the data", " Section 8 Sensitivity Testing Results In this section we’ll use the slash pile detection workflow to perform parameter sensitivity testing with different resolution CHM data as input. The objective here is to generate the point estimate data for statistical analysis to fully evaluate our slash pile detection method’s performance. In this prior section, we demonstrated how to use the cloud2trees::cloud2raster() function to process raw point cloud data CHM data (a DSM with the ground removed) for our raster-based watershed segmentation methodology. The cloud2trees package makes it easy to generate CHM data at various resolutions, so we’ll use it to systematically test the influence of CHM resolution on both pile detection and form quantification accuracy. Using various CHM resolutions, we will repeatedly execute the entire pile detection method while systematically varying the values of one or more structural parameters (such as minimum area or maximum height). These sensitivity tests will be performed under two conditions: using only the CHM data as input (structural detection) and incorporating the RGB spectral data via our data fusion approach across five different levels of the spectral_weight parameter. The results of these sensitivity tests will serve as individual point estimates of detection accuracy (i.e. F-score) and quantification accuracy (e.g., RMSE and MAPE) for each unique combination of CHM resolution, spectral data weighting, and parameter settings. This generated dataset will be used as the input for subsequent statistical modeling to quantify the influence of parameters and input data on the detection and form quantification accuracy of our slash pile detection methodology. 8.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data to generate a set of CHM rasters at varying resolutions chm_res_list &lt;- seq(from=0.10,to=0.50,by=0.1) # process point clouds chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;CHMing...........&quot;,chm_res_m)) dir_temp &lt;- paste0(&quot;../data/point_cloud_processing_delivery_chm&quot;,chm_res_m,&quot;m&quot;) # do it if(!dir.exists(dir_temp)){ # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = &quot;../data&quot; , input_las_dir = &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.25 , chm_res_m = chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = &quot;../data/point_cloud_processing_delivery&quot;, to = dir_temp) } }) # which dirs? chm_res_list[ chm_res_list %&gt;% purrr::map(~paste0(&quot;../data/point_cloud_processing_delivery_chm&quot;,.x,&quot;m&quot;)) %&gt;% unlist() %&gt;% dir.exists() ] 8.2 Structural Only: Parameter Testing we could simply map these combinations over our slash_pile_detect_watershed() function we reviewed in this prior section, but that would entail performing the same action multiple times. we defined a specialized function to efficiently map over all of these combinations in this section to obtain pile predictions based on the different settings. let’s test different parameter combinations of our watershed segmentation, rules-based slash pile detection methodology for each CHM raster resolution from more coarse, to finer resolution param_combos_df &lt;- tidyr::crossing( max_ht_m = seq(from = 2, to = 5, by = 1) # set the max expected pile height (could also do a minimum??) , min_area_m2 = c(2) # seq(from = 1, to = 2, by = 1) # set the min expected pile area , max_area_m2 = seq(from = 10, to = 60, by = 10) # set the max expected pile area , convexity_pct = seq(from = 0.05, to = 0.95, length.out = 7) # min required overlap between the predicted pile and the convex hull of the predicted pile , circle_fit_iou_pct = seq(from = 0.05, to = 0.95, length.out = 7) ) %&gt;% dplyr::mutate(rn = dplyr::row_number()) %&gt;% dplyr::relocate(rn) # param_combos_df %&gt;% dplyr::glimpse() # param_combos_df %&gt;% dplyr::count(convexity_pct) # param_combos_df %&gt;% dplyr::count(circle_fit_iou_pct) # seq(from = 0.05, to = 0.95, length.out = 7) # how many combos are we testing? n_combos_tested_chm &lt;- nrow(param_combos_df) #combos per chm n_combos_tested &lt;- length(chm_res_list)*n_combos_tested_chm #combos overall structural only # there are 5 spectral_weight settings + no spectral data (spectral_weight=0) = 6 spectral_settings_tested &lt;- 6 # how many combos overall is this for the spectral testing? n_combos_tested_spectral &lt;- n_combos_tested*spectral_settings_tested # how many combos PER CHM is this for the spectral testing? n_combos_tested_spectral_chm &lt;- n_combos_tested_chm*spectral_settings_tested map over each CHM raster for pile detection using each of these parameter combinations param_combos_piles_flist &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;param_combos_piles_detect_fn...........&quot;,chm_res_m)) # file f_temp &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_piles_chm&quot;,chm_res_m,&quot;m.gpkg&quot;)) # chm dir dir_temp &lt;- paste0(&quot;../data/point_cloud_processing_delivery_chm&quot;,chm_res_m,&quot;m&quot;) # chm file chm_f &lt;- file.path(dir_temp, paste0(&quot;chm_&quot;, chm_res_m,&quot;m.tif&quot;)) # check and do it if(!file.exists(f_temp) &amp;&amp; file.exists(chm_f) ){ # read chm chm_rast &lt;- terra::rast(chm_f) # do it param_combos_piles &lt;- param_combos_piles_detect_fn( chm = chm_rast %&gt;% terra::crop( stand_boundary %&gt;% dplyr::slice(1) %&gt;% sf::st_buffer(5) %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() ) , param_combos_df = param_combos_df , smooth_segs = T , ofile = f_temp ) # param_combos_piles %&gt;% dplyr::glimpse() # save it sf::st_write(param_combos_piles, f_temp, append = F, quiet = T) return(f_temp) }else if(file.exists(f_temp)){ return(f_temp) }else{ return(NULL) } }) # which successes? param_combos_piles_flist 8.2.1 Validation over parameter combinations now we need to validate these combinations against the ground truth data and we can map over the ground_truth_prediction_match() function to get true positive, false positive (commission), and false negative (omission) classifications for the predicted and ground truth piles param_combos_gt_flist &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;ground_truth_prediction_match...........&quot;,chm_res_m)) param_combos_piles_fnm &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_piles_chm&quot;,chm_res_m,&quot;m.gpkg&quot;)) # file creating now f_temp &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_gt_chm&quot;,chm_res_m,&quot;m.csv&quot;)) # check if(!file.exists(f_temp) &amp;&amp; file.exists(param_combos_piles_fnm)){ # read it param_combos_piles &lt;- sf::st_read(param_combos_piles_fnm) # do it param_combos_gt &lt;- unique(param_combos_df$rn) %&gt;% purrr::map(\\(x) ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) , gt_id = &quot;pile_id&quot; , predictions = param_combos_piles %&gt;% dplyr::filter(rn == x) %&gt;% dplyr::filter( pred_id %in% (param_combos_piles %&gt;% dplyr::filter(rn == x) %&gt;% sf::st_intersection( stand_boundary %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(pred_id)) ) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) %&gt;% dplyr::mutate(rn=x) ) %&gt;% dplyr::bind_rows() # write it param_combos_gt %&gt;% readr::write_csv(f_temp, append = F, progress = F) return(f_temp) }else if(file.exists(f_temp)){ return(f_temp) }else{ return(NULL) } }) # which successes? param_combos_gt_flist 8.2.2 Aggregate Validation Metrics to Parameter Combination now we’re going to calculate aggregated detection accuracy metrics and quantification accuracy metrics detection accuracy metrics: Precision precision measures how many of the objects our method detected as slash piles were actually correct. A high precision means the method has a low rate of false alarms. Recall recall (i.e. detection rate) indicates how many actual (ground truth) slash piles our method successfully identified. High recall means the method is good at finding most existing piles, minimizing omissions. F-score provides a single, balanced measure that combines both precision and recall. A high F-score indicates overall effectiveness in both finding most piles and ensuring most detections are correct. quantification accuracy metrics: Mean Error (ME) represents the direction of bias (over or under-prediction) in the original units RMSE represents the typical magnitude of error in the original units, with a stronger penalty for large errors MAPE represents the typical magnitude of error as a percentage, allowing for scale-independent comparisons regarding the form quantification accuracy evaluation, we will assess the method’s accuracy by comparing the true-positive matches using the following metrics: Diameter compares the predicted diameter (from the maximum internal distance) to the ground truth field-measured diameter Area compares the predicted area from the irregular shape to the image-annotated area based on the potentially irregular pile perimeter Height compares the predicted maximum height from the CHM to the ground truth field-measured height param_combos_gt_agg_flist &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;param_combos_gt_agg...........&quot;,chm_res_m)) # param_combos_piles file param_combos_piles_fnm &lt;- param_combos_piles_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.gpkg&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_piles_fnm) || !file.exists(param_combos_piles_fnm)){return(NULL)} # param_combos_gt file param_combos_gt_fnm &lt;- param_combos_gt_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_gt_fnm) || !file.exists(param_combos_gt_fnm)){return(NULL)} # file creating now f_temp &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_gt_agg_chm&quot;,chm_res_m,&quot;m.csv&quot;)) # check and do it if(!file.exists(f_temp)){ # read param_combos_piles param_combos_piles &lt;- sf::st_read(param_combos_piles_fnm) # read param_combos_piles param_combos_gt &lt;- readr::read_csv(param_combos_gt_fnm) ####################################### # let&#39;s attach a flag to only work with piles that intersect with the stand boundary # add in/out to piles data ####################################### param_combos_piles &lt;- param_combos_piles %&gt;% dplyr::left_join( param_combos_piles %&gt;% sf::st_intersection( stand_boundary %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(rn,pred_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand,F) ) %&gt;% # # get the length (diameter) and width of the polygon # st_bbox_by_row(dimensions = T) %&gt;% # gets shape_length, where shape_length=length of longest bbox side # and paraboloid volume dplyr::mutate( # paraboloid_volume_m3 = (1/8) * pi * (shape_length^2) * max_height_m paraboloid_volume_m3 = (1/8) * pi * (diameter_m^2) * max_height_m ) # param_combos_piles %&gt;% dplyr::glimpse() ####################################### # add data to validation ####################################### param_combos_gt &lt;- param_combos_gt %&gt;% dplyr::mutate(pile_id = as.numeric(pile_id)) %&gt;% # add area of gt dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id,image_gt_area_m2,height_m,field_diameter_m) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( rn,pred_id , is_in_stand , area_m2, volume_m3, max_height_m, diameter_m , paraboloid_volume_m3 # , shape_length # , shape_width ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m , pred_paraboloid_volume_m3 = paraboloid_volume_m3 ) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::case_when( is_in_stand == T ~ T , is_in_stand == F ~ F , match_grp == &quot;omission&quot; ~ T , T ~ F ) ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # area_m2 , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # height_m , diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m ) ####################################### # aggregate results from ground_truth_prediction_match() ####################################### param_combos_gt_agg &lt;- unique(param_combos_gt$rn) %&gt;% purrr::map(\\(x) agg_ground_truth_match( param_combos_gt %&gt;% dplyr::filter( is_in_stand &amp; rn == x ) ) %&gt;% dplyr::mutate(rn = x) %&gt;% dplyr::select(!tidyselect::starts_with(&quot;gt_&quot;)) ) %&gt;% dplyr::bind_rows() %&gt;% # add in info on all parameter combinations dplyr::inner_join( param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct( rn,max_ht_m,min_area_m2,max_area_m2,convexity_pct,circle_fit_iou_pct ) , by = &quot;rn&quot; , relationship = &quot;one-to-one&quot; ) # write it param_combos_gt_agg %&gt;% readr::write_csv(f_temp, append = F, progress = F) return(f_temp) }else if(file.exists(f_temp)){ return(f_temp) }else{ return(NULL) } }) # which successes? param_combos_gt_agg_flist 8.3 Data Fusion: Parameter Testing We also reviewed a data fusion approach that uses both a CHM generated from aerial point cloud data (for structural information) and RGB imagery, whereby initial candidate slash piles are first identified based on their structural form and then, filtered spectrally using the RGB imagery. We created a process to perform this filtering which takes as input: 1) a spatial data frame of candidate polygons; 2) a raster with RGB spectral data; 3) user-defined spectral weighting (voting system). let’s apply that process to the candidate piles detected using the structural data only from the prior section. param_combos_spectral_gt_flist &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;param_combos_spectral_gt...........&quot;,chm_res_m)) # param_combos_piles file param_combos_piles_fnm &lt;- param_combos_piles_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.gpkg&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_piles_fnm) || !file.exists(param_combos_piles_fnm)){return(NULL)} # param_combos_gt file param_combos_gt_fnm &lt;- param_combos_gt_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_gt_fnm) || !file.exists(param_combos_gt_fnm)){return(NULL)} # file creating now f_temp &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_spectral_gt_chm&quot;,chm_res_m,&quot;m.csv&quot;)) # check and do it if(!file.exists(f_temp)){ # read param_combos_piles param_combos_piles &lt;- sf::st_read(param_combos_piles_fnm) # read param_combos_piles param_combos_gt &lt;- readr::read_csv(param_combos_gt_fnm) ####################################### # let&#39;s attach a flag to only work with piles that intersect with the stand boundary # add in/out to piles data ####################################### param_combos_spectral_gt &lt;- c(1:5) %&gt;% purrr::map(function(sw){ # polygon_spectral_filtering param_combos_piles_filtered &lt;- polygon_spectral_filtering( sf_data = param_combos_piles , rgb_rast = ortho_rast , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 , spectral_weight = sw ) %&gt;% dplyr::mutate(spectral_weight=sw) # dplyr::glimpse(param_combos_piles_filtered) # param_combos_piles_filtered %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(rn) %&gt;% # dplyr::inner_join( # param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(rn) %&gt;% dplyr::rename(orig_n=n) # ) %&gt;% # dplyr::arrange(desc(orig_n-n)) # now we need to reclassify the combinations against the ground truth data gt_reclassify &lt;- param_combos_gt %&gt;% # add info from predictions dplyr::left_join( param_combos_piles_filtered %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( rn,pred_id,spectral_weight ) , by = dplyr::join_by(rn,pred_id) ) %&gt;% # dplyr::count(match_grp) # reclassify dplyr::mutate( # reclassify match_grp match_grp = dplyr::case_when( match_grp == &quot;true positive&quot; &amp; is.na(spectral_weight) ~ &quot;omission&quot; # is.na(spectral_weight) =&gt; removed by spectral filtering , match_grp == &quot;commission&quot; &amp; is.na(spectral_weight) ~ &quot;remove&quot; # is.na(spectral_weight) =&gt; removed by spectral filtering , T ~ match_grp ) # update pred_id , pred_id = dplyr::case_when( match_grp == &quot;omission&quot; ~ NA , T ~ pred_id ) # update spectral_weight (just adds it to this iteration&#39;s omissions) , spectral_weight = sw ) %&gt;% # remove old commissions # dplyr::count(match_grp) dplyr::filter(match_grp!=&quot;remove&quot;) # return return(gt_reclassify) }) %&gt;% dplyr::bind_rows() # write it param_combos_spectral_gt %&gt;% readr::write_csv(f_temp, append = F, progress = F) return(f_temp) }else if(file.exists(f_temp)){ return(f_temp) }else{ return(NULL) } }) # which successes? param_combos_spectral_gt_flist 8.3.1 Aggregate Validation Metrics to Parameter Combination now we’re going to calculate aggregated detection accuracy metrics and quantification accuracy metrics param_combos_spectral_gt_agg_flist &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ message(paste0(&quot;param_combos_spectral_gt_agg...........&quot;,chm_res_m)) # param_combos_piles file param_combos_piles_fnm &lt;- param_combos_piles_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.gpkg&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_piles_fnm) || !file.exists(param_combos_piles_fnm)){return(NULL)} # param_combos_gt file param_combos_gt_fnm &lt;- param_combos_gt_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_gt_fnm) || !file.exists(param_combos_gt_fnm)){return(NULL)} # param_combos_spectral_gt_flist file param_combos_spectral_gt_fnm &lt;- param_combos_spectral_gt_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(param_combos_spectral_gt_fnm) || !file.exists(param_combos_spectral_gt_fnm)){return(NULL)} # file creating now f_temp &lt;- file.path(&quot;../data&quot;,paste0(&quot;param_combos_spectral_gt_agg_chm&quot;,chm_res_m,&quot;m.csv&quot;)) # check and do it if(!file.exists(f_temp)){ # read param_combos_piles param_combos_piles &lt;- sf::st_read(param_combos_piles_fnm) # read param_combos_gt param_combos_gt &lt;- readr::read_csv(param_combos_gt_fnm) # read param_combos_spectral_gt param_combos_spectral_gt &lt;- readr::read_csv(param_combos_spectral_gt_fnm) ####################################### # let&#39;s attach a flag to only work with piles that intersect with the stand boundary # add in/out to piles data ####################################### param_combos_piles &lt;- param_combos_piles %&gt;% dplyr::left_join( param_combos_piles %&gt;% sf::st_intersection( stand_boundary %&gt;% sf::st_transform(sf::st_crs(param_combos_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(rn,pred_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand,F) ) %&gt;% # # get the length (diameter) and width of the polygon # st_bbox_by_row(dimensions = T) %&gt;% # gets shape_length, where shape_length=length of longest bbox side # and paraboloid volume dplyr::mutate( # paraboloid_volume_m3 = (1/8) * pi * (shape_length^2) * max_height_m paraboloid_volume_m3 = (1/8) * pi * (diameter_m^2) * max_height_m ) # param_combos_piles %&gt;% dplyr::glimpse() ####################################### # add data to validation ####################################### # add it to validation param_combos_spectral_gt &lt;- param_combos_spectral_gt %&gt;% # add original candidate piles from the structural watershed method with spectral_weight=0 dplyr::bind_rows( param_combos_gt %&gt;% dplyr::mutate(spectral_weight=0) %&gt;% dplyr::select(names(param_combos_spectral_gt)) ) %&gt;% # make a description of spectral_weight dplyr::mutate( spectral_weight_desc = factor( spectral_weight , ordered = T , levels = 0:5 , labels = c( &quot;no spectral criteria&quot; , &quot;1 spectral criteria req.&quot; , &quot;2 spectral criteria req.&quot; , &quot;3 spectral criteria req.&quot; , &quot;4 spectral criteria req.&quot; , &quot;5 spectral criteria req.&quot; ) ) ) %&gt;% # add area of gt dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id,image_gt_area_m2,height_m,field_diameter_m) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( param_combos_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( rn,pred_id ,is_in_stand , area_m2, volume_m3, max_height_m, diameter_m , paraboloid_volume_m3 # , shape_length # , shape_width ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m , pred_paraboloid_volume_m3 = paraboloid_volume_m3 ) , by = dplyr::join_by(rn,pred_id) ) %&gt;% dplyr::mutate( is_in_stand = dplyr::case_when( is_in_stand == T ~ T , is_in_stand == F ~ F , match_grp == &quot;omission&quot; ~ T , T ~ F ) ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # area_m2 , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # height_m , diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m ) ####################################### # aggregate results from ground_truth_prediction_match() ####################################### # unique combinations combo_temp &lt;- param_combos_spectral_gt %&gt;% dplyr::distinct(rn,spectral_weight) # aggregate results from ground_truth_prediction_match() param_combos_spectral_gt_agg &lt;- 1:nrow(combo_temp) %&gt;% purrr::map(\\(x) agg_ground_truth_match( param_combos_spectral_gt %&gt;% dplyr::filter( is_in_stand &amp; rn == combo_temp$rn[x] &amp; spectral_weight == combo_temp$spectral_weight[x] ) ) %&gt;% dplyr::mutate( rn = combo_temp$rn[x] , spectral_weight = combo_temp$spectral_weight[x] ) %&gt;% dplyr::select(!tidyselect::starts_with(&quot;gt_&quot;)) ) %&gt;% dplyr::bind_rows() %&gt;% # add in info on all parameter combinations # add in info on all parameter combinations dplyr::inner_join( param_combos_df , by = &quot;rn&quot; , relationship = &quot;many-to-one&quot; ) # write it param_combos_spectral_gt_agg %&gt;% readr::write_csv(f_temp, append = F, progress = F) return(f_temp) }else if(file.exists(f_temp)){ return(f_temp) }else{ return(NULL) } }) # which successes? param_combos_spectral_gt_agg_flist 8.4 Read Data for Analysis let’s read this data in for analysis 8.4.1 Structural Only param_combos_gt_agg &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ # param_combos_gt file fnm &lt;- param_combos_gt_agg_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(fnm) || !file.exists(fnm)){return(NULL)} # read it readr::read_csv(fnm, progress = F, show_col_types = F) %&gt;% dplyr::mutate(chm_res_m = chm_res_m) }) %&gt;% dplyr::bind_rows() # add in combos that returned no results # param_combos_gt_agg %&gt;% dplyr::mutate(tot = tp_n + fn_n) %&gt;% dplyr::select(tot) %&gt;% summary() # (slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% nrow()) param_combos_gt_agg &lt;- param_combos_df %&gt;% tidyr::crossing( chm_res_m = chm_res_list ) %&gt;% dplyr::left_join( param_combos_gt_agg %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , names(param_combos_df %&gt;% dplyr::select(-c(rn))) ))) , by = dplyr::join_by(rn,chm_res_m) ) %&gt;% # fill TP,FP,FN counts for those with no predictions dplyr::mutate( chm_res_m_desc = paste0(chm_res_m, &quot;m CHM&quot;) %&gt;% factor() %&gt;% forcats::fct_reorder(chm_res_m) , fn_n = dplyr::case_when( is.na(tp_n) &amp; is.na(fp_n) &amp; is.na(fn_n) ~ (slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% nrow()) , T ~ fn_n ) , dplyr::across( c(tp_n,fp_n) , ~dplyr::coalesce(.x,0) ) , ) %&gt;% # fill detection rates for those with no predictions dplyr::mutate( omission_rate = dplyr::case_when( is.na(omission_rate) &amp; dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 1 # every single actual pile was missed , T ~ omission_rate ) # False Negative Rate or Miss Rate , commission_rate = dplyr::case_when( is.na(commission_rate) &amp; dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 0 # if no predictions are made, the model could not have made any commission errors , T ~ commission_rate ) # False Positive Rate , precision = dplyr::case_when( is.na(precision) &amp; dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 1 # if no predictions are made, the model made zero incorrect positive claims , T ~ precision ) , recall = dplyr::case_when( is.na(recall) &amp; dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 0 # every single actual pile was missed , T ~ recall ) , f_score = dplyr::case_when( is.na(f_score) &amp; ( dplyr::coalesce(precision,0) == 0 | dplyr::coalesce(recall,0) == 0 ) ~ 0 , T ~ f_score ) ) what did we get from all of that work? param_combos_gt_agg %&gt;% dplyr::glimpse() ## Rows: 5,880 ## Columns: 25 ## $ rn &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, … ## $ max_ht_m &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ min_area_m2 &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ max_area_m2 &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1… ## $ convexity_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ circle_fit_iou_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.20, 0.20, 0.2… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, … ## $ tp_n &lt;dbl&gt; 98, 97, 91, 79, 59, 95, 90, 80, 72, 51, 91, 8… ## $ fp_n &lt;dbl&gt; 76, 126, 156, 184, 266, 70, 108, 140, 174, 25… ## $ fn_n &lt;dbl&gt; 23, 24, 30, 42, 62, 26, 31, 41, 49, 70, 30, 4… ## $ omission_rate &lt;dbl&gt; 0.1900826, 0.1983471, 0.2479339, 0.3471074, 0… ## $ commission_rate &lt;dbl&gt; 0.43678161, 0.56502242, 0.63157895, 0.6996197… ## $ precision &lt;dbl&gt; 0.5632184, 0.4349776, 0.3684211, 0.3003802, 0… ## $ recall &lt;dbl&gt; 0.8099174, 0.8016529, 0.7520661, 0.6528926, 0… ## $ f_score &lt;dbl&gt; 0.6644068, 0.5639535, 0.4945652, 0.4114583, 0… ## $ diff_area_m2_rmse &lt;dbl&gt; 0.9553187, 1.0630419, 1.7936904, 4.7264949, 3… ## $ diff_diameter_m_rmse &lt;dbl&gt; 0.4146916, 0.6204824, 0.7931262, 1.1344303, 1… ## $ diff_height_m_rmse &lt;dbl&gt; 0.3186457, 0.3295112, 0.3433166, 0.5022307, 0… ## $ diff_area_m2_mean &lt;dbl&gt; -0.4845496, 0.5805644, 1.5061345, 1.7276581, … ## $ diff_diameter_m_mean &lt;dbl&gt; 0.1722271, 0.4569563, 0.6992050, 0.8418140, 1… ## $ diff_height_m_mean &lt;dbl&gt; -0.2039459, -0.2158827, -0.2325115, -0.284825… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1077556, 0.1273854, 0.2328611, 0.3611736, 0… ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.09959918, 0.16915037, 0.24160115, 0.3229551… ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.1255508, 0.1306792, 0.1348453, 0.1453663, 0… ## $ chm_res_m_desc &lt;fct&gt; 0.1m CHM, 0.2m CHM, 0.3m CHM, 0.4m CHM, 0.5m … we should have the same number of records per tested CHM resolution as the number of parameter records tested (n = 1,176) for an overall total of 5,880 combinations tested param_combos_gt_agg %&gt;% dplyr::count(chm_res_m_desc) ## # A tibble: 5 × 2 ## chm_res_m_desc n ## &lt;fct&gt; &lt;int&gt; ## 1 0.1m CHM 1176 ## 2 0.2m CHM 1176 ## 3 0.3m CHM 1176 ## 4 0.4m CHM 1176 ## 5 0.5m CHM 1176 that is close enough as all we are looking to do is assess the sensitivity of the parameterization of the detection method and identify the most appropriate parameter settings to use for a given CHM resolution 8.4.2 Data Fusion param_combos_spectral_gt_agg &lt;- chm_res_list %&gt;% purrr::map(function(chm_res_m){ # param_combos_gt file fnm &lt;- param_combos_spectral_gt_agg_flist %&gt;% stringr::str_subset(pattern = paste0(&quot;chm&quot;,chm_res_m,&quot;m.csv&quot;)) %&gt;% purrr::pluck(1) if(is.null(fnm) || !file.exists(fnm)){return(NULL)} # read it readr::read_csv(fnm, progress = F, show_col_types = F) %&gt;% dplyr::mutate(chm_res_m = chm_res_m) }) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate( chm_res_m_desc = paste0(chm_res_m, &quot;m CHM&quot;) %&gt;% factor() %&gt;% forcats::fct_reorder(chm_res_m) , spectral_weight_fact = ifelse(spectral_weight==0,&quot;structural only&quot;,&quot;structural+spectral&quot;) %&gt;% factor() ) # param_combos_spectral_gt_agg %&gt;% dplyr::glimpse() what did we get from all of that work? param_combos_spectral_gt_agg %&gt;% dplyr::glimpse() ## Rows: 35,280 ## Columns: 27 ## $ tp_n &lt;dbl&gt; 98, 95, 91, 88, 81, 50, 0, 98, 95, 91, 88, 81… ## $ fp_n &lt;dbl&gt; 76, 70, 55, 36, 15, 1, 0, 76, 70, 55, 36, 15,… ## $ fn_n &lt;dbl&gt; 23, 26, 30, 33, 40, 71, 121, 23, 26, 30, 33, … ## $ omission_rate &lt;dbl&gt; 0.1900826, 0.2148760, 0.2479339, 0.2727273, 0… ## $ commission_rate &lt;dbl&gt; 0.43678161, 0.42424242, 0.37671233, 0.2903225… ## $ precision &lt;dbl&gt; 0.5632184, 0.5757576, 0.6232877, 0.7096774, 0… ## $ recall &lt;dbl&gt; 0.8099174, 0.7851240, 0.7520661, 0.7272727, 0… ## $ f_score &lt;dbl&gt; 0.6644068, 0.6643357, 0.6816479, 0.7183673, 0… ## $ diff_area_m2_rmse &lt;dbl&gt; 0.9553187, 0.9671790, 0.9832242, 0.9714572, 0… ## $ diff_diameter_m_rmse &lt;dbl&gt; 0.4146916, 0.4184979, 0.4186223, 0.4221027, 0… ## $ diff_height_m_rmse &lt;dbl&gt; 0.3186457, 0.3232764, 0.3270866, 0.3098395, 0… ## $ diff_area_m2_mean &lt;dbl&gt; -0.4845496, -0.4896862, -0.4906696, -0.478697… ## $ diff_diameter_m_mean &lt;dbl&gt; 0.1722271, 0.1724538, 0.1737368, 0.1746051, 0… ## $ diff_height_m_mean &lt;dbl&gt; -0.2039459, -0.2087653, -0.2134582, -0.204894… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1077556, 0.1092832, 0.1113608, 0.1094018, 0… ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.09959918, 0.10076252, 0.10063595, 0.1007289… ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.1255508, 0.1287027, 0.1322157, 0.1283063, 0… ## $ rn &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14… ## $ spectral_weight &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ max_ht_m &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ min_area_m2 &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ max_area_m2 &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1… ## $ convexity_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.2… ## $ circle_fit_iou_pct &lt;dbl&gt; 0.05, 0.20, 0.35, 0.50, 0.65, 0.80, 0.95, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … ## $ chm_res_m_desc &lt;fct&gt; 0.1m CHM, 0.1m CHM, 0.1m CHM, 0.1m CHM, 0.1m … ## $ spectral_weight_fact &lt;fct&gt; structural+spectral, structural+spectral, str… # scales::comma(n_combos_tested*6,accuracy=1) we should have the same number of records per tested CHM resolution as the number of parameter records tested (n = 1,176) multiplied by six for the different five levels of the spectral_weight parameter tested when adding the spectral data in our data fusion approach and one combination representing no spectral data; for a total of 7,056 combinations tested per CHM resolution and an overall total of 35,280 combinations tested param_combos_spectral_gt_agg %&gt;% dplyr::count(chm_res_m_desc) ## # A tibble: 5 × 2 ## chm_res_m_desc n ## &lt;fct&gt; &lt;int&gt; ## 1 0.1m CHM 7056 ## 2 0.2m CHM 7056 ## 3 0.3m CHM 7056 ## 4 0.4m CHM 7056 ## 5 0.5m CHM 7056 that is close enough as all we are looking to do is assess the sensitivity of the parameterization of the detection method and identify the most appropriate parameter settings to use for a given CHM resolution 8.5 Structural Only: Sensitivity Testing let’s look at the sensitivity testing results for the raster-based method using only structural data of the study area from the CHM to evaluate how changes to the specific thresholds and settings within the detection methodology impact the final results. Since the method doesn’t use training data, its performance is highly dependent on these manually defined parameters we tested a total of 1,176 combinations tested per CHM resolution and an overall total of 5,880 combinations tested 8.5.1 Main Effects: pile detection what is the detection accuracy across all parameter combinations tested for each CHM resolution? # this is a lot of work, so we&#39;re going to make it a function plt_detection_dist2 &lt;- function( df , my_subtitle = &quot;&quot; , show_rug = T ) { # Construct the formula for facet_grid # facet_formula &lt;- reformulate(&quot;metric&quot;, &quot;chm_res_m_desc&quot;) # reformulate(col_facet_var, row_facet_var) pal_eval_metric &lt;- c( RColorBrewer::brewer.pal(3,&quot;Oranges&quot;)[3] , RColorBrewer::brewer.pal(3,&quot;Greys&quot;)[3] , RColorBrewer::brewer.pal(3,&quot;Purples&quot;)[3] ) df_temp &lt;- df %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 ) %&gt;% factor( ordered = T , levels = 1:3 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) ) # chm check nrow_check &lt;- df %&gt;% dplyr::count(chm_res_m_desc) %&gt;% dplyr::pull(n) %&gt;% max() # plot if(nrow_check&lt;=15){ # round df_temp &lt;- df_temp %&gt;% dplyr::mutate( value = round(value,2) ) # agg for median plotting xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(chm_res_m_desc,metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , scales::percent(value,accuracy=1) ) ) # plot plt &lt;- df_temp %&gt;% dplyr::count(chm_res_m_desc,metric,value) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, fill = metric, color = metric) ) + ggplot2::geom_vline( data = xxxdf_temp , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + # ggplot2::geom_jitter(mapping = ggplot2::aes(y=-0.2), width = 0, height = 0.1) + # ggplot2::geom_boxplot(width = 0.1, color = &quot;black&quot;, fill = NA, outliers = F) + ggplot2::geom_segment( mapping = ggplot2::aes(y=n,yend=0) , lwd = 2, alpha = 0.8 ) + ggplot2::geom_point( mapping = ggplot2::aes(y=n) , alpha = 1 , shape = 21, color = &quot;gray44&quot;, size = 5 ) + ggplot2::geom_text( mapping = ggplot2::aes(y=n,label=n) , size = 2.5, color = &quot;white&quot; # , vjust = -0.01 ) + ggplot2::geom_text( data = xxxdf_temp , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5, color = &quot;black&quot; ) + # ggplot2::geom_rug() + ggplot2::scale_fill_manual(values = pal_eval_metric) + ggplot2::scale_color_manual(values = pal_eval_metric) + ggplot2::scale_y_continuous(expand = ggplot2::expansion(mult = c(0, .2))) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) # , limits = c(0,1.05) ) + ggplot2::facet_grid(cols = dplyr::vars(metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free_x&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) }else{ # agg for median plotting xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(chm_res_m_desc,metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , scales::percent(value,accuracy=1) ) ) plt &lt;- df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, fill = metric, color = metric) ) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), color = NA, alpha = 0.9) + # ggplot2::geom_rug( # # # setting these makes the plotting more computationally intensive # # alpha = 0.5 # # , length = ggplot2::unit(0.01, &quot;npc&quot;) # ) + ggplot2::geom_vline( data = xxxdf_temp , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + ggplot2::geom_text( data = xxxdf_temp , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5, color = &quot;black&quot; ) + ggplot2::scale_fill_manual(values = pal_eval_metric) + ggplot2::scale_color_manual(values = pal_eval_metric) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1.05) ) + ggplot2::facet_grid(cols = dplyr::vars(metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free_y&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) if(show_rug){ plt &lt;- plt + ggplot2::geom_rug( # # setting these makes the plotting more computationally intensive # alpha = 0.5 # , length = ggplot2::unit(0.01, &quot;npc&quot;) ) } } return(plt) } # plot it plt_detection_dist2( df = param_combos_gt_agg , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile detection accuracy metrics for all&quot; , &quot; (n=&quot; , scales::comma(n_combos_tested_chm, accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested&quot; ) ) collapsing across all other parameters, what is the main effect of each individual parameter or CHM resolution? param_combos_gt_agg %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m) , names_to = &quot;param&quot; , values_to = &quot;param_value&quot; ) %&gt;% dplyr::group_by(param, param_value, metric) %&gt;% dplyr::summarise( median = median(value,na.rm=T) , q25 = stats::quantile(value,na.rm=T,probs = 0.25) , q75 = stats::quantile(value,na.rm=T,probs = 0.75) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( param = dplyr::case_when( param == &quot;chm_res_m&quot; ~ 1 , param == &quot;max_ht_m&quot; ~ 2 , param == &quot;min_area_m2&quot; ~ 3 , param == &quot;max_area_m2&quot; ~ 4 , param == &quot;convexity_pct&quot; ~ 5 , param == &quot;circle_fit_iou_pct&quot; ~ 6 ) %&gt;% factor( ordered = T , levels = 1:6 , labels = c( &quot;CHM resolution (m)&quot; , &quot;max_ht_m&quot; , &quot;min_area_m2&quot; , &quot;max_area_m2&quot; , &quot;convexity_pct&quot; , &quot;circle_fit_iou_pct&quot; ) ) , metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 ) %&gt;% factor( ordered = T , levels = 1:3 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(y = median, x = param_value, color = metric, fill = metric, group = metric, shape = metric) ) + ggplot2::geom_ribbon( mapping = ggplot2::aes(ymin = q25, ymax = q75) , alpha = 0.2, color = NA ) + ggplot2::geom_line(lwd = 1.5, alpha = 0.8) + ggplot2::geom_point(size = 2) + ggplot2::facet_wrap(facets = dplyr::vars(param), scales = &quot;free_x&quot;) + # ggplot2::scale_color_viridis_d(begin = 0.2, end = 0.8) + ggplot2::scale_fill_manual(values = rev(pal_eval_metric)) + ggplot2::scale_color_manual(values = rev(pal_eval_metric)) + ggplot2::scale_y_continuous(limits = c(0,1), labels = scales::percent, breaks = scales::breaks_extended(10)) + ggplot2::labs( x = &quot;&quot;, y = &quot;median value&quot;, color = &quot;&quot;, fill = &quot;&quot; , subtitle = &quot;Structural Data Only&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) based on these main effect aggregated results using our point cloud and validation data: increasing the CHM resolution (making it more coarse) consistently reduced all detection accuracy metrics (F-score, precision, and recall) across the tested range of 0.1m to 0.5m increasing the max_ht_m (which sets the maximum height of the CHM slice) steadily reduced precision. conversely, F-score and recall improved when the parameter was increased from 2 m to 3 m, remaining stable or slightly declining thereafter increasing the max_area_m2 (which determines the maximum pile area) had minimal impact on detection metrics once the value was set above ~10 m2 increasing convexity_pct (toward 1 to favor more regular shapes) had minimal impact on metrics until values exceeded ~0.75. at this point, recall decreased significantly while precision improved but not enough to offset the losses from the recall decline as F-score plummeted increasing circle_fit_iou_pct (toward 1 to favor circular shapes) improved precision and F-score up to a value of ~0.6 with minimal effect on recall. Beyond this point, recall dropped significantly and overall accuracy crashed past. do the trends vary by CHM resolution? param_combos_gt_agg %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct) , names_to = &quot;param&quot; , values_to = &quot;param_value&quot; ) %&gt;% dplyr::group_by(param, param_value, metric, chm_res_m) %&gt;% dplyr::summarise( median = median(value,na.rm=T) , q25 = stats::quantile(value,na.rm=T,probs = 0.25) , q75 = stats::quantile(value,na.rm=T,probs = 0.75) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( param = dplyr::case_when( param == &quot;chm_res_m&quot; ~ 1 , param == &quot;max_ht_m&quot; ~ 2 , param == &quot;min_area_m2&quot; ~ 3 , param == &quot;max_area_m2&quot; ~ 4 , param == &quot;convexity_pct&quot; ~ 5 , param == &quot;circle_fit_iou_pct&quot; ~ 6 ) %&gt;% factor( ordered = T , levels = 1:6 , labels = c( &quot;CHM resolution (m)&quot; , &quot;max_ht_m&quot; , &quot;min_area_m2&quot; , &quot;max_area_m2&quot; , &quot;convexity_pct&quot; , &quot;circle_fit_iou_pct&quot; ) ) , metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 ) %&gt;% factor( ordered = T , levels = 1:3 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(y = median, x = param_value, color = metric, fill = metric, group = metric, shape = metric) ) + # ggplot2::geom_ribbon( # mapping = ggplot2::aes(ymin = q25, ymax = q75) # , alpha = 0.2, color = NA # ) + ggplot2::geom_line(lwd = 1.5, alpha = 0.8) + ggplot2::geom_point(size = 2) + ggplot2::facet_grid(cols = dplyr::vars(param), rows = dplyr::vars(chm_res_m), scales = &quot;free&quot;) + # ggplot2::scale_color_viridis_d(begin = 0.2, end = 0.8) + ggplot2::scale_fill_manual(values = rev(pal_eval_metric)) + ggplot2::scale_color_manual(values = rev(pal_eval_metric)) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( x = &quot;&quot;, y = &quot;median value&quot;, color = &quot;&quot;, fill = &quot;&quot; , subtitle = &quot;Structural Data Only&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text = ggplot2::element_text(size = 7) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) generally, the tends do not appear to vary substantially by CHM resolution but we can see that detection accuracy decreases as CHM resolution becomes more coarse 8.5.2 Main Effects: form quantification let’s check out the the ability of the method to properly extract the form of the piles by looking at the quantification accuracy metrics where: Mean Error (ME) represents the direction of bias (over or under-prediction) in the original units RMSE represents the typical magnitude of error in the original units, with a stronger penalty for large errors MAPE represents the typical magnitude of error as a percentage, allowing for scale-independent comparisons as a reminder regarding the form quantification accuracy evaluation, we will assess the method’s accuracy by comparing the true-positive matches using the following metrics: Diameter compares the predicted diameter (from the maximum internal distance) to the ground truth field-measured diameter Area compares the predicted area from the irregular shape to the image-annotated area based on the potentially irregular pile perimeter Height compares the predicted maximum height from the CHM to the ground truth field-measured height what is the quantification accuracy across all parameter combinations tested for each CHM resolution? # let&#39;s average across all other factors to look at the main effect by parameter for the **MAPE** metrics quantifying the pile form accuracy # this is a lot of work, so we&#39;re going to make it a function plt_form_quantification_trend &lt;- function( df , my_subtitle = &quot;&quot; , quant_metric = &quot;mape&quot; # rmse, mean, mape ) { quant_metric &lt;- dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;mape&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;rmse&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;mean&quot; , T ~ &quot;mape&quot; ) p &lt;- df %&gt;% tidyr::pivot_longer( cols = tidyselect::ends_with(paste0(&quot;_&quot;,quant_metric)) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m) , names_to = &quot;param&quot; , values_to = &quot;param_value&quot; ) %&gt;% dplyr::group_by(param, param_value, metric) %&gt;% dplyr::summarise( median = median(value,na.rm=T) , q25 = stats::quantile(value,na.rm=T,probs = 0.25) , q75 = stats::quantile(value,na.rm=T,probs = 0.75) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( param = dplyr::case_when( param == &quot;chm_res_m&quot; ~ 1 , param == &quot;max_ht_m&quot; ~ 2 , param == &quot;min_area_m2&quot; ~ 3 , param == &quot;max_area_m2&quot; ~ 4 , param == &quot;convexity_pct&quot; ~ 5 , param == &quot;circle_fit_iou_pct&quot; ~ 6 ) %&gt;% factor( ordered = T , levels = 1:6 , labels = c( &quot;CHM resolution (m)&quot; , &quot;max_ht_m&quot; , &quot;min_area_m2&quot; , &quot;max_area_m2&quot; , &quot;convexity_pct&quot; , &quot;circle_fit_iou_pct&quot; ) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(y = median, x = param_value, color = pile_metric, fill = pile_metric, group = pile_metric) #, shape = pile_metric) ) + # ggplot2::geom_ribbon( # mapping = ggplot2::aes(ymin = q25, ymax = q75) # , alpha = 0.2, color = NA # ) + ggplot2::geom_line(lwd = 1.5, alpha = 0.8) + ggplot2::geom_point(size = 2) + ggplot2::facet_grid(cols = dplyr::vars(param), rows = dplyr::vars(pile_metric), scales = &quot;free&quot;, axes = &quot;all&quot;) + # ggplot2::scale_color_viridis_d(begin = 0.2, end = 0.8) + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::labs( x = &quot;&quot; , y = paste0(ifelse(quant_metric==&quot;mean&quot;,&quot;Mean Error&quot;, toupper(quant_metric)), &quot; (median)&quot;) , color = &quot;&quot;, fill = &quot;&quot; , title = ifelse(quant_metric==&quot;mean&quot;,&quot;Mean Error&quot;, toupper(quant_metric)) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_text(size = 8) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) if(quant_metric == &quot;mape&quot;){ p &lt;- p + ggplot2::scale_y_continuous(labels = scales::percent, breaks = scales::breaks_extended(10)) }else{ p &lt;- p + ggplot2::scale_y_continuous(labels = scales::comma, breaks = scales::breaks_extended(10)) } return(p) } # plt_form_quantification_trend(param_combos_gt_agg, quant_metric = &quot;mean&quot;) # plt_form_quantification_trend(param_combos_gt_agg, quant_metric = &quot;mape&quot;) # this is a lot of work, so we&#39;re going to make it a function plt_form_quantification_dist2 &lt;- function( df , my_subtitle = &quot;&quot; , show_rug = T , quant_metric = &quot;mape&quot; # rmse, mean, mape ) { # reshape data to go long by evaluation metric df_temp &lt;- df %&gt;% dplyr::ungroup() %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m_desc,chm_res_m # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) ) # plot # chm check nrow_check &lt;- df %&gt;% dplyr::count(chm_res_m_desc) %&gt;% dplyr::pull(n) %&gt;% max() # plot if(nrow_check&lt;=15){ # round df_temp &lt;- df_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) %&gt;% dplyr::mutate( value = dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ round(value,2) , T ~ round(value,1) ) ) # agg for median plotting xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(chm_res_m_desc,pile_metric,eval_metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.1) , T ~ scales::comma(value,accuracy=0.1) ) ) ) # plot p &lt;- df_temp %&gt;% dplyr::count(chm_res_m_desc,pile_metric,value) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x=value,color = pile_metric,fill = pile_metric)) + ggplot2::geom_vline( data = xxxdf_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + ggplot2::geom_segment( mapping = ggplot2::aes(y=n,yend=0) , lwd = 2, alpha = 0.8 ) + ggplot2::geom_point( mapping = ggplot2::aes(y=n) , alpha = 1 , shape = 21, color = &quot;gray44&quot;, size = 5 ) + ggplot2::geom_text( mapping = ggplot2::aes(y=n,label=n) , size = 2.5, color = &quot;white&quot; # , vjust = -0.01 ) + ggplot2::scale_y_continuous(expand = ggplot2::expansion(mult = c(0, .2))) + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::geom_text( data = xxxdf_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5 , color = &quot;black&quot; ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle , title = dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;Mean Error&quot; , T ~ &quot;MAPE&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) }else{ # aggregate xxxdf_temp &lt;- df_temp %&gt;% dplyr::group_by(chm_res_m_desc,pile_metric,eval_metric) %&gt;% dplyr::summarise(value = median(value,na.rm=T)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( value_lab = paste0( &quot;median:\\n&quot; , dplyr::case_when( eval_metric %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=0.1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) ) p &lt;- df_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) %&gt;% ggplot2::ggplot() + # ggplot2::geom_vline(xintercept = 0, color = &quot;gray&quot;) + ggplot2::geom_density(mapping = ggplot2::aes(x = value, y = ggplot2::after_stat(scaled), fill = pile_metric), color = NA, alpha = 0.9) + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::geom_vline( data = xxxdf_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) , mapping = ggplot2::aes(xintercept = value) , color = &quot;gray44&quot;, linetype = &quot;dashed&quot; ) + ggplot2::geom_text( data = xxxdf_temp %&gt;% dplyr::filter( eval_metric==dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) ) , mapping = ggplot2::aes( x = -Inf, y = Inf # always in upper left? # x = value, y = 0 , label = value_lab ) , hjust = -0.1, vjust = 1 # always in upper left? # , hjust = -0.1, vjust = -5 , size = 2.5 ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free&quot;) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = my_subtitle , title = dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;Mean Error&quot; , T ~ &quot;MAPE&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_blank() , panel.grid.minor.y = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) if(show_rug){ p &lt;- p + ggplot2::geom_rug(mapping = ggplot2::aes(x = value, color = pile_metric)) } } if( dplyr::case_when( tolower(quant_metric) == &quot;mape&quot; ~ &quot;MAPE&quot; , tolower(quant_metric) == &quot;rmse&quot; ~ &quot;RMSE&quot; , tolower(quant_metric) == &quot;mean&quot; ~ &quot;ME&quot; , T ~ &quot;MAPE&quot; ) %in% c(&quot;RRMSE&quot;, &quot;MAPE&quot;) ){ return(p+ggplot2::scale_x_continuous(labels = scales::percent_format(accuracy = 1))) }else{ return(p) } } 8.5.2.1 MAPE MAPE represents the typical magnitude of error as a percentage, allowing for scale-independent comparisons distribution across all parameter combinations tested # plot it plt_form_quantification_dist2( df = param_combos_gt_agg , quant_metric = &quot;mape&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification accuracy metrics for all&quot; , &quot; (n=&quot; , scales::comma(n_combos_tested_chm, accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested&quot; ) , show_rug = F ) let’s average across all other factors to look at the median main effect by parameter and quantification metric plt_form_quantification_trend(param_combos_gt_agg, quant_metric = &quot;mape&quot;) Across the different pile measurement metrics, there are non-linear trends between MAPE and CHM resolution, convexity_pct, and circle_fit_iou_pct. Additionally, the height MAPE does not appear to vary much across the different CHM resolutions tested, so non-linear trends between the height measurement error and parameter settings may be less consequential. 8.5.2.2 Mean Error (ME) Mean Error (ME) represents the direction of bias (over or under-prediction) in the original units distribution across all parameter combinations tested # plot it plt_form_quantification_dist2( df = param_combos_gt_agg , quant_metric = &quot;mean&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification accuracy metrics for all&quot; , &quot; (n=&quot; , scales::comma(n_combos_tested_chm, accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested&quot; ) , show_rug = F ) let’s average across all other factors to look at the median main effect by parameter and quantification metric plt_form_quantification_trend(param_combos_gt_agg, quant_metric = &quot;mean&quot;) 8.5.2.3 RMSE RMSE represents the typical magnitude of error in the original units, with a stronger penalty for large errors # plot it plt_form_quantification_dist2( df = param_combos_gt_agg , quant_metric = &quot;rmse&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification accuracy metrics for all&quot; , &quot; (n=&quot; , scales::comma(n_combos_tested_chm, accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested&quot; ) , show_rug = F ) let’s average across all other factors to look at the median main effect by parameter and quantification metric plt_form_quantification_trend(param_combos_gt_agg, quant_metric = &quot;rmse&quot;) 8.5.3 Best settings Of the parameter levels we tested to generate these accuracy point estimates, let’s identify the best-performing parameter combinations that not only balance detection and quantification accuracy but also achieve the highest recall rates. we’ll select these by choosing any combination whose recall rate is at least one standard deviation above the average for this top group. if no combinations meet this criterion, we will instead select the top 10 combinations based on their recall rates. 8.5.3.1 Overall (across CHM resolution) To select the best-performing parameter combinations, we will prioritize those that balance detection and quantification accuracy. From this group, we will then identify the settings that achieve the highest pile detection rates (recall). We emphasize that these recommendations are for users who can generate a CHM from the original point cloud. This is critical because creating a new CHM at the desired resolution is a fundamentally different process than simply disaggregating an existing, coarser raster. we’ll use the F-Score and the average rank of the MAPE metrics across all form measurements (i.e. height, diameter, area, volume) to determine the best overall list ##################### START USER DEFINED ##################### # what percent should we classify as top? pct_th_top &lt;- 0.01 # of those top, how many should be selected by recall? n_th_top &lt;- 12 ##################### END USER DEFINED ##################### # math on user defined to label stuff # structural only n_combos_top_overall &lt;- n_combos_tested*pct_th_top n_th_top_chm &lt;- round(n_th_top/2) pct_th_top_chm &lt;- pct_th_top*2 n_combos_top_chm &lt;- floor(n_combos_tested_chm*pct_th_top_chm) # double it so we look at more than 14?? n_combos_top_spectral_chm &lt;- floor(n_combos_tested_spectral_chm*pct_th_top_chm) # param_combos_gt_agg %&gt;% nrow() # param_combos_gt_agg %&gt;% dplyr::select(tidyselect::ends_with(&quot;_mape&quot;)) %&gt;% dplyr::glimpse() param_combos_ranked &lt;- param_combos_gt_agg %&gt;% ########## # first. find overall top combinations irrespective of CHM res ########## dplyr::ungroup() %&gt;% dplyr::mutate( # label combining params lab = stringr::str_c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m, sep = &quot;:&quot;) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~dplyr::percent_rank(-.x) , .names = &quot;ovrall_pct_rank_quant_{.col}&quot; ) , dplyr::across( .cols = c(f_score) # .cols = c(f_score,recall) , .fn = ~dplyr::percent_rank(.x) , .names = &quot;ovrall_pct_rank_det_{.col}&quot; ) ) %&gt;% ########## # second. find top combinations by CHM res ########## dplyr::group_by(chm_res_m) %&gt;% dplyr::mutate( dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mape&quot;) &amp; !tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , .fn = ~dplyr::percent_rank(-.x) , .names = &quot;chm_pct_rank_quant_{.col}&quot; ) , dplyr::across( .cols = c(f_score) # .cols = c(f_score,recall) , .fn = ~dplyr::percent_rank(.x) , .names = &quot;chm_pct_rank_det_{.col}&quot; ) ) %&gt;% # now get the max of these pct ranks by row dplyr::rowwise() %&gt;% dplyr::mutate( ovrall_pct_rank_quant_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;ovrall_pct_rank_quant_&quot;) ) , na.rm = T ) , ovrall_pct_rank_det_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;ovrall_pct_rank_det_&quot;) ) , na.rm = T ) , chm_pct_rank_quant_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;chm_pct_rank_quant_&quot;) ) , na.rm = T ) , chm_pct_rank_det_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;chm_pct_rank_det_&quot;) ) , na.rm = T ) ) %&gt;% dplyr::ungroup() %&gt;% # fill na values dplyr::mutate( dplyr::across( .cols = c(ovrall_pct_rank_det_mean, ovrall_pct_rank_quant_mean, chm_pct_rank_det_mean, chm_pct_rank_quant_mean) , .fn = ~ifelse(is.na(.x),0,.x) ) ) %&gt;% # now make quadrant var dplyr::mutate( # groupings for the quadrant plot ovrall_accuracy_grp = dplyr::case_when( ovrall_pct_rank_det_mean&gt;=0.95 &amp; ovrall_pct_rank_quant_mean&gt;=0.95 ~ 1 , ovrall_pct_rank_det_mean&gt;=0.90 &amp; ovrall_pct_rank_quant_mean&gt;=0.90 ~ 2 , ovrall_pct_rank_det_mean&gt;=0.75 &amp; ovrall_pct_rank_quant_mean&gt;=0.75 ~ 3 , ovrall_pct_rank_det_mean&gt;=0.50 &amp; ovrall_pct_rank_quant_mean&gt;=0.50 ~ 4 , ovrall_pct_rank_det_mean&gt;=0.50 &amp; ovrall_pct_rank_quant_mean&lt;0.50 ~ 5 , ovrall_pct_rank_det_mean&lt;0.50 &amp; ovrall_pct_rank_quant_mean&gt;=0.50 ~ 6 , T ~ 7 ) %&gt;% factor( ordered = T , levels = 1:7 , labels = c( &quot;top 5% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.95 &amp; ovrall_pct_rank_f_score&gt;=0.95 ~ 1 , &quot;top 10% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.90 &amp; ovrall_pct_rank_f_score&gt;=0.90 ~ 2 , &quot;top 25% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.75 &amp; ovrall_pct_rank_f_score&gt;=0.75 ~ 3 , &quot;top 50% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.50 &amp; ovrall_pct_rank_f_score&gt;=0.50 ~ 4 , &quot;top 50% quantification&quot; # ovrall_pct_rank_mean&gt;=0.50 &amp; ovrall_pct_rank_f_score&lt;0.50 ~ 5 , &quot;top 50% detection&quot; # ovrall_pct_rank_mean&lt;0.50 &amp; ovrall_pct_rank_f_score&gt;=0.50 ~ 6 , &quot;bottom 50% detection &amp; quantification&quot; ) ) , chm_accuracy_grp = dplyr::case_when( chm_pct_rank_det_mean&gt;=0.95 &amp; chm_pct_rank_quant_mean&gt;=0.95 ~ 1 , chm_pct_rank_det_mean&gt;=0.90 &amp; chm_pct_rank_quant_mean&gt;=0.90 ~ 2 , chm_pct_rank_det_mean&gt;=0.75 &amp; chm_pct_rank_quant_mean&gt;=0.75 ~ 3 , chm_pct_rank_det_mean&gt;=0.50 &amp; chm_pct_rank_quant_mean&gt;=0.50 ~ 4 , chm_pct_rank_det_mean&gt;=0.50 &amp; chm_pct_rank_quant_mean&lt;0.50 ~ 5 , chm_pct_rank_det_mean&lt;0.50 &amp; chm_pct_rank_quant_mean&gt;=0.50 ~ 6 , T ~ 7 ) %&gt;% factor( ordered = T , levels = 1:7 , labels = c( &quot;top 5% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.95 &amp; chm_pct_rank_f_score&gt;=0.95 ~ 1 , &quot;top 10% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.90 &amp; chm_pct_rank_f_score&gt;=0.90 ~ 2 , &quot;top 25% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.75 &amp; chm_pct_rank_f_score&gt;=0.75 ~ 3 , &quot;top 50% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.50 &amp; chm_pct_rank_f_score&gt;=0.50 ~ 4 , &quot;top 50% quantification&quot; # chm_pct_rank_mean&gt;=0.50 &amp; chm_pct_rank_f_score&lt;0.50 ~ 5 , &quot;top 50% detection&quot; # chm_pct_rank_mean&lt;0.50 &amp; chm_pct_rank_f_score&gt;=0.50 ~ 6 , &quot;bottom 50% detection &amp; quantification&quot; ) ) , ) %&gt;% ########## # first. find overall top combinations irrespective of CHM res ########## dplyr::ungroup() %&gt;% dplyr::mutate( ovrall_balanced_pct_rank = dplyr::percent_rank( (ovrall_pct_rank_det_mean+ovrall_pct_rank_quant_mean)/2 ) # equally weight quant and detection , ovrall_lab = forcats::fct_reorder(lab, ovrall_balanced_pct_rank) ) %&gt;% dplyr::arrange(desc(ovrall_balanced_pct_rank),desc(ovrall_pct_rank_det_mean),desc(ovrall_pct_rank_quant_mean)) %&gt;% dplyr::mutate( ovrall_balanced_rank = dplyr::row_number() # is_top_overall = using rows in case not all combos resulted in piles and/or # there are many ties in the data leading to no records with a percent rank &lt;= pct_th_top (e.g. many tied at 98%) , is_top_overall = dplyr::row_number()&lt;=(n_combos_top_overall) # ovrall_balanced_pct_rank&gt;=(1-pct_th_top) ) %&gt;% dplyr::arrange(desc(is_top_overall),desc(recall),desc(ovrall_pct_rank_det_mean),desc(ovrall_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate(is_final_selection = is_top_overall &amp; dplyr::row_number()&lt;=n_th_top) %&gt;% ########## # second. find top combinations by CHM res ########## dplyr::group_by(chm_res_m) %&gt;% dplyr::mutate( chm_balanced_pct_rank = dplyr::percent_rank( (chm_pct_rank_det_mean+chm_pct_rank_quant_mean)/2 ) # equally weight quant and detection , chm_lab = forcats::fct_reorder(lab, chm_balanced_pct_rank) ) %&gt;% dplyr::arrange(chm_res_m,desc(chm_balanced_pct_rank),desc(chm_pct_rank_det_mean),desc(chm_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate( chm_balanced_rank = dplyr::row_number() # is_top_chm = using rows in case not all combos resulted in piles and/or # there are many ties in the data leading to no records with a percent rank &lt;= pct_th_top (e.g. many tied at 98%) , is_top_chm = dplyr::row_number()&lt;=n_combos_top_chm # double it so we look at more than 14?? # chm_balanced_pct_rank&gt;=(1-pct_th_top) ) %&gt;% dplyr::arrange(chm_res_m,desc(is_top_chm),desc(recall),desc(chm_pct_rank_det_mean),desc(chm_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate(is_final_selection_chm = is_top_chm &amp; dplyr::row_number()&lt;=n_th_top_chm) %&gt;% # half it because it&#39;s going to be a lot to show in our facet ggplot ##### clean up dplyr::ungroup() %&gt;% dplyr::select(-c( c(tidyselect::ends_with(&quot;_mape&quot;) &amp; tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_mape&quot;) &amp; tidyselect::starts_with(&quot;chm_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_f_score&quot;) &amp; tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_f_score&quot;) &amp; tidyselect::starts_with(&quot;chm_pct_rank_&quot;)) )) # huh? # param_combos_ranked %&gt;% dplyr::glimpse() # param_combos_ranked %&gt;% dplyr::count(is_final_selection) to determine the combinations that achieved the best balance between both detection and quantification accuracy, we’re selecting the parameter combinations that are in the upper-right of the quadrant plot. That is, the parameter combinations that performed best at both pile detection accuracy and pile form quantification accuracy # plot param_combos_ranked %&gt;% ggplot2::ggplot( mapping=ggplot2::aes(x = ovrall_pct_rank_det_mean, y = ovrall_pct_rank_quant_mean, color = ovrall_accuracy_grp) ) + ggplot2::geom_vline(xintercept = 0.5, color = &quot;gray22&quot;) + ggplot2::geom_hline(yintercept = 0.5, color = &quot;gray22&quot;) + ggplot2::geom_vline(xintercept = 0.75, color = &quot;gray44&quot;) + ggplot2::geom_hline(yintercept = 0.75, color = &quot;gray44&quot;) + ggplot2::geom_vline(xintercept = 0.9, color = &quot;gray66&quot;) + ggplot2::geom_hline(yintercept = 0.9, color = &quot;gray66&quot;) + ggplot2::geom_point() + ggplot2::scale_colour_viridis_d(direction = -1) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::scale_y_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::labs( x = &quot;Percentile F-Score&quot;, y = &quot;Percentile MAPE (mean)&quot; , color = &quot;&quot; , subtitle = &quot;Structural Data Only&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 8) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text = ggplot2::element_text(size = 7) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) 8.5.3.1.1 Top 1.0% let’s check out the parameter settings of the top 1.0% (n=59) from all 5,880 combinations tested. these are “votes” for the parameter setting based on the combinations that achieved the best balance between both detection and quantification accuracy. pal_param &lt;- viridis::cividis(n=6, alpha = 0.9) param_combos_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(tidyselect::contains(&quot;f_score&quot;), max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::count(metric, value) %&gt;% dplyr::group_by(metric) %&gt;% dplyr::mutate( pct=n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\nn=&quot;, scales::comma(n,accuracy=1)) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = factor(value), y=pct, label=lab, fill = metric) ) + ggplot2::geom_col(width = 0.6) + ggplot2::geom_text(color = &quot;black&quot;, size = 2.5, vjust = -0.2) + ggplot2::facet_wrap(facets = dplyr::vars(metric), ncol=2, scales = &quot;free_x&quot;) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::scale_fill_manual(values = pal_param[1:5]) + ggplot2::labs( x = &quot;parameter setting&quot;, y = &quot;&quot; , fill = &quot;&quot; , subtitle = paste0( &quot;Structural Data Only&quot; , &quot;\\nparameter settings of top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_overall, accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations tested\\nbased on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 6) , axis.text.x = ggplot2::element_text(size = 8) , plot.subtitle = ggplot2::element_text(size = 8) ) these results indicate that the finer resolution CHM data is preferable for detecting and quantifying slash piles from aerial point cloud data using our methodology. Given our study site, there is a single max_ht_m setting that best fits the data collected at this site. The remaining structural parameters tested (max_area_m2, convexity_pct, circle_fit_iou_pct) can yield good results over a broad setting range but it is important to remember that the influence of these settings is dependent on the value of the other parameters. That is, the effect of one parameter (e.g., convexity_pct) on the accuracy metrics changes depending on the value of another parameter (e.g., circle_fit_iou_pct). what is the expected detection accuracy of the top 1.0% (n=59) combinations tested? plt_detection_dist( df = param_combos_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile detection metrics for top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_overall, accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations tested\\nbased on both detection and quantification accuracy&quot; ) ) These results are promising for our detection methodology when given structural data only (i.e. CHM data but no spectral data). Using the structural data alone, the best performing parameterization settings of those tested achieved an F-score (balanced detection accuracy) of approximately 77.1% with a detection rate (recall) of approximately 71.1% what is the expected quantification accuracy of the top 1.0% (n=59) combinations tested? # plot it plt_form_quantification_dist( df = param_combos_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_overall, accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations tested\\nbased on both detection and quantification accuracy&quot; ) ) These results are just as promising as the detection accuracy results and indicate that when given structural data only (i.e. CHM data but no spectral data) the methodology can accurately quantify slash pile height and diameter with sub-meter (i.e. &lt; 1m) accuracy when compared with field-measured values. Over the range of parameter settings tested, the methodology also performs well at determining the pile footprint when compared with the image-annotated perimeters as indicated by the error in pile area. 8.5.3.1.2 Top 12 settings Let’s focus on the top 12 parameter settings tested to highlight the pile detection and form quantification accuracies achieved by these settings # pal_temp %&gt;% scales::show_col() # filter and reshape param_combos_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m , ovrall_lab # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% factor( ordered = T , levels = c( &quot;detection&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Detection&quot; , &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) , value_lab = dplyr::case_when( eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=0.1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% # make var for color dplyr::group_by(pile_metric, eval_metric) %&gt;% dplyr::mutate( # for ME, color by abs...for f-score,recall,precision color by -value so that higher means better... # ...since higher means worse for quantification accuracy metrics value_dir = dplyr::case_when( eval_metric %in% c(&quot;ME&quot;) ~ abs(value) , eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;) ~ -value , T ~ value ) , value_z = (value_dir-mean(value_dir,na.rm=T))/sd(value_dir,na.rm=T) # this is the key to the different colors within facets ) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(!eval_metric %in% c(&quot;RRMSE&quot;)) %&gt;% # View() ggplot2::ggplot(mapping = ggplot2::aes(x = eval_metric, y = ovrall_lab)) + ggplot2::geom_tile( mapping = ggplot2::aes(fill = pile_metric, alpha = -value_z) , color = &quot;gray&quot; ) + ggplot2::geom_text( mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) , color = &quot;white&quot; ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), scales = &quot;free_x&quot;) + ggplot2::scale_x_discrete(position = &quot;top&quot;) + ggplot2::scale_fill_manual(values = c(&quot;gray33&quot;, harrypotter::hp(n=3,option = &quot;hermionegranger&quot;) )) + ggplot2::scale_alpha_binned(range = c(0.55, 1)) + # this is the key to the different colors within facets ggplot2::theme_light() + ggplot2::labs( x = &quot;&quot; , y = &quot;max_ht_m : max_area_m2 : convexity_pct : circle_fit_iou_pct : chm_res_m&quot; , subtitle = paste0( &quot;Structural Data Only&quot; , &quot;\\npile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) , caption = &quot;*darker colors indicate relatively higher accuracy values&quot; ) + ggplot2::theme( legend.position = &quot;none&quot; , panel.grid = ggplot2::element_blank() , strip.placement = &quot;outside&quot; , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.title.x = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) this plot allows for a simultaneous comparison of all metrics for pile detection and pile form quantification. it includes only the parameter combinations that achieved the best balanced accuracy, helping users identify the optimal settings by evaluating the trade-offs between detection and form quantification. let’s table this param_combos_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% # first select to arrange eval_metric dplyr::select( ovrall_lab , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( ovrall_lab , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m # detection , f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% # names() dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) %&gt;% dplyr::mutate(blank= &quot; &quot; ) %&gt;% dplyr::relocate(blank, .before = f_score) %&gt;% dplyr::arrange(desc(ovrall_lab)) %&gt;% kableExtra::kbl( caption = paste0( &quot;Structural Data Only&quot; , &quot;&lt;br&gt;pile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;&lt;br&gt;based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;&quot; ,&quot;max_ht_m&quot;,&quot;max_area_m2&quot;,&quot;convexity_pct&quot;,&quot;circle_fit_iou_pct&quot;,&quot;chm_res_m&quot; , &quot; &quot; , &quot;F-score&quot;, &quot;Recall&quot;, &quot;Precision&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 3) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=7 , &quot;Detection&quot; = 3 , &quot;Area&quot; = 3 , &quot;Height&quot; = 3 , &quot;Diameter&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(7,19,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 7:19 , extra_css = &quot;font-size: 10px;&quot; , include_thead = T ) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) Table 8.1: Structural Data Onlypile detection and form quantification accuracy metrics for the top parameter settings tested (n=12) based on both detection and quantification accuracy Detection Area Height Diameter max_ht_m max_area_m2 convexity_pct circle_fit_iou_pct chm_res_m F-score Recall Precision ME RMSE MAPE ME RMSE MAPE ME RMSE MAPE 2:10:0.8:0.05:0.1 2 10 0.80 0.05 0.1 79% 78% 80% -0.50 1.0 11% -0.20 0.3 13% 0.17 0.4 10% 2:20:0.8:0.05:0.1 2 20 0.80 0.05 0.1 81% 82% 80% -0.60 1.7 11% -0.24 0.4 13% 0.18 0.5 11% 2:60:0.8:0.05:0.1 2 60 0.80 0.05 0.1 81% 83% 80% -0.64 1.7 11% -0.27 0.5 14% 0.18 0.5 11% 2:50:0.8:0.05:0.1 2 50 0.80 0.05 0.1 81% 83% 80% -0.64 1.7 11% -0.27 0.5 14% 0.18 0.5 11% 2:40:0.8:0.05:0.1 2 40 0.80 0.05 0.1 81% 83% 80% -0.64 1.7 11% -0.27 0.5 14% 0.18 0.5 11% 2:30:0.8:0.05:0.1 2 30 0.80 0.05 0.1 81% 83% 80% -0.64 1.7 11% -0.27 0.5 14% 0.18 0.5 11% 2:20:0.8:0.2:0.1 2 20 0.80 0.20 0.1 80% 79% 80% -0.61 1.7 11% -0.25 0.5 14% 0.18 0.5 11% 2:60:0.8:0.2:0.1 2 60 0.80 0.20 0.1 80% 81% 80% -0.65 1.7 11% -0.27 0.5 14% 0.19 0.5 11% 2:50:0.8:0.2:0.1 2 50 0.80 0.20 0.1 80% 81% 80% -0.65 1.7 11% -0.27 0.5 14% 0.19 0.5 11% 2:40:0.8:0.2:0.1 2 40 0.80 0.20 0.1 80% 81% 80% -0.65 1.7 11% -0.27 0.5 14% 0.19 0.5 11% 2:30:0.8:0.2:0.1 2 30 0.80 0.20 0.1 80% 81% 80% -0.65 1.7 11% -0.27 0.5 14% 0.19 0.5 11% 2:30:0.65:0.5:0.1 2 30 0.65 0.50 0.1 75% 78% 72% -0.64 1.8 11% -0.25 0.4 14% 0.19 0.5 11% what is the expected detection accuracy of the top 12 settings? plt_detection_dist( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile detection metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected quantification accuracy of the top 12 settings? # plot it plt_form_quantification_dist( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) finally, here are the combinations selected compared against all 5,880 combinations tested. param_combos_ranked %&gt;% dplyr::select( rn,max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct , is_final_selection , f_score, precision, recall # quantification accuracy , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::ends_with(&quot;_mape&quot;) # ,precision,recall ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter|precision|recall)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; , &quot;recall&quot; , &quot;precision&quot; ) , labels = c( &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) , color_metric = ifelse(is_final_selection, pile_metric, NA) %&gt;% factor() ) %&gt;% dplyr::arrange(is_final_selection) %&gt;% # plot ggplot2::ggplot(mapping = ggplot2::aes(x = f_score, y = value, color = color_metric)) + ggplot2::geom_point() + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric)) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;, na.value = &quot;gray88&quot;) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::scale_y_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,NA) ) + ggplot2::labs(x = &quot;F-Score&quot;, y = &quot;MAPE&quot;, caption = &quot;*records in gray not selected&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) 8.5.3.2 by CHM resolution To select the best-performing parameter combinations of those tested, we will prioritize those that balance detection and quantification accuracy. From this group, we will then identify the settings that achieve the highest pile detection rates (recall). These recommendations are for users who are working with a CHM with a resolution in the range of those tested for this analysis or can aggregate (i.e. make more coarse) a CHM to a resolution tested for the purpose of either improving processing performance or enhancing pile detection and/or quantification accuracy based on the results shown here we already created this data above (param_combos_ranked) using the F-Score and the average rank of the MAPE metrics across all form measurements (i.e. height, diameter, area) to determine the best overall list by CHM resolution 8.5.3.2.1 Top 2.0% let’s check out the parameter settings of the top 2.0% (n=23) from all 1,176 combinations tested by CHM resolution. these are “votes” for the parameter setting based on the combinations that achieved the best balance between both detection and quantification accuracy. param_combos_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(tidyselect::contains(&quot;f_score&quot;), max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,chm_res_m_desc) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::count(chm_res_m,chm_res_m_desc, metric, value) %&gt;% dplyr::group_by(chm_res_m,chm_res_m_desc, metric) %&gt;% dplyr::mutate( pct=n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1)) #, &quot;\\nn=&quot;, scales::comma(n,accuracy=1)) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = factor(value), y=pct, label=lab, fill = metric) ) + ggplot2::geom_col(width = 0.6) + ggplot2::geom_text(color = &quot;black&quot;, size = 2.2, vjust = -0.2) + ggplot2::facet_grid(cols = dplyr::vars(metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free_x&quot;) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::scale_fill_manual(values = pal_param[1:4]) + ggplot2::labs( x = &quot;parameter setting&quot;, y = &quot;&quot; , fill = &quot;&quot; , subtitle = paste0( &quot;Structural Data Only&quot; , &quot;\\nparameter settings of top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_chm , accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 6) , axis.text.x = ggplot2::element_text(size = 8) , plot.subtitle = ggplot2::element_text(size = 8) ) what is the expected detection accuracy of the top 2.0% (n=23) combinations tested by CHM resolution? plt_detection_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile detection metrics for top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected MAPE of the top 2.0% (n=23) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mape&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected Mean Error (ME) of the top 2.0% (n=23) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mean&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected RMSE of the top 2.0% (n=23) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;rmse&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) 8.5.3.2.2 Top 6 settings Let’s focus on the top 6 parameter settings tested by CHM resolution to highlight the pile detection and form quantification accuracies achieved by these settings # pal_temp %&gt;% scales::show_col() # filter and reshape param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,chm_res_m_desc , chm_lab # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% factor( ordered = T , levels = c( &quot;detection&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Detection&quot; , &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) , value_lab = dplyr::case_when( eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=0.1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% # make var for color dplyr::group_by(chm_res_m,chm_res_m_desc, pile_metric, eval_metric) %&gt;% dplyr::mutate( # for ME, color by abs...for f-score,recall,precision color by -value so that higher means better... # ...since higher means worse for quantification accuracy metrics value_dir = dplyr::case_when( eval_metric %in% c(&quot;ME&quot;) ~ abs(value) , eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;) ~ -value , T ~ value ) , value_z = (value_dir-mean(value_dir,na.rm=T))/sd(value_dir,na.rm=T) # this is the key to the different colors within facets ) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(!eval_metric %in% c(&quot;RRMSE&quot;)) %&gt;% # View() ggplot2::ggplot(mapping = ggplot2::aes(x = eval_metric, y = chm_lab)) + ggplot2::geom_tile( mapping = ggplot2::aes(fill = pile_metric, alpha = -value_z) , color = &quot;gray&quot; ) + ggplot2::geom_text( mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) , color = &quot;white&quot; , size = 3 ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free&quot;) + ggplot2::scale_x_discrete(position = &quot;top&quot;) + ggplot2::scale_fill_manual(values = c(&quot;gray33&quot;, harrypotter::hp(n=3,option = &quot;hermionegranger&quot;) )) + ggplot2::scale_alpha_binned(range = c(0.55, 1)) + # this is the key to the different colors within facets ggplot2::theme_light() + ggplot2::labs( x = &quot;&quot; , y = &quot;max_ht_m : max_area_m2 : convexity_pct : circle_fit_iou_pct : chm_res_m&quot; , subtitle = paste0( &quot;Structural Data Only&quot; , &quot;\\npile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) , caption = &quot;*darker colors indicate relatively higher accuracy values&quot; ) + ggplot2::theme( legend.position = &quot;none&quot; , panel.grid = ggplot2::element_blank() , strip.placement = &quot;outside&quot; , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 7) , axis.title.x = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) this plot allows for a simultaneous comparison of all metrics for pile detection and pile form quantification. it includes only the parameter combinations of those tested that achieved the best balanced accuracy, helping users identify the optimal settings by evaluating the trade-offs between detection and form quantification. let’s table this param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% # first select to arrange eval_metric dplyr::select( chm_lab, chm_res_m_desc , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( chm_lab, chm_res_m_desc , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m # detection , f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% # names() dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) %&gt;% dplyr::mutate(blank= &quot; &quot; ) %&gt;% dplyr::relocate(blank, .before = f_score) %&gt;% dplyr::arrange(chm_res_m, desc(chm_lab)) %&gt;% dplyr::select(-chm_res_m) %&gt;% dplyr::relocate(chm_res_m_desc) %&gt;% kableExtra::kbl( caption = paste0( &quot;Structural Data Only&quot; , &quot;&lt;br&gt;pile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution &quot; , &quot;&lt;br&gt;based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;.&quot;, &quot;&quot; ,&quot;max_ht_m&quot;,&quot;max_area_m2&quot;,&quot;convexity_pct&quot;,&quot;circle_fit_iou_pct&quot; , &quot; &quot; , &quot;F-score&quot;, &quot;Recall&quot;, &quot;Precision&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 3) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=7 , &quot;Detection&quot; = 3 # , &quot;Volume&quot; = 3 , &quot;Area&quot; = 3 , &quot;Height&quot; = 3 , &quot;Diameter&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(7,19,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 7:19 , extra_css = &quot;font-size: 10px;&quot; , include_thead = T ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) Table 8.2: Structural Data Onlypile detection and form quantification accuracy metrics for the top parameter settings tested (n=6) by CHM resolution based on both detection and quantification accuracy Detection Area Height Diameter . max_ht_m max_area_m2 convexity_pct circle_fit_iou_pct F-score Recall Precision ME RMSE MAPE ME RMSE MAPE ME RMSE MAPE 0.1m CHM 2:10:0.8:0.05:0.1 2 10 0.80 0.05 79% 78% 80% -0.50 1.0 11% -0.20 0.3 13% 0.17 0.4 10% 3:10:0.8:0.35:0.1 3 10 0.80 0.35 77% 79% 75% -0.46 0.9 11% -0.02 0.4 17% 0.17 0.4 10% 5:60:0.8:0.65:0.1 5 60 0.80 0.65 76% 90% 66% -0.80 2.1 10% -0.10 0.6 18% 0.21 0.5 10% 5:50:0.8:0.65:0.1 5 50 0.80 0.65 76% 90% 66% -0.80 2.1 10% -0.10 0.6 18% 0.21 0.5 10% 5:40:0.8:0.65:0.1 5 40 0.80 0.65 75% 88% 66% -0.63 1.7 10% -0.05 0.6 18% 0.21 0.5 10% 3:10:0.8:0.5:0.1 3 10 0.80 0.50 77% 77% 78% -0.46 0.9 11% -0.02 0.4 17% 0.17 0.4 10% 0.2m CHM 2:10:0.8:0.05:0.2 2 10 0.80 0.05 70% 74% 66% 0.53 1.0 12% -0.22 0.3 13% 0.43 0.6 16% 2:10:0.8:0.2:0.2 2 10 0.80 0.20 68% 69% 67% 0.52 1.0 12% -0.23 0.3 14% 0.42 0.6 16% 3:10:0.8:0.65:0.2 3 10 0.80 0.65 73% 68% 80% 0.62 1.0 13% 0.00 0.4 17% 0.46 0.6 17% 3:10:0.35:0.65:0.2 3 10 0.35 0.65 73% 68% 79% 0.62 1.0 13% 0.00 0.4 17% 0.46 0.6 17% 3:10:0.2:0.65:0.2 3 10 0.20 0.65 73% 68% 79% 0.62 1.0 13% 0.00 0.4 17% 0.46 0.6 17% 3:10:0.05:0.65:0.2 3 10 0.05 0.65 73% 68% 79% 0.62 1.0 13% 0.00 0.4 17% 0.46 0.6 17% 0.3m CHM 3:10:0.8:0.65:0.3 3 10 0.80 0.65 65% 67% 63% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 3:10:0.65:0.65:0.3 3 10 0.65 0.65 65% 67% 62% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 3:10:0.5:0.65:0.3 3 10 0.50 0.65 65% 67% 62% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 3:10:0.35:0.65:0.3 3 10 0.35 0.65 65% 67% 62% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 3:10:0.2:0.65:0.3 3 10 0.20 0.65 65% 67% 62% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 3:10:0.05:0.65:0.3 3 10 0.05 0.65 65% 67% 62% 1.40 1.7 23% -0.02 0.4 16% 0.64 0.7 23% 0.4m CHM 2:20:0.8:0.05:0.4 2 20 0.80 0.05 55% 79% 42% 2.43 3.1 37% -0.24 0.4 14% 1.02 1.1 34% 2:60:0.8:0.05:0.4 2 60 0.80 0.05 56% 81% 42% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:50:0.8:0.05:0.4 2 50 0.80 0.05 56% 81% 42% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:40:0.8:0.05:0.4 2 40 0.80 0.05 56% 81% 42% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:30:0.8:0.05:0.4 2 30 0.80 0.05 56% 81% 42% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:30:0.8:0.2:0.4 2 30 0.80 0.20 54% 75% 42% 2.50 3.2 37% -0.31 0.5 15% 1.01 1.1 34% 0.5m CHM 2:60:0.8:0.65:0.5 2 60 0.80 0.65 42% 34% 54% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% 2:50:0.8:0.65:0.5 2 50 0.80 0.65 42% 34% 54% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% 2:40:0.8:0.65:0.5 2 40 0.80 0.65 42% 34% 54% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% 2:30:0.8:0.65:0.5 2 30 0.80 0.65 42% 34% 54% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% 2:30:0.2:0.65:0.5 2 30 0.20 0.65 41% 34% 53% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% 2:30:0.05:0.65:0.5 2 30 0.05 0.65 41% 34% 53% 3.33 4.0 49% -0.34 0.6 17% 1.20 1.3 39% what is the expected detection accuracy of the top 6 settings by CHM resolution? plt_detection_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile detection metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected MAPE of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mape&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected Mean Error (ME) of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mean&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected RMSE of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;rmse&quot; , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) 8.6 Data Fusion: Sensitivity Testing let’s look at the sensitivity testing results for the data fusion approach approach that uses both a CHM generated from aerial point cloud data (for structural information) and RGB imagery we tested a total of 7,056 combinations per CHM resolution and an overall total of 35,280 combinations 8.6.1 Main Effects: pile detection what is the detection accuracy across all parameter combinations tested for each CHM resolution? # plot it plt_detection_dist2( df = param_combos_spectral_gt_agg , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile detection accuracy metrics for all&quot; , &quot; (n=&quot; , scales::comma(n_combos_tested_spectral_chm, accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution&quot; ) , show_rug = F ) collapsing across all other parameters, what is the main effect of each individual parameter, including the spectral_weight parameter from the data fusion approach, or CHM resolution? param_combos_spectral_gt_agg %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight) , names_to = &quot;param&quot; , values_to = &quot;param_value&quot; ) %&gt;% dplyr::group_by(param, param_value, metric) %&gt;% dplyr::summarise( median = median(value,na.rm=T) , q25 = stats::quantile(value,na.rm=T,probs = 0.25) , q75 = stats::quantile(value,na.rm=T,probs = 0.75) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( param = dplyr::case_when( param == &quot;spectral_weight&quot; ~ 1 , param == &quot;chm_res_m&quot; ~ 2 , param == &quot;max_ht_m&quot; ~ 3 , param == &quot;min_area_m2&quot; ~ 4 , param == &quot;max_area_m2&quot; ~ 5 , param == &quot;convexity_pct&quot; ~ 6 , param == &quot;circle_fit_iou_pct&quot; ~ 7 ) %&gt;% factor( ordered = T , levels = 1:7 , labels = c( &quot;spectral_weight&quot; , &quot;CHM resolution (m)&quot; , &quot;max_ht_m&quot; , &quot;min_area_m2&quot; , &quot;max_area_m2&quot; , &quot;convexity_pct&quot; , &quot;circle_fit_iou_pct&quot; ) ) , metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 ) %&gt;% factor( ordered = T , levels = 1:3 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(y = median, x = param_value, color = metric, fill = metric, group = metric, shape = metric) ) + ggplot2::geom_ribbon( mapping = ggplot2::aes(ymin = q25, ymax = q75) , alpha = 0.2, color = NA ) + ggplot2::geom_line(lwd = 1.5, alpha = 0.8) + ggplot2::geom_point(size = 2) + ggplot2::facet_wrap(facets = dplyr::vars(param), scales = &quot;free_x&quot;) + # ggplot2::scale_color_viridis_d(begin = 0.2, end = 0.8) + ggplot2::scale_fill_manual(values = rev(pal_eval_metric)) + ggplot2::scale_color_manual(values = rev(pal_eval_metric)) + ggplot2::scale_y_continuous(limits = c(0,1), labels = scales::percent, breaks = scales::breaks_extended(10)) + ggplot2::labs(x = &quot;&quot;, y = &quot;median value&quot;, color = &quot;&quot;, fill = &quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) based on these main effect aggregated results, the influence of the parameters specific to the structural detection of slash piles remained the same as when tested without the spectral data. with respect to the spectral_weight parameter included in the data fusion approach: increasing the spectral_weight (where “5” requires all spectral index thresholds to be met) had minimal impact on metrics until a value of “3”, at which point F-score and precision both saw slight improvements. at a spectral_weight of “4”, the F-score significantly improved due to a substantial increase in precision. setting spectral_weight to “5” resulted in a slight drop in recall (detection rate) and a proportionally inverse increase in precision, leading to an additional increase in F-score. 8.6.2 Main Effects: form quantification let’s check out the the ability of the method to properly extract the form of the piles by looking at the quantification accuracy metrics where: Mean Error (ME) represents the direction of bias (over or under-prediction) in the original units RMSE represents the typical magnitude of error in the original units, with a stronger penalty for large errors MAPE represents the typical magnitude of error as a percentage, allowing for scale-independent comparisons we expect that the spectral data does not alter the quantification of slash pile form. this is because spectral information is used solely to filter candidate piles, meaning it neither reshapes existing ones nor introduces new detections. let’s average across all other factors to look at the main effect by parameter for the MAPE metrics quantifying the pile form accuracy param_combos_spectral_gt_agg %&gt;% dplyr::select( spectral_weight , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c(tidyselect::ends_with(&quot;_mape&quot;)) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% tidyr::pivot_longer( cols = c(spectral_weight) , names_to = &quot;param&quot; , values_to = &quot;param_value&quot; ) %&gt;% dplyr::group_by(param, param_value, metric) %&gt;% dplyr::summarise( median = median(value,na.rm=T) , q25 = stats::quantile(value,na.rm=T,probs = 0.25) , q75 = stats::quantile(value,na.rm=T,probs = 0.75) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( metric = dplyr::case_when( metric == &quot;f_score&quot; ~ 1 , metric == &quot;recall&quot; ~ 2 , metric == &quot;precision&quot; ~ 3 # rmse , metric == &quot;pct_diff_volume_field_mape&quot; ~ 4 , metric == &quot;pct_diff_paraboloid_volume_field_mape&quot; ~ 5 , metric == &quot;pct_diff_area_m2_mape&quot; ~ 6 , metric == &quot;pct_diff_height_m_mape&quot; ~ 7 , metric == &quot;pct_diff_diameter_m_mape&quot; ~ 8 ) %&gt;% factor( ordered = T , levels = 1:8 , labels = c( &quot;F-score&quot; , &quot;Recall&quot; , &quot;Precision&quot; , &quot;MAPE: Volume irregular (%)&quot; , &quot;MAPE: Volume paraboloid (%)&quot; , &quot;MAPE: Area (%)&quot; , &quot;MAPE: Height (%)&quot; , &quot;MAPE: Diameter (%)&quot; ) ) # , param_value = factor(x = param_value, labels = levels(param_combos_spectral_gt$spectral_weight_desc)) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(y = median, x = param_value, color = metric, fill = metric, group = metric, shape = metric) ) + # ggplot2::geom_ribbon( # mapping = ggplot2::aes(ymin = q25, ymax = q75) # , alpha = 0.2, color = NA # ) + ggplot2::geom_line(lwd = 1.5, alpha = 0.8) + ggplot2::geom_point(size = 2) + ggplot2::facet_wrap(facets = dplyr::vars(param), scales = &quot;free_x&quot;) + harrypotter::scale_fill_hp_d(option = &quot;hermionegranger&quot;) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;) + ggplot2::scale_shape_manual(values = c(15,16,17,18,0)) + ggplot2::scale_y_continuous(limits = c(0,1), labels = scales::percent, breaks = scales::breaks_extended(10)) + ggplot2::labs(x = &quot;&quot;, y = &quot;median value&quot;, color = &quot;&quot;, fill = &quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) this is exactly what we expected to happen 8.6.3 Top settings Of those tested, let’s identify the best-performing parameter combinations that not only balance detection and quantification accuracy but also achieve the highest recall rates. we’ll select these by choosing any combination whose recall rate is at least one standard deviation above the average for this top group. if no combinations meet this criterion, we will instead select the top 10 combinations based on their recall rates. 8.6.3.1 Overall (across CHM resolution) To select the best-performing parameter combinations of those tested, we will prioritize those that balance detection and quantification accuracy. From this group, we will then identify the settings that achieve the highest pile detection rates (recall). We emphasize that these recommendations are for users who can generate a CHM from the original point cloud. This is critical because creating a new CHM at the desired resolution is a fundamentally different process than simply disaggregating an existing, coarser raster. we’ll use the F-Score and the average rank of the MAPE metrics across all form measurements (i.e. height, diameter, area, volume) to determine the best overall list # param_combos_spectral_gt_agg %&gt;% nrow() # param_combos_spectral_gt_agg %&gt;% # dplyr::filter( # dplyr::if_any( # tidyselect::ends_with(&quot;_mape&quot;) # , is.na # ) # ) %&gt;% # View() param_combos_spectral_ranked &lt;- param_combos_spectral_gt_agg %&gt;% ########## # first. find overall top combinations irrespective of CHM res ########## dplyr::ungroup() %&gt;% dplyr::mutate( # label combining params lab = stringr::str_c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight, sep = &quot;:&quot;) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~dplyr::percent_rank(-.x) , .names = &quot;ovrall_pct_rank_quant_{.col}&quot; ) , dplyr::across( .cols = c(f_score) # .cols = c(f_score,recall) , .fn = ~dplyr::percent_rank(.x) , .names = &quot;ovrall_pct_rank_det_{.col}&quot; ) ) %&gt;% ########## # second. find top combinations by CHM res ########## dplyr::group_by(chm_res_m) %&gt;% dplyr::mutate( dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mape&quot;) &amp; !tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , .fn = ~dplyr::percent_rank(-.x) , .names = &quot;chm_pct_rank_quant_{.col}&quot; ) , dplyr::across( .cols = c(f_score) # .cols = c(f_score,recall) , .fn = ~dplyr::percent_rank(.x) , .names = &quot;chm_pct_rank_det_{.col}&quot; ) ) %&gt;% # now get the max of these pct ranks by row dplyr::rowwise() %&gt;% dplyr::mutate( ovrall_pct_rank_quant_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;ovrall_pct_rank_quant_&quot;) ) , na.rm = T ) , ovrall_pct_rank_det_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;ovrall_pct_rank_det_&quot;) ) , na.rm = T ) , chm_pct_rank_quant_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;chm_pct_rank_quant_&quot;) ) , na.rm = T ) , chm_pct_rank_det_mean = mean( dplyr::c_across( tidyselect::starts_with(&quot;chm_pct_rank_det_&quot;) ) , na.rm = T ) ) %&gt;% dplyr::ungroup() %&gt;% # fill na values dplyr::mutate( dplyr::across( .cols = c(ovrall_pct_rank_det_mean, ovrall_pct_rank_quant_mean, chm_pct_rank_det_mean, chm_pct_rank_quant_mean) , .fn = ~ifelse(is.na(.x),0,.x) ) ) %&gt;% # dplyr::select(ovrall_pct_rank_det_mean, ovrall_pct_rank_quant_mean) %&gt;% summary() # now make quadrant var dplyr::mutate( # groupings for the quadrant plot ovrall_accuracy_grp = dplyr::case_when( ovrall_pct_rank_det_mean&gt;=0.95 &amp; ovrall_pct_rank_quant_mean&gt;=0.95 ~ 1 , ovrall_pct_rank_det_mean&gt;=0.90 &amp; ovrall_pct_rank_quant_mean&gt;=0.90 ~ 2 , ovrall_pct_rank_det_mean&gt;=0.75 &amp; ovrall_pct_rank_quant_mean&gt;=0.75 ~ 3 , ovrall_pct_rank_det_mean&gt;=0.50 &amp; ovrall_pct_rank_quant_mean&gt;=0.50 ~ 4 , ovrall_pct_rank_det_mean&gt;=0.50 &amp; ovrall_pct_rank_quant_mean&lt;0.50 ~ 5 , ovrall_pct_rank_det_mean&lt;0.50 &amp; ovrall_pct_rank_quant_mean&gt;=0.50 ~ 6 , T ~ 7 ) %&gt;% factor( ordered = T , levels = 1:7 , labels = c( &quot;top 5% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.95 &amp; ovrall_pct_rank_f_score&gt;=0.95 ~ 1 , &quot;top 10% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.90 &amp; ovrall_pct_rank_f_score&gt;=0.90 ~ 2 , &quot;top 25% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.75 &amp; ovrall_pct_rank_f_score&gt;=0.75 ~ 3 , &quot;top 50% detection &amp; quantification&quot; # ovrall_pct_rank_mean&gt;=0.50 &amp; ovrall_pct_rank_f_score&gt;=0.50 ~ 4 , &quot;top 50% quantification&quot; # ovrall_pct_rank_mean&gt;=0.50 &amp; ovrall_pct_rank_f_score&lt;0.50 ~ 5 , &quot;top 50% detection&quot; # ovrall_pct_rank_mean&lt;0.50 &amp; ovrall_pct_rank_f_score&gt;=0.50 ~ 6 , &quot;bottom 50% detection &amp; quantification&quot; ) ) , chm_accuracy_grp = dplyr::case_when( chm_pct_rank_det_mean&gt;=0.95 &amp; chm_pct_rank_quant_mean&gt;=0.95 ~ 1 , chm_pct_rank_det_mean&gt;=0.90 &amp; chm_pct_rank_quant_mean&gt;=0.90 ~ 2 , chm_pct_rank_det_mean&gt;=0.75 &amp; chm_pct_rank_quant_mean&gt;=0.75 ~ 3 , chm_pct_rank_det_mean&gt;=0.50 &amp; chm_pct_rank_quant_mean&gt;=0.50 ~ 4 , chm_pct_rank_det_mean&gt;=0.50 &amp; chm_pct_rank_quant_mean&lt;0.50 ~ 5 , chm_pct_rank_det_mean&lt;0.50 &amp; chm_pct_rank_quant_mean&gt;=0.50 ~ 6 , T ~ 7 ) %&gt;% factor( ordered = T , levels = 1:7 , labels = c( &quot;top 5% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.95 &amp; chm_pct_rank_f_score&gt;=0.95 ~ 1 , &quot;top 10% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.90 &amp; chm_pct_rank_f_score&gt;=0.90 ~ 2 , &quot;top 25% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.75 &amp; chm_pct_rank_f_score&gt;=0.75 ~ 3 , &quot;top 50% detection &amp; quantification&quot; # chm_pct_rank_mean&gt;=0.50 &amp; chm_pct_rank_f_score&gt;=0.50 ~ 4 , &quot;top 50% quantification&quot; # chm_pct_rank_mean&gt;=0.50 &amp; chm_pct_rank_f_score&lt;0.50 ~ 5 , &quot;top 50% detection&quot; # chm_pct_rank_mean&lt;0.50 &amp; chm_pct_rank_f_score&gt;=0.50 ~ 6 , &quot;bottom 50% detection &amp; quantification&quot; ) ) , ) %&gt;% ########## # first. find overall top combinations irrespective of CHM res ########## dplyr::ungroup() %&gt;% dplyr::mutate( ovrall_balanced_pct_rank = dplyr::percent_rank( (ovrall_pct_rank_det_mean+ovrall_pct_rank_quant_mean)/2 ) # equally weight quant and detection , ovrall_lab = forcats::fct_reorder(lab, ovrall_balanced_pct_rank) ) %&gt;% dplyr::arrange(desc(ovrall_balanced_pct_rank),desc(ovrall_pct_rank_det_mean),desc(ovrall_pct_rank_quant_mean)) %&gt;% dplyr::mutate( ovrall_balanced_rank = dplyr::row_number() # is_top_overall = using rows in case not all combos resulted in piles and/or # there are many ties in the data leading to no records with a percent rank &lt;= pct_th_top (e.g. many tied at 98%) , is_top_overall = dplyr::row_number()&lt;=(n_combos_tested_spectral*pct_th_top) # ovrall_balanced_pct_rank&gt;=(1-pct_th_top) ) %&gt;% dplyr::arrange(desc(is_top_overall),desc(recall),desc(ovrall_pct_rank_det_mean),desc(ovrall_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate(is_final_selection = is_top_overall &amp; dplyr::row_number()&lt;=n_th_top) %&gt;% ########## # second. find top combinations by CHM res ########## dplyr::group_by(chm_res_m) %&gt;% dplyr::mutate( chm_balanced_pct_rank = dplyr::percent_rank( (chm_pct_rank_det_mean+chm_pct_rank_quant_mean)/2 ) # equally weight quant and detection , chm_lab = forcats::fct_reorder(lab, chm_balanced_pct_rank) ) %&gt;% dplyr::arrange(chm_res_m,desc(chm_balanced_pct_rank),desc(chm_pct_rank_det_mean),desc(chm_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate( chm_balanced_rank = dplyr::row_number() # is_top_chm = using rows in case not all combos resulted in piles and/or # there are many ties in the data leading to no records with a percent rank &lt;= pct_th_top (e.g. many tied at 98%) , is_top_chm = dplyr::row_number()&lt;=n_combos_top_spectral_chm # double it so we look at more than 14?? # chm_balanced_pct_rank&gt;=(1-pct_th_top) ) %&gt;% dplyr::arrange(chm_res_m,desc(is_top_chm),desc(recall),desc(chm_pct_rank_det_mean),desc(chm_pct_rank_quant_mean),ovrall_balanced_rank) %&gt;% dplyr::mutate(is_final_selection_chm = is_top_chm &amp; dplyr::row_number()&lt;=n_th_top_chm) %&gt;% # half it because it&#39;s going to be a lot to show in our facet ggplot ##### clean up dplyr::ungroup() %&gt;% dplyr::select(-c( c(tidyselect::ends_with(&quot;_mape&quot;) &amp; tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_mape&quot;) &amp; tidyselect::starts_with(&quot;chm_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_f_score&quot;) &amp; tidyselect::starts_with(&quot;ovrall_pct_rank_&quot;)) , c(tidyselect::ends_with(&quot;_f_score&quot;) &amp; tidyselect::starts_with(&quot;chm_pct_rank_&quot;)) )) # huh? # param_combos_spectral_ranked %&gt;% dplyr::glimpse() # param_combos_spectral_ranked %&gt;% dplyr::count(is_final_selection) to determine the combinations of those tested that achieved the best balance between both detection and quantification accuracy, we’re selecting the parameter combinations that are in the upper-right of the quadrant plot. That is, the parameter combinations that performed best at both pile detection accuracy and pile form quantification accuracy # plot param_combos_spectral_ranked %&gt;% dplyr::slice_sample(prop = (1/3)) %&gt;% ggplot2::ggplot( mapping=ggplot2::aes(x = ovrall_pct_rank_det_mean, y = ovrall_pct_rank_quant_mean, color = ovrall_accuracy_grp) ) + ggplot2::geom_vline(xintercept = 0.5, color = &quot;gray22&quot;) + ggplot2::geom_hline(yintercept = 0.5, color = &quot;gray22&quot;) + ggplot2::geom_vline(xintercept = 0.75, color = &quot;gray44&quot;) + ggplot2::geom_hline(yintercept = 0.75, color = &quot;gray44&quot;) + ggplot2::geom_vline(xintercept = 0.9, color = &quot;gray66&quot;) + ggplot2::geom_hline(yintercept = 0.9, color = &quot;gray66&quot;) + ggplot2::geom_point() + ggplot2::scale_colour_viridis_d(direction = -1) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::scale_y_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::labs( x = &quot;Percentile F-Score&quot;, y = &quot;Percentile MAPE (mean)&quot; , color = &quot;&quot; , subtitle = &quot;Data Fusion&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 8) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text = ggplot2::element_text(size = 7) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 5, alpha = 1)) , shape = &quot;none&quot; ) 8.6.3.1.1 Top 1.0% let’s check out the parameter settings of the top 1.0% (n=352) from all 35,280 combinations tested. these are “votes” for the parameter setting based on the combinations that achieved the best balance between both detection and quantification accuracy. param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(tidyselect::contains(&quot;f_score&quot;), max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::count(metric, value) %&gt;% dplyr::group_by(metric) %&gt;% dplyr::mutate( pct=n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\nn=&quot;, scales::comma(n,accuracy=1)) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = factor(value), y=pct, label=lab, fill = metric) ) + ggplot2::geom_col(width = 0.6) + ggplot2::geom_text(color = &quot;black&quot;, size = 2.5, vjust = -0.2) + ggplot2::facet_wrap(facets = dplyr::vars(metric), ncol=2, scales = &quot;free_x&quot;) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::scale_fill_manual(values = pal_param[1:6]) + ggplot2::labs( x = &quot;parameter setting&quot;, y = &quot;&quot; , fill = &quot;&quot; , subtitle = paste0( &quot;Data Fusion&quot; , &quot;\\nparameter settings of top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(sum(param_combos_spectral_ranked$is_top_overall), accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations\\nbased on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 6) , axis.text.x = ggplot2::element_text(size = 8) , plot.subtitle = ggplot2::element_text(size = 8) ) what is the expected detection accuracy of the top 1.0% (n=352) combinations tested? plt_detection_dist( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile detection metrics for top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(sum(param_combos_spectral_ranked$is_top_overall), accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected quantification accuracy of the top 1.0% (n=352) combinations tested? # plot it plt_form_quantification_dist( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Structural Data Only&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top,accuracy=0.1) , &quot; (n=&quot; , scales::comma(sum(param_combos_spectral_ranked$is_top_overall), accuracy = 1) , &quot;) &quot; , &quot;overall parameter combinations\\nbased on both detection and quantification accuracy&quot; ) ) 8.6.3.1.2 Top 12 settings Let’s focus on the top 12 parameter settings tested to highlight the pile detection and form quantification accuracies achieved by these settings # pal_temp %&gt;% scales::show_col() # filter and reshape param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight , ovrall_lab # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% factor( ordered = T , levels = c( &quot;detection&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Detection&quot; , &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) , value_lab = dplyr::case_when( eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=0.1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% # make var for color dplyr::group_by(pile_metric, eval_metric) %&gt;% dplyr::mutate( # for ME, color by abs...for f-score,recall,precision color by -value so that higher means better... # ...since higher means worse for quantification accuracy metrics value_dir = dplyr::case_when( eval_metric %in% c(&quot;ME&quot;) ~ abs(value) , eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;) ~ -value , T ~ value ) , value_z = (value_dir-mean(value_dir,na.rm=T))/sd(value_dir,na.rm=T) # this is the key to the different colors within facets ) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(!eval_metric %in% c(&quot;RRMSE&quot;)) %&gt;% # View() ggplot2::ggplot(mapping = ggplot2::aes(x = eval_metric, y = ovrall_lab)) + ggplot2::geom_tile( mapping = ggplot2::aes(fill = pile_metric, alpha = -value_z) , color = &quot;gray&quot; ) + ggplot2::geom_text( mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) , color = &quot;white&quot; ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), scales = &quot;free_x&quot;) + ggplot2::scale_x_discrete(position = &quot;top&quot;) + ggplot2::scale_fill_manual(values = c(&quot;gray33&quot;, harrypotter::hp(n=3,option = &quot;hermionegranger&quot;) )) + ggplot2::scale_alpha_binned(range = c(0.55, 1)) + # this is the key to the different colors within facets ggplot2::theme_light() + ggplot2::labs( x = &quot;&quot; , y = &quot;max_ht_m : max_area_m2 : convexity_pct : circle_fit_iou_pct : chm_res_m : spectral_weight&quot; , subtitle = paste0( &quot;Data Fusion&quot; , &quot;\\npile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) , caption = &quot;*darker colors indicate relatively higher accuracy values&quot; ) + ggplot2::theme( legend.position = &quot;none&quot; , panel.grid = ggplot2::element_blank() , strip.placement = &quot;outside&quot; , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.title.x = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) this plot allows for a simultaneous comparison of all metrics for pile detection and pile form quantification. it includes only the parameter combinations that achieved the best balanced accuracy, helping users identify the optimal settings by evaluating the trade-offs between detection and form quantification. let’s table this param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% # first select to arrange eval_metric dplyr::select( ovrall_lab , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( ovrall_lab , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight # detection , f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% # names() dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) %&gt;% dplyr::mutate(blank= &quot; &quot; ) %&gt;% dplyr::relocate(blank, .before = f_score) %&gt;% dplyr::arrange(desc(ovrall_lab)) %&gt;% kableExtra::kbl( caption = paste0( &quot;Data Fusion&quot; , &quot;&lt;br&gt;pile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;&lt;br&gt;based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;&quot; ,&quot;max_ht_m&quot;,&quot;max_area_m2&quot;,&quot;convexity_pct&quot;,&quot;circle_fit_iou_pct&quot;,&quot;chm_res_m&quot;,&quot;spectral_weight&quot; , &quot; &quot; , &quot;F-score&quot;, &quot;Recall&quot;, &quot;Precision&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 3) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=8 , &quot;Detection&quot; = 3 # , &quot;Volume&quot; = 3 , &quot;Area&quot; = 3 , &quot;Height&quot; = 3 , &quot;Diameter&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(8,20,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 8:20 , extra_css = &quot;font-size: 10px;&quot; , include_thead = T ) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) Table 8.3: Data Fusionpile detection and form quantification accuracy metrics for the top parameter settings tested (n=12) based on both detection and quantification accuracy Detection Area Height Diameter max_ht_m max_area_m2 convexity_pct circle_fit_iou_pct chm_res_m spectral_weight F-score Recall Precision ME RMSE MAPE ME RMSE MAPE ME RMSE MAPE 5:60:0.8:0.65:0.1:4 5 60 0.80 0.65 0.1 4 89% 90% 88% -0.80 2.1 10% -0.10 0.6 18% 0.21 0.5 10% 5:50:0.8:0.65:0.1:4 5 50 0.80 0.65 0.1 4 89% 90% 88% -0.80 2.1 10% -0.10 0.6 18% 0.21 0.5 10% 5:60:0.65:0.65:0.1:4 5 60 0.65 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:60:0.5:0.65:0.1:4 5 60 0.50 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:60:0.35:0.65:0.1:4 5 60 0.35 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:60:0.2:0.65:0.1:4 5 60 0.20 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:60:0.05:0.65:0.1:4 5 60 0.05 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.65:0.65:0.1:4 5 50 0.65 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.5:0.65:0.1:4 5 50 0.50 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.35:0.65:0.1:4 5 50 0.35 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.2:0.65:0.1:4 5 50 0.20 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.05:0.65:0.1:4 5 50 0.05 0.65 0.1 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% what is the expected detection accuracy of the top 12 settings? plt_detection_dist( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile detection metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected quantification accuracy of the top 12 settings? # plot it plt_form_quantification_dist( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top,accuracy=1) , &quot;) &quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) finally, here are the combinations selected compared against all 35,280 combinations tested. dplyr::bind_rows( param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection) , param_combos_spectral_ranked %&gt;% dplyr::filter(!is_final_selection) %&gt;% dplyr::slice_sample(prop = (1/6)) ) %&gt;% dplyr::select( rn,max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct , is_final_selection , f_score, precision, recall # quantification accuracy , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::ends_with(&quot;_mape&quot;) # ,precision,recall ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter|precision|recall)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; , &quot;recall&quot; , &quot;precision&quot; ) , labels = c( &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Recall&quot; , &quot;Precision&quot; ) ) , color_metric = ifelse(is_final_selection, pile_metric, NA) %&gt;% factor() ) %&gt;% dplyr::arrange(is_final_selection) %&gt;% # plot ggplot2::ggplot(mapping = ggplot2::aes(x = f_score, y = value, color = color_metric)) + ggplot2::geom_point() + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric)) + harrypotter::scale_color_hp_d(option = &quot;hermionegranger&quot;, na.value = &quot;gray88&quot;) + ggplot2::scale_x_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,1) ) + ggplot2::scale_y_continuous( labels = scales::percent_format(accuracy = 1) , limits = c(0,NA) ) + ggplot2::labs(x = &quot;F-Score&quot;, y = &quot;MAPE&quot;, caption = &quot;*records in gray not selected&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) 8.6.3.2 by CHM resolution To select the best-performing parameter combinations of those tested by CHM resolution, we will prioritize those that balance detection and quantification accuracy. From this group, we will then identify the settings that achieve the highest pile detection rates (recall). These recommendations are for users who are working with a CHM with a resolution in the range of those tested for this analysis or can aggregate (i.e. make more coarse) a CHM to a resolution tested for the purpose of either improving processing performance or enhancing pile detection and/or quantification accuracy based on the results shown here we already created this data above (param_combos_ranked) using the F-Score and the average rank of the MAPE metrics across all form measurements (i.e. height, diameter, area, volume) to determine the best overall list of those tested by CHM resolution 8.6.3.2.1 Top 2.0% Of those tested, let’s check out the parameter settings of the top 2.0% (n=141) from all 7,056 combinations tested by CHM resolution. these are “votes” for the parameter setting based on the combinations that achieved the best balance between both detection and quantification accuracy. param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(tidyselect::contains(&quot;f_score&quot;), max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,chm_res_m_desc,spectral_weight) %&gt;% tidyr::pivot_longer( cols = c(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,spectral_weight) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::count(chm_res_m,chm_res_m_desc, metric, value) %&gt;% dplyr::group_by(chm_res_m,chm_res_m_desc, metric) %&gt;% dplyr::mutate( pct=n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1)) #, &quot;\\nn=&quot;, scales::comma(n,accuracy=1)) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = factor(value), y=pct, label=lab, fill = metric) ) + ggplot2::geom_col(width = 0.6) + ggplot2::geom_text(color = &quot;black&quot;, size = 2.2, vjust = -0.2) + ggplot2::facet_grid(cols = dplyr::vars(metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free_x&quot;) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::scale_fill_manual(values = pal_param[c(1:4,6)]) + ggplot2::labs( x = &quot;parameter setting&quot;, y = &quot;&quot; , fill = &quot;&quot; , subtitle = paste0( &quot;Data Fusion&quot; , &quot;\\nparameter settings of top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_spectral_chm , accuracy = 1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 6) , axis.text.x = ggplot2::element_text(size = 8) , plot.subtitle = ggplot2::element_text(size = 8) ) an interesting finding here is that as CHM resolution becomes more coarse, the importance of the spectral data increases (i.e. spectral_weight) for accurately detecting and representing pile form what is the expected detection accuracy of the top 2.0% (n=141) combinations tested by CHM resolution? plt_detection_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile detection metrics for top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_spectral_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected MAPE of the top 2.0% (n=141) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mape&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_spectral_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected Mean Error (ME) of the top 2.0% (n=141) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mean&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_spectral_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected RMSE of the top 2.0% (n=141) combinations tested by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_top_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;rmse&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top &quot; , scales::percent(pct_th_top_chm,accuracy=0.1) , &quot; (n=&quot; , scales::comma(n_combos_top_spectral_chm, accuracy=1) , &quot;) &quot; , &quot;parameter combinations tested by CHM resolution\\nbased on both detection and quantification accuracy&quot; ) ) 8.6.3.2.2 Final 6 settings # pal_temp %&gt;% scales::show_col() # filter and reshape param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% dplyr::select( max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,chm_res_m_desc,spectral_weight , chm_lab # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% tidyr::pivot_longer( cols = c( f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = stringr::str_extract(metric, &quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision)$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% factor( ordered = T , levels = c( &quot;detection&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Detection&quot; , &quot;Volume&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) , value_lab = dplyr::case_when( eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;RRMSE&quot;, &quot;MAPE&quot;) ~ scales::percent(value,accuracy=0.1) , eval_metric == &quot;ME&quot; ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% # make var for color dplyr::group_by(chm_res_m,chm_res_m_desc, pile_metric, eval_metric) %&gt;% dplyr::mutate( # for ME, color by abs...for f-score,recall,precision color by -value so that higher means better... # ...since higher means worse for quantification accuracy metrics value_dir = dplyr::case_when( eval_metric %in% c(&quot;ME&quot;) ~ abs(value) , eval_metric %in% c(&quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;) ~ -value , T ~ value ) , value_z = (value_dir-mean(value_dir,na.rm=T))/sd(value_dir,na.rm=T) # this is the key to the different colors within facets ) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(!eval_metric %in% c(&quot;RRMSE&quot;)) %&gt;% # View() ggplot2::ggplot(mapping = ggplot2::aes(x = eval_metric, y = chm_lab)) + ggplot2::geom_tile( mapping = ggplot2::aes(fill = pile_metric, alpha = -value_z) , color = &quot;gray&quot; ) + ggplot2::geom_text( mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) , color = &quot;white&quot; , size = 3 ) + ggplot2::facet_grid(cols = dplyr::vars(pile_metric), rows = dplyr::vars(chm_res_m_desc), scales = &quot;free&quot;) + ggplot2::scale_x_discrete(position = &quot;top&quot;) + ggplot2::scale_fill_manual(values = c(&quot;gray33&quot;, harrypotter::hp(n=3,option = &quot;hermionegranger&quot;) )) + ggplot2::scale_alpha_binned(range = c(0.55, 1)) + # this is the key to the different colors within facets ggplot2::theme_light() + ggplot2::labs( x = &quot;&quot; , y = &quot;max_ht_m : max_area_m2 : convexity_pct : circle_fit_iou_pct : chm_res_m : spectral_weight&quot; , subtitle = paste0( &quot;Data Fusion&quot; , &quot;\\npile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) , caption = &quot;*darker colors indicate relatively higher accuracy values&quot; ) + ggplot2::theme( legend.position = &quot;none&quot; , panel.grid = ggplot2::element_blank() , strip.placement = &quot;outside&quot; , strip.text.x = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.y = ggplot2::element_text(size = 7) , axis.title.x = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 8) ) this plot allows for a simultaneous comparison of all metrics for pile detection and pile form quantification. it includes only the parameter combinations that achieved the best balanced accuracy, helping users identify the optimal settings by evaluating the trade-offs between detection and form quantification. let’s table this param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) %&gt;% # first select to arrange eval_metric dplyr::select( chm_lab, chm_res_m_desc , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( chm_lab, chm_res_m_desc , max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct,chm_res_m,spectral_weight # detection , f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% # names() dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) %&gt;% dplyr::mutate(blank= &quot; &quot; ) %&gt;% dplyr::relocate(blank, .before = f_score) %&gt;% dplyr::arrange(chm_res_m, desc(chm_lab)) %&gt;% dplyr::select(-chm_res_m) %&gt;% dplyr::relocate(chm_res_m_desc) %&gt;% kableExtra::kbl( caption = paste0( &quot;Data Fusion&quot; , &quot;&lt;br&gt;pile detection and form quantification accuracy metrics for the top parameter settings tested&quot; # , scales::percent(1-pct_rank_th_top,accuracy=1) , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution &quot; , &quot;&lt;br&gt;based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;.&quot;, &quot;&quot; ,&quot;max_ht_m&quot;,&quot;max_area_m2&quot;,&quot;convexity_pct&quot;,&quot;circle_fit_iou_pct&quot;,&quot;spectral_weight&quot; , &quot; &quot; , &quot;F-score&quot;, &quot;Recall&quot;, &quot;Precision&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 3) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=8 , &quot;Detection&quot; = 3 # , &quot;Volume&quot; = 3 , &quot;Area&quot; = 3 , &quot;Height&quot; = 3 , &quot;Diameter&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(8,20,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 8:20 , extra_css = &quot;font-size: 10px;&quot; , include_thead = T ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) Table 8.4: Data Fusionpile detection and form quantification accuracy metrics for the top parameter settings tested (n=6) by CHM resolution based on both detection and quantification accuracy Detection Area Height Diameter . max_ht_m max_area_m2 convexity_pct circle_fit_iou_pct spectral_weight F-score Recall Precision ME RMSE MAPE ME RMSE MAPE ME RMSE MAPE 0.1m CHM 5:50:0.65:0.65:0.1:4 5 50 0.65 0.65 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.5:0.65:0.1:4 5 50 0.50 0.65 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.35:0.65:0.1:4 5 50 0.35 0.65 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.2:0.65:0.1:4 5 50 0.20 0.65 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:50:0.05:0.65:0.1:4 5 50 0.05 0.65 4 89% 91% 87% -0.81 2.1 10% -0.09 0.6 18% 0.21 0.5 10% 5:40:0.8:0.5:0.1:4 5 40 0.80 0.50 4 87% 92% 83% -0.66 1.7 11% -0.06 0.6 19% 0.19 0.5 10% 0.2m CHM 2:60:0.8:0.05:0.2:4 2 60 0.80 0.05 4 80% 84% 76% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 2:50:0.8:0.05:0.2:4 2 50 0.80 0.05 4 80% 84% 76% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 2:40:0.8:0.05:0.2:4 2 40 0.80 0.05 4 80% 84% 76% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 2:30:0.8:0.05:0.2:4 2 30 0.80 0.05 4 80% 84% 76% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 2:40:0.8:0.05:0.2:3 2 40 0.80 0.05 3 76% 84% 70% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 2:30:0.8:0.05:0.2:3 2 30 0.80 0.05 3 76% 84% 70% 0.53 1.7 13% -0.27 0.5 14% 0.48 0.7 18% 0.3m CHM 5:60:0.8:0.65:0.3:5 5 60 0.80 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 5:60:0.65:0.65:0.3:5 5 60 0.65 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 5:60:0.5:0.65:0.3:5 5 60 0.50 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 5:60:0.35:0.65:0.3:5 5 60 0.35 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 5:60:0.2:0.65:0.3:5 5 60 0.20 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 5:60:0.05:0.65:0.3:5 5 60 0.05 0.65 5 80% 78% 82% 1.59 2.2 22% -0.14 0.7 18% 0.74 0.8 24% 0.4m CHM 2:40:0.8:0.05:0.4:4 2 40 0.80 0.05 4 63% 81% 52% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:30:0.8:0.05:0.4:4 2 30 0.80 0.05 4 63% 81% 52% 2.48 3.1 37% -0.29 0.5 15% 1.01 1.1 34% 2:20:0.5:0.05:0.4:5 2 20 0.50 0.05 5 70% 81% 62% 1.77 5.6 38% -0.30 0.5 15% 0.96 1.2 35% 2:20:0.35:0.05:0.4:5 2 20 0.35 0.05 5 70% 81% 62% 1.77 5.6 38% -0.30 0.5 15% 0.96 1.2 35% 2:20:0.2:0.05:0.4:5 2 20 0.20 0.05 5 70% 81% 62% 1.77 5.6 38% -0.30 0.5 15% 0.96 1.2 35% 2:20:0.05:0.05:0.4:5 2 20 0.05 0.05 5 70% 81% 62% 1.77 5.6 38% -0.30 0.5 15% 0.96 1.2 35% 0.5m CHM 3:60:0.5:0.35:0.5:5 3 60 0.50 0.35 5 64% 83% 51% 3.67 4.4 50% -0.11 0.8 21% 1.30 1.4 41% 3:60:0.35:0.35:0.5:5 3 60 0.35 0.35 5 64% 83% 51% 3.67 4.4 50% -0.11 0.8 21% 1.30 1.4 41% 3:60:0.2:0.35:0.5:5 3 60 0.20 0.35 5 64% 83% 51% 3.67 4.4 50% -0.11 0.8 21% 1.30 1.4 41% 3:60:0.05:0.35:0.5:5 3 60 0.05 0.35 5 64% 83% 51% 3.67 4.4 50% -0.11 0.8 21% 1.30 1.4 41% 3:60:0.65:0.35:0.5:5 3 60 0.65 0.35 5 63% 83% 51% 3.67 4.4 50% -0.11 0.8 21% 1.30 1.4 41% 3:60:0.8:0.05:0.5:5 3 60 0.80 0.05 5 64% 87% 50% 3.78 4.4 50% -0.11 0.7 20% 1.33 1.4 42% what is the expected detection accuracy of the top 6 settings by CHM resolution? plt_detection_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile detection metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected MAPE of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mape&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected Mean Error (ME) of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;mean&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) what is the expected RMSE of the top 6 settings by CHM resolution? # plot it plt_form_quantification_dist2( df = param_combos_spectral_ranked %&gt;% dplyr::filter(is_final_selection_chm) %&gt;% dplyr::select(!tidyselect::contains(&quot;_pct_rank_&quot;)) , quant_metric = &quot;rmse&quot; , paste0( &quot;Data Fusion&quot; , &quot;\\ndistribution of pile form quantification metrics for the top parameter settings tested&quot; , &quot; (n=&quot; , scales::comma(n_th_top_chm,accuracy=1) , &quot;) by CHM resolution&quot; , &quot;\\nbased on both detection and quantification accuracy&quot; ) ) 8.7 save the data let’s save the data for potential future use param_combos_ranked %&gt;% readr::write_csv(file.path(&quot;../data&quot;, &quot;param_combos_ranked.csv&quot;), append = F, progress = F) param_combos_spectral_ranked %&gt;% readr::write_csv(file.path(&quot;../data&quot;, &quot;param_combos_spectral_ranked.csv&quot;), append = F, progress = F) "],["stats_method.html", "Section 9 Statistical Testing of Method Settings 9.1 Bayesian GLM - F-score 9.2 Bayesian GLM - Diameter MAPE 9.3 Bayesian GLM - Height MAPE 9.4 Balanced Accuracy Bayesian Optimization 9.5 Balanced Accuracy Validation", " Section 9 Statistical Testing of Method Settings In this prior section we performed sensitivity testing of our slash pile detection method using multiple CHM raster resolutions and ended up testing tens of thousands of possible parameterizations and input data combinations. using the tested parameter and data input combinations, we’re going build statistical models to quantify the influence of these parameters and input data on pile detection and quantification accuracy. we’ll utilize a Bayesian modelling framework which will allow us to probabilistically quantify parameter influence while accounting for uncertainty. here are some of the hypotheses about the slash pile detection methodology that we’ll be exploring: does CHM resolution influences detection and quantification accuracy? does the effect of CHM resolution change based on the inclusion of spectral data versus using only structural data? does the use of spectral data have a meaningful impact on detection and quantification accuracy our analysis data set will be the param_combos_spectral_ranked data which includes accuracy measurements at the parameter combination level using both structural data only as well as structural and spectral data in our data fusion approach. in this data, a row is unique by the full set of parameters and input data tested: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, spectral_weight. there are four structural parameters: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct which are used to determine candidate slash piles from the CHM data alone, and the chm_res_m and spectral_weight parameters represent the input data with spectral_weight classifying if spectral data was not used (i.e. spectral_weight = 0), or if spectral data was used, what the weighting of that spectral data was on a 1-5 scale where the number represents the number of individual spectral index thresholds that must be met for a candidate pile detected from the structural data to be kept. for example, a value of “5” requires that all spectral criteria be met and will result in more candidate piles being filtered out than a value of “3”. See this section for full details on the data fusion approach. we’ll read in the sensitivity test result data which includes point estimates of detection and form quantification accuracy if it’s not already in memory if( length(ls()[grep(&quot;param_combos_ranked&quot;,ls())])!=1 ){ param_combos_ranked &lt;- readr::read_csv(file.path(&quot;../data&quot;, &quot;param_combos_ranked.csv&quot;), progress = F, show_col_types = F) } if( length(ls()[grep(&quot;param_combos_spectral_ranked&quot;,ls())])!=1 ){ param_combos_spectral_ranked &lt;- readr::read_csv(file.path(&quot;../data&quot;, &quot;param_combos_spectral_ranked.csv&quot;), progress = F, show_col_types = F) } # convert spectral weight to factor for modelling param_combos_spectral_ranked &lt;- param_combos_spectral_ranked %&gt;% dplyr::mutate( spectral_weight = factor(spectral_weight) # replace 0 F-score with very small positive to run GLM models , f_score = ifelse(f_score==0,1e-4,f_score) ) # check out this data param_combos_spectral_ranked %&gt;% dplyr::select( max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m , spectral_weight, spectral_weight_fact , f_score, precision, recall , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% dplyr::glimpse() ## Rows: 35,280 ## Columns: 13 ## $ max_ht_m &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, … ## $ max_area_m2 &lt;dbl&gt; 40, 50, 50, 50, 50, 50, 60, 60, 60, 60, 60, 5… ## $ convexity_pct &lt;dbl&gt; 0.80, 0.05, 0.20, 0.35, 0.50, 0.65, 0.05, 0.2… ## $ circle_fit_iou_pct &lt;dbl&gt; 0.50, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.6… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … ## $ spectral_weight &lt;fct&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, … ## $ spectral_weight_fact &lt;fct&gt; structural+spectral, structural+spectral, str… ## $ f_score &lt;dbl&gt; 0.8740157, 0.8870968, 0.8870968, 0.8870968, 0… ## $ precision &lt;dbl&gt; 0.8345865, 0.8661417, 0.8661417, 0.8661417, 0… ## $ recall &lt;dbl&gt; 0.9173554, 0.9090909, 0.9090909, 0.9090909, 0… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1063683, 0.1013882, 0.1013882, 0.1013882, 0… ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.10231758, 0.09905328, 0.09905328, 0.0990532… ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.1851636, 0.1822841, 0.1822841, 0.1822841, 0… a row is unique by the full set of parameters tested: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, spectral_weight # a row is unique by max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, and spectral_weight identical( param_combos_spectral_ranked %&gt;% dplyr::distinct(max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, spectral_weight) %&gt;% nrow() , param_combos_spectral_ranked %&gt;% nrow() ) ## [1] TRUE here are the number of records which returned valid predicted slash pile polygons by CHM resolution and data input setting (i.e. structural only versus data fusion). the number of records for the data fusion approach (“structural+spectral”) should be roughly five times the number of records as the structural only approach because we tested five different settings of the structural_weight parameter from the lowest weighting of the spectral data of “1” (only one spectral index threshold must be met) to the highest weighting of spectral data “5” (all spectral index thresholds must be met) param_combos_spectral_ranked %&gt;% dplyr::count(chm_res_m_desc,spectral_weight_fact) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x=n,y=spectral_weight_fact, color = spectral_weight_fact, fill = spectral_weight_fact)) + ggplot2::geom_col(width = 0.6) + ggplot2::geom_text( mapping = ggplot2::aes(label=scales::comma(n)) , color = &quot;black&quot;, size = 3 , hjust = -0.1 ) + ggplot2::facet_grid(rows = dplyr::vars(chm_res_m_desc)) + harrypotter::scale_fill_hp_d(option = &quot;slytherin&quot;) + harrypotter::scale_color_hp_d(option = &quot;slytherin&quot;) + ggplot2::scale_x_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.1))) + ggplot2::labs(y=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) ) 9.1 Bayesian GLM - F-score given that our data contains only one observation per parameter combination, we’re going to use a Bayesian Beta generalized linear model (GLM) to ensure a statistically sound approach and interpretable relationships between each parameter and the dependent variable (e.g. F-score). our model will treat the parameters as a mix of continuous and nominal variables, preventing model saturation (where the model has as many parameters to estimate as data points, so the data perfectly explains the model). A Bayesian hierarchical model would not be appropriate for this structure, since it is designed for datasets with nested or grouped observations (e.g. if we had evaluated the method across different plots or study sites). Our Bayesian Beta regression models the F-score with a Beta distribution because it is a proportion between 0 and 1, which ensures that the predictions and uncertainty estimates are always within the valid range. We’re treating the four structural parameters (e.g. max_ht_m and circle_fit_iou_pct) and the CHM resolution (chm_res_m) as metric (i.e., continuous) variables, as this is statistically sound for our data and allows for a continuous interpretation where the model coefficient will represent the change in F-score for a one-unit change in the parameter value. The spectral_weight parameter, however, will be treated as nominal to capture its discrete effects without assuming a linear relationship. 9.1.1 Model selection we’re going to use a sub-sample of the data to perform model testing. our objective is to construct the model such that it faithfully represents the data. we reviewed the main effect parameter trends against F-score here and used these to guide our model design. we’ll follow Kurz 2025 and compare our models with the LOO information criterion Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower estimates. # subsample data set.seed(222) ms_df_temp &lt;- param_combos_spectral_ranked %&gt;% dplyr::slice_sample(prop = 0.11) # mcmc setup iter_temp &lt;- 2444 warmup_temp &lt;- 1222 chains_temp &lt;- 4 #################################################################### # base model with form selected based on main effect trends #################################################################### fscore_mod1_temp &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Beta(link = &quot;logit&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod1_temp&quot;) ) fscore_mod1_temp &lt;- brms::add_criterion(fscore_mod1_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by chm_res_m and vice-versa #################################################################### fscore_mod2_temp &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Beta(link = &quot;logit&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod2_temp&quot;) ) fscore_mod2_temp &lt;- brms::add_criterion(fscore_mod2_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by convexity_pct and vice-versa #################################################################### fscore_mod3_temp &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + circle_fit_iou_pct:convexity_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Beta(link = &quot;logit&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod3_temp&quot;) ) fscore_mod3_temp &lt;- brms::add_criterion(fscore_mod3_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### fscore_mod4_temp &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + circle_fit_iou_pct:convexity_pct + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m:convexity_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Beta(link = &quot;logit&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod4_temp&quot;) ) fscore_mod4_temp &lt;- brms::add_criterion(fscore_mod4_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m. quadratic convexity_pct #################################################################### fscore_mod5_temp &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct:convexity_pct + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m:convexity_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Beta(link = &quot;logit&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod5_temp&quot;) ) fscore_mod5_temp &lt;- brms::add_criterion(fscore_mod4_temp, criterion = &quot;loo&quot;) compare our models with the LOO information criterion. with the brms::loo_compare() function, we can compute a formal difference score between models with the output rank ordering the models such that the best fitting model appears on top. all models also receive a difference score relative to the best model and a standard error of the difference score brms::loo_compare(fscore_mod1_temp, fscore_mod2_temp, fscore_mod3_temp, fscore_mod4_temp, fscore_mod5_temp) %&gt;% kableExtra::kbl(caption = &quot;F-score model selection with LOO information criterion&quot;) %&gt;% kableExtra::kable_styling() Table 9.1: F-score model selection with LOO information criterion elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic fscore_mod4_temp 0.0000 0.00000 4254.854 139.8614 26.42988 1.441628 -8509.709 279.7227 fscore_mod5_temp 0.0000 0.00000 4254.854 139.8614 26.42988 1.441628 -8509.709 279.7227 fscore_mod3_temp -216.3790 26.76322 4038.475 139.5926 27.71362 1.931427 -8076.951 279.1851 fscore_mod2_temp -229.8413 28.35355 4025.013 138.5435 27.54291 1.893650 -8050.026 277.0871 fscore_mod1_temp -234.9112 30.47721 4019.943 139.0671 27.27559 1.942107 -8039.886 278.1342 we can also look at the AIC-type model weights brms::model_weights(fscore_mod1_temp, fscore_mod2_temp, fscore_mod3_temp, fscore_mod4_temp, fscore_mod5_temp) %&gt;% round(digits = 4) we can also quickly look at the Bayeisan \\(R^2\\) returned from the brms::bayes_R2() function dplyr::bind_rows( brms::bayes_R2(fscore_mod1_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;fscore_mod1_temp&quot;) , brms::bayes_R2(fscore_mod2_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;fscore_mod2_temp&quot;) , brms::bayes_R2(fscore_mod3_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;fscore_mod3_temp&quot;) , brms::bayes_R2(fscore_mod4_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;fscore_mod4_temp&quot;) , brms::bayes_R2(fscore_mod5_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;fscore_mod5_temp&quot;) ) %&gt;% dplyr::mutate(mod = factor(mod)) %&gt;% ggplot2::ggplot(mapping=ggplot2::aes(y=R2, x = mod)) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 ) + # ggplot2::facet_grid(cols = dplyr::vars(spectral_weight)) + # ggplot2::scale_fill_manual(values = pal_chm_res_m) + ggplot2::labs(x = &quot;&quot;, y = &quot;Bayesian R-squared&quot;) + ggplot2::theme_light() the more complex models were selected as the best. while our model evaluation indicated that the more parsimonious model with fewer parameters was comparable to the most complex model tested, we’ll the more complex model (fscore_mod5_temp) model for our based on the AIC-type model weights. because the selected model includes a quadratic term and multiple interactions parameter interpretation will be a challenge, so we will have to rely on plotting the modeled relationships rather than trying to interpret the coefficients. 9.1.2 Modeling the four structural parameters (e.g. max_ht_m and circle_fit_iou_pct) and the CHM resolution (chm_res_m) as metric (i.e., continuous) variables. we include an interaction between chm_res_m and spectral_weight to directly compare the effect of CHM resolution with and without the use of spectral data. we’ll generally follow Kurz (2023a; 2023b; 2025 for multiple linear regression model building using the brms Bayesian model framework based on McElreath (2015, Ch. 5,7) and Kruschke (2015, Ch. 18) the fully factored Bayesian statistical model that details the likelihood, linear model, and priors used is: \\[\\begin{align*} \\text{F-score}_i \\sim &amp; \\operatorname{Beta}(\\mu_{i}, \\phi) \\\\ \\operatorname{logit}(\\mu_i) = &amp; (\\beta_1 \\cdot \\text{max_ht_m}_i) + (\\beta_2 \\cdot \\text{max_area_m2}_i) \\\\ &amp; + (\\beta_3 \\cdot \\text{circle_fit_iou_pct}_i) + (\\beta_4 \\cdot (\\text{circle_fit_iou_pct}_i)^2) \\\\ &amp; + (\\beta_5 \\cdot \\text{convexity_pct}_i) + (\\beta_6 \\cdot (\\text{convexity_pct}_i)^2) \\\\ &amp; + (\\beta_7 \\cdot \\text{chm_res_m}_i) \\\\ &amp; + \\sum_{j=0}^{5} \\left( \\beta_{8, j} \\cdot \\mathbf{I}(\\text{spectral_weight}_i = j) \\right) \\\\ &amp; + (\\beta_9 \\cdot \\text{circle_fit_iou_pct}_i \\cdot \\text{convexity_pct}_i) \\\\ &amp; + (\\beta_{10} \\cdot \\text{circle_fit_iou_pct}_i \\cdot \\text{chm_res_m}_i) \\\\ &amp; + (\\beta_{11} \\cdot \\text{convexity_pct}_i \\cdot \\text{chm_res_m}_i) \\\\ &amp; + \\sum_{j=0}^{5} \\left( \\beta_{12, j} \\cdot \\text{chm_res_m}_i \\cdot \\mathbf{I}(\\text{spectral_weight}_i = j) \\right) \\\\ &amp; + (\\beta_{13} \\cdot \\text{circle_fit_iou_pct}_i \\cdot \\text{chm_res_m}_i \\cdot \\text{convexity_pct}_i) \\\\ \\beta_k \\sim &amp; \\operatorname{Normal}(0, \\sigma_k) \\quad \\text{for } k = 0, \\dots, 13 \\\\ \\sigma_k \\sim &amp; \\operatorname{Student T}(3,0,2.5) \\quad \\text{for } k = 0, \\dots, 13 \\\\ \\phi \\sim &amp; \\operatorname{Gamma}(0.01,0.01) \\\\ \\end{align*}\\] where, \\(i\\) represents a single observation in the dataset which corresponds to a specific combination of the six parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, and spectral_weight) and its resulting F-score. Where k is used to index the different beta coefficients, which correspond to the intercept and the effects of each of the independent variables and their interactions and j denotes the specific level of the nominal (i.e. categorical) predictor spectral_weight let’s fit the model using the brms framework to fit Bayesian regression models using the Stan probabilistic programming language. if we want to set the prior for \\(\\beta_0\\) given a non-centered predictors, then we need to use the 0 + Intercept syntax to fit the model (see Kurz 2025 for full discussion), but we’ll just fit the model with the brsm::brm() default settings which automatically mean centers the predictors and also set the intercept to 0 so that we get explicit coefficient estimates for each level of our spectral_weight nominal variable which determines the intercept in this model The table below details the terms used in our Bayesian GLM model defined in the brms::brm() call: Term in Formula Type of Effect Description of Relationship Tested 0 + Zero Intercept Specifies that the model is fit without a global intercept (baseline is determined by the combination of all factor levels). max_ht_m Main Effect (Linear) Tests the direct, isolated linear influence of the maximum pile height threshold on the F-score. max_area_m2 Main Effect (Linear) Tests the direct, isolated linear influence of the maximum pile area threshold on the F-score. chm_res_m Main Effect (Linear) Tests the direct, isolated linear influence of the input Canopy Height Model (CHM) resolution on the F-score. spectral_weight Main Effect (Factor) The model estimates a separate coefficient for each of the six spectral weight levels (0 through 5). This coefficient represents the estimated mean F-score for that specific spectral weight level when all continuous variables are zero. circle_fit_iou_pct Main Effect (Linear) Tests the direct linear influence of the pile’s circular conformity threshold on the F-score. convexity_pct Main Effect (Linear) Tests the direct linear influence of the pile’s boundary smoothness (convexity) threshold on the F-score. I(circle_fit_iou_pct^2) Nonlinear (Quadratic) Models a curved relationship where the F-score may peak or bottom out at an intermediate threshold for pile circularity. I(convexity_pct^2) Nonlinear (Quadratic) Models a curved relationship where the F-score may peak or bottom out at an intermediate threshold for pile boundary smoothness. circle_fit_iou_pct:convexity_pct Two-Way Interaction Captures how the optimal balance between pile circular conformity and boundary smoothness changes for the F-score. chm_res_m:spectral_weight Two-Way Interaction (Factor) Captures how the effect of CHM resolution on the F-score changes across each of the six spectral weighting levels. circle_fit_iou_pct:chm_res_m Two-Way Interaction Captures how the importance of the pile’s circular conformity threshold changes as the input data resolution changes. convexity_pct:chm_res_m Two-Way Interaction Captures how the sensitivity to the pile boundary smoothness threshold changes with the input data resolution. circle_fit_iou_pct:chm_res_m:convexity_pct Three-Way Interaction The most complex term, showing how the combined effects of the circularity and convexity thresholds change simultaneously across different input CHM resolutions. brms_f_score_mod &lt;- brms::brm( formula = f_score ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct:convexity_pct + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m:convexity_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = param_combos_spectral_ranked # %&gt;% dplyr::slice_sample(prop = 0.33) , family = Beta(link = &quot;logit&quot;) # , prior = c( # brms::prior(student_t(3, 0, 5), class = &quot;b&quot;) # , brms::prior(gamma(0.01, 0.01), class = &quot;phi&quot;) # ) # mcmc , iter = 14000, warmup = 7000 , chains = 4 # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;brms_f_score_mod&quot;) ) # brms::make_stancode(brms_f_score_mod) # brms::prior_summary(brms_f_score_mod) # print(brms_f_score_mod) # brms::neff_ratio(brms_f_score_mod) # brms::rhat(brms_f_score_mod) # brms::nuts_params(brms_f_score_mod) The brms::brm model summary brms_f_score_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | parameter == &quot;phi&quot; ) %&gt;% # dplyr::mutate( # dplyr::across( # dplyr::where(is.numeric) # , ~ dplyr::case_when( # stringr::str_ends(parameter,&quot;_pct&quot;) ~ .x*0.01 # convert to percentage point change # , T ~ .x # ) # ) # ) %&gt;% kableExtra::kbl(digits = 3, caption = &quot;Bayesian model for F-score&quot;) %&gt;% kableExtra::kable_styling() Table 9.2: Bayesian model for F-score parameter estimate est.error q2.5 q97.5 b_max_ht_m -0.033 0.004 -0.042 -0.025 b_max_area_m2 0.006 0.000 0.005 0.006 b_circle_fit_iou_pct 5.893 0.100 5.696 6.091 b_Icircle_fit_iou_pctE2 -9.792 0.066 -9.923 -9.662 b_convexity_pct 0.297 0.103 0.094 0.498 b_Iconvexity_pctE2 -5.165 0.065 -5.291 -5.037 b_chm_res_m -6.767 0.159 -7.081 -6.456 b_spectral_weight0 0.897 0.057 0.786 1.010 b_spectral_weight1 0.896 0.057 0.785 1.008 b_spectral_weight2 0.896 0.057 0.786 1.009 b_spectral_weight3 0.925 0.057 0.814 1.038 b_spectral_weight4 1.209 0.056 1.099 1.320 b_spectral_weight5 1.083 0.056 0.973 1.195 b_circle_fit_iou_pct:convexity_pct 2.815 0.127 2.569 3.065 b_circle_fit_iou_pct:chm_res_m 2.690 0.230 2.240 3.141 b_convexity_pct:chm_res_m 10.563 0.232 10.105 11.020 b_chm_res_m:spectral_weight1 0.001 0.120 -0.234 0.237 b_chm_res_m:spectral_weight2 0.001 0.121 -0.236 0.238 b_chm_res_m:spectral_weight3 0.000 0.120 -0.235 0.236 b_chm_res_m:spectral_weight4 -0.263 0.117 -0.491 -0.033 b_chm_res_m:spectral_weight5 0.628 0.115 0.403 0.853 b_circle_fit_iou_pct:convexity_pct:chm_res_m -6.991 0.407 -7.789 -6.188 phi 4.170 0.031 4.110 4.230 note the quadratic coefficients ending in E2, Kruschke (2015) provides some insight on how to interpret: A quadratic has the form \\(y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^{2}\\). When \\(\\beta_{2}\\) is zero, the form reduces to a line. Therefore, this extended model can produce any fit that the linear model can. When \\(\\beta_{2}\\) is positive, a plot of the curve is a parabola that opens upward. When \\(\\beta_{2}\\) is negative, the curve is a parabola that opens downward. We have no reason to think that the curvature in the family-income data is exactly a parabola, but the quadratic trend might describe the data much better than a line alone. (p. 496) 9.1.3 Posterior Predictive Checks Markov chain Monte Carlo (MCMC) simulations were conducted using the brms package (Bürkner 2017) to estimate posterior predictive distributions of the parameters of interest. We ran 4 chains of 14,000 iterations with the first 7,000 discarded as burn-in. Trace-plots were utilized to visually assess model convergence. check the trace plots for problems with convergence of the Markov chains plot(brms_f_score_mod) Sufficient convergence was checked with \\(\\hat{R}\\) values near 1 (Brooks &amp; Gelman, 1998). in the plot below, \\(\\hat{R}\\) values are colored using different shades (lighter is better). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: below 1.05 (good) mid: between 1.05 and 1.1 (ok) dark: above 1.1 (too high) check our \\(\\hat{R}\\) values brms::mcmc_plot(brms_f_score_mod, type = &quot;rhat_hist&quot;) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(n = 6)) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) and another check of our \\(\\hat{R}\\) values # and another check of our $\\hat{R}$ values brms_f_score_mod %&gt;% brms::rhat() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename(rhat = 2) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;phi&quot; ) %&gt;% dplyr::mutate( chk = (rhat &lt;= 1*0.998 | rhat &gt;= 1*1.002) ) %&gt;% ggplot(aes(x = rhat, y = parameter, color = chk, fill = chk)) + geom_vline(xintercept = 1, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;, lwd = 1.2) + geom_vline(xintercept = 1*0.998, lwd = 1.5) + geom_vline(xintercept = 1*1.002, lwd = 1.5) + geom_vline(xintercept = 1*0.999, lwd = 1.2, color = &quot;gray33&quot;) + geom_vline(xintercept = 1*1.001, lwd = 1.2, color = &quot;gray33&quot;) + geom_point() + scale_fill_manual(values = c(&quot;navy&quot;, &quot;firebrick&quot;)) + scale_color_manual(values = c(&quot;navy&quot;, &quot;firebrick&quot;)) + scale_y_discrete(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\hat{R}$&quot;) , subtitle = latex2exp::TeX(&quot;MCMC chain convergence check for $\\\\hat{R}$ values&quot;) , title = &quot;F-Score&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.text.y = element_text(size = 4) , panel.grid.major.x = element_blank() , panel.grid.minor.x = element_blank() , plot.subtitle = element_text(size = 8) , plot.title = element_text(size = 9) ) The effective length of an MCMC chain is indicated by the effective sample size (ESS), which refers to the sample size of the MCMC chain not to the sample size of the data where acceptable values allow “for reasonably accurate and stable estimates of the limits of the 95% HDI…If accuracy of the HDI limits is not crucial for your application, then a smaller ESS may be sufficient” (Kruschke 2015, p. 184) Ratios of effective sample size (ESS) to total sample size with values are colored using different shades (lighter is better). A ratio close to “1” (no autocorrelation) is ideal, while a low ratio suggests the need for more samples or model re-parameterization. Efficiently mixing MCMC chains are important because they guarantee the resulting posterior samples accurately represent the true distribution of model parameters, which is necessary for reliable and precise estimation of parameter values and their associated uncertainties (credible intervals). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: between 0.5 and 1 (high) mid: between 0.1 and 0.5 (good) dark: below 0.1 (low) # and another effective sample size check brms::mcmc_plot(brms_f_score_mod, type = &quot;neff_hist&quot;) + # brms::mcmc_plot(brms_f_score_mod, type = &quot;neff&quot;) + ggplot2::scale_x_continuous(limits = c(0,NA), breaks = scales::breaks_extended(n = 9)) + # ggplot2::scale_color_discrete(drop = F) + # ggplot2::scale_fill_discrete(drop = F) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) our observed range of ESS to Total Sample Size ratios (~0.2 to ~0.8) are generally considered good to excellent, indicating the MCMC chains are performing well and mixing efficiently Posterior predictive checks were used to evaluate model goodness-of-fit by comparing data simulated from the model with the observed data used to estimate the model parameters (Hobbs &amp; Hooten, 2015). Calculating the proportion of MCMC iterations in which the test statistic (i.e., mean and sum of squares) from the simulated data and observed data are more extreme than one another provides the Bayesian p-value. Lack of fit is indicated by a value close to 0 or 1 while a value of 0.5 indicates perfect fit (Hobbs &amp; Hooten, 2015). To learn more about this approach to posterior predictive checks, check out Gabry’s (2025) vignette, Graphical posterior predictive checks using the bayesplot package. posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data. our objective is to construct the model such that it faithfully represents the data. # posterior predictive check brms::pp_check( brms_f_score_mod , type = &quot;dens_overlay&quot; , ndraws = 100 ) + ggplot2::labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + ggplot2::theme_light() + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) , plot.subtitle = ggplot2::element_text(size = 8) , plot.title = ggplot2::element_text(size = 9) ) another way brms::pp_check(brms_f_score_mod, type = &quot;ecdf_overlay&quot;, ndraws = 100) + ggplot2::labs(subtitle = &quot;posterior-predictive check (ECDF: empirical cumulative distribution function)&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) ) 9.1.4 Conditional Effects first, lets look at densities of the posterior samples per parameter brms::mcmc_plot(brms_f_score_mod, type = &quot;dens&quot;) + # ggplot2::theme_light() + ggplot2::theme( strip.text = ggplot2::element_text(size = 7.5, face = &quot;bold&quot;, color = &quot;black&quot;) ) and we can look at the default coefficient plot that is commonly used in reporting coefficient “significance” in frequentist analysis # easy way to get the default coeff plot brms::mcmc_plot(brms_f_score_mod, type = &quot;intervals&quot;) Regarding interactions and polynomial models like this, McElreath (2015) notes: parameters are the linear and square components of the curve, respectively. But that doesn’t make them transparent. You have to plot these model fits to understand what they are saying. (p. 112-113) all of the interactions and the quadradic trend of this model combine to make these coefficients by themselves uninterpretable as the coefficients are only meaningful in the context of the other terms in the interaction or by adding the quadratic component we can do this by checking for the main effects of the individual variables on F-score (averages across all other effects) brms::conditional_effects(brms_f_score_mod) ### ggplot version # brms::conditional_effects(brms_f_score_mod) %&gt;% # purrr::pluck(&quot;max_ht_m&quot;) %&gt;% # ggplot(aes(x = max_ht_m)) + # geom_ribbon(aes(ymin = lower__, ymax = upper__), fill = &quot;blue&quot;, alpha = 0.2) + # geom_line(aes(y = estimate__), color = &quot;blue&quot;) + # labs( # x = &quot;max_ht_m&quot;, # y = &quot;F-score&quot;, # title = &quot;Conditional Effects&quot; # ) 9.1.5 Posterior Predictive Expectation we will test our hypotheses using the posterior distributions of the expected values (i.e., the posterior predictions of the mean) obtained via tidybayes::add_epred_draws(). our analysis will include two stages using parameter levels of the four structural parameters: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct. in practice, these values should be informed by the treatment and slash pile construction prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy # let&#39;s fix the structural parameters based on expectations from the prescription structural_params_settings &lt;- dplyr::tibble( max_ht_m = 2.3 , max_area_m2 = 46 ) # dplyr::bind_rows( # # structural only # param_combos_ranked %&gt;% dplyr::filter(is_top_overall) %&gt;% dplyr::select(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct) # # fusion # , param_combos_spectral_ranked %&gt;% # dplyr::ungroup() %&gt;% # dplyr::filter(is_top_overall &amp; spectral_weight!=0) %&gt;% # dplyr::arrange(ovrall_balanced_rank) %&gt;% # same number of records as structural only # dplyr::filter(dplyr::row_number()&lt;=sum(param_combos_ranked$is_top_overall)) %&gt;% # dplyr::select(max_ht_m,max_area_m2,convexity_pct,circle_fit_iou_pct) # ) %&gt;% # tidyr::pivot_longer( # cols = dplyr::everything() # , names_to = &quot;metric&quot; # , values_to = &quot;value&quot; # ) %&gt;% # dplyr::count(metric, value) %&gt;% # dplyr::group_by(metric) %&gt;% # dplyr::arrange(metric,desc(n),value) %&gt;% # dplyr::slice(1) %&gt;% # dplyr::select(-n) %&gt;% # tidyr::pivot_wider(names_from = metric, values_from = value) %&gt;% # dplyr::mutate(is_top_overall = T) %&gt;% # # we just need `max_ht_m`, `max_area_m2` # dplyr::select(max_ht_m, max_area_m2) # huh? structural_params_settings %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 2 ## $ max_ht_m &lt;dbl&gt; 2.3 ## $ max_area_m2 &lt;dbl&gt; 46 now we’ll get the posterior predictive draws but over a range of circle_fit_iou_pct and convexity_pct including the best setting seq_temp &lt;- seq(from = 0.05, to = 1.0, by = 0.1) seq2_temp &lt;- seq_temp[seq(1, length(seq_temp), by = 2)] # get every other element # draws draws_temp &lt;- # get the draws for levels of # spectral_weight circle_fit_iou_pct convexity_pct tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight) , circle_fit_iou_pct = seq_temp , convexity_pct = seq_temp , chm_res_m = seq(from = 0.1, to = 1.0, by = 0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% # dplyr::glimpse() tidybayes::add_epred_draws(brms_f_score_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate( is_seq = (convexity_pct %in% seq_temp) &amp; (circle_fit_iou_pct %in% seq_temp) ) # # huh? draws_temp %&gt;% dplyr::glimpse() ## Rows: 6,666,000 ## Columns: 12 ## Groups: spectral_weight, circle_fit_iou_pct, convexity_pct, chm_res_m, max_ht_m, max_area_m2, .row [6,000] ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ convexity_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .row &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ value &lt;dbl&gt; 0.6778712, 0.6924090, 0.6793626, 0.6784690, 0.69338… ## $ is_seq &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU… 9.1.5.1 Geometric shape regularity let’s look at the influence of the parameters that control the geometric shape regularity filtering: circle_fit_iou_pct and convexity_pct. to do this, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy 9.1.5.1.1 circle_fit_iou_pct we need to look at the influence of circle_fit_iou_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.1) , convexity_pct %in% seq2_temp ) %&gt;% dplyr::mutate(convexity_pct = factor(convexity_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct, y = value, color = convexity_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.95) , lwd = 1.1, fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;mako&quot;, begin = 0.6, end = 0.1) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `circle_fit_iou_pct` on F-score&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`circle_fit_iou_pct`&quot; , y = &quot;F-score&quot; , color = &quot;`convexity_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) the non-linear relationship between the circle_fit_iou_pct parameter and the F-score is prominent, confirmed by the model’s quadratic coefficient. this trend is consistent across all levels of spectral_weight and CHM resolution. this figure also demonstrates how, within the optimal range of circle_fit_iou_pct, the intermediate values of the convexity_pct parameter seem to result in the best detection accuracy across CHM resolution levels. Across all CHM resolutions and spectral weighting levels, setting circle_fit_iou_pct too high (e.g &gt; 0.7) results in steep declines in detection accuracy. 9.1.5.1.2 convexity_pct we need to look at the influence of convexity_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.1) , circle_fit_iou_pct %in% seq2_temp ) %&gt;% dplyr::mutate(circle_fit_iou_pct = factor(circle_fit_iou_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct, y = value, color = circle_fit_iou_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.5,0.95) , lwd = 1.1 , fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;magma&quot;, begin = 0.5, end = 0.1) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `convexity_pct` on F-score&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`convexity_pct`&quot; , y = &quot;F-score&quot; , color = &quot;`circle_fit_iou_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) As expected, the model shows that the influence of the convexity_pct parameter on the F-score is conditional on the circle_fit_iou_pct setting. When circle_fit_iou_pct is set too high (requiring nearly perfectly circular pile perimeters), convexity_pct has a minimal impact on the F-score. When circle_fit_iou_pct is set to an optimal value near its vertex (e.g., ~0.25-0.55), the range of convexity_pct values below 0.5 result in the best pile detection for finer resolution CHM data (e.g. &lt; 0.3 m) but for coarser resolution CHM data the optimal convexity_pct setting increases to ~0.37-0.62. Across all CHM resolutions and spectral weighting levels, setting convexity_pct too high (e.g &gt; 0.7) results in steep declines in detection accuracy. 9.1.5.1.3 Optimizing geometric filtering Given the complexity of our model, which includes a non-linear link function and parameter interactions, calculating the optimal parameter values by solving for them algebraically from the model’s coefficients would be prone to error. instead, we can use a robust Bayesian approach that leverages the model’s posterior predictive distribution. This method is powerful because it inherently accounts for all sources of model uncertainty. first, we’ll generate a large number of predictions across a fine grid of parameter values (e.g. in steps of 0.01) for each posterior draw of the model coefficients. we’ll generate a large number (e.g. 1000+) of posterior predictive draws for each combination of parameter values. for each posterior predictive draw, we’ll then identify the parameter combination that maximizes the F-score and we’ll be left with a posterior distribution of optimal parameter combinations. this approach demonstrates a key advantage of the Bayesian framework, allowing us to ask complex questions and find the most probable optimal parameter combination while fully accounting for uncertainty. # let&#39;s get the draws at a very granular level vertex_draws_temp &lt;- tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight, spectral_weight_fact) , circle_fit_iou_pct = seq(from = 0.0, to = 1, by = 0.01) # very granular to identify vertex , convexity_pct = seq(from = 0.0, to = 1, by = 0.01) # very granular to identify vertex , chm_res_m = seq(0.1,0.5,by=0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% tidybayes::add_epred_draws(brms_f_score_mod, ndraws = 1000, value = &quot;value&quot;) %&gt;% dplyr::ungroup() %&gt;% # for each draw, get the highest f-score by chm_res_m, spectral_weight # which we&#39;ll use to identify the optimal circle_fit_iou_pct,convexity_pct settings # these are essentially &quot;votes&quot; based on likelihood dplyr::group_by( .draw , chm_res_m, spectral_weight ) %&gt;% dplyr::arrange(desc(value),circle_fit_iou_pct,convexity_pct) %&gt;% dplyr::slice(1) # vertex_draws_temp %&gt;% dplyr::glimpse() # this thing is huge plot the posterior distribution of optimal parameter setting for circle_fit_iou_pct vertex_draws_temp %&gt;% # dplyr::filter(chm_res_m==0.4) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + # ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1), breaks = scales::breaks_extended(6)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8) ) our model is very confident that the optimal circle_fit_iou_pct for maximizing detection accuracy is in a narrow range, just look at that x-axis scale plot the posterior distribution of optimal parameter setting for convexity_pct vertex_draws_temp %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + # ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1), breaks = scales::breaks_extended(6)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) when the circle_fit_iou_pct parameter is optimized, the influence of convexity_pct on detection accuracy is dependent on the CHM resolution. for coarser CHM data (&gt;0.3 m), the model’s predictions indicate with high certainty that the optimal convexity_pct is higher (i.e. requiring more smooth boundaries) than the optimal convexity_pct setting (i.e. requiring less smooth boundaries) for finer resoultion CHM data. this finding is consistent with our previous results and provides additional evidence that the smoothing effect of coarser resolution CHM data makes convexity_pct most effective at filtering irregular objects only when it is set to an intermediate level (e.g. ~0.5). we can look at this another way, check it vertex_draws_temp %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = convexity_pct, x = circle_fit_iou_pct)) + # geom_point(alpha=0.2) + ggplot2::geom_jitter(alpha=0.2, height = .01, width = .01) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) # , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + # ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1), breaks = scales::breaks_extended(6)) + # ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text = ggplot2::element_text(size = 8) ) note, in the plot above, we slightly “jitter” the points so that they are visible where they would otherwise be stacked on top of each other and only look like a few points instead of the 1000 draws from the posterior we used let’s table the HDI of the optimal values # summarize it table_vertex_draws_temp &lt;- vertex_draws_temp %&gt;% dplyr::group_by( chm_res_m, spectral_weight ) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$y , median_hdi_lower_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymin , median_hdi_upper_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymax # get median_hdi , median_hdi_est_convexity_pct = tidybayes::median_hdci(convexity_pct)$y , median_hdi_lower_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymin , median_hdi_upper_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymax ) %&gt;% dplyr::ungroup() # table it table_vertex_draws_temp %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , rep(c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;),2) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;circle_fit_iou_pct&quot; = 3 , &quot;convexity_pct&quot; = 3 )) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.3: circle_fit_iou_pct convexity_pct CHM resolution spectral_weight median HDI low HDI high median HDI low HDI high 0.1 0 0.34 0.33 0.34 0.20 0.19 0.21 1 0.34 0.33 0.34 0.20 0.19 0.21 2 0.34 0.33 0.34 0.20 0.19 0.21 3 0.34 0.33 0.34 0.20 0.19 0.21 4 0.34 0.33 0.34 0.20 0.19 0.21 5 0.34 0.33 0.34 0.20 0.19 0.21 0.2 0 0.35 0.35 0.35 0.28 0.28 0.29 1 0.35 0.35 0.35 0.28 0.28 0.29 2 0.35 0.35 0.35 0.28 0.28 0.29 3 0.35 0.35 0.35 0.28 0.28 0.29 4 0.35 0.35 0.35 0.28 0.28 0.29 5 0.35 0.35 0.35 0.28 0.28 0.29 0.3 0 0.36 0.35 0.36 0.36 0.36 0.37 1 0.36 0.35 0.36 0.36 0.36 0.37 2 0.36 0.35 0.36 0.36 0.36 0.37 3 0.36 0.35 0.36 0.36 0.36 0.37 4 0.36 0.35 0.36 0.36 0.36 0.37 5 0.36 0.35 0.36 0.36 0.36 0.37 0.4 0 0.36 0.35 0.36 0.44 0.43 0.44 1 0.36 0.35 0.36 0.44 0.43 0.44 2 0.36 0.35 0.36 0.44 0.43 0.44 3 0.36 0.35 0.36 0.44 0.43 0.44 4 0.36 0.35 0.36 0.44 0.43 0.44 5 0.36 0.35 0.36 0.44 0.43 0.44 0.5 0 0.35 0.35 0.35 0.52 0.51 0.52 1 0.35 0.35 0.35 0.52 0.51 0.52 2 0.35 0.35 0.35 0.52 0.51 0.52 3 0.35 0.35 0.35 0.52 0.51 0.52 4 0.35 0.35 0.35 0.52 0.51 0.52 5 0.35 0.35 0.35 0.52 0.51 0.52 to fix our structural parameter levels so that we can continue to explore the influence of the input data, we’ll select the median of the optimal setting of circle_fit_iou_pct and convexity_pct by CHM resolution levels and spectral weighting. This will result in no one CHM resolution and spectral weighting combination using it’s optimal circle_fit_iou_pct and convexity_pct setting but will provide us with values in the plausible range of optimal settings that work across the CHM resolutions tested with empirical data. structural_params_settings &lt;- vertex_draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( # get median_hdi circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$y # , median_hdi_lower_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymin # , median_hdi_upper_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymax # get median_hdi , convexity_pct = tidybayes::median_hdci(convexity_pct)$y # , median_hdi_lower_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymin # , median_hdi_upper_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymax ) %&gt;% dplyr::bind_cols( structural_params_settings ) # what? structural_params_settings %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 4 ## $ circle_fit_iou_pct &lt;dbl&gt; 0.35 ## $ convexity_pct &lt;dbl&gt; 0.36 ## $ max_ht_m &lt;dbl&gt; 2.3 ## $ max_area_m2 &lt;dbl&gt; 46 9.1.5.2 Input data to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m), we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct). the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy we’ll make contrasts of the posterior predictions to probabilistically quantify the influence of the input data (e.g. inclusion of spectral data and it’s weighting and CHM resolution). before we do this we’re going to borrow code from (Tinkham and Woolsey 2024) to make and plot the Bayesian contrasts ############################################ # make the variables for the contrast ############################################ make_contrast_vars &lt;- function(my_data){ my_data %&gt;% dplyr::mutate( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax # check probability of contrast , pr_gt_zero = mean(value &gt; 0) %&gt;% scales::percent(accuracy = 1) , pr_lt_zero = mean(value &lt; 0) %&gt;% scales::percent(accuracy = 1) # check probability that this direction is true , is_diff_dir = dplyr::case_when( median_hdi_est &gt;= 0 ~ value &gt; 0 , median_hdi_est &lt; 0 ~ value &lt; 0 ) , pr_diff = mean(is_diff_dir) # make a label , pr_diff_lab = dplyr::case_when( median_hdi_est &gt; 0 ~ paste0( &quot;Pr(&quot; , stringr::word(contrast, 1, sep = fixed(&quot;-&quot;)) %&gt;% stringr::str_squish() , &quot;&gt;&quot; , stringr::word(contrast, 2, sep = fixed(&quot;-&quot;)) %&gt;% stringr::str_squish() , &quot;)=&quot; , pr_diff %&gt;% scales::percent(accuracy = 1) ) , median_hdi_est &lt; 0 ~ paste0( &quot;Pr(&quot; , stringr::word(contrast, 2, sep = fixed(&quot;-&quot;)) %&gt;% stringr::str_squish() , &quot;&gt;&quot; , stringr::word(contrast, 1, sep = fixed(&quot;-&quot;)) %&gt;% stringr::str_squish() , &quot;)=&quot; , pr_diff %&gt;% scales::percent(accuracy = 1) ) ) # make a SMALLER label , pr_diff_lab_sm = dplyr::case_when( median_hdi_est &gt;= 0 ~ paste0( &quot;Pr(&gt;0)=&quot; , pr_diff %&gt;% scales::percent(accuracy = 1) ) , median_hdi_est &lt; 0 ~ paste0( &quot;Pr(&lt;0)=&quot; , pr_diff %&gt;% scales::percent(accuracy = 1) ) ) , pr_diff_lab_pos = dplyr::case_when( median_hdi_est &gt; 0 ~ median_hdi_upper , median_hdi_est &lt; 0 ~ median_hdi_lower ) * 1.075 , sig_level = dplyr::case_when( pr_diff &gt; 0.99 ~ 0 , pr_diff &gt; 0.95 ~ 1 , pr_diff &gt; 0.9 ~ 2 , pr_diff &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) } ############################################ # plot the contrast ############################################ plt_contrast &lt;- function( my_data , x = &quot;value&quot; , y = &quot;contrast&quot; , fill = &quot;pr_diff&quot; , label = &quot;pr_diff_lab&quot; , label_pos = &quot;pr_diff_lab_pos&quot; , label_size = 3 , x_expand = c(0.1, 0.1) , facet = NA , y_axis_title = &quot;&quot; , x_axis_title = &quot;difference&quot; , caption_text = &quot;&quot; # form_temp , annotate_size = 2.2 , annotate_which = &quot;both&quot; # &quot;both&quot;, &quot;left&quot;, &quot;right&quot; , include_zero = T ) { # df for annotation get_annotation_df &lt;- function( my_text_list = c( &quot;Bottom Left (h0,v0)&quot;,&quot;Top Left (h0,v1)&quot; ,&quot;Bottom Right h1,v0&quot;,&quot;Top Right h1,v1&quot; ) , hjust = c(0,0,1,1) # higher values = right, lower values = left , vjust = c(0,1.3,0,1.3) # higher values = down, lower values = up ){ df = data.frame( xpos = c(-Inf,-Inf,Inf,Inf) , ypos = c(-Inf, Inf,-Inf,Inf) , annotate_text = my_text_list , hjustvar = hjust , vjustvar = vjust ) return(df) } if(annotate_which==&quot;left&quot;){ text_list &lt;- c( &quot;&quot;,&quot;L.H.S. &lt; R.H.S.&quot; ,&quot;&quot;,&quot;&quot; ) }else if(annotate_which==&quot;right&quot;){ text_list &lt;- c( &quot;&quot;,&quot;&quot; ,&quot;&quot;,&quot;L.H.S. &gt; R.H.S.&quot; ) }else{ text_list &lt;- c( &quot;&quot;,&quot;L.H.S. &lt; R.H.S.&quot; ,&quot;&quot;,&quot;L.H.S. &gt; R.H.S.&quot; ) } # plot base plt &lt;- my_data %&gt;% ggplot(aes(x = .data[[x]], y = .data[[y]])) if(include_zero){ plt &lt;- plt + geom_vline(xintercept = 0, linetype = &quot;solid&quot;, color = &quot;gray33&quot;, lwd = 1.1) } # plot meat plt &lt;- plt + tidybayes::stat_halfeye( mapping = aes(fill = .data[[fill]]) , point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , point_size = 0.9 , justification = -0.01 ) + geom_text( data = get_annotation_df( my_text_list = text_list ) , mapping = aes( x = xpos, y = ypos , hjust = hjustvar, vjust = vjustvar , label = annotate_text , fontface = &quot;bold&quot; ) , size = annotate_size , color = &quot;gray30&quot; # &quot;#2d2a4d&quot; #&quot;#204445&quot; ) + # scale_fill_fermenter( # n.breaks = 5 # 10 use 10 if can go full range 0-1 # , palette = &quot;PuOr&quot; # &quot;RdYlBu&quot; # , direction = 1 # , limits = c(0.5,1) # use c(0,1) if can go full range 0-1 # , labels = scales::percent # ) + scale_fill_stepsn( n.breaks = 5 # 10 use 10 if can go full range 0-1 , colors = harrypotter::hp(n=5, option=&quot;ravenclaw&quot;, direction = -1) # RColorBrewer::brewer.pal(11,&quot;PuOr&quot;)[c(3,4,8,10,11)] , limits = c(0.5,1) # use c(0,1) if can go full range 0-1 , labels = scales::percent ) + scale_x_continuous(expand = expansion(mult = x_expand)) + labs( y = y_axis_title , x = x_axis_title , fill = &quot;Pr(contrast)&quot; , subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI&quot; , caption = caption_text ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1.05) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) # label or not if(!is.na(label) &amp;&amp; !is.na(label_pos) &amp;&amp; !is.na(label_size)){ plt &lt;- plt + geom_text( data = my_data %&gt;% dplyr::filter(pr_diff_lab_pos&gt;=0) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(tidyselect::all_of(c( y , fill , label , label_pos , facet ))) %&gt;% dplyr::distinct() , mapping = aes(x = .data[[label_pos]], label = .data[[label]]) , vjust = -1, hjust = 0, size = label_size ) + geom_text( data = my_data %&gt;% dplyr::filter(pr_diff_lab_pos&lt;0) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(tidyselect::all_of(c( y , fill , label , label_pos , facet ))) %&gt;% dplyr::distinct() , mapping = aes(x = .data[[label_pos]], label = .data[[label]]) , vjust = -1, hjust = +1, size = label_size ) } # return facet or not if(max(is.na(facet))==0){ return( plt + facet_grid(cols = vars(.data[[facet]])) ) } else{return(plt)} } now get the posterior predictive draws draws_temp &lt;- tidyr::crossing( structural_params_settings , param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight_fact, spectral_weight) , param_combos_spectral_ranked %&gt;% dplyr::distinct(chm_res_m) ) %&gt;% tidybayes::add_epred_draws(brms_f_score_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) # # huh? draws_temp %&gt;% dplyr::glimpse() ## Rows: 33,330 ## Columns: 12 ## Groups: circle_fit_iou_pct, convexity_pct, max_ht_m, max_area_m2, spectral_weight_fact, spectral_weight, chm_res_m, .row [30] ## $ circle_fit_iou_pct &lt;dbl&gt; 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0… ## $ convexity_pct &lt;dbl&gt; 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3,… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 4… ## $ spectral_weight_fact &lt;fct&gt; structural only, structural only, structural only… ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,… ## $ .row &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15… ## $ value &lt;dbl&gt; 0.8102877, 0.8088862, 0.8099895, 0.8118048, 0.811… 9.1.5.2.1 CHM resolution first, we’ll look at the impact of changing CHM resolution by the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). our questions regarding CHM resolution were: question 1: does CHM resolution influences detection accuracy? question 2: does the effect of CHM resolution change based on the inclusion of spectral data versus using only structural data? we can answer those questions using our model by considering the credible slope of the CHM resolution predictor as a function of the spectral_weight parameter (e.g. Kurz 2025; Kruschke (2015, Ch. 18)) pal_spectral_weight &lt;- c(&quot;gray77&quot;, harrypotter::hp(n=5, option = &quot;gryffindor&quot;, direction = 1)) # %&gt;% scales::show_col() # brms::posterior_summary(brms_f_score_mod) draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = chm_res_m, y = value, color = spectral_weight)) + # tidybayes::stat_halfeye() + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + # ggplot2::facet_wrap(facets = dplyr::vars(spectral_weight)) ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;F-score&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) there are a few takeaways from this plot: including spectral data and setting the spectral_weight to “1”, “2”, or “3” appears to be not much different than not including spectral data at all (but we’ll probabilistically test this later on) including spectral data and setting the spectral_weight to “4” yields a larger negative impact of decreasing CHM resolution on detection accuracy including spectral data and setting the spectral_weight to “5” yields a smaller negative impact of decreasing CHM resolution on detection accuracy and beyond a CHM resolution of ~0.13 m, detection accuracy is maximized when setting the spectral_weight to “5”. this makes intuitive sense because as the structural information about slash piles becomes less fine grain (i.e. more coarse), we should put more weight into the spectral data for detecting slash piles all of this is to say that the impact of CHM resolution varies based on the spectral_weight setting and vice-versa averaging across all other parameters to look at the main effect of including spectral data with the spectral_weight parameter, these results align with what we saw during our data summarization exploration: increasing the spectral_weight (where “5” requires all spectral index thresholds to be met) had minimal impact on metrics until a value of “3”, at which point F-score saw a minimal increase; at a spectral_weight of “4”, the F-score significantly improved, but at a value of “5” F-score was lower than not including the spectral data at all when CHM resolution was fine (e.g. &lt;0.3) but for coarse resolution CHM data the spectral data became more important for detection accuracy. let’s test including predictions at CHM resolutions outside of the bounds of the data tested (e.g. &gt; 0.5 m resolution) tidyr::crossing( structural_params_settings , param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight_fact, spectral_weight) , chm_res_m = seq(0.05,1,by = 0.05) ) %&gt;% tidybayes::add_epred_draws(brms_f_score_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = chm_res_m, y = value, color = spectral_weight)) + # tidybayes::stat_halfeye() + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + # ggplot2::facet_wrap(facets = dplyr::vars(spectral_weight)) ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(n=8)) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;F-score&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) even at the coarse CHM resolutions not represented in the data, the model is still confident that coarser resolution CHM data decreases detection accuracy we can look at the posterior distributions of the expected F-score at different CHM resolution levels by the inclusion (or exclusion) of spectral data and it’s weighting draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=chm_res_m)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = spectral_weight) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), labeller = &quot;label_both&quot;) + ggplot2::scale_fill_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(limits = c(0,NA), labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;F-score&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) table that draws_temp %&gt;% dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(spectral_weight, chm_res_m) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(spectral_weight, chm_res_m) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;F-score&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM resolution&quot; , c(&quot;F-score&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.4: F-score95% HDI of the posterior predictive distribution spectral_weight CHM resolution F-scoremedian HDI low HDI high spectral_weight: 0 0.1 80.9% 80.2% 81.5% 0.2 76.0% 75.3% 76.6% 0.3 70.3% 69.7% 70.9% 0.4 63.9% 63.1% 64.7% 0.5 57.0% 55.8% 58.1% spectral_weight: 1 0.1 80.9% 80.2% 81.6% 0.2 76.0% 75.4% 76.7% 0.3 70.3% 69.7% 71.0% 0.4 63.9% 63.1% 64.7% 0.5 57.0% 55.9% 58.1% spectral_weight: 2 0.1 80.9% 80.2% 81.6% 0.2 76.0% 75.4% 76.7% 0.3 70.3% 69.6% 70.9% 0.4 63.9% 63.1% 64.8% 0.5 57.0% 55.8% 58.1% spectral_weight: 3 0.1 81.3% 80.7% 82.1% 0.2 76.5% 76.0% 77.3% 0.3 70.9% 70.3% 71.5% 0.4 64.6% 63.8% 65.4% 0.5 57.7% 56.4% 58.7% spectral_weight: 4 0.1 84.9% 84.3% 85.5% 0.2 80.4% 79.9% 80.9% 0.3 74.9% 74.4% 75.6% 0.4 68.5% 67.8% 69.3% 0.5 61.4% 60.2% 62.4% spectral_weight: 5 0.1 84.4% 84.0% 85.0% 0.2 81.2% 80.8% 81.7% 0.3 77.5% 77.0% 78.0% 0.4 73.3% 72.6% 73.9% 0.5 68.6% 67.6% 69.5% now we’ll probabilistically test the hypothesis that coarser resolution CHM data results in lower detection accuracy and quantify by how much. we’ll look at the influence of CHM resolution based on the inclusion of spectral data (or exclusion) and it’s weighting determined by the spectral_weight parameter contrast_temp &lt;- draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::group_by(spectral_weight) %&gt;% tidybayes::compare_levels( value , by = chm_res_m , comparison = # &quot;control&quot; # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = chm_res_m) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(spectral_weight, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;CHM resolution contrast&quot; , x_axis_title = &quot;difference (F-score)&quot; , facet = &quot;spectral_weight&quot; , label_size = NA , x_expand = c(0,0.1) , annotate_which = &quot;left&quot; ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `spectral_weight`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( spectral_weight, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper , pr_lt_zero # , pr_gt_zero ) %&gt;% dplyr::arrange(spectral_weight, contrast) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM res. contrast&quot; , &quot;difference (F-score)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; , &quot;Pr(diff&lt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.5: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts spectral_weight CHM res. contrast difference (F-score) HDI low HDI high Pr(diff&lt;0) spectral_weight: 0 0.2 - 0.1 -4.9% -5.1% -4.7% 100% 0.3 - 0.1 -10.6% -11.2% -10.0% 100% 0.3 - 0.2 -5.7% -6.0% -5.4% 100% 0.4 - 0.1 -17.0% -17.9% -16.0% 100% 0.4 - 0.2 -12.1% -12.8% -11.3% 100% 0.4 - 0.3 -6.4% -6.8% -6.0% 100% 0.5 - 0.1 -23.9% -25.3% -22.4% 100% 0.5 - 0.2 -19.0% -20.2% -17.8% 100% 0.5 - 0.3 -13.3% -14.1% -12.4% 100% 0.5 - 0.4 -6.9% -7.3% -6.4% 100% spectral_weight: 1 0.2 - 0.1 -4.9% -5.1% -4.6% 100% 0.3 - 0.1 -10.6% -11.1% -10.0% 100% 0.3 - 0.2 -5.7% -6.0% -5.3% 100% 0.4 - 0.1 -17.0% -17.8% -15.9% 100% 0.4 - 0.2 -12.1% -12.8% -11.3% 100% 0.4 - 0.3 -6.4% -6.8% -6.0% 100% 0.5 - 0.1 -23.9% -25.2% -22.4% 100% 0.5 - 0.2 -19.0% -20.2% -17.8% 100% 0.5 - 0.3 -13.3% -14.1% -12.4% 100% 0.5 - 0.4 -6.9% -7.3% -6.4% 100% spectral_weight: 2 0.2 - 0.1 -4.9% -5.1% -4.7% 100% 0.3 - 0.1 -10.6% -11.1% -10.0% 100% 0.3 - 0.2 -5.7% -6.0% -5.3% 100% 0.4 - 0.1 -17.0% -17.9% -16.0% 100% 0.4 - 0.2 -12.1% -12.8% -11.3% 100% 0.4 - 0.3 -6.4% -6.8% -6.0% 100% 0.5 - 0.1 -23.9% -25.2% -22.5% 100% 0.5 - 0.2 -19.0% -20.1% -17.8% 100% 0.5 - 0.3 -13.3% -14.2% -12.5% 100% 0.5 - 0.4 -6.9% -7.4% -6.5% 100% spectral_weight: 3 0.2 - 0.1 -4.8% -5.1% -4.6% 100% 0.3 - 0.1 -10.4% -11.0% -9.9% 100% 0.3 - 0.2 -5.6% -6.0% -5.3% 100% 0.4 - 0.1 -16.8% -17.8% -15.8% 100% 0.4 - 0.2 -12.0% -12.7% -11.2% 100% 0.4 - 0.3 -6.3% -6.8% -5.9% 100% 0.5 - 0.1 -23.7% -25.2% -22.2% 100% 0.5 - 0.2 -18.8% -20.1% -17.6% 100% 0.5 - 0.3 -13.2% -14.1% -12.4% 100% 0.5 - 0.4 -6.9% -7.4% -6.4% 100% spectral_weight: 4 0.2 - 0.1 -4.5% -4.7% -4.3% 100% 0.3 - 0.1 -10.0% -10.5% -9.5% 100% 0.3 - 0.2 -5.5% -5.8% -5.2% 100% 0.4 - 0.1 -16.4% -17.2% -15.5% 100% 0.4 - 0.2 -11.9% -12.6% -11.3% 100% 0.4 - 0.3 -6.4% -6.8% -6.0% 100% 0.5 - 0.1 -23.6% -25.0% -22.4% 100% 0.5 - 0.2 -19.0% -20.1% -17.9% 100% 0.5 - 0.3 -13.6% -14.4% -12.7% 100% 0.5 - 0.4 -7.2% -7.6% -6.7% 100% spectral_weight: 5 0.2 - 0.1 -3.2% -3.4% -3.0% 100% 0.3 - 0.1 -6.9% -7.4% -6.5% 100% 0.3 - 0.2 -3.7% -4.0% -3.4% 100% 0.4 - 0.1 -11.2% -11.9% -10.3% 100% 0.4 - 0.2 -7.9% -8.5% -7.3% 100% 0.4 - 0.3 -4.2% -4.5% -3.9% 100% 0.5 - 0.1 -15.9% -17.0% -14.6% 100% 0.5 - 0.2 -12.6% -13.6% -11.6% 100% 0.5 - 0.3 -8.9% -9.6% -8.1% 100% 0.5 - 0.4 -4.7% -5.1% -4.3% 100% it is clear from these contrasts that coarser CHM resolutions lead to a decrease in detection accuracy. without the inclusion of spectral data (i.e. spectral_weight = “0”), a 0.1 m increase in CHM resolution coarseness results in an approximate decrease in F-score of ~5-7 percentage points. for example, the expected F-score decreases from 72% to 66% when moving from a 0.2 m resolution CHM raster to a 0.3 m raster, respectively. when spectral data is included, this trend of decreasing accuracy with coarser resolution persists, but there is a greater improvement in detection accuracy at coarser resolutions when making the resolution more granular. for example, when including spectral data and setting the spectral_weight parameter to “4” (i.e., requiring four spectral thresholds to be met), a shift from a 0.5 m resolution raster to a 0.3 m raster results in a substantial F-score increase of 14.5 percentage points, from 57% to 71%. 9.1.5.2.2 Spectral data now we’ll look at the impact of including (or excluding) spectral data and the weighting of the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). # viridis::rocket(5, begin = 0.9, end = 0.6) %&gt;% scales::show_col() # brms::posterior_summary(brms_f_score_mod) draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = spectral_weight, y = value, color = factor(chm_res_m))) + # tidybayes::stat_halfeye() + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + # ggplot2::facet_wrap(facets = dplyr::vars(spectral_weight)) ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, color = &quot;CHM resolution&quot;, y = &quot;F-score&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) there are a few takeaways from this plot: setting the spectral_weight to “3”, “4”, or “5” improves detection accuracy across CHM resolution levels whereas values of “1” or “2” appear to be similar to including no spectral data at all including spectral data and setting the spectral_weight to “5” results in a only a slight change in detection accuracy compared to a value of “4” for the finder resolution CHM data (e.g. 0.2 m or less) but beyond a CHM resolution of ~0.25 m detection accuracy is maximized when setting the spectral_weight to “5”. this makes intuitive sense because as the structural information about slash piles becomes less fine grain (i.e. more coarse), we should put more weight into the spectral data for detecting slash piles all of this is to say that the impact of spectral_weight varies based on the CHM resolution setting and vice-versa we can look at the posterior distributions of the expected F-score at different spectral_weight settings by the input CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=spectral_weight)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = chm_res_m) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(chm_res_m)) + ggplot2::scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(limits = c(0,NA), labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, y = &quot;F-score&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) we already saw this same data above in our CHM resolution testing, but we’ll table that again but this time grouping by CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(chm_res_m, spectral_weight) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(chm_res_m,spectral_weight) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;F-score&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , c(&quot;F-score&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.6: F-score95% HDI of the posterior predictive distribution CHM resolution spectral_weight F-scoremedian HDI low HDI high CHM resolution: 0.1 0 80.9% 80.2% 81.5% 1 80.9% 80.2% 81.6% 2 80.9% 80.2% 81.6% 3 81.3% 80.7% 82.1% 4 84.9% 84.3% 85.5% 5 84.4% 84.0% 85.0% CHM resolution: 0.2 0 76.0% 75.3% 76.6% 1 76.0% 75.4% 76.7% 2 76.0% 75.4% 76.7% 3 76.5% 76.0% 77.3% 4 80.4% 79.9% 80.9% 5 81.2% 80.8% 81.7% CHM resolution: 0.3 0 70.3% 69.7% 70.9% 1 70.3% 69.7% 71.0% 2 70.3% 69.6% 70.9% 3 70.9% 70.3% 71.5% 4 74.9% 74.4% 75.6% 5 77.5% 77.0% 78.0% CHM resolution: 0.4 0 63.9% 63.1% 64.7% 1 63.9% 63.1% 64.7% 2 63.9% 63.1% 64.8% 3 64.6% 63.8% 65.4% 4 68.5% 67.8% 69.3% 5 73.3% 72.6% 73.9% CHM resolution: 0.5 0 57.0% 55.8% 58.1% 1 57.0% 55.9% 58.1% 2 57.0% 55.8% 58.1% 3 57.7% 56.4% 58.7% 4 61.4% 60.2% 62.4% 5 68.6% 67.6% 69.5% now we’ll probabilistically test the hypothesis that the inclusion of spectral data improves detection accuracy and quantify by how much. we’ll look at the influence of spectral data based on the CHM resolution to actually compare the different levels of spectral_weight, we’ll use the MCMC draws to contrast the posterior predictions at different levels of the parameter (see below) contrast_temp &lt;- draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::group_by(chm_res_m) %&gt;% tidybayes::compare_levels( value , by = spectral_weight , comparison = # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = spectral_weight) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(chm_res_m, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;`spectral_weight` contrast&quot; , x_axis_title = &quot;difference (F-score)&quot; , facet = &quot;chm_res_m&quot; , label_size = 2 , x_expand = c(0.5,0.5) ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `chm_res_m`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( chm_res_m, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper # , pr_lt_zero , pr_gt_zero ) %&gt;% dplyr::arrange(chm_res_m, contrast) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , &quot;difference (F-score)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; # , &quot;Pr(diff&lt;0)&quot; , &quot;Pr(diff&gt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.7: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts CHM resolution spectral_weight difference (F-score) HDI low HDI high Pr(diff&gt;0) CHM resolution: 0.1 1 - 0 0.0% -0.8% 0.9% 50% 2 - 0 0.0% -0.9% 0.9% 49% 2 - 1 0.0% -0.9% 0.8% 51% 3 - 0 0.5% -0.5% 1.2% 84% 3 - 1 0.4% -0.4% 1.4% 83% 3 - 2 0.4% -0.4% 1.4% 84% 4 - 0 4.0% 3.2% 4.8% 100% 4 - 1 4.0% 3.2% 4.7% 100% 4 - 2 4.0% 3.3% 4.8% 100% 4 - 3 3.6% 2.8% 4.3% 100% 5 - 0 3.6% 2.8% 4.4% 100% 5 - 1 3.6% 2.8% 4.3% 100% 5 - 2 3.5% 2.9% 4.3% 100% 5 - 3 3.1% 2.3% 3.8% 100% 5 - 4 -0.5% -1.2% 0.1% 9% CHM resolution: 0.2 1 - 0 0.0% -0.7% 0.8% 52% 2 - 0 0.0% -0.8% 0.7% 51% 2 - 1 0.0% -0.8% 0.7% 50% 3 - 0 0.5% -0.3% 1.2% 91% 3 - 1 0.5% -0.2% 1.3% 90% 3 - 2 0.5% -0.2% 1.3% 92% 4 - 0 4.4% 3.7% 5.0% 100% 4 - 1 4.4% 3.8% 5.1% 100% 4 - 2 4.4% 3.8% 5.1% 100% 4 - 3 3.9% 3.3% 4.6% 100% 5 - 0 5.2% 4.6% 5.9% 100% 5 - 1 5.2% 4.5% 5.8% 100% 5 - 2 5.2% 4.6% 5.9% 100% 5 - 3 4.7% 4.1% 5.3% 100% 5 - 4 0.8% 0.2% 1.4% 100% CHM resolution: 0.3 1 - 0 0.0% -0.7% 0.8% 52% 2 - 0 0.0% -0.7% 0.7% 50% 2 - 1 0.0% -0.8% 0.7% 48% 3 - 0 0.6% -0.2% 1.3% 94% 3 - 1 0.6% -0.1% 1.3% 94% 3 - 2 0.6% -0.2% 1.2% 95% 4 - 0 4.6% 4.0% 5.3% 100% 4 - 1 4.6% 4.0% 5.3% 100% 4 - 2 4.6% 4.0% 5.4% 100% 4 - 3 4.0% 3.4% 4.7% 100% 5 - 0 7.2% 6.6% 7.8% 100% 5 - 1 7.2% 6.6% 7.8% 100% 5 - 2 7.2% 6.6% 7.8% 100% 5 - 3 6.6% 6.0% 7.2% 100% 5 - 4 2.6% 1.9% 3.1% 100% CHM resolution: 0.4 1 - 0 0.0% -0.9% 1.0% 52% 2 - 0 0.0% -1.0% 0.9% 52% 2 - 1 0.0% -1.0% 1.0% 48% 3 - 0 0.6% -0.3% 1.6% 89% 3 - 1 0.6% -0.3% 1.6% 89% 3 - 2 0.6% -0.4% 1.7% 89% 4 - 0 4.6% 3.6% 5.5% 100% 4 - 1 4.6% 3.8% 5.6% 100% 4 - 2 4.6% 3.7% 5.6% 100% 4 - 3 4.0% 3.0% 4.9% 100% 5 - 0 9.4% 8.5% 10.3% 100% 5 - 1 9.3% 8.5% 10.1% 100% 5 - 2 9.3% 8.4% 10.2% 100% 5 - 3 8.7% 7.8% 9.6% 100% 5 - 4 4.7% 3.9% 5.5% 100% CHM resolution: 0.5 1 - 0 0.0% -1.4% 1.5% 53% 2 - 0 0.0% -1.5% 1.4% 51% 2 - 1 0.0% -1.3% 1.5% 50% 3 - 0 0.7% -0.8% 2.1% 81% 3 - 1 0.6% -0.8% 2.1% 80% 3 - 2 0.6% -0.7% 2.3% 80% 4 - 0 4.4% 2.8% 5.8% 100% 4 - 1 4.4% 3.0% 5.7% 100% 4 - 2 4.3% 2.9% 5.7% 100% 4 - 3 3.7% 2.2% 5.0% 100% 5 - 0 11.6% 10.3% 12.9% 100% 5 - 1 11.6% 10.5% 13.0% 100% 5 - 2 11.6% 10.3% 12.9% 100% 5 - 3 10.9% 9.7% 12.4% 100% 5 - 4 7.2% 6.0% 8.4% 100% We’ve previously observed that setting the spectral_weight to “1” or “2” appears to have minimal impact on detection accuracy, with improvements only becoming apparent at levels of “3,” “4,” or “5.” These contrasts allow us to evaluate those hypotheses probabilistically. At a 0.2m CHM resolution, for example, there is no evidence that including spectral data but setting spectral_weight to “1” is better or worse than not including it at all (spectral_weight = “0”). Although setting spectral_weight to “3” provides a highly certain improvement in detection accuracy (~90% probability) compared to not using any spectral data, the improvement is small, at less than one percentage point. The model indicates with high certainty (&gt;99% probability) that the optimal setting for 0.2m CHM data is spectral_weight = “5,” which improves F-score by 6 percentage points compared to not including spectral data at all. For coarser CHM data (e.g., &gt;0.3m), we can be highly confident (&gt;99% probability) that spectral_weight set to “5” is the optimal setting for detection accuracy. At this setting, F-score is increased by 10 percentage points for 0.4m resolution rasters and by 12 percentage points for 0.5m resolution rasters when compared to not including spectral data at all. 9.2 Bayesian GLM - Diameter MAPE 9.2.1 Model selection we’re going to use a sub-sample of the data to perform model testing. our objective is to construct the model such that it faithfully represents the data. we reviewed the main effect parameter trends against MAPE here and used these to guide our model design. we’ll follow Kurz 2025 and compare our models with the LOO information criterion Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower estimates. # subsample data set.seed(222) ms_df_temp &lt;- param_combos_spectral_ranked %&gt;% dplyr::slice_sample(prop = 0.11) # mcmc setup iter_temp &lt;- 2444 warmup_temp &lt;- 1222 chains_temp &lt;- 4 #################################################################### # base model with form selected based on main effect trends #################################################################### diam_mape_mod1_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod1_temp&quot;) ) diam_mape_mod1_temp &lt;- brms::add_criterion(diam_mape_mod1_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by chm_res_m and vice-versa #################################################################### diam_mape_mod2_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod2_temp&quot;) ) diam_mape_mod2_temp &lt;- brms::add_criterion(diam_mape_mod2_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by convexity_pct and vice-versa #################################################################### diam_mape_mod3_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod3_temp&quot;) ) diam_mape_mod3_temp &lt;- brms::add_criterion(diam_mape_mod3_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### diam_mape_mod4_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod4_temp&quot;) ) diam_mape_mod4_temp &lt;- brms::add_criterion(diam_mape_mod4_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### diam_mape_mod5_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod5_temp&quot;) ) diam_mape_mod5_temp &lt;- brms::add_criterion(diam_mape_mod5_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### diam_mape_mod6_temp &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;diam_mape_mod6_temp&quot;) ) diam_mape_mod6_temp &lt;- brms::add_criterion(diam_mape_mod6_temp, criterion = &quot;loo&quot;) compare our models with the LOO information criterion. with the brms::loo_compare() function, we can compute a formal difference score between models with the output rank ordering the models such that the best fitting model appears on top. all models also receive a difference score relative to the best model and a standard error of the difference score brms::loo_compare( diam_mape_mod1_temp, diam_mape_mod2_temp, diam_mape_mod3_temp , diam_mape_mod4_temp, diam_mape_mod5_temp, diam_mape_mod6_temp ) %&gt;% kableExtra::kbl(caption = &quot;Diameter MAPE model selection with LOO information criterion&quot;) %&gt;% kableExtra::kable_styling() Table 9.8: Diameter MAPE model selection with LOO information criterion elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic diam_mape_mod6_temp 0.00000 0.000000 4858.224 230.2337 50.45998 8.675364 -9716.447 460.4674 diam_mape_mod4_temp -27.48832 9.248765 4830.735 230.5794 45.42794 7.940583 -9661.471 461.1589 diam_mape_mod5_temp -209.19202 23.057174 4649.032 209.4472 43.45478 7.092683 -9298.063 418.8943 diam_mape_mod3_temp -225.57831 23.411588 4632.645 210.1472 39.40540 6.586324 -9265.291 420.2943 diam_mape_mod2_temp -241.68897 25.707239 4616.535 208.9627 39.61183 6.834882 -9233.070 417.9254 diam_mape_mod1_temp -255.46016 25.441375 4602.764 209.4960 37.39897 6.526955 -9205.527 418.9920 we can also look at the AIC-type model weights brms::model_weights( diam_mape_mod1_temp, diam_mape_mod2_temp, diam_mape_mod3_temp , diam_mape_mod4_temp, diam_mape_mod5_temp, diam_mape_mod6_temp ) %&gt;% round(digits = 4) we can also quickly look at the Bayeisan \\(R^2\\) returned from the brms::bayes_R2() function dplyr::bind_rows( brms::bayes_R2(diam_mape_mod1_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod1_temp&quot;) , brms::bayes_R2(diam_mape_mod2_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod2_temp&quot;) , brms::bayes_R2(diam_mape_mod3_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod3_temp&quot;) , brms::bayes_R2(diam_mape_mod4_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod4_temp&quot;) , brms::bayes_R2(diam_mape_mod5_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod5_temp&quot;) , brms::bayes_R2(diam_mape_mod6_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;diam_mape_mod6_temp&quot;) ) %&gt;% dplyr::mutate(mod = factor(mod)) %&gt;% ggplot2::ggplot(mapping=ggplot2::aes(y=R2, x = mod)) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 ) + # ggplot2::facet_grid(cols = dplyr::vars(spectral_weight)) + # ggplot2::scale_fill_manual(values = pal_chm_res_m) + ggplot2::labs(x = &quot;&quot;, y = &quot;Bayesian R-squared&quot;) + ggplot2::theme_light() the more complex models were selected as the best. because the selected model includes quadratic terms and multiple interactions parameter interpretation will be a challenge, so we will have to rely on plotting the modeled relationships rather than trying to interpret the coefficients. 9.2.2 Modeling the selected MAPE model predicts diameter error using the four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) and data properties representing the CHM resolution (chm_res_m) and the use of spectral data (spectral_weight). The model includes quadratic terms for both chm_res_m and circle_fit_iou_pct to allow for non-linear relationships between these parameters and MAPE. To account for how different parameters influence each other, the model includes several interaction terms. The circle_fit_iou_pct:chm_res_m and the circle_fit_iou_pct:convexity_pct interactions were included to explore how the effect of the geometric filtering parameters varies with CHM resolution and with each other. In addition, the model includes spectral_weight as a main effect and in an interaction with chm_res_m. This means that the predicted MAPE can vary by the spectral_weight setting even when all other variables are zero (i.e. the intercept), effectively giving each level of spectral_weight its own unique intercept. Finally, the chm_res_m:spectral_weight interaction allows the effect of CHM resolution (i.e. its slope) on MAPE to vary across each spectral_weight setting. the fully factored Bayesian statistical model that details the likelihood, linear model, and priors used is: \\[\\begin{align*} \\text{MAPE}_i \\sim &amp; \\operatorname{Gamma}(\\mu_i, \\text{shape}) \\\\ \\log(\\mu_i) = &amp; (\\beta_1 \\cdot \\text{max_ht_m}_i) + (\\beta_2 \\cdot \\text{max_area_m2}_i) \\\\ &amp; + (\\beta_3 \\cdot \\text{convexity_pct}_i) + (\\beta_4 \\cdot (\\text{convexity_pct}_i)^2) \\\\ &amp; + (\\beta_5 \\cdot \\text{circle_fit_iou_pct}_i) + (\\beta_6 \\cdot (\\text{circle_fit_iou_pct}_i)^2) \\\\ &amp; + (\\beta_7 \\cdot \\text{chm_res_m}_i) + (\\beta_8 \\cdot (\\text{chm_res_m}_i)^2) \\\\ &amp; + \\sum_{j=0}^{5} \\left( \\beta_{9, j} \\cdot \\mathbf{I}(\\text{spectral_weight}_i = j) \\right) \\\\ &amp; + (\\beta_{10} \\cdot \\text{convexity_pct}_i \\cdot \\text{circle_fit_iou_pct}_i) \\\\ &amp; + (\\beta_{11} \\cdot \\text{convexity_pct}_i \\cdot \\text{chm_res_m}_i) \\\\ &amp; + (\\beta_{12} \\cdot \\text{circle_fit_iou_pct}_i \\cdot \\text{chm_res_m}_i) \\\\ &amp; + \\sum_{j=0}^{5} \\left( \\beta_{13, j} \\cdot \\text{chm_res_m}_i \\cdot \\mathbf{I}(\\text{spectral_weight}_i = j) \\right) \\\\ &amp; + (\\beta_{14} \\cdot \\text{convexity_pct}_i \\cdot \\text{circle_fit_iou_pct}_i \\cdot \\text{chm_res_m}_i) \\\\ \\beta_k \\sim &amp; \\operatorname{Student-t}(3, 0, 10) \\quad \\text{for } k = 1, \\dots, 14 \\\\ \\text{shape} \\sim &amp; \\operatorname{Gamma}(0.01, 0.01) \\end{align*}\\] where, \\(i\\) represents a single observation in the dataset which corresponds to a specific combination of the six parameters (, max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct, chm_res_m, and spectral_weight) and its resulting MAPE. Where k is used to index the different beta coefficients, which correspond to the intercept and the effects of each of the independent variables and their interactions and j denotes the specific level of the nominal (i.e. categorical) predictor spectral_weight we reviewed the main effect parameter trends against MAPE here and used these to guide our model design The table below details the terms used in our Bayesian GLM model defined in the brms::brm() call: Term in Formula Type of Effect Description of Relationship Tested 0 + Zero Intercept Specifies that the model is fit without a global intercept. The effect of each factor level and the value of continuous variables at zero is estimated directly. max_ht_m Main Effect (Linear) Tests the direct linear influence of the maximum pile height threshold on MAPE. max_area_m2 Main Effect (Linear) Tests the direct linear influence of the maximum pile area threshold on MAPE. chm_res_m Main Effect (Linear) Tests the direct linear influence of the input CHM resolution on MAPE. I(chm_res_m^2) Nonlinear (Quadratic) Models a curved relationship with CHM resolution, allowing MAPE to potentially decrease then increase (or vice versa) as resolution changes. spectral_weight Main Effect (Factor) The model estimates a coefficient for each of the six spectral weight levels (0 through 5), representing the estimated mean MAPE for that specific level when all continuous variables are zero. circle_fit_iou_pct Main Effect (Linear) Tests the direct linear influence of the pile’s circular conformity threshold on MAPE. convexity_pct Main Effect (Linear) Tests the direct linear influence of the pile’s boundary smoothness (convexity) threshold on MAPE. I(circle_fit_iou_pct^2) Nonlinear (Quadratic) Models a curved relationship where MAPE may peak or bottom out at an intermediate threshold for pile circularity. I(convexity_pct^2) Nonlinear (Quadratic) Models a curved relationship where MAPE may peak or bottom out at an intermediate threshold for pile boundary smoothness. convexity_pct:circle_fit_iou_pct Two-Way Interaction Captures how the optimal balance between pile circular conformity and boundary smoothness changes for MAPE. chm_res_m:spectral_weight Two-Way Interaction (Factor) Captures how the effect of CHM resolution’s slope on MAPE changes across each of the six spectral weighting levels. convexity_pct:chm_res_m Two-Way Interaction Captures how the sensitivity to the pile boundary smoothness threshold changes with the input data resolution. circle_fit_iou_pct:chm_res_m Two-Way Interaction Captures how the importance of the pile’s circular conformity threshold changes as the input data resolution changes. convexity_pct:circle_fit_iou_pct:chm_res_m Three-Way Interaction Shows how the combined effects of the convexity and circularity thresholds change simultaneously across different input CHM resolutions. brms_diam_mape_mod &lt;- brms::brm( formula = pct_diff_diameter_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = param_combos_spectral_ranked # %&gt;% dplyr::slice_sample(prop = 0.33) , family = Gamma(link = &quot;log&quot;) # mcmc , iter = 14000, warmup = 7000 , chains = 4 # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;brms_diam_mape_mod&quot;) ) # brms::make_stancode(brms_diam_mape_mod) # brms::prior_summary(brms_diam_mape_mod) # print(brms_diam_mape_mod) # brms::neff_ratio(brms_diam_mape_mod) # brms::rhat(brms_diam_mape_mod) # brms::nuts_params(brms_diam_mape_mod) The brms::brm model summary brms_diam_mape_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | parameter == &quot;phi&quot; ) %&gt;% kableExtra::kbl(digits = 3, caption = &quot;Bayesian model for Diameter MAPE&quot;) %&gt;% kableExtra::kable_styling() Table 9.9: Bayesian model for Diameter MAPE parameter estimate est.error q2.5 q97.5 b_max_ht_m 0.008 0.001 0.005 0.010 b_max_area_m2 0.001 0.000 0.001 0.001 b_convexity_pct 0.182 0.027 0.130 0.234 b_Iconvexity_pctE2 -0.305 0.017 -0.339 -0.271 b_circle_fit_iou_pct 0.430 0.031 0.370 0.492 b_Icircle_fit_iou_pctE2 -0.481 0.023 -0.526 -0.436 b_chm_res_m 6.855 0.063 6.733 6.979 b_Ichm_res_mE2 -5.378 0.080 -5.534 -5.221 b_spectral_weight0 -2.967 0.016 -2.999 -2.936 b_spectral_weight1 -2.967 0.016 -2.998 -2.936 b_spectral_weight2 -2.967 0.016 -2.999 -2.936 b_spectral_weight3 -2.967 0.016 -2.999 -2.936 b_spectral_weight4 -2.967 0.016 -2.998 -2.936 b_spectral_weight5 -2.902 0.016 -2.933 -2.871 b_convexity_pct:circle_fit_iou_pct -0.245 0.045 -0.334 -0.159 b_convexity_pct:chm_res_m -0.135 0.064 -0.261 -0.011 b_circle_fit_iou_pct:chm_res_m -0.924 0.072 -1.065 -0.783 b_chm_res_m:spectral_weight1 0.000 0.033 -0.064 0.065 b_chm_res_m:spectral_weight2 0.000 0.033 -0.064 0.064 b_chm_res_m:spectral_weight3 0.000 0.033 -0.064 0.064 b_chm_res_m:spectral_weight4 0.000 0.033 -0.064 0.065 b_chm_res_m:spectral_weight5 -0.114 0.033 -0.178 -0.049 b_convexity_pct:circle_fit_iou_pct:chm_res_m 1.372 0.131 1.117 1.631 note the quadratic coefficients ending in E2, Kruschke (2015) provides some insight on how to interpret: A quadratic has the form \\(y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^{2}\\). When \\(\\beta_{2}\\) is zero, the form reduces to a line. Therefore, this extended model can produce any fit that the linear model can. When \\(\\beta_{2}\\) is positive, a plot of the curve is a parabola that opens upward. When \\(\\beta_{2}\\) is negative, the curve is a parabola that opens downward. We have no reason to think that the curvature in the family-income data is exactly a parabola, but the quadratic trend might describe the data much better than a line alone. (p. 496) 9.2.3 Posterior Predictive Checks Markov chain Monte Carlo (MCMC) simulations were conducted using the brms package (Bürkner 2017) to estimate posterior predictive distributions of the parameters of interest. We ran 4 chains of 10,000 iterations with the first 5,000 discarded as burn-in. Trace-plots were utilized to visually assess model convergence. check the trace plots for problems with convergence of the Markov chains plot(brms_diam_mape_mod) Sufficient convergence was checked with \\(\\hat{R}\\) values near 1 (Brooks &amp; Gelman, 1998). in the plot below, \\(\\hat{R}\\) values are colored using different shades (lighter is better). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: below 1.05 (good) mid: between 1.05 and 1.1 (ok) dark: above 1.1 (too high) check our \\(\\hat{R}\\) values brms::mcmc_plot(brms_diam_mape_mod, type = &quot;rhat_hist&quot;) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(n = 6)) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) The effective length of an MCMC chain is indicated by the effective sample size (ESS), which refers to the sample size of the MCMC chain not to the sample size of the data where acceptable values allow “for reasonably accurate and stable estimates of the limits of the 95% HDI…If accuracy of the HDI limits is not crucial for your application, then a smaller ESS may be sufficient” (Kruschke 2015, p. 184) Ratios of effective sample size (ESS) to total sample size with values are colored using different shades (lighter is better). A ratio close to “1” (no autocorrelation) is ideal, while a low ratio suggests the need for more samples or model re-parameterization. Efficiently mixing MCMC chains are important because they guarantee the resulting posterior samples accurately represent the true distribution of model parameters, which is necessary for reliable and precise estimation of parameter values and their associated uncertainties (credible intervals). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: between 0.5 and 1 (high) mid: between 0.1 and 0.5 (good) dark: below 0.1 (low) # and another effective sample size check brms::mcmc_plot(brms_diam_mape_mod, type = &quot;neff_hist&quot;) + # brms::mcmc_plot(brms_diam_mape_mod, type = &quot;neff&quot;) + ggplot2::scale_x_continuous(limits = c(0,NA), breaks = scales::breaks_extended(n = 9)) + # ggplot2::scale_color_discrete(drop = F) + # ggplot2::scale_fill_discrete(drop = F) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) Posterior predictive checks were used to evaluate model goodness-of-fit by comparing data simulated from the model with the observed data used to estimate the model parameters (Hobbs &amp; Hooten, 2015). Calculating the proportion of MCMC iterations in which the test statistic (i.e., mean and sum of squares) from the simulated data and observed data are more extreme than one another provides the Bayesian p-value. Lack of fit is indicated by a value close to 0 or 1 while a value of 0.5 indicates perfect fit (Hobbs &amp; Hooten, 2015). To learn more about this approach to posterior predictive checks, check out Gabry’s (2025) vignette, Graphical posterior predictive checks using the bayesplot package. posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data. our objective is to construct the model such that it faithfully represents the data. # posterior predictive check brms::pp_check( brms_diam_mape_mod , type = &quot;dens_overlay&quot; , ndraws = 100 ) + ggplot2::labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + ggplot2::theme_light() + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) , plot.subtitle = ggplot2::element_text(size = 8) , plot.title = ggplot2::element_text(size = 9) ) another way brms::pp_check(brms_diam_mape_mod, type = &quot;ecdf_overlay&quot;, ndraws = 100) + ggplot2::labs(subtitle = &quot;posterior-predictive check (ECDF: empirical cumulative distribution function)&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) ) 9.2.4 Conditional Effects first, lets look at densities of the posterior samples per parameter brms::mcmc_plot(brms_diam_mape_mod, type = &quot;dens&quot;) + # ggplot2::theme_light() + ggplot2::theme( strip.text = ggplot2::element_text(size = 7.5, face = &quot;bold&quot;, color = &quot;black&quot;) ) and we can look at the default coefficient plot that is commonly used in reporting coefficient “significance” in frequentist analysis # easy way to get the default coeff plot brms::mcmc_plot(brms_diam_mape_mod, variable = &quot;\\\\bb_&quot;, regex = T, type = &quot;intervals&quot;) Regarding interactions and polynomial models like the one we use, McElreath (2015) notes: parameters are the linear and square components of the curve, respectively. But that doesn’t make them transparent. You have to plot these model fits to understand what they are saying. (p. 112-113) all of the interactions and the quadradic trend of this model combine to make these coefficients by themselves uninterpretable as the coefficients are only meaningful in the context of the other terms in the interaction or by adding the quadratic component we can do this by checking for the main effects of the individual variables on F-score (averages across all other effects) brms::conditional_effects(brms_diam_mape_mod) 9.2.5 Posterior Predictive Expectation we will test our hypotheses using the posterior distributions of the expected values (i.e., the posterior predictions of the mean) obtained via tidybayes::add_epred_draws(). our analysis will include two stages using parameter levels of the four structural parameters: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct. in practice, these values should be informed by the treatment prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct are fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy as a reminder, here are those parameter levels structural_params_settings %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 4 ## $ circle_fit_iou_pct &lt;dbl&gt; 0.35 ## $ convexity_pct &lt;dbl&gt; 0.36 ## $ max_ht_m &lt;dbl&gt; 2.3 ## $ max_area_m2 &lt;dbl&gt; 46 now we’ll get the posterior predictive draws but over a range of circle_fit_iou_pct and convexity_pct including the best setting seq_temp &lt;- seq(from = 0.05, to = 1.0, by = 0.1) seq2_temp &lt;- seq_temp[seq(1, length(seq_temp), by = 2)] # get every other element # draws draws_temp &lt;- # get the draws for levels of # spectral_weight circle_fit_iou_pct convexity_pct tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight) , circle_fit_iou_pct = seq_temp %&gt;% unique() , convexity_pct = seq_temp %&gt;% unique() , chm_res_m = seq(from = 0.1, to = 1.0, by = 0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% # dplyr::glimpse() tidybayes::add_epred_draws(brms_diam_mape_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate( is_seq = (convexity_pct %in% seq_temp) &amp; (circle_fit_iou_pct %in% seq_temp) ) # # huh? draws_temp %&gt;% dplyr::glimpse() ## Rows: 6,666,000 ## Columns: 12 ## Groups: spectral_weight, circle_fit_iou_pct, convexity_pct, chm_res_m, max_ht_m, max_area_m2, .row [6,000] ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ convexity_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .row &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ value &lt;dbl&gt; 0.1045783, 0.1045749, 0.1026696, 0.1045097, 0.10403… ## $ is_seq &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU… 9.2.5.1 Geometric shape regularity let’s look at the influence of the parameters that control the geometric shape regularity filtering: circle_fit_iou_pct and convexity_pct. to do this, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy 9.2.5.1.1 circle_fit_iou_pct we need to look at the influence of circle_fit_iou_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.2) , convexity_pct %in% seq2_temp ) %&gt;% dplyr::mutate(convexity_pct = factor(convexity_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct, y = value, color = convexity_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.95) , lwd = 1.1, fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;, scales = &quot;free_y&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;mako&quot;, begin = 0.6, end = 0.1) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `circle_fit_iou_pct` on Diameter MAPE&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`circle_fit_iou_pct`&quot; , y = &quot;Diameter MAPE&quot; , color = &quot;`convexity_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) For all of these faceted plots, take note of the narrow range of the y-axis (Predicted Diameter MAPE), which is particularly narrow for finer resolution CHM data (e.g., &lt;0.3m). The non-linear relationship between the circle_fit_iou_pct parameter and the Diameter MAPE is prominent, especially for coarser resolution CHM data. This is confirmed by the statistical model’s negative quadratic coefficient for the squared term of circle_fit_iou_pct (i.e., I(circle_fit_iou_pct^2)), which indicates a downward-opening parabolic shape. Across all CHM resolutions and irrespective of the spectral_weight setting, diameter quantification accuracy is highest (MAPE is lowest) at the highest values of the circle_fit_iou_pct parameter (e.g., greater than 0.6). This finding is intuitive: diameter error is calculated only for True Positive matches, and when a successful match is made between a prediction and a ground truth pile at these high circularity thresholds, it strongly suggests the predicted pile perimeter accurately conforms to the ground truth pile shape. The influence of the circle_fit_iou_pct parameter on diameter accuracy is conditional on the convexity_pct parameter setting. The relationship between these parameters is most evident with coarser resolution CHM data (e.g., &gt;0.3m) and looking at cases when convexity_pct parameter is set low (e.g., less than 0.4) the best diameter quantification accuracy occurs when the circle_fit_iou_pct parameter is set high (e.g., greater than 0.5), and vice-versa. This effect occurs because both parameters function as geometric shape filters in the rules-based methodology. When the piles in the treatment area are generally uniform (e.g., mostly circular), the parameters become somewhat redundant. However, when pile shapes are heterogeneous, these two filtering parameters must be balanced to fine-tune the retention of objects. For instance, if piles are expected to be rectangular, the optimal setting would be to effectively disable the circle_fit_iou_pct filter (i.e., set it to ‘0’) and rely on the convexity_pct filter to retain objects with the expected perimeter regularity. Finally, the circle_fit_iou_pct parameter has a smaller influence on diameter quantification accuracy with finer resolution CHM data (e.g., &lt;0.3m) and a larger influence on Diameter MAPE for coarser CHM data (e.g., &gt;0.3m). For the coarser CHM data, increasing values of the circle_fit_iou_pct parameter on the right side of the vertex increased diameter quantification accuracy (decreased MAPE) at an increasing rate as the parameter approached ‘1’. 9.2.5.1.2 convexity_pct we need to look at the influence of convexity_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.2) , circle_fit_iou_pct %in% seq2_temp ) %&gt;% dplyr::mutate(circle_fit_iou_pct = factor(circle_fit_iou_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct, y = value, color = circle_fit_iou_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.95) , lwd = 1.1 , fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;, scales = &quot;free_y&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;magma&quot;, begin = 0.5, end = 0.1) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `convexity_pct` on Diameter MAPE&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`convexity_pct`&quot; , y = &quot;Diameter MAPE&quot; , color = &quot;`circle_fit_iou_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) The model shows that the influence of the convexity_pct parameter on the Diameter MAPE is conditional on the CHM resolution. The magnitude of this influence varies significantly: for finer resolution CHM data (e.g., less than 0.3m), the convexity_pct parameter has a minimal impact on the Diameter MAPE, as evidenced by the narrow range of the y-axis; conversely, its influence is considerably larger at coarser resolutions. Across all CHM resolutions tested, it is clear that the influence of the circle_fit_iou_pct parameter on diameter accuracy is conditional on the convexity_pct parameter setting. This relationship is most pronounced with coarser resolution CHM data (e.g., greater than 0.3m). For example, using 0.5m CHM data, the vertex of the downward-opening parabola (which indicates the largest diameter quantification error) shifts across the convexity_pct range: it is located at lower convexity_pct values (i.e., less than 0.5) when the circle_fit_iou_pct parameter is set low (e.g., less than 0.4), but shifts to higher convexity_pct values (i.e., greater than 0.6) when the circle_fit_iou_pct parameter is set high (e.g., greater than 0.6). This inverse relationship occurs because both parameters function as geometric shape filters in the rules-based methodology. For the test data, where piles generally exhibit regular, circular footprints, the two filters become somewhat redundant. Therefore, the lowest Diameter MAPE (highest accuracy) is achieved when the parameters are complementary: when circle_fit_iou_pct is high (near 1) and convexity_pct is low (near 0), or vice-versa. Additionally, if circle_fit_iou_pct is at an intermediate level (near 0.5), convexity_pct should be set either high or low to maintain diameter quantification accuracy. It is important to note though, that these relationships are specific to regularly shaped circular pile footprints; if pile bases are expected to be square or rectangular, the parameters should be rebalanced. For instance, in a scenario predicting rectangular piles, the optimal setting would be to effectively disable the circle_fit_iou_pct filter (set to ‘0’) and instead rely on the convexity_pct filter to enforce the expected shape regularity filtering. 9.2.5.1.3 Optimizing geometric filtering Given the complexity of our model, which includes a non-linear link function and parameter interactions, calculating the optimal parameter values by solving for them algebraically from the model’s coefficients would be prone to error. instead, we can use a robust Bayesian approach that leverages the model’s posterior predictive distribution. This method is powerful because it inherently accounts for all sources of model uncertainty. first, we’ll generate a large number of predictions across a fine grid of parameter values (e.g. in steps of 0.01) for each posterior draw of the model coefficients. we’ll generate a large number (e.g. 1000+) of posterior predictive draws for each combination of parameter values. for each posterior predictive draw, we’ll then identify the parameter combination that maximizes the Diameter MAPE and we’ll be left with a posterior distribution of optimal parameter combinations. this approach demonstrates a key advantage of the Bayesian framework, allowing us to ask complex questions and find the most probable optimal parameter combination while fully accounting for uncertainty. note, we only extract draws based on not using any spectral data (i.e. spectral_weight = 0) to save on plotting space and because we expect form quantification to only be minimally influenced by the inclusion of spectral data # let&#39;s get the draws at a very granular level vertex_draws_temp &lt;- tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::filter(spectral_weight==&quot;0&quot;) %&gt;% dplyr::distinct(spectral_weight, spectral_weight_fact) , circle_fit_iou_pct = seq(from = 0.0, to = 1, by = 0.01) # very granular to identify vertex , convexity_pct = seq(from = 0.0, to = 1, by = 0.02) # very granular to identify vertex , chm_res_m = seq(0.1,0.5,by=0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% tidybayes::add_epred_draws(brms_diam_mape_mod, ndraws = 1000, value = &quot;value&quot;) %&gt;% dplyr::ungroup() %&gt;% # for each draw, get the highest Diameter MAPE by chm_res_m, spectral_weight # which we&#39;ll use to identify the optimal circle_fit_iou_pct,convexity_pct settings # these are essentially &quot;votes&quot; based on likelihood dplyr::group_by( .draw , chm_res_m, spectral_weight ) %&gt;% dplyr::arrange(value,circle_fit_iou_pct,convexity_pct) %&gt;% # notice the ascending sort of value (mape) here to take the lowest dplyr::slice(1) # vertex_draws_temp %&gt;% dplyr::glimpse() # this thing is huge plot the posterior distribution of optimal parameter setting for circle_fit_iou_pct vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + # ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(limits = c(0,1), breaks = scales::breaks_extended(6)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8) ) The optimal circle_fit_iou_pct setting for maximizing diameter quantification accuracy is predicted to be near it’s highest setting of ‘1’. This finding is likely not very applicable in real-world scenarios but it is intuitive: diameter error is calculated only for True Positive matches, and when a successful match is made between a prediction and a ground truth pile at these high circularity thresholds, it strongly suggests the predicted pile perimeter accurately conforms to the ground truth pile shape. plot the posterior distribution of optimal parameter setting for convexity_pct vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_x_continuous(limits = c(0,1), breaks = scales::breaks_extended(6)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) when the circle_fit_iou_pct parameter is optimized (i.e. set near ‘1’), the influence of convexity_pct on form quantification accuracy is dependent on the CHM resolution. only for the finest resolution CHM data (i.e. 0.1m) tested, the model’s predictions indicate with high certainty that the optimal convexity_pct is its maximum value of ‘1’. for coarser resolution CHM data (e.g. 0.3m), the 95% HDI for the optimal convexity_pct spans the entire 0-1 range, indicating the model is not confident in any specific setting. an important distinction is that this finding of irrelavance for the convexity_pct parameter on diameter quantification is only for cases when circle_fit_iou_pct is already optimized, which, as shown above, was at a level near 1 for this coarser-resolution CHM data. at these higher circle_fit_iou_pct levels , the filtering for irregularly shaped objects is accomplished solely by the circle_fit_iou_pct parameter so the convexity_pct is less important for accurate quantification of predicted diameter. however, when the circle_fit_iou_pct parameter is not optimized or is turned off (e.g., set to 0), convexity_pct becomes a crucial parameter for filtering irregularly shaped objects. we can look at this another way, check it vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = convexity_pct, x = circle_fit_iou_pct)) + # geom_point(alpha=0.2) + ggplot2::geom_jitter(alpha=0.2, height = .01, width = 0.0) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) # , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; ) + # ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(limits = c(0,1)) + # ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) note, in the plot above, we slightly “jitter” the points so that they are visible where they would otherwise be stacked on top of each other and only look like a few points instead of the 1000 draws from the posterior we used let’s table the HDI of the optimal values # summarize it vertex_draws_temp &lt;- vertex_draws_temp %&gt;% dplyr::group_by( chm_res_m, spectral_weight ) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$y , median_hdi_lower_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymin , median_hdi_upper_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymax # get median_hdi , median_hdi_est_convexity_pct = tidybayes::median_hdci(convexity_pct)$y , median_hdi_lower_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymin , median_hdi_upper_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymax ) %&gt;% dplyr::ungroup() # table it vertex_draws_temp %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , rep(c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;),2) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;circle_fit_iou_pct&quot; = 3 , &quot;convexity_pct&quot; = 3 )) Table 9.10: circle_fit_iou_pct convexity_pct CHM resolution spectral_weight median HDI low HDI high median HDI low HDI high 0.1 0 1 1 1 1 1 1 0.2 0 1 1 1 1 1 1 0.3 0 1 1 1 0 0 1 0.4 0 1 1 1 0 0 0 0.5 0 1 1 1 0 0 0 9.2.5.2 Input data to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m), we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct). the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy we’ll make contrasts of the posterior predictions to probabilistically quantify the influence of the input data (e.g. inclusion of spectral data and it’s weighting and CHM resolution) let’s get the posterior predictive draws # structural_params_settings draws_temp &lt;- tidyr::crossing( structural_params_settings , param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight_fact, spectral_weight) , param_combos_spectral_ranked %&gt;% dplyr::distinct(chm_res_m) ) %&gt;% tidybayes::add_epred_draws(brms_diam_mape_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) # # huh? # draws_temp %&gt;% dplyr::glimpse() 9.2.5.2.1 CHM resolution first, we’ll look at the impact of changing CHM resolution by the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). our questions regarding CHM resolution were: question 1: does CHM resolution influence quantification accuracy? question 2: does the effect of CHM resolution change based on the inclusion of spectral data versus using only structural data? we can answer those questions using our model by considering the credible slope of the CHM resolution predictor as a function of the spectral_weight parameter (e.g. Kurz 2025; Kruschke (2015, Ch. 18)) draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = chm_res_m, y = value, color = spectral_weight)) + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;Diameter MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) the primary takeaway from this plot is that coarser resolution CHM data produces significantly worse diameter quantification accuracy (i.e. higher MAPE) irrespective of the inclusion of spectral data or it’s weighting. if the objective is to quantify slash pile form with any sort of accuracy, a CHM resolution of 0.2m or finer is needed. based on the vertex of the parabola, the optimal CHM resolution for accurately quantifying diameter is between 0.1m and 0.2m. remember that the inclusion of spectral data in the data fusion detection methodology does not alter candidate pile form nor add new piles, so we don’t expect much variability in quantification accuracy at a given CHM resolution based on the inclusion of spectral data. any changes in overall pile quantification accuracy (e.g. when aggregated to the stand level) from the inclusion of spectral data is a result of the spectral data filtering out candidate piles that would otherwise alter the overall, aggregated accuracy. we can look at the posterior distributions of the expected Diameter MAPE at different CHM resolution levels by the inclusion (or exclusion) of spectral data and it’s weighting draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=chm_res_m)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = spectral_weight) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), labeller = &quot;label_both&quot;) + ggplot2::scale_fill_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;Diameter MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) those are some tight posterior distributions and HDI’s, meaning our model is very confident in the expected diameter accuracy at the CHM resolutions tested. put another way, the output from our pile detection methodology is consistent in terms of quantification of detected pile diameter and it’s error relative to field-measured values. table that draws_temp %&gt;% dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(spectral_weight, chm_res_m) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(spectral_weight, chm_res_m) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;Diameter MAPE&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM resolution&quot; , c(&quot;Diameter MAPE&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.11: Diameter MAPE95% HDI of the posterior predictive distribution spectral_weight CHM resolution Diameter MAPEmedian HDI low HDI high spectral_weight: 0 0.1 10.9% 10.8% 11.1% 0.2 18.1% 17.9% 18.3% 0.3 26.9% 26.7% 27.1% 0.4 35.9% 35.6% 36.2% 0.5 43.1% 42.6% 43.6% spectral_weight: 1 0.1 10.9% 10.8% 11.1% 0.2 18.1% 17.9% 18.3% 0.3 26.9% 26.7% 27.1% 0.4 35.9% 35.6% 36.2% 0.5 43.1% 42.6% 43.6% spectral_weight: 2 0.1 10.9% 10.8% 11.1% 0.2 18.1% 17.9% 18.3% 0.3 26.9% 26.7% 27.1% 0.4 35.9% 35.6% 36.2% 0.5 43.1% 42.5% 43.6% spectral_weight: 3 0.1 10.9% 10.8% 11.1% 0.2 18.1% 17.9% 18.3% 0.3 26.9% 26.7% 27.2% 0.4 35.9% 35.6% 36.3% 0.5 43.1% 42.6% 43.6% spectral_weight: 4 0.1 10.9% 10.8% 11.1% 0.2 18.1% 17.9% 18.3% 0.3 26.9% 26.7% 27.1% 0.4 35.9% 35.6% 36.3% 0.5 43.1% 42.5% 43.6% spectral_weight: 5 0.1 11.5% 11.4% 11.7% 0.2 18.9% 18.7% 19.0% 0.3 27.8% 27.5% 28.0% 0.4 36.6% 36.3% 37.0% 0.5 43.4% 42.9% 44.0% now we’ll probabilistically test the hypothesis that coarser resolution CHM data results in lower diameter quantification accuracy and determine by how much. we’ll look at the influence of CHM resolution based on the inclusion of spectral data (or exclusion) and it’s weighting determined by the spectral_weight parameter we’ll only make contrasts against the lowest CHM resolution tested which will be treated as a “control” in the tidybayes::compare_levels() call contrast_temp &lt;- draws_temp %&gt;% dplyr::group_by(spectral_weight) %&gt;% tidybayes::compare_levels( value , by = chm_res_m , comparison = &quot;control&quot; # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) # &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = chm_res_m) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(spectral_weight, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;CHM resolution contrast&quot; , x_axis_title = &quot;difference (Diameter MAPE)&quot; , facet = &quot;spectral_weight&quot; , label_size = 2.5 , x_expand = c(0.1,0.6) # , annotate_which = &quot;right&quot; ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `spectral_weight`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( spectral_weight, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper , pr_gt_zero # , pr_lt_zero ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::arrange(spectral_weight, contrast) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM res. contrast&quot; , &quot;difference (Diameter MAPE)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; , &quot;Pr(diff&gt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.12: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts spectral_weight CHM res. contrast difference (Diameter MAPE) HDI low HDI high Pr(diff&gt;0) spectral_weight: 0 0.2 - 0.1 7.2% 7.1% 7.3% 100% 0.3 - 0.1 16.0% 15.8% 16.2% 100% 0.4 - 0.1 25.0% 24.6% 25.3% 100% 0.5 - 0.1 32.1% 31.6% 32.7% 100% spectral_weight: 1 0.2 - 0.1 7.2% 7.1% 7.3% 100% 0.3 - 0.1 16.0% 15.8% 16.2% 100% 0.4 - 0.1 25.0% 24.7% 25.3% 100% 0.5 - 0.1 32.2% 31.6% 32.8% 100% spectral_weight: 2 0.2 - 0.1 7.2% 7.1% 7.3% 100% 0.3 - 0.1 16.0% 15.8% 16.2% 100% 0.4 - 0.1 25.0% 24.6% 25.3% 100% 0.5 - 0.1 32.1% 31.5% 32.6% 100% spectral_weight: 3 0.2 - 0.1 7.2% 7.1% 7.2% 100% 0.3 - 0.1 16.0% 15.8% 16.2% 100% 0.4 - 0.1 25.0% 24.7% 25.4% 100% 0.5 - 0.1 32.2% 31.6% 32.7% 100% spectral_weight: 4 0.2 - 0.1 7.2% 7.1% 7.3% 100% 0.3 - 0.1 16.0% 15.8% 16.2% 100% 0.4 - 0.1 25.0% 24.7% 25.4% 100% 0.5 - 0.1 32.2% 31.6% 32.7% 100% spectral_weight: 5 0.2 - 0.1 7.3% 7.3% 7.4% 100% 0.3 - 0.1 16.2% 16.0% 16.4% 100% 0.4 - 0.1 25.1% 24.8% 25.5% 100% 0.5 - 0.1 31.9% 31.3% 32.5% 100% it is clear from these contrasts that coarser CHM resolutions lead to a decrease in diameter quantification accuracy and the pattern and difference in accuracy between resolution levels is consistent whether or not spectral data is included and it’s weighting if included. taking the method that does not use spectral data as an example (i.e. spectral_weight = 0), the lowest diameter MAPE of 10.6% was achieved using a 0.1m CHM and the diameter quantification accuracy decreased (MAPE increased) steadily as CHM resolution became more coarse with a 41.8% diameter MAPE expected fore the 0.5 m resolution data. we can be certain (&gt;99% probability) that there is a significant decrease in diameter quantification accuracy (i.e. increase in MAPE) for coarser resolution CHM data compared to finer resolution data. 9.2.5.2.2 Spectral data now we’ll look at the impact of including (or excluding) spectral data and the weighting of the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). Note: we expect that the spectral data does not significantly alter the quantification of slash pile form. this is because spectral information is used solely to filter candidate piles, meaning it neither reshapes existing ones nor introduces new detections. # viridis::rocket(5, begin = 0.9, end = 0.6) %&gt;% scales::show_col() # brms::posterior_summary(brms_diam_mape_mod) draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = spectral_weight, y = value, color = factor(chm_res_m))) + # tidybayes::stat_halfeye() + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + # ggplot2::facet_wrap(facets = dplyr::vars(spectral_weight)) ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, color = &quot;CHM resolution&quot;, y = &quot;Diameter MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) while there is a slight decrease in diameter quantification accuracy (increase in MAPE) at the highest spectral weighting, the inclusion of spectral data and the setting of the spectral_weight parameter does not significantly alter the form quantification accuracy irrespective of the CHM resolution we can look at the posterior distributions of the expected Diameter MAPE at different spectral_weight settings by the input CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=spectral_weight)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = chm_res_m) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(chm_res_m)) + ggplot2::scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(limits = c(0,NA), labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, y = &quot;Diameter MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) we already saw this same data above in our CHM resolution testing, but we’ll table that again but this time grouping by CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(chm_res_m, spectral_weight) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(chm_res_m,spectral_weight) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;Diameter MAPE&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , c(&quot;Diameter MAPE&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.13: Diameter MAPE95% HDI of the posterior predictive distribution CHM resolution spectral_weight Diameter MAPEmedian HDI low HDI high CHM resolution: 0.1 0 10.9% 10.8% 11.1% 1 10.9% 10.8% 11.1% 2 10.9% 10.8% 11.1% 3 10.9% 10.8% 11.1% 4 10.9% 10.8% 11.1% 5 11.5% 11.4% 11.7% CHM resolution: 0.2 0 18.1% 17.9% 18.3% 1 18.1% 17.9% 18.3% 2 18.1% 17.9% 18.3% 3 18.1% 17.9% 18.3% 4 18.1% 17.9% 18.3% 5 18.9% 18.7% 19.0% CHM resolution: 0.3 0 26.9% 26.7% 27.1% 1 26.9% 26.7% 27.1% 2 26.9% 26.7% 27.1% 3 26.9% 26.7% 27.2% 4 26.9% 26.7% 27.1% 5 27.8% 27.5% 28.0% CHM resolution: 0.4 0 35.9% 35.6% 36.2% 1 35.9% 35.6% 36.2% 2 35.9% 35.6% 36.2% 3 35.9% 35.6% 36.3% 4 35.9% 35.6% 36.3% 5 36.6% 36.3% 37.0% CHM resolution: 0.5 0 43.1% 42.6% 43.6% 1 43.1% 42.6% 43.6% 2 43.1% 42.5% 43.6% 3 43.1% 42.6% 43.6% 4 43.1% 42.5% 43.6% 5 43.4% 42.9% 44.0% now we’ll probabilistically test the hypothesis that the inclusion of spectral data improves detection accuracy and quantify by how much. we’ll look at the influence of spectral data based on the CHM resolution to actually compare the different levels of spectral_weight, we’ll use the MCMC draws to contrast the posterior predictions at different levels of the parameter (see below) contrast_temp &lt;- draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::group_by(chm_res_m) %&gt;% tidybayes::compare_levels( value , by = spectral_weight , comparison = # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = spectral_weight) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(chm_res_m, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;`spectral_weight` contrast&quot; , x_axis_title = &quot;difference (Diameter MAPE)&quot; , facet = &quot;chm_res_m&quot; , label_size = 2 , x_expand = c(0.5,0.5) ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `chm_res_m`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( chm_res_m, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper # , pr_lt_zero , pr_gt_zero ) %&gt;% dplyr::arrange(chm_res_m, contrast) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , &quot;difference (Diameter MAPE)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; # , &quot;Pr(diff&lt;0)&quot; , &quot;Pr(diff&gt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.14: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts CHM resolution spectral_weight difference (Diameter MAPE) HDI low HDI high Pr(diff&gt;0) CHM resolution: 0.1 1 - 0 0.0% -0.2% 0.2% 47% 2 - 0 0.0% -0.2% 0.2% 50% 2 - 1 0.0% -0.2% 0.2% 53% 3 - 0 0.0% -0.2% 0.2% 49% 3 - 1 0.0% -0.2% 0.2% 50% 3 - 2 0.0% -0.2% 0.2% 50% 4 - 0 0.0% -0.2% 0.2% 48% 4 - 1 0.0% -0.2% 0.2% 51% 4 - 2 0.0% -0.2% 0.2% 50% 4 - 3 0.0% -0.2% 0.2% 51% 5 - 0 0.6% 0.4% 0.8% 100% 5 - 1 0.6% 0.4% 0.8% 100% 5 - 2 0.6% 0.4% 0.8% 100% 5 - 3 0.6% 0.4% 0.8% 100% 5 - 4 0.6% 0.4% 0.8% 100% CHM resolution: 0.2 1 - 0 0.0% -0.2% 0.2% 48% 2 - 0 0.0% -0.2% 0.2% 48% 2 - 1 0.0% -0.2% 0.2% 53% 3 - 0 0.0% -0.2% 0.2% 49% 3 - 1 0.0% -0.2% 0.2% 49% 3 - 2 0.0% -0.2% 0.2% 51% 4 - 0 0.0% -0.2% 0.2% 50% 4 - 1 0.0% -0.2% 0.2% 50% 4 - 2 0.0% -0.2% 0.2% 49% 4 - 3 0.0% -0.2% 0.2% 51% 5 - 0 0.8% 0.6% 1.0% 100% 5 - 1 0.8% 0.6% 1.0% 100% 5 - 2 0.8% 0.6% 1.0% 100% 5 - 3 0.8% 0.6% 1.0% 100% 5 - 4 0.8% 0.6% 1.0% 100% CHM resolution: 0.3 1 - 0 0.0% -0.2% 0.3% 49% 2 - 0 0.0% -0.2% 0.3% 47% 2 - 1 0.0% -0.2% 0.2% 50% 3 - 0 0.0% -0.2% 0.3% 48% 3 - 1 0.0% -0.2% 0.3% 51% 3 - 2 0.0% -0.2% 0.2% 51% 4 - 0 0.0% -0.2% 0.3% 49% 4 - 1 0.0% -0.2% 0.3% 50% 4 - 2 0.0% -0.2% 0.2% 51% 4 - 3 0.0% -0.2% 0.2% 51% 5 - 0 0.8% 0.6% 1.1% 100% 5 - 1 0.9% 0.6% 1.1% 100% 5 - 2 0.9% 0.6% 1.1% 100% 5 - 3 0.9% 0.6% 1.1% 100% 5 - 4 0.8% 0.6% 1.1% 100% CHM resolution: 0.4 1 - 0 0.0% -0.4% 0.4% 50% 2 - 0 0.0% -0.4% 0.4% 49% 2 - 1 0.0% -0.4% 0.4% 49% 3 - 0 0.0% -0.4% 0.3% 49% 3 - 1 0.0% -0.4% 0.4% 51% 3 - 2 0.0% -0.4% 0.4% 54% 4 - 0 0.0% -0.4% 0.4% 51% 4 - 1 0.0% -0.4% 0.4% 50% 4 - 2 0.0% -0.3% 0.4% 52% 4 - 3 0.0% -0.4% 0.4% 51% 5 - 0 0.7% 0.3% 1.1% 100% 5 - 1 0.7% 0.3% 1.1% 100% 5 - 2 0.7% 0.3% 1.1% 100% 5 - 3 0.7% 0.3% 1.1% 100% 5 - 4 0.7% 0.3% 1.1% 100% CHM resolution: 0.5 1 - 0 0.0% -0.6% 0.7% 50% 2 - 0 0.0% -0.6% 0.7% 51% 2 - 1 0.0% -0.7% 0.7% 48% 3 - 0 0.0% -0.7% 0.6% 51% 3 - 1 0.0% -0.6% 0.7% 50% 3 - 2 0.0% -0.6% 0.6% 52% 4 - 0 0.0% -0.7% 0.7% 53% 4 - 1 0.0% -0.6% 0.8% 51% 4 - 2 0.0% -0.6% 0.7% 51% 4 - 3 0.0% -0.6% 0.7% 49% 5 - 0 0.4% -0.3% 1.0% 85% 5 - 1 0.3% -0.3% 1.1% 84% 5 - 2 0.4% -0.3% 1.1% 86% 5 - 3 0.4% -0.4% 1.0% 86% 5 - 4 0.4% -0.3% 1.0% 84% although we can be very certain that there are differences in diameter quantification accuracy (&gt;99% probability across most CHM resolutions) when the spectral_weight is set to “5” (i.e. requiring that all spectral criteria be met) compared to the other settings of spectral_weight or not including spectral data, these differences are so small with nearly all of them showing a difference in diameter MAPE of &lt;1%. 9.3 Bayesian GLM - Height MAPE 9.3.1 Model selection we’re going to use a sub-sample of the data to perform model testing. our objective is to construct the model such that it faithfully represents the data. we reviewed the main effect parameter trends against MAPE here and used these to guide our model design. we’ll follow Kurz 2025 and compare our models with the LOO information criterion Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower estimates. # subsample data set.seed(222) ms_df_temp &lt;- param_combos_spectral_ranked %&gt;% dplyr::slice_sample(prop = 0.11) # mcmc setup iter_temp &lt;- 2444 warmup_temp &lt;- 1222 chains_temp &lt;- 4 #################################################################### # base model with form selected based on main effect trends #################################################################### height_mape_mod1_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod1_temp&quot;) ) height_mape_mod1_temp &lt;- brms::add_criterion(height_mape_mod1_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by chm_res_m and vice-versa #################################################################### height_mape_mod2_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod2_temp&quot;) ) height_mape_mod2_temp &lt;- brms::add_criterion(height_mape_mod2_temp, criterion = &quot;loo&quot;) #################################################################### # allows slope and curvature of circle_fit_iou_pct to vary by convexity_pct and vice-versa #################################################################### height_mape_mod3_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod3_temp&quot;) ) height_mape_mod3_temp &lt;- brms::add_criterion(height_mape_mod3_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### height_mape_mod4_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod4_temp&quot;) ) height_mape_mod4_temp &lt;- brms::add_criterion(height_mape_mod4_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### height_mape_mod5_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod5_temp&quot;) ) height_mape_mod5_temp &lt;- brms::add_criterion(height_mape_mod5_temp, criterion = &quot;loo&quot;) #################################################################### # a three-way interaction of circle_fit_iou_pct, convexity_pct and chm_res_m #################################################################### height_mape_mod6_temp &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = ms_df_temp , family = Gamma(link = &quot;log&quot;) # mcmc , iter = iter_temp, warmup = warmup_temp , chains = chains_temp # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;height_mape_mod6_temp&quot;) ) height_mape_mod6_temp &lt;- brms::add_criterion(height_mape_mod6_temp, criterion = &quot;loo&quot;) compare our models with the LOO information criterion. with the brms::loo_compare() function, we can compute a formal difference score between models with the output rank ordering the models such that the best fitting model appears on top. all models also receive a difference score relative to the best model and a standard error of the difference score brms::loo_compare( height_mape_mod1_temp, height_mape_mod2_temp, height_mape_mod3_temp , height_mape_mod4_temp, height_mape_mod5_temp, height_mape_mod6_temp ) %&gt;% kableExtra::kbl(caption = &quot;Height MAPE model selection with LOO information criterion&quot;) %&gt;% kableExtra::kable_styling() Table 9.15: Height MAPE model selection with LOO information criterion elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic height_mape_mod6_temp 0.0000 0.00000 6288.058 113.9030 44.88877 5.472842 -12576.12 227.8060 height_mape_mod5_temp -128.8016 11.38928 6159.256 118.7742 45.39308 5.826347 -12318.51 237.5484 height_mape_mod4_temp -240.8235 31.72005 6047.234 128.6006 46.03526 6.017574 -12094.47 257.2011 height_mape_mod3_temp -343.5301 34.92927 5944.528 133.4217 45.74430 6.183430 -11889.06 266.8435 height_mape_mod2_temp -345.5319 37.53070 5942.526 134.4929 40.24100 5.598372 -11885.05 268.9857 height_mape_mod1_temp -368.9222 44.36319 5919.136 140.7629 40.86776 5.809111 -11838.27 281.5258 we can also look at the AIC-type model weights brms::model_weights( height_mape_mod1_temp, height_mape_mod2_temp, height_mape_mod3_temp , height_mape_mod4_temp, height_mape_mod5_temp, height_mape_mod6_temp ) %&gt;% round(digits = 4) we can also quickly look at the Bayeisan \\(R^2\\) returned from the brms::bayes_R2() function dplyr::bind_rows( brms::bayes_R2(height_mape_mod1_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod1_temp&quot;) , brms::bayes_R2(height_mape_mod2_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod2_temp&quot;) , brms::bayes_R2(height_mape_mod3_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod3_temp&quot;) , brms::bayes_R2(height_mape_mod4_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod4_temp&quot;) , brms::bayes_R2(height_mape_mod5_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod5_temp&quot;) , brms::bayes_R2(height_mape_mod6_temp,summary=F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate(mod = &quot;height_mape_mod6_temp&quot;) ) %&gt;% dplyr::mutate(mod = factor(mod)) %&gt;% ggplot2::ggplot(mapping=ggplot2::aes(y=R2, x = mod)) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 ) + # ggplot2::facet_grid(cols = dplyr::vars(spectral_weight)) + # ggplot2::scale_fill_manual(values = pal_chm_res_m) + ggplot2::labs(x = &quot;&quot;, y = &quot;Bayesian R-squared&quot;) + ggplot2::theme_light() the more complex models were selected as the best. because the selected model includes quadratic terms and multiple interactions parameter interpretation will be a challenge, so we will have to rely on plotting the modeled relationships rather than trying to interpret the coefficients. 9.3.2 Modeling the fully factored Bayesian statistical model that details the likelihood, linear model, and priors used is the same as above for Diameter MAPE we reviewed the main effect parameter trends against MAPE here and used these to guide our model design brms_height_mape_mod &lt;- brms::brm( formula = pct_diff_height_m_mape ~ 0 + # no intercept to allow all values of spectral_weight to be shown instead of set as the baseline max_ht_m + max_area_m2 + convexity_pct + I(convexity_pct^2) + # changed from base model circle_fit_iou_pct + I(circle_fit_iou_pct^2) + # changed from base model convexity_pct:circle_fit_iou_pct + # changed from base model convexity_pct:chm_res_m + # changed from base model circle_fit_iou_pct:chm_res_m + # changed from base model convexity_pct:circle_fit_iou_pct:chm_res_m + # changed from base model chm_res_m + I(chm_res_m^2) + # changed from base model spectral_weight + chm_res_m:spectral_weight , data = param_combos_spectral_ranked # %&gt;% dplyr::slice_sample(prop = 0.33) , family = Gamma(link = &quot;log&quot;) # mcmc , iter = 14000, warmup = 7000 , chains = 4 # , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;brms_height_mape_mod&quot;) ) # brms::make_stancode(brms_height_mape_mod) # brms::prior_summary(brms_height_mape_mod) # print(brms_height_mape_mod) # brms::neff_ratio(brms_height_mape_mod) # brms::rhat(brms_height_mape_mod) # brms::nuts_params(brms_height_mape_mod) The brms::brm model summary brms_height_mape_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | parameter == &quot;phi&quot; ) %&gt;% kableExtra::kbl(digits = 3, caption = &quot;Bayesian model for Height MAPE&quot;) %&gt;% kableExtra::kable_styling() Table 9.16: Bayesian model for Height MAPE parameter estimate est.error q2.5 q97.5 b_max_ht_m 0.075 0.001 0.073 0.077 b_max_area_m2 0.002 0.000 0.002 0.002 b_convexity_pct 0.241 0.022 0.199 0.284 b_Iconvexity_pctE2 0.016 0.014 -0.012 0.043 b_circle_fit_iou_pct -0.750 0.025 -0.799 -0.701 b_Icircle_fit_iou_pctE2 0.333 0.019 0.295 0.370 b_chm_res_m -1.839 0.050 -1.938 -1.741 b_Ichm_res_mE2 3.247 0.065 3.119 3.375 b_spectral_weight0 -1.793 0.013 -1.818 -1.768 b_spectral_weight1 -1.793 0.013 -1.818 -1.768 b_spectral_weight2 -1.793 0.013 -1.818 -1.768 b_spectral_weight3 -1.793 0.013 -1.818 -1.768 b_spectral_weight4 -1.793 0.013 -1.818 -1.768 b_spectral_weight5 -1.817 0.013 -1.842 -1.792 b_convexity_pct:circle_fit_iou_pct 0.000 0.036 -0.070 0.069 b_convexity_pct:chm_res_m -0.788 0.052 -0.892 -0.685 b_circle_fit_iou_pct:chm_res_m 1.790 0.057 1.678 1.903 b_chm_res_m:spectral_weight1 0.000 0.026 -0.051 0.051 b_chm_res_m:spectral_weight2 0.000 0.026 -0.053 0.051 b_chm_res_m:spectral_weight3 0.000 0.026 -0.052 0.051 b_chm_res_m:spectral_weight4 0.000 0.027 -0.052 0.052 b_chm_res_m:spectral_weight5 0.057 0.026 0.006 0.110 b_convexity_pct:circle_fit_iou_pct:chm_res_m -0.199 0.106 -0.407 0.008 note the quadratic coefficients ending in E2, Kruschke (2015) provides some insight on how to interpret: A quadratic has the form \\(y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^{2}\\). When \\(\\beta_{2}\\) is zero, the form reduces to a line. Therefore, this extended model can produce any fit that the linear model can. When \\(\\beta_{2}\\) is positive, a plot of the curve is a parabola that opens upward. When \\(\\beta_{2}\\) is negative, the curve is a parabola that opens downward. We have no reason to think that the curvature in the family-income data is exactly a parabola, but the quadratic trend might describe the data much better than a line alone. (p. 496) 9.3.3 Posterior Predictive Checks Markov chain Monte Carlo (MCMC) simulations were conducted using the brms package (Bürkner 2017) to estimate posterior predictive distributions of the parameters of interest. We ran 4 chains of 10,000 iterations with the first 5,000 discarded as burn-in. Trace-plots were utilized to visually assess model convergence. check the trace plots for problems with convergence of the Markov chains plot(brms_height_mape_mod) Sufficient convergence was checked with \\(\\hat{R}\\) values near 1 (Brooks &amp; Gelman, 1998). in the plot below, \\(\\hat{R}\\) values are colored using different shades (lighter is better). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: below 1.05 (good) mid: between 1.05 and 1.1 (ok) dark: above 1.1 (too high) check our \\(\\hat{R}\\) values brms::mcmc_plot(brms_height_mape_mod, type = &quot;rhat_hist&quot;) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(n = 6)) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) The effective length of an MCMC chain is indicated by the effective sample size (ESS), which refers to the sample size of the MCMC chain not to the sample size of the data where acceptable values allow “for reasonably accurate and stable estimates of the limits of the 95% HDI…If accuracy of the HDI limits is not crucial for your application, then a smaller ESS may be sufficient” (Kruschke 2015, p. 184) Ratios of effective sample size (ESS) to total sample size with values are colored using different shades (lighter is better). A ratio close to “1” (no autocorrelation) is ideal, while a low ratio suggests the need for more samples or model re-parameterization. Efficiently mixing MCMC chains are important because they guarantee the resulting posterior samples accurately represent the true distribution of model parameters, which is necessary for reliable and precise estimation of parameter values and their associated uncertainties (credible intervals). The chosen thresholds are somewhat arbitrary, but can be useful guidelines in practice (Gabry and Mahr 2025): light: between 0.5 and 1 (high) mid: between 0.1 and 0.5 (good) dark: below 0.1 (low) # and another effective sample size check brms::mcmc_plot(brms_height_mape_mod, type = &quot;neff_hist&quot;) + # brms::mcmc_plot(brms_height_mape_mod, type = &quot;neff&quot;) + ggplot2::scale_x_continuous(limits = c(0,NA), breaks = scales::breaks_extended(n = 9)) + # ggplot2::scale_color_discrete(drop = F) + # ggplot2::scale_fill_discrete(drop = F) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; ) Posterior predictive checks were used to evaluate model goodness-of-fit by comparing data simulated from the model with the observed data used to estimate the model parameters (Hobbs &amp; Hooten, 2015). Calculating the proportion of MCMC iterations in which the test statistic (i.e., mean and sum of squares) from the simulated data and observed data are more extreme than one another provides the Bayesian p-value. Lack of fit is indicated by a value close to 0 or 1 while a value of 0.5 indicates perfect fit (Hobbs &amp; Hooten, 2015). To learn more about this approach to posterior predictive checks, check out Gabry’s (2025) vignette, Graphical posterior predictive checks using the bayesplot package. posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data. our objective is to construct the model such that it faithfully represents the data. # posterior predictive check brms::pp_check( brms_height_mape_mod , type = &quot;dens_overlay&quot; , ndraws = 100 ) + ggplot2::labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + ggplot2::theme_light() + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) , plot.subtitle = ggplot2::element_text(size = 8) , plot.title = ggplot2::element_text(size = 9) ) another way brms::pp_check(brms_height_mape_mod, type = &quot;ecdf_overlay&quot;, ndraws = 100) + ggplot2::labs(subtitle = &quot;posterior-predictive check (ECDF: empirical cumulative distribution function)&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = ggplot2::element_text(size = 14) ) 9.3.4 Conditional Effects first, lets look at densities of the posterior samples per parameter brms::mcmc_plot(brms_height_mape_mod, type = &quot;dens&quot;) + # ggplot2::theme_light() + ggplot2::theme( strip.text = ggplot2::element_text(size = 7.5, face = &quot;bold&quot;, color = &quot;black&quot;) ) and we can look at the default coefficient plot that is commonly used in reporting coefficient “significance” in frequentist analysis # easy way to get the default coeff plot brms::mcmc_plot(brms_height_mape_mod, variable = &quot;\\\\bb_&quot;, regex = T, type = &quot;intervals&quot;) Regarding interactions and polynomial models like the one we use, McElreath (2015) notes: parameters are the linear and square components of the curve, respectively. But that doesn’t make them transparent. You have to plot these model fits to understand what they are saying. (p. 112-113) all of the interactions and the quadradic trend of this model combine to make these coefficients by themselves uninterpretable as the coefficients are only meaningful in the context of the other terms in the interaction or by adding the quadratic component we can do this by checking for the main effects of the individual variables on Height MAPE (averages across all other effects) brms::conditional_effects(brms_height_mape_mod) 9.3.5 Posterior Predictive Expectation we will test our hypotheses using the posterior distributions of the expected values (i.e., the posterior predictions of the mean) obtained via tidybayes::add_epred_draws(). our analysis will include two stages using parameter levels of the four structural parameters: max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct. in practice, these values should be informed by the treatment prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct are fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy as a reminder, here are those parameter levels structural_params_settings %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 4 ## $ circle_fit_iou_pct &lt;dbl&gt; 0.35 ## $ convexity_pct &lt;dbl&gt; 0.36 ## $ max_ht_m &lt;dbl&gt; 2.3 ## $ max_area_m2 &lt;dbl&gt; 46 now we’ll get the posterior predictive draws but over a range of circle_fit_iou_pct and convexity_pct including the best setting seq_temp &lt;- seq(from = 0.05, to = 1.0, by = 0.1) seq2_temp &lt;- seq_temp[seq(1, length(seq_temp), by = 2)] # get every other element # draws draws_temp &lt;- # get the draws for levels of # spectral_weight circle_fit_iou_pct convexity_pct tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight) , circle_fit_iou_pct = seq_temp %&gt;% unique() , convexity_pct = seq_temp %&gt;% unique() , chm_res_m = seq(from = 0.1, to = 1.0, by = 0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% # dplyr::glimpse() tidybayes::add_epred_draws(brms_height_mape_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate( is_seq = (convexity_pct %in% seq_temp) &amp; (circle_fit_iou_pct %in% seq_temp) ) # # huh? draws_temp %&gt;% dplyr::glimpse() ## Rows: 6,666,000 ## Columns: 12 ## Groups: spectral_weight, circle_fit_iou_pct, convexity_pct, chm_res_m, max_ht_m, max_area_m2, .row [6,000] ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ convexity_pct &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .row &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ value &lt;dbl&gt; 0.1795179, 0.1804930, 0.1812731, 0.1823152, 0.18121… ## $ is_seq &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU… 9.3.5.1 Geometric shape regularity let’s look at the influence of the parameters that control the geometric shape regularity filtering: circle_fit_iou_pct and convexity_pct. to do this, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. In the first stage, we will fix the max_ht_m and max_area_m2 parameters at levels expected based on the treatment and slash pile construction prescription implemented on the ground. We will then explore the influence of the two geometric shape filtering parameters (circle_fit_iou_pct and convexity_pct) over different levels of the spectral_weight parameter and CHM resolution data. In the second stage, we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m). As in the first stage, the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy 9.3.5.1.1 circle_fit_iou_pct we need to look at the influence of circle_fit_iou_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.2) , convexity_pct %in% seq2_temp ) %&gt;% dplyr::mutate(convexity_pct = factor(convexity_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct, y = value, color = convexity_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.95) , lwd = 1.1 , fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;, scales = &quot;free_y&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;mako&quot;, begin = 0.6, end = 0.1) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `circle_fit_iou_pct` on Height MAPE&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`circle_fit_iou_pct`&quot; , y = &quot;Height MAPE&quot; , color = &quot;`convexity_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) For all of these faceted plots, note the variation in the y-axis (Predicted Height MAPE) range across different CHM resolution levels. The influence of the circle_fit_iou_pct parameter on the Height MAPE is dependent on the CHM resolution but, unlike diameter quantification, its trend does not change based on the convexity_pct parameter setting. The magnitude of this influence decreases with finer data: for the finest resolution CHM data (0.1m), changes in circle_fit_iou_pct only shift the MAPE by approximately 6 percentage points, while for the coarsest resolution CHM data (0.5m), the shift in MAPE is approximately 11 percentage points as circle_fit_iou_pct is varied. There is a notable shift in the influence of the circle_fit_iou_pct parameter as CHM resolution moves from fine to coarse. With fine resolution CHM data (0.1m), height quantification accuracy improves (MAPE decreases) as the circle_fit_iou_pct parameter is increased toward its highest setting of ‘1’, with improvements stabilizing around 0.6. For moderate resolution CHM data (0.3m), the parabolic relationship between the circle_fit_iou_pct parameter and the Height MAPE becomes evident. Height accuracy is optimized at low-intermediate levels of the circle_fit_iou_pct parameter (e.g., 0.25–0.5), and height quantification accuracy steeply declines (MAPE increases) for values set above this level. For coarse resolution CHM data (0.5m), there is a consistent decrease in height quantification accuracy (increase in MAPE) as the circle_fit_iou_pct parameter is increased toward its highest setting of ‘1’; this trend is opposite of what was found for the fine resolution CHM data. With coarse resolution CHM data, the best height accuracy is achieved at the lowest circle_fit_iou_pct parameter settings, near ‘0’. These seemingly conflicting trends likely occur because the coarser resolution CHM data smoothes out variation in height from the aerial point cloud, while the variability in the elevation profile within a detected slash pile is retained when using finer resolution data. 9.3.5.1.2 convexity_pct we need to look at the influence of convexity_pct in the context of the other terms in the interaction draws_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( is_seq , chm_res_m %in% seq(0.1,0.5,by=0.2) , circle_fit_iou_pct %in% seq2_temp ) %&gt;% dplyr::mutate(circle_fit_iou_pct = factor(circle_fit_iou_pct, ordered = T)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct, y = value, color = circle_fit_iou_pct)) + tidybayes::stat_lineribbon( point_interval = &quot;median_hdi&quot;, .width = c(0.95) , lwd = 1.1 , fill = NA ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), rows = dplyr::vars(chm_res_m), labeller = &quot;label_both&quot;, scales = &quot;free_y&quot;) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;magma&quot;, begin = 0.5, end = 0.1) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs( title = &quot;conditional effect of `convexity_pct` on Height MAPE&quot; # , subtitle = &quot;Faceted by spectral_weight and chm_res_m&quot; , x = &quot;`convexity_pct`&quot; , y = &quot;Height MAPE&quot; , color = &quot;`circle_fit_iou_pct`&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) The model shows that the influence of the convexity_pct parameter on the Height MAPE is primarily conditional on the CHM resolution. The circle_fit_iou_pct parameter further influences the relationship between convexity_pct and height quantification accuracy but only at intermediate CHM resolutions (0.3m). Conversely, at the finest (0.1m) and coarsest (0.5m) CHM data levels, the circle_fit_iou_pct parameter does not alter the relationship between convexity_pct and Height MAPE but alters the magnitude of the influence. The magnitude of the convexity_pct parameter’s influence on Height MAPE is lowest for intermediate CHM resolutions (0.3m), with changes in the parameter only resulting in approximately 1.5 percentage point shifts in MAPE. The influence is significantly larger for other resolutions, causing a 6 percentage point shift over the convexity_pct range at finer resolutions (e.g. 0.1m) and a 10 percentage point influence at coarser resolutions (e.g. 0.5m). There is a notable shift in the optimal trend of the convexity_pct parameter as CHM resolution changes. With fine resolution CHM data (0.1m), height quantification accuracy improves (MAPE decreases) in a very linear trend as the convexity_pct parameter is decreased toward its lowest setting of ‘0’. This indicates that allowing for less regular (more concave/less smooth) segments yields better height accuracy at the finest resolution. This trend reverses for coarse resolution CHM data (0.5m), where there is a consistent decrease in height quantification accuracy (increase in MAPE) as the convexity_pct parameter is decreased toward its lowest setting of ‘0’. With coarse resolution CHM data, the best height accuracy is achieved at the highest convexity_pct parameter settings, near ‘1’. This suggests that at coarser resolutions, a very strict shape requirement is necessary to minimize errors in height estimation. Additionally, for coarser resolution data, the penalty in height quantification accuracy for decreasing convexity_pct toward 0 is steeper when the circle_fit_iou_pct parameter is set to higher levels (e.g., greater than 0.65) than when circle_fit_iou_pct is set to lower values (e.g., less than 0.25). This heightened penalty occurs because simultaneously requiring a pile to be highly circular (circle_fit_iou_pct high) and allowing it to be highly irregular (convexity_pct low) introduces high geometric uncertainty into the segmented area used for height calculation, making such a parameter combination unlikely to be applicable for optimizing height quantification accuracy using this pile detection method. 9.3.5.1.3 Optimizing geometric filtering Given the complexity of our model, which includes a non-linear link function and parameter interactions, calculating the optimal parameter values by solving for them algebraically from the model’s coefficients would be prone to error. instead, we can use a robust Bayesian approach that leverages the model’s posterior predictive distribution. This method is powerful because it inherently accounts for all sources of model uncertainty. first, we’ll generate a large number of predictions across a fine grid of parameter values (e.g. in steps of 0.01) for each posterior draw of the model coefficients. we’ll generate a large number (e.g. 1000+) of posterior predictive draws for each combination of parameter values. for each posterior predictive draw, we’ll then identify the parameter combination that maximizes the Height MAPE and we’ll be left with a posterior distribution of optimal parameter combinations. this approach demonstrates a key advantage of the Bayesian framework, allowing us to ask complex questions and find the most probable optimal parameter combination while fully accounting for uncertainty. note, we only extract draws based on not using any spectral data (i.e. spectral_weight = 0) to save on plotting space and because we expect form quantification to only be minimally influenced by the inclusion of spectral data # let&#39;s get the draws at a very granular level vertex_draws_temp &lt;- tidyr::crossing( param_combos_spectral_ranked %&gt;% dplyr::filter(spectral_weight==&quot;0&quot;) %&gt;% dplyr::distinct(spectral_weight, spectral_weight_fact) , circle_fit_iou_pct = seq(from = 0.0, to = 1, by = 0.01) # very granular to identify vertex , convexity_pct = seq(from = 0.0, to = 1, by = 0.02) # very granular to identify vertex , chm_res_m = seq(0.1,0.5,by=0.1) , max_ht_m = structural_params_settings$max_ht_m , max_area_m2 = structural_params_settings$max_area_m2 ) %&gt;% tidybayes::add_epred_draws(brms_height_mape_mod, ndraws = 1000, value = &quot;value&quot;) %&gt;% dplyr::ungroup() %&gt;% # for each draw, get the highest Height MAPE by chm_res_m, spectral_weight # which we&#39;ll use to identify the optimal circle_fit_iou_pct,convexity_pct settings # these are essentially &quot;votes&quot; based on likelihood dplyr::group_by( .draw , chm_res_m, spectral_weight ) %&gt;% dplyr::arrange(value,circle_fit_iou_pct,convexity_pct) %&gt;% # notice the ascending sort of value (mape) here to take the lowest dplyr::slice(1) # vertex_draws_temp %&gt;% dplyr::glimpse() # this thing is huge plot the posterior distribution of optimal parameter setting for circle_fit_iou_pct vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = circle_fit_iou_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_x_continuous(limits = c(0,1)) + # ggplot2::scale_x_continuous(limits = c(0,1), breaks = scales::breaks_extended(6)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8) ) like we saw above, the optimal circle_fit_iou_pct for maximizing Height quantification accuracy shifts from higher (e.g. ~0.6-0.9) for fine resolution CHM data (e.g. &lt;=0.2m) to lower (e.g. &lt;0.25) for coarse resolution CHM data (e.g &gt;=0.4m) plot the posterior distribution of optimal parameter setting for convexity_pct vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = convexity_pct)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) when the circle_fit_iou_pct parameter is optimized, the influence of convexity_pct on form quantification accuracy is dependent on the CHM resolution. only for the finest resolution CHM data (i.e. 0.1m) tested, the model’s predictions indicate with high certainty that the optimal convexity_pct is its minimum value of ‘0’. for intermediate resolution CHM data (e.g. 0.3m), the 95% HDI for the optimal convexity_pct spans the entire 0-1 range, indicating the model is not confident in any specific setting. for the coarsest resolution CHM data (i.e. 0.5m) tested, the model’s predictions indicate with high certainty that the optimal convexity_pct is its maximum value of ‘1’ we can look at this another way, check it vertex_draws_temp %&gt;% dplyr::filter( chm_res_m %in% seq(0.1,0.5,by=0.1) ) %&gt;% dplyr::ungroup() %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = convexity_pct, x = circle_fit_iou_pct)) + # geom_point(alpha=0.2) + ggplot2::geom_jitter(alpha=0.2, height = .01, width = .01) + ggplot2::facet_grid( cols = dplyr::vars(spectral_weight) , rows = dplyr::vars(chm_res_m) # , scales = &quot;free_y&quot; , labeller = &quot;label_both&quot; ) + ggplot2::scale_y_continuous(limits = c(0,1)) + ggplot2::scale_x_continuous(limits = c(0,1)) + ggplot2::theme_light() + ggplot2::theme( strip.text.x = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) note, in the plot above, we slightly “jitter” the points so that they are visible where they would otherwise be stacked on top of each other and only look like a few points instead of the 1000 draws from the posterior we used let’s table the HDI of the optimal values # summarize it vertex_draws_temp &lt;- vertex_draws_temp %&gt;% dplyr::group_by( chm_res_m, spectral_weight ) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$y , median_hdi_lower_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymin , median_hdi_upper_circle_fit_iou_pct = tidybayes::median_hdci(circle_fit_iou_pct)$ymax # get median_hdi , median_hdi_est_convexity_pct = tidybayes::median_hdci(convexity_pct)$y , median_hdi_lower_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymin , median_hdi_upper_convexity_pct = tidybayes::median_hdci(convexity_pct)$ymax ) %&gt;% dplyr::ungroup() # table it vertex_draws_temp %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , rep(c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;),2) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;circle_fit_iou_pct&quot; = 3 , &quot;convexity_pct&quot; = 3 )) Table 9.17: circle_fit_iou_pct convexity_pct CHM resolution spectral_weight median HDI low HDI high median HDI low HDI high 0.1 0 0.86 0.81 0.94 0.00 0 0 0.2 0 0.59 0.56 0.63 0.00 0 0 0.3 0 0.37 0.31 0.42 0.56 0 1 0.4 0 0.17 0.13 0.21 1.00 1 1 0.5 0 0.00 0.00 0.00 1.00 1 1 9.3.5.2 Input data to explore the influence of the input data, which includes the presence or absence of spectral data and its weighting (i.e. spectral_weight) as well as the CHM resolution (chm_res_m), we will fix all four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct). the max_ht_m, max_area_m2 parameters will be fixed at expected levels based on the slash pile construction prescription while the convexity_pct, circle_fit_iou_pct will be fixed at the optimal levels determined based on the Bayesian posterior predictive distribution of detection accuracy we’ll make contrasts of the posterior predictions to probabilistically quantify the influence of the input data (e.g. inclusion of spectral data and it’s weighting and CHM resolution) let’s get the posterior predictive draws draws_temp &lt;- tidyr::crossing( structural_params_settings , param_combos_spectral_ranked %&gt;% dplyr::distinct(spectral_weight_fact, spectral_weight) , param_combos_spectral_ranked %&gt;% dplyr::distinct(chm_res_m) ) %&gt;% tidybayes::add_epred_draws(brms_height_mape_mod, ndraws = 1111) %&gt;% dplyr::rename(value = .epred) # # huh? # draws_temp %&gt;% dplyr::glimpse() 9.3.5.2.1 CHM resolution first, we’ll look at the impact of changing CHM resolution by the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). our questions regarding CHM resolution were: question 1: does CHM resolution influence quantification accuracy? question 2: does the effect of CHM resolution change based on the inclusion of spectral data versus using only structural data? we can answer those questions using our model by considering the credible slope of the CHM resolution predictor as a function of the spectral_weight parameter (e.g. Kurz 2025; Kruschke (2015, Ch. 18)) draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = chm_res_m, y = value, color = spectral_weight)) + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;Height MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) this trend demonstrates that increasing the coarseness of the CHM data has a minimal impact of about 1 percentage point on Height quantification accuracy for CHM data with resolutions in the range of 0.1m to 0.4m. however, increasing the CHM resolution coarseness beyond this level results in a more significant reduction in Height quantification accuracy (i.e. increase in height MAPE) and height accuracy degrades at an increasing rate the more coarse the CHM data…don’t do it we can look at the posterior distributions of the expected Height MAPE at different CHM resolution levels by the inclusion (or exclusion) of spectral data and it’s weighting…make sure to note the y-axis range (it’s fairly narrow) draws_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=chm_res_m)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = spectral_weight) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(spectral_weight), labeller = &quot;label_both&quot;) + ggplot2::scale_fill_manual(values = pal_spectral_weight) + ggplot2::scale_y_continuous(limits = c(0,NA), labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;CHM resolution&quot;, y = &quot;Height MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) table that draws_temp %&gt;% dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(spectral_weight, chm_res_m) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(spectral_weight, chm_res_m) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;Height MAPE&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM resolution&quot; , c(&quot;Height MAPE&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.18: Height MAPE95% HDI of the posterior predictive distribution spectral_weight CHM resolution Height MAPEmedian HDI low HDI high spectral_weight: 0 0.1 16.7% 16.5% 16.9% 0.2 15.8% 15.7% 15.9% 0.3 16.0% 15.9% 16.1% 0.4 17.2% 17.1% 17.4% 0.5 19.8% 19.6% 20.0% spectral_weight: 1 0.1 16.7% 16.6% 16.9% 0.2 15.8% 15.7% 15.9% 0.3 16.0% 15.9% 16.1% 0.4 17.2% 17.1% 17.4% 0.5 19.8% 19.6% 20.0% spectral_weight: 2 0.1 16.7% 16.6% 16.9% 0.2 15.8% 15.7% 15.9% 0.3 16.0% 15.9% 16.1% 0.4 17.2% 17.1% 17.4% 0.5 19.8% 19.6% 20.0% spectral_weight: 3 0.1 16.7% 16.6% 16.9% 0.2 15.8% 15.7% 16.0% 0.3 16.0% 15.9% 16.1% 0.4 17.2% 17.1% 17.4% 0.5 19.8% 19.6% 20.0% spectral_weight: 4 0.1 16.7% 16.6% 16.9% 0.2 15.8% 15.7% 15.9% 0.3 16.0% 15.9% 16.1% 0.4 17.2% 17.1% 17.4% 0.5 19.8% 19.6% 20.0% spectral_weight: 5 0.1 16.4% 16.2% 16.6% 0.2 15.6% 15.5% 15.7% 0.3 15.9% 15.8% 16.0% 0.4 17.2% 17.1% 17.3% 0.5 19.9% 19.7% 20.1% note that even though these figures make it seem that height quantification accuracy is much worse for the coarser resolution CHM data compared to the finer resolution data, there is only a ~3 percentage point increase in height MAPE from the finest resolution 0.1m to the coarsest resolution 0.5m tested. for example, when spectral data is not included (i.e. spectral_weight = 0) the predicted Height MAPE is 15.3% using 0.1m CHM data and 18.1% when using 0.5m CHM data. now we’ll probabilistically test the hypothesis that coarser resolution CHM data results in lower Height quantification accuracy and determine by how much. we’ll look at the influence of CHM resolution based on the inclusion of spectral data (or exclusion) and it’s weighting determined by the spectral_weight parameter contrast_temp &lt;- draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::group_by(spectral_weight) %&gt;% tidybayes::compare_levels( value , by = chm_res_m , comparison = # &quot;control&quot; # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = chm_res_m) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(spectral_weight, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(spectral_weight = forcats::fct_relabel(spectral_weight,~paste0(&quot;spectral_weight: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;CHM resolution contrast&quot; , x_axis_title = &quot;difference (Height MAPE)&quot; , facet = &quot;spectral_weight&quot; , label_size = 0 , x_expand = c(0.3,0.3) , annotate_which = &quot;both&quot; ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `spectral_weight`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( spectral_weight, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper , pr_gt_zero # , pr_lt_zero ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::arrange(spectral_weight, contrast) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;spectral_weight&quot;, &quot;CHM res. contrast&quot; , &quot;difference (Height MAPE)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; , &quot;Pr(diff&gt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.19: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts spectral_weight CHM res. contrast difference (Height MAPE) HDI low HDI high Pr(diff&gt;0) spectral_weight: 0 0.2 - 0.1 -0.9% -1.0% -0.8% 0% 0.3 - 0.1 -0.7% -0.9% -0.6% 0% 0.3 - 0.2 0.2% 0.1% 0.2% 100% 0.4 - 0.1 0.5% 0.3% 0.7% 100% 0.4 - 0.2 1.4% 1.3% 1.5% 100% 0.4 - 0.3 1.3% 1.2% 1.3% 100% 0.5 - 0.1 3.1% 2.8% 3.4% 100% 0.5 - 0.2 4.0% 3.8% 4.2% 100% 0.5 - 0.3 3.8% 3.7% 4.0% 100% 0.5 - 0.4 2.6% 2.5% 2.7% 100% spectral_weight: 1 0.2 - 0.1 -0.9% -1.0% -0.8% 0% 0.3 - 0.1 -0.7% -0.9% -0.6% 0% 0.3 - 0.2 0.2% 0.1% 0.2% 100% 0.4 - 0.1 0.5% 0.3% 0.7% 100% 0.4 - 0.2 1.4% 1.3% 1.5% 100% 0.4 - 0.3 1.2% 1.2% 1.3% 100% 0.5 - 0.1 3.1% 2.8% 3.4% 100% 0.5 - 0.2 4.0% 3.8% 4.2% 100% 0.5 - 0.3 3.8% 3.7% 4.0% 100% 0.5 - 0.4 2.6% 2.5% 2.7% 100% spectral_weight: 2 0.2 - 0.1 -0.9% -1.0% -0.8% 0% 0.3 - 0.1 -0.7% -0.9% -0.6% 0% 0.3 - 0.2 0.2% 0.1% 0.2% 100% 0.4 - 0.1 0.5% 0.3% 0.7% 100% 0.4 - 0.2 1.4% 1.3% 1.5% 100% 0.4 - 0.3 1.2% 1.2% 1.3% 100% 0.5 - 0.1 3.1% 2.8% 3.4% 100% 0.5 - 0.2 4.0% 3.8% 4.2% 100% 0.5 - 0.3 3.8% 3.6% 4.0% 100% 0.5 - 0.4 2.6% 2.5% 2.7% 100% spectral_weight: 3 0.2 - 0.1 -0.9% -1.0% -0.8% 0% 0.3 - 0.1 -0.7% -0.9% -0.6% 0% 0.3 - 0.2 0.2% 0.1% 0.2% 100% 0.4 - 0.1 0.5% 0.3% 0.7% 100% 0.4 - 0.2 1.4% 1.3% 1.5% 100% 0.4 - 0.3 1.2% 1.2% 1.3% 100% 0.5 - 0.1 3.1% 2.8% 3.4% 100% 0.5 - 0.2 4.0% 3.8% 4.2% 100% 0.5 - 0.3 3.8% 3.7% 4.0% 100% 0.5 - 0.4 2.6% 2.5% 2.7% 100% spectral_weight: 4 0.2 - 0.1 -0.9% -1.0% -0.8% 0% 0.3 - 0.1 -0.7% -0.9% -0.6% 0% 0.3 - 0.2 0.2% 0.1% 0.2% 100% 0.4 - 0.1 0.5% 0.3% 0.7% 100% 0.4 - 0.2 1.4% 1.3% 1.5% 100% 0.4 - 0.3 1.2% 1.2% 1.3% 100% 0.5 - 0.1 3.1% 2.8% 3.4% 100% 0.5 - 0.2 4.0% 3.8% 4.2% 100% 0.5 - 0.3 3.8% 3.7% 4.0% 100% 0.5 - 0.4 2.6% 2.5% 2.7% 100% spectral_weight: 5 0.2 - 0.1 -0.8% -0.9% -0.7% 0% 0.3 - 0.1 -0.5% -0.7% -0.4% 0% 0.3 - 0.2 0.3% 0.2% 0.3% 100% 0.4 - 0.1 0.8% 0.6% 1.0% 100% 0.4 - 0.2 1.6% 1.5% 1.7% 100% 0.4 - 0.3 1.3% 1.3% 1.4% 100% 0.5 - 0.1 3.5% 3.3% 3.8% 100% 0.5 - 0.2 4.3% 4.1% 4.5% 100% 0.5 - 0.3 4.0% 3.9% 4.2% 100% 0.5 - 0.4 2.7% 2.6% 2.8% 100% these contrasts confirm what we saw by looking at the predicted relationship between CHM resolution and height MAPE, that increasing the coarseness of the CHM data has a minimal impact of about 1 percentage point on Height quantification accuracy for CHM data with resolutions in the range of 0.1m to 0.4m. however, increasing the CHM resolution coarseness beyond this level results in a more significant reduction in Height quantification accuracy (i.e. increase in height MAPE) and accuracy degrades at an increasing rate the more coarse the CHM data. for example, when spectral data is not included (i.e. spectral_weight = 0) the predicted difference in Height MAPE is ~1% when going from 0.1m to 0.2m-0.4m CHM data but a decrease in height quantification accuracy of ~4 percentage points is predicted going from 0.2m to 0.5m CHM data, for example. 9.3.5.2.2 Spectral data now we’ll look at the impact of including (or excluding) spectral data and the weighting of the spectral_weight parameter where a value of “0” indicates no spectral data was used (i.e. structural only), the lowest weighting of the spectral data is “1” (only one spectral index threshold must be met), and the highest weighting of spectral data is “5” (all spectral index thresholds must be met). Note: we expect that the spectral data does not significantly alter the quantification of slash pile form. this is because spectral information is used solely to filter candidate piles, meaning it neither reshapes existing ones nor introduces new detections. # viridis::rocket(5, begin = 0.9, end = 0.6) %&gt;% scales::show_col() # brms::posterior_summary(brms_height_mape_mod) draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = spectral_weight, y = value, color = factor(chm_res_m))) + # tidybayes::stat_halfeye() + tidybayes::stat_lineribbon(point_interval = &quot;median_hdi&quot;, .width = c(0.95)) + # ggplot2::facet_wrap(facets = dplyr::vars(spectral_weight)) ggplot2::scale_fill_brewer(palette = &quot;Greys&quot;) + ggplot2::scale_color_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(labels = scales::percent) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, color = &quot;CHM resolution&quot;, y = &quot;Height MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, lwd = 8, fill = NA)) , fill = &quot;none&quot; ) while there is a slight change in height quantification accuracy at the highest spectral weighting, the inclusion of spectral data and the setting of the spectral_weight parameter does not significantly alter the height quantification accuracy irrespective of the CHM resolution we can look at the posterior distributions of the expected Height MAPE at different spectral_weight settings by the input CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y=value, x=spectral_weight)) + tidybayes::stat_eye( mapping = ggplot2::aes(fill = chm_res_m) , point_interval = median_hdi, .width = .95 , slab_alpha = 0.95 , interval_color = &quot;gray44&quot;, linewidth = 1 , point_color = &quot;gray44&quot;, point_fill = &quot;gray44&quot;, point_size = 1 ) + ggplot2::facet_grid(cols = dplyr::vars(chm_res_m)) + ggplot2::scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.9, end = 0.6) + ggplot2::scale_y_continuous(limits = c(0,NA), labels = scales::percent, breaks = scales::breaks_extended(16)) + ggplot2::labs(x = &quot;`spectral_weight`&quot;, y = &quot;Height MAPE&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 8, color = &quot;black&quot;, face = &quot;bold&quot;) ) we already saw this same data above in our CHM resolution testing, but we’ll table that again but this time grouping by CHM resolution draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) %&gt;% dplyr::group_by(chm_res_m, spectral_weight) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(chm_res_m,spectral_weight) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;Height MAPE&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , c(&quot;Height MAPE&lt;br&gt;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.20: Height MAPE95% HDI of the posterior predictive distribution CHM resolution spectral_weight Height MAPEmedian HDI low HDI high CHM resolution: 0.1 0 16.7% 16.5% 16.9% 1 16.7% 16.6% 16.9% 2 16.7% 16.6% 16.9% 3 16.7% 16.6% 16.9% 4 16.7% 16.6% 16.9% 5 16.4% 16.2% 16.6% CHM resolution: 0.2 0 15.8% 15.7% 15.9% 1 15.8% 15.7% 15.9% 2 15.8% 15.7% 15.9% 3 15.8% 15.7% 16.0% 4 15.8% 15.7% 15.9% 5 15.6% 15.5% 15.7% CHM resolution: 0.3 0 16.0% 15.9% 16.1% 1 16.0% 15.9% 16.1% 2 16.0% 15.9% 16.1% 3 16.0% 15.9% 16.1% 4 16.0% 15.9% 16.1% 5 15.9% 15.8% 16.0% CHM resolution: 0.4 0 17.2% 17.1% 17.4% 1 17.2% 17.1% 17.4% 2 17.2% 17.1% 17.4% 3 17.2% 17.1% 17.4% 4 17.2% 17.1% 17.4% 5 17.2% 17.1% 17.3% CHM resolution: 0.5 0 19.8% 19.6% 20.0% 1 19.8% 19.6% 20.0% 2 19.8% 19.6% 20.0% 3 19.8% 19.6% 20.0% 4 19.8% 19.6% 20.0% 5 19.9% 19.7% 20.1% now we’ll probabilistically test the hypothesis that the inclusion of spectral data improves detection accuracy and quantify by how much. we’ll look at the influence of spectral data based on the CHM resolution to actually compare the different levels of spectral_weight, we’ll use the MCMC draws to contrast the posterior predictions at different levels of the parameter (see below) contrast_temp &lt;- draws_temp %&gt;% dplyr::filter( round(chm_res_m,2) == round(chm_res_m,1) # let&#39;s just look at every 0.1 m (10 cm) ) %&gt;% dplyr::group_by(chm_res_m) %&gt;% tidybayes::compare_levels( value , by = spectral_weight , comparison = # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) &quot;pairwise&quot; ) %&gt;% # dplyr::glimpse() dplyr::rename(contrast = spectral_weight) %&gt;% # group the data before calculating contrast variables %&gt;% dplyr::group_by(chm_res_m, contrast) %&gt;% make_contrast_vars() %&gt;% # relabel the label for the facets dplyr::mutate(chm_res_m = chm_res_m %&gt;% factor() %&gt;% forcats::fct_relabel(~paste0(&quot;CHM resolution: &quot;, .x, recycle0 = T))) # huh? # contrast_temp %&gt;% dplyr::glimpse() # plot it plt_contrast( contrast_temp # , caption_text = form_temp , y_axis_title = &quot;`spectral_weight` contrast&quot; , x_axis_title = &quot;difference (Height MAPE)&quot; , facet = &quot;chm_res_m&quot; , label_size = 1.7 , x_expand = c(0.4,0.3) ) + labs( subtitle = &quot;posterior predictive distribution of group constrasts with 95% &amp; 50% HDI\\nby `chm_res_m`&quot; ) let’s table it contrast_temp %&gt;% dplyr::distinct( chm_res_m, contrast , median_hdi_est, median_hdi_lower, median_hdi_upper # , pr_lt_zero , pr_gt_zero ) %&gt;% dplyr::arrange(chm_res_m, contrast) %&gt;% # format pcts dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi_&quot;) , ~ scales::percent(.x, accuracy = 0.1) )) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts&quot; , col.names = c( &quot;CHM resolution&quot;, &quot;spectral_weight&quot; , &quot;difference (Height MAPE)&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; # , &quot;Pr(diff&lt;0)&quot; , &quot;Pr(diff&gt;0)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.21: brms::brm model: 95% HDI of the posterior predictive distribution of group constrasts CHM resolution spectral_weight difference (Height MAPE) HDI low HDI high Pr(diff&gt;0) CHM resolution: 0.1 1 - 0 0.0% -0.2% 0.3% 50% 2 - 0 0.0% -0.2% 0.2% 51% 2 - 1 0.0% -0.2% 0.2% 52% 3 - 0 0.0% -0.2% 0.2% 51% 3 - 1 0.0% -0.2% 0.2% 53% 3 - 2 0.0% -0.2% 0.2% 50% 4 - 0 0.0% -0.2% 0.2% 50% 4 - 1 0.0% -0.2% 0.2% 51% 4 - 2 0.0% -0.2% 0.2% 49% 4 - 3 0.0% -0.2% 0.2% 48% 5 - 0 -0.3% -0.5% -0.1% 0% 5 - 1 -0.3% -0.5% -0.1% 0% 5 - 2 -0.3% -0.5% -0.1% 0% 5 - 3 -0.3% -0.5% -0.1% 0% 5 - 4 -0.3% -0.5% -0.1% 0% CHM resolution: 0.2 1 - 0 0.0% -0.1% 0.2% 50% 2 - 0 0.0% -0.1% 0.1% 50% 2 - 1 0.0% -0.1% 0.1% 50% 3 - 0 0.0% -0.1% 0.1% 51% 3 - 1 0.0% -0.1% 0.1% 53% 3 - 2 0.0% -0.1% 0.1% 50% 4 - 0 0.0% -0.1% 0.1% 50% 4 - 1 0.0% -0.1% 0.1% 50% 4 - 2 0.0% -0.1% 0.1% 49% 4 - 3 0.0% -0.1% 0.1% 47% 5 - 0 -0.2% -0.3% -0.1% 0% 5 - 1 -0.2% -0.3% -0.1% 0% 5 - 2 -0.2% -0.3% -0.1% 1% 5 - 3 -0.2% -0.3% -0.1% 0% 5 - 4 -0.2% -0.3% -0.1% 0% CHM resolution: 0.3 1 - 0 0.0% -0.1% 0.1% 50% 2 - 0 0.0% -0.1% 0.1% 51% 2 - 1 0.0% -0.1% 0.1% 52% 3 - 0 0.0% -0.1% 0.1% 52% 3 - 1 0.0% -0.1% 0.1% 52% 3 - 2 0.0% -0.1% 0.1% 51% 4 - 0 0.0% -0.1% 0.1% 49% 4 - 1 0.0% -0.1% 0.1% 50% 4 - 2 0.0% -0.1% 0.1% 50% 4 - 3 0.0% -0.1% 0.1% 47% 5 - 0 -0.1% -0.2% 0.0% 3% 5 - 1 -0.1% -0.2% 0.0% 3% 5 - 2 -0.1% -0.2% 0.0% 2% 5 - 3 -0.1% -0.2% 0.0% 2% 5 - 4 -0.1% -0.2% 0.0% 2% CHM resolution: 0.4 1 - 0 0.0% -0.1% 0.2% 50% 2 - 0 0.0% -0.2% 0.1% 49% 2 - 1 0.0% -0.2% 0.1% 50% 3 - 0 0.0% -0.1% 0.2% 49% 3 - 1 0.0% -0.2% 0.1% 50% 3 - 2 0.0% -0.1% 0.2% 50% 4 - 0 0.0% -0.2% 0.1% 49% 4 - 1 0.0% -0.1% 0.1% 49% 4 - 2 0.0% -0.1% 0.1% 51% 4 - 3 0.0% -0.2% 0.1% 50% 5 - 0 0.0% -0.2% 0.1% 41% 5 - 1 0.0% -0.2% 0.1% 39% 5 - 2 0.0% -0.2% 0.1% 41% 5 - 3 0.0% -0.2% 0.1% 40% 5 - 4 0.0% -0.2% 0.1% 40% CHM resolution: 0.5 1 - 0 0.0% -0.2% 0.3% 49% 2 - 0 0.0% -0.3% 0.2% 50% 2 - 1 0.0% -0.2% 0.2% 50% 3 - 0 0.0% -0.3% 0.2% 49% 3 - 1 0.0% -0.2% 0.3% 50% 3 - 2 0.0% -0.2% 0.3% 48% 4 - 0 0.0% -0.3% 0.2% 49% 4 - 1 0.0% -0.2% 0.3% 49% 4 - 2 0.0% -0.2% 0.2% 50% 4 - 3 0.0% -0.3% 0.2% 51% 5 - 0 0.1% -0.2% 0.3% 76% 5 - 1 0.1% -0.1% 0.3% 77% 5 - 2 0.1% -0.2% 0.3% 77% 5 - 3 0.1% -0.2% 0.3% 76% 5 - 4 0.1% -0.2% 0.3% 76% although we can be very certain that there are differences in Height quantification accuracy (&gt;99% probability across most CHM resolutions) when the spectral_weight is set to “5” (i.e. requiring that all spectral criteria be met) compared to the other settings of spectral_weight or not including spectral data for the finer resolution CHM data (e.g. &lt;0.4m), these differences are so small with nearly all of them showing a difference in Height MAPE of &lt;1% 9.4 Balanced Accuracy Bayesian Optimization now we’re going to find the optimal parameter settings for our pile detection methodology by using the Bayesian models we developed for F-score (brms_f_score_mod) and MAPE for height (brms_height_mape_mod) and diameter (brms_diam_mape_mod). we’ll use tidybayes::add_epred_draws() to obtain the posterior predictions of the expected value (e.g. F-score) from each model across a common grid of parameter settings (newdata). the predictions from each model will be joined on the parameter settings and draw number (.draw). then we’ll use a customized ranking filter on each posterior draw to find the parameter combination that best balances detection and quantification accuracy. This approach allows us to weight the accuracies according to specific objectives, such as sacrificing some form quantification accuracy to gain better detection accuracy. this methodology is statistically sound because it accounts for uncertainty by using the full posterior distribution from all models throughout the optimization process. unlike methods that rely on single point estimates (like our initial sensitivity testing), this approach can handle complex, non-linear, and interactive relationships. The final output is not a single optimal solution but a posterior distribution of optimal settings, which quantifies the range of credible parameter values that satisfy the optimization criteria. first, let’s generate the grid to see how many different parameter combinations we’re testing. note, we hold the max_ht_m (2.3 m) and max_area_m2 (46 m2) parameters constant based on our expectations from the treatment prescription implemented on the ground. if we didn’t do this, we would risk over-fitting the optimization based on the training data used. # grid of parameter settings for use in each tidybayes::add_epred_draws() call newdata_temp &lt;- tidyr::crossing( param_combos_spectral_ranked %&gt;% # dplyr::filter(spectral_weight %in% c(&quot;0&quot;,&quot;4&quot;,&quot;5&quot;)) %&gt;% dplyr::distinct(spectral_weight) , circle_fit_iou_pct = seq(from = 0, to = 1.0, by = 0.02) , convexity_pct = seq(from = 0, to = 1.0, by = 0.02) , chm_res_m = seq(from = 0.1, to = 0.5, by = 0.05) , max_ht_m = structural_params_settings$max_ht_m # seq(from = 2.1, to = 4.3, length.out = 5) , max_area_m2 = structural_params_settings$max_area_m2 # seq(from = 20, to = 55, length.out = 5) ) # huh? newdata_temp %&gt;% dplyr::glimpse() ## Rows: 140,454 ## Columns: 6 ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ convexity_pct &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.5… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… # nrow(newdata_temp)/nrow(param_combos_spectral_ranked) the number of records in our newdata is the number of different parameter combinations we’re testing for each draw. modelling allows us to test so many more possible combinations (4.0 times more here) than getting point estimates as we did with our sensitivity testing! get the posterior predictions from the detection accuracy model F-score (brms_f_score_mod) and MAPE for height (brms_height_mape_mod) and diameter (brms_diam_mape_mod) for quantification accuracy # names of variables to join the draws on join_names_temp &lt;- c(names(newdata_temp), &quot;.draw&quot;) ndraws_temp &lt;- 333 # draws full_draws_temp &lt;- # brms_f_score_mod tidybayes::add_epred_draws(newdata = newdata_temp, object = brms_f_score_mod, ndraws = ndraws_temp, value = &quot;f_score&quot;) %&gt;% # join brms_diam_mape_mod dplyr::inner_join( tidybayes::add_epred_draws(newdata = newdata_temp, object = brms_diam_mape_mod, ndraws = ndraws_temp, value = &quot;diameter_mape&quot;) , by = join_names_temp ) %&gt;% # join brms_height_mape_mod dplyr::inner_join( tidybayes::add_epred_draws(newdata = newdata_temp, object = brms_height_mape_mod, ndraws = ndraws_temp, value = &quot;height_mape&quot;) , by = join_names_temp ) %&gt;% # select dplyr::select(dplyr::all_of( c(join_names_temp, &quot;f_score&quot;, &quot;diameter_mape&quot;, &quot;height_mape&quot;) )) # huh? full_draws_temp %&gt;% dplyr::glimpse() ## Rows: 46,771,182 ## Columns: 10 ## Groups: spectral_weight, circle_fit_iou_pct, convexity_pct, chm_res_m, max_ht_m, max_area_m2 [140,454] ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ convexity_pct &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ f_score &lt;dbl&gt; 0.6170156, 0.5835475, 0.5902940, 0.6036380, 0.60168… ## $ diameter_mape &lt;dbl&gt; 0.1016914, 0.1031600, 0.1029575, 0.1013529, 0.10385… ## $ height_mape &lt;dbl&gt; 0.1809501, 0.1842020, 0.1868028, 0.1835908, 0.18351… the number of records should be equal to the number of records in our newdata multiplied by the number of draws (ndraws) identical( as.numeric(nrow(newdata_temp)*ndraws_temp) , nrow(full_draws_temp) %&gt;% as.numeric() ) ## [1] TRUE 9.4.1 Balanced Accuracy Selection now we’ll use a customized ranking filter on each posterior draw to find the parameter combination that best balances detection and quantification accuracy. This approach allows us to weight the accuracies according to specific objectives, such as sacrificing some form quantification accuracy to gain better detection accuracy # weights need to add to 1 weight_detection_temp &lt;- 0.7 weight_quantification_temp &lt;- 0.3 # rank the draws best_balanced_accuracy_combos &lt;- full_draws_temp %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::mutate( pct_rank_detection = dplyr::percent_rank(f_score) , dplyr::across( .cols = tidyselect::ends_with(&quot;_mape&quot;) , .fn = ~dplyr::percent_rank(-.x) # -mape so largest gets highest pct rank , .names = &quot;{.col}_pct_rank&quot; ) ) %&gt;% # average of mapes to get quantification mape average dplyr::mutate( pct_rank_quantification = (height_mape_pct_rank+diameter_mape_pct_rank)/2 # apply weights to get balanced_accuracy (0-1) with 1 being best , balanced_accuracy = (weight_detection_temp*pct_rank_detection) + (weight_quantification_temp*pct_rank_quantification) ) %&gt;% # dplyr::filter(.draw==1) %&gt;% dplyr::arrange(desc(balanced_accuracy)) %&gt;% View() # for each draw, find the setting that maximizes balanced_accuracy dplyr::group_by(.draw) %&gt;% dplyr::slice_max(order_by = balanced_accuracy, n = 1, with_ties = FALSE) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-tidyselect::starts_with(&quot;pct_rank_&quot;), -tidyselect::ends_with(&quot;_pct_rank&quot;), -balanced_accuracy) # add on the structural only data best_balanced_accuracy_combos &lt;- full_draws_temp %&gt;% dplyr::filter(spectral_weight==&quot;0&quot;) %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::mutate( pct_rank_detection = dplyr::percent_rank(f_score) , dplyr::across( .cols = tidyselect::ends_with(&quot;_mape&quot;) , .fn = ~dplyr::percent_rank(-.x) # -mape so largest gets highest pct rank , .names = &quot;{.col}_pct_rank&quot; ) ) %&gt;% # average of mapes to get quantification mape average dplyr::mutate( pct_rank_quantification = (height_mape_pct_rank+diameter_mape_pct_rank)/2 # apply weights to get balanced_accuracy (0-1) with 1 being best , balanced_accuracy = (weight_detection_temp*pct_rank_detection) + (weight_quantification_temp*pct_rank_quantification) ) %&gt;% # dplyr::filter(.draw==1) %&gt;% dplyr::arrange(desc(balanced_accuracy)) %&gt;% View() # for each draw, find the setting that maximizes balanced_accuracy dplyr::group_by(.draw) %&gt;% dplyr::slice_max(order_by = balanced_accuracy, n = 1, with_ties = FALSE) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-tidyselect::starts_with(&quot;pct_rank_&quot;), -tidyselect::ends_with(&quot;_pct_rank&quot;), -balanced_accuracy) %&gt;% # add on data fusion combos dplyr::mutate(method_input_data = 0) %&gt;% dplyr::bind_rows( best_balanced_accuracy_combos %&gt;% dplyr::mutate(method_input_data = 1) ) %&gt;% dplyr::mutate( method_input_data = factor(method_input_data, levels = 0:1, labels = c(&quot;structural only&quot;, &quot;structural+spectral&quot;), ordered = T) ) # huh? best_balanced_accuracy_combos %&gt;% dplyr::glimpse() ## Rows: 666 ## Columns: 11 ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.4… ## $ convexity_pct &lt;dbl&gt; 0.08, 0.10, 0.08, 0.10, 0.06, 0.08, 0.08, 0.10, 0.0… ## $ chm_res_m &lt;dbl&gt; 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ f_score &lt;dbl&gt; 0.8069613, 0.7946836, 0.8002498, 0.7988866, 0.79587… ## $ diameter_mape &lt;dbl&gt; 0.1089178, 0.1095609, 0.1086618, 0.1091353, 0.10854… ## $ height_mape &lt;dbl&gt; 0.1545983, 0.1555827, 0.1558584, 0.1555255, 0.15532… ## $ method_input_data &lt;ord&gt; structural only, structural only, structural only, … # best_balanced_accuracy_combos %&gt;% dplyr::select(max_area_m2) %&gt;% summary() the number of records 333 corresponds to the number of draws we got from the posterior predictive distribution, each one selected as the parameter combination that best balanced detection and quantification accuracy from the 140,454 tested for the data fusion approach this output is not a single optimal solution but a posterior distribution of optimal settings, which quantifies the range of credible parameter values that satisfy the optimization criteria. we’ll have data for both the structural only method and the data fusion method (i.e. “structural+spectral”) best_balanced_accuracy_combos %&gt;% dplyr::count(method_input_data) ## # A tibble: 2 × 2 ## method_input_data n ## &lt;ord&gt; &lt;int&gt; ## 1 structural only 333 ## 2 structural+spectral 333 we also tested different parameter combinations in the absence of spectral data (i.e. spectral_weight = 0) so that we get optimal settings for cases when we only have structural data to attempt to detect piles from the number of parameter combinations tested per draw with structural data only is equivalent to the number of combinations tested per draw for the data fusion approach divided by six (for spectral_weight setting “1”-“5” and without spectral data “0”): full_draws_temp %&gt;% dplyr::filter(spectral_weight==&quot;0&quot;) %&gt;% nrow() %&gt;% `/`(ndraws_temp) %&gt;% scales::comma(accuracy=1) ## [1] &quot;23,409&quot; pivot to long # pivot to long best_balanced_accuracy_combos_long &lt;- best_balanced_accuracy_combos %&gt;% # get rid of vars we fixed dplyr::select(-c(max_ht_m, max_area_m2)) %&gt;% dplyr::mutate( spectral_weight = spectral_weight %&gt;% as.character() %&gt;% as.numeric() ) %&gt;% tidyr::pivot_longer(cols = -c(.draw,method_input_data)) let’s get the same data but by different CHM resolution levels tested to represent the optimal setting if CHM resolution is fixed and cannot be selected # let&#39;s get the same data but by different CHM resolution levels tested to represent the optimal setting if CHM resolution is fixed and cannot be selected # rank the draws best_balanced_accuracy_combos_chm &lt;- full_draws_temp %&gt;% dplyr::group_by(.draw, chm_res_m) %&gt;% dplyr::mutate( pct_rank_detection = dplyr::percent_rank(f_score) , dplyr::across( .cols = tidyselect::ends_with(&quot;_mape&quot;) , .fn = ~dplyr::percent_rank(-.x) # -mape so largest gets highest pct rank , .names = &quot;{.col}_pct_rank&quot; ) ) %&gt;% # average of mapes to get quantification mape average dplyr::mutate( pct_rank_quantification = (height_mape_pct_rank+diameter_mape_pct_rank)/2 # apply weights to get balanced_accuracy (0-1) with 1 being best , balanced_accuracy = (weight_detection_temp*pct_rank_detection) + (weight_quantification_temp*pct_rank_quantification) ) %&gt;% # dplyr::filter(.draw==1) %&gt;% dplyr::arrange(desc(balanced_accuracy)) %&gt;% View() # for each draw, find the setting that maximizes balanced_accuracy dplyr::group_by(.draw, chm_res_m) %&gt;% dplyr::slice_max(order_by = balanced_accuracy, n = 1, with_ties = FALSE) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-tidyselect::starts_with(&quot;pct_rank_&quot;), -tidyselect::ends_with(&quot;_pct_rank&quot;), -balanced_accuracy) # add on the structural only data best_balanced_accuracy_combos_chm &lt;- full_draws_temp %&gt;% dplyr::filter(spectral_weight==&quot;0&quot;) %&gt;% dplyr::group_by(.draw, chm_res_m) %&gt;% dplyr::mutate( pct_rank_detection = dplyr::percent_rank(f_score) , dplyr::across( .cols = tidyselect::ends_with(&quot;_mape&quot;) , .fn = ~dplyr::percent_rank(-.x) # -mape so largest gets highest pct rank , .names = &quot;{.col}_pct_rank&quot; ) ) %&gt;% # average of mapes to get quantification mape average dplyr::mutate( pct_rank_quantification = (height_mape_pct_rank+diameter_mape_pct_rank)/2 # apply weights to get balanced_accuracy (0-1) with 1 being best , balanced_accuracy = (weight_detection_temp*pct_rank_detection) + (weight_quantification_temp*pct_rank_quantification) ) %&gt;% # dplyr::filter(.draw==1) %&gt;% dplyr::arrange(desc(balanced_accuracy)) %&gt;% View() # for each draw, find the setting that maximizes balanced_accuracy dplyr::group_by(.draw, chm_res_m) %&gt;% dplyr::slice_max(order_by = balanced_accuracy, n = 1, with_ties = FALSE) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-tidyselect::starts_with(&quot;pct_rank_&quot;), -tidyselect::ends_with(&quot;_pct_rank&quot;), -balanced_accuracy) %&gt;% # add on data fusion combos dplyr::mutate(method_input_data = 0) %&gt;% dplyr::bind_rows( best_balanced_accuracy_combos_chm %&gt;% dplyr::mutate(method_input_data = 1) ) %&gt;% dplyr::mutate( method_input_data = factor(method_input_data, levels = 0:1, labels = c(&quot;structural only&quot;, &quot;structural+spectral&quot;), ordered = T) ) # huh? best_balanced_accuracy_combos_chm %&gt;% dplyr::glimpse() ## Rows: 5,994 ## Columns: 11 ## $ spectral_weight &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ circle_fit_iou_pct &lt;dbl&gt; 0.36, 0.40, 0.40, 0.40, 0.36, 0.34, 0.34, 0.34, 0.3… ## $ convexity_pct &lt;dbl&gt; 0.16, 0.18, 0.22, 0.30, 0.36, 0.44, 0.48, 0.54, 0.5… ## $ chm_res_m &lt;dbl&gt; 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.5… ## $ max_ht_m &lt;dbl&gt; 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2… ## $ max_area_m2 &lt;dbl&gt; 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,… ## $ .draw &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ f_score &lt;dbl&gt; 0.8348130, 0.7974862, 0.7661282, 0.7378913, 0.71128… ## $ diameter_mape &lt;dbl&gt; 0.1098208, 0.1422830, 0.1800632, 0.2222840, 0.26884… ## $ height_mape &lt;dbl&gt; 0.1602975, 0.1554388, 0.1550191, 0.1568298, 0.15998… ## $ method_input_data &lt;ord&gt; structural only, structural only, structural only, … # best_balanced_accuracy_combos_chm %&gt;% # dplyr::ungroup() %&gt;% # dplyr::count(chm_res_m,method_input_data) 9.4.2 Overall (across CHM resolution) these recommendations are for users who can generate a CHM from the original point cloud (e.g. using cloud2trees::cloud2raster()). This is a critical distinction because creating a new CHM at the desired resolution is a fundamentally different process than simply disaggregating an existing, coarser raster. 9.4.2.1 Posterior distribution of optimal settings let’s check out the posterior distribution of optimal settings for each parameter. remember, it is these parameter settings combined that are expected to yield the best balance between detection and quantification accuracy based on our weighting note, we distinguish the optimal settings based on the availability of spectral data which determines whether or not we can use a data fusion (i.e. “structural+spectral”) approach # plot it best_balanced_accuracy_combos_long %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(method_input_data) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + # ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1.2)) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;predicted optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8, angle = 90) ) let’s table the HDI of the optimal values # let&#39;s save these optimal settings for later use # summarize it optimal_param_settings &lt;- best_balanced_accuracy_combos_long %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::group_by(method_input_data,name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() # table it optimal_param_settings %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~dplyr::case_when( name == &quot;spectral_weight&quot; ~ scales::comma(.x,accuracy=1) , T ~scales::comma(.x,accuracy=.01) ) )) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;predicted optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;.&quot;, &quot;parameter&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;optimal setting&quot; = 3 )) Table 9.22: predicted optimal parameter settings based on both detection and quantification accuracy optimal setting . parameter median HDI low HDI high structural only chm_res_m 0.10 0.10 0.10 circle_fit_iou_pct 0.44 0.44 0.46 convexity_pct 0.08 0.06 0.12 spectral_weight 0 0 0 structural+spectral chm_res_m 0.10 0.10 0.10 circle_fit_iou_pct 0.46 0.44 0.48 convexity_pct 0.08 0.04 0.10 spectral_weight 5 4 5 based on the training data and our model, we have a high degree of certainty that these optimal parameter settings will return the best balanced accuracy. this is evidenced by the 95% highest density intervals (HDIs) of the posterior distribution of optimal solutions, which are either very narrow or centered on a single parameter setting, indicating low uncertainty in the model’s recommendation. However, it is crucial to remember that these settings should be refined based on the actual, on-the-ground treatment prescription and implementation. For example, if a prescription called for piles to be constructed as half-frustum of a cone with rounded ends (lolwut; Hardy 1996), these settings would be inappropriate since they assume mostly circular pile footprints which the method (based on the convexity_pct and circle_fit_iou_pct settings) would not be suited for 9.4.2.2 Posterior distribution of accuracy what can we expect from a detection and form quantification accuracy perspective? note, we distinguish the predicted accuracies based on the availability of spectral data which determines whether or not we can use a data fusion (i.e. “structural+spectral”) approach # plot it best_balanced_accuracy_combos_long %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(method_input_data) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::scale_x_continuous(labels = scales::percent) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;predicted pile detection and form quantification accuracy metrics&quot; , &quot;\\nusing optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8, angle = 90) ) let’s table the HDI of the predicted accuracy metrics # summarize it best_balanced_accuracy_combos_long %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% dplyr::group_by(method_input_data, name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~ scales::percent(.x,accuracy=.1) )) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;predicted pile detection and form quantification accuracy metrics&quot; , &quot;&lt;br&gt;using optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;.&quot;, &quot;metric&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;predicted value&quot; = 3 )) Table 9.23: predicted pile detection and form quantification accuracy metricsusing optimal parameter settings based on both detection and quantification accuracy predicted value . metric median HDI low HDI high structural only F-score 79.7% 78.9% 80.5% diameter MAPE 10.9% 10.8% 11.0% height MAPE 15.6% 15.4% 15.7% structural+spectral F-score 83.1% 82.4% 83.8% diameter MAPE 11.4% 10.7% 11.6% height MAPE 15.3% 15.1% 15.5% The narrow 95% highest density intervals (HDIs) of the posterior distribution for the accuracy metrics indicate a high degree of confidence that the method is capable of high detection and form quantification accuracy. This predicted performance, however, is contingent on using the specific optimal parameter settings identified in this analysis. These expectations are specific to the training data, which consisted of piles that were generally circular with few irregularities in their footprint. As such, these results should not be anticipated if the actual on-the-ground pile prescription and implementation differ from those of this training data. Similarly, the same level of accuracy should not be expected if the parameterization of the detection method is altered, even when applied to piles with similar shapes and structures. 9.4.3 by CHM resolution these recommendations are for users who cannot generate a CHM from the original point cloud and only have access to a CHM at a provided resolution (assuming that resolution is &lt;= 0.5) # pivot to long best_balanced_accuracy_combos_long &lt;- best_balanced_accuracy_combos_chm %&gt;% # get rid of vars we fixed dplyr::select(-c(max_ht_m, max_area_m2)) %&gt;% dplyr::mutate( spectral_weight = spectral_weight %&gt;% as.character() %&gt;% as.numeric() , chm_res_m_desc = paste0(chm_res_m, &quot;m CHM&quot;) %&gt;% factor() %&gt;% forcats::fct_reorder(chm_res_m) ) %&gt;% tidyr::pivot_longer(cols = -c(.draw,method_input_data,chm_res_m,chm_res_m_desc)) # best_balanced_accuracy_combos_long %&gt;% dplyr::glimpse() # best_balanced_accuracy_combos_long %&gt;% dplyr::ungroup() %&gt;% dplyr::count(name) 9.4.3.1 Posterior distribution of optimal settings let’s check out the posterior distribution of optimal settings for each parameter. remember, it is these parameter settings combined that are expected to yield the best balance between detection and quantification accuracy based on our weighting 9.4.3.1.1 Data Fusion let’s start with the data fusion approach which assumes users have RGB data to complement the structural CHM data # plot it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural+spectral&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(chm_res_m_desc) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + # ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1.2)) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;Data Fusion (structural+spectral)&quot; , &quot;\\npredicted optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, angle = 90) ) let’s table the HDI of the optimal values # summarize it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural+spectral&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::group_by(chm_res_m_desc,method_input_data,name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~dplyr::case_when( name == &quot;spectral_weight&quot; ~ scales::comma(.x,accuracy=1) , T ~scales::comma(.x,accuracy=.01) ) )) %&gt;% dplyr::select(-method_input_data) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;Data Fusion (structural+spectral)&quot; , &quot;&lt;br&gt;predicted optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;CHM resolution&quot;, &quot;parameter&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;optimal setting&quot; = 3 )) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.24: Data Fusion (structural+spectral)predicted optimal parameter settings based on both detection and quantification accuracy optimal setting CHM resolution parameter median HDI low HDI high 0.1m CHM circle_fit_iou_pct 0.44 0.42 0.48 convexity_pct 0.08 0.00 0.14 spectral_weight 4 4 5 0.15m CHM circle_fit_iou_pct 0.46 0.44 0.48 convexity_pct 0.14 0.10 0.18 spectral_weight 4 4 5 0.2m CHM circle_fit_iou_pct 0.48 0.42 0.48 convexity_pct 0.20 0.16 0.24 spectral_weight 4 4 5 0.25m CHM circle_fit_iou_pct 0.46 0.40 0.48 convexity_pct 0.24 0.20 0.32 spectral_weight 4 4 5 0.3m CHM circle_fit_iou_pct 0.38 0.36 0.42 convexity_pct 0.40 0.36 0.48 spectral_weight 4 4 5 0.35m CHM circle_fit_iou_pct 0.34 0.30 0.36 convexity_pct 0.58 0.54 0.66 spectral_weight 5 4 5 0.4m CHM circle_fit_iou_pct 0.32 0.30 0.32 convexity_pct 0.68 0.60 0.70 spectral_weight 5 4 5 0.45m CHM circle_fit_iou_pct 0.30 0.28 0.30 convexity_pct 0.70 0.68 0.72 spectral_weight 5 5 5 0.5m CHM circle_fit_iou_pct 0.28 0.26 0.28 convexity_pct 0.76 0.72 0.76 spectral_weight 5 5 5 9.4.3.1.2 Structural only now we’ll consider an approach that only uses structural data without the benefit of supplemental spectral data # plot it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural only&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;), name!=&quot;spectral_weight&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(chm_res_m_desc) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + # ggplot2::scale_x_continuous(expand = ggplot2::expansion(mult = 1.2)) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;Structural only&quot; , &quot;\\npredicted optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, angle = 90) ) let’s table the HDI of the optimal values # summarize it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural only&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name!=&quot;f_score&quot;, !stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::group_by(chm_res_m_desc,method_input_data,name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~dplyr::case_when( name == &quot;spectral_weight&quot; ~ scales::comma(.x,accuracy=1) , T ~scales::comma(.x,accuracy=.01) ) )) %&gt;% dplyr::select(-method_input_data) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;Structural only&quot; , &quot;&lt;br&gt;predicted optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;CHM resolution&quot;, &quot;parameter&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;optimal setting&quot; = 3 )) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.25: Structural onlypredicted optimal parameter settings based on both detection and quantification accuracy optimal setting CHM resolution parameter median HDI low HDI high 0.1m CHM circle_fit_iou_pct 0.38 0.36 0.38 convexity_pct 0.16 0.14 0.18 spectral_weight 0 0 0 0.15m CHM circle_fit_iou_pct 0.40 0.38 0.40 convexity_pct 0.22 0.18 0.24 spectral_weight 0 0 0 0.2m CHM circle_fit_iou_pct 0.40 0.40 0.42 convexity_pct 0.26 0.22 0.28 spectral_weight 0 0 0 0.25m CHM circle_fit_iou_pct 0.40 0.40 0.42 convexity_pct 0.30 0.30 0.32 spectral_weight 0 0 0 0.3m CHM circle_fit_iou_pct 0.38 0.36 0.38 convexity_pct 0.38 0.36 0.40 spectral_weight 0 0 0 0.35m CHM circle_fit_iou_pct 0.36 0.34 0.36 convexity_pct 0.46 0.44 0.48 spectral_weight 0 0 0 0.4m CHM circle_fit_iou_pct 0.34 0.34 0.36 convexity_pct 0.48 0.48 0.50 spectral_weight 0 0 0 0.45m CHM circle_fit_iou_pct 0.34 0.34 0.36 convexity_pct 0.52 0.52 0.54 spectral_weight 0 0 0 0.5m CHM circle_fit_iou_pct 0.34 0.34 0.34 convexity_pct 0.56 0.56 0.58 spectral_weight 0 0 0 9.4.3.2 Posterior distribution of accuracy what can we expect from a detection and form quantification accuracy perspective? 9.4.3.2.1 Data Fusion let’s start with the data fusion approach which assumes users have RGB data to complement the structural CHM data # plot it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural+spectral&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(chm_res_m_desc) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::scale_x_continuous(labels = scales::percent) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;Data Fusion (structural+spectral)&quot; , &quot;\\npredicted pile detection and form quantification accuracy metrics&quot; , &quot;\\nusing optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, angle = 90) ) let’s table the HDI of the predicted accuracy metrics # summarize it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural+spectral&quot;) %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% dplyr::group_by(chm_res_m_desc, method_input_data, name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~ scales::percent(.x,accuracy=.1) )) %&gt;% dplyr::select(-method_input_data) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;Data Fusion (structural+spectral)&quot; , &quot;&lt;br&gt;predicted pile detection and form quantification accuracy metrics&quot; , &quot;&lt;br&gt;using optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;CHM Resolution&quot;, &quot;metric&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;predicted value&quot; = 3 )) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.26: Data Fusion (structural+spectral)predicted pile detection and form quantification accuracy metricsusing optimal parameter settings based on both detection and quantification accuracy predicted value CHM Resolution metric median HDI low HDI high 0.1m CHM F-score 83.5% 82.7% 84.9% diameter MAPE 10.9% 10.7% 11.2% height MAPE 15.5% 15.3% 15.7% 0.15m CHM F-score 80.3% 79.7% 82.3% diameter MAPE 14.1% 13.9% 15.0% height MAPE 15.3% 15.2% 15.4% 0.2m CHM F-score 77.3% 76.6% 80.7% diameter MAPE 17.8% 17.6% 18.8% height MAPE 15.4% 15.2% 15.5% 0.25m CHM F-score 75.1% 74.1% 79.2% diameter MAPE 21.9% 21.7% 23.1% height MAPE 15.6% 15.5% 15.7% 0.3m CHM F-score 74.6% 72.9% 77.8% diameter MAPE 26.8% 26.4% 27.8% height MAPE 15.9% 15.8% 16.0% 0.35m CHM F-score 69.2% 67.7% 73.0% diameter MAPE 31.3% 30.8% 32.3% height MAPE 16.2% 16.1% 16.3% 0.4m CHM F-score 67.0% 65.1% 69.1% diameter MAPE 35.7% 35.2% 36.0% height MAPE 16.7% 16.5% 16.8% 0.45m CHM F-score 66.1% 64.5% 67.3% diameter MAPE 39.5% 39.1% 39.9% height MAPE 17.4% 17.2% 17.5% 0.5m CHM F-score 63.9% 62.8% 65.1% diameter MAPE 42.3% 41.7% 42.8% height MAPE 18.2% 18.0% 18.4% 9.4.3.2.2 Structural only now we’ll consider an approach that only uses structural data without the benefit of supplemental spectral data # plot it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural only&quot;) %&gt;% # filter out accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.95) , quantiles = 100 , point_size = 3 ) + ggplot2::facet_grid( rows = dplyr::vars(chm_res_m_desc) , cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::scale_x_continuous(labels = scales::percent) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;Structural only&quot; , &quot;\\npredicted pile detection and form quantification accuracy metrics&quot; , &quot;\\nusing optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text.x = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 7, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7, angle = 90) ) let’s table the HDI of the predicted accuracy metrics # summarize it best_balanced_accuracy_combos_long %&gt;% dplyr::filter(method_input_data==&quot;structural only&quot;) %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% dplyr::group_by(chm_res_m_desc, method_input_data, name) %&gt;% dplyr::summarise( # get median_hdi median_hdi_est = tidybayes::median_hdci(value)$y , median_hdi_lower = tidybayes::median_hdci(value)$ymin , median_hdi_upper = tidybayes::median_hdci(value)$ymax ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(dplyr::across( tidyselect::starts_with(&quot;median_hdi&quot;) , ~ scales::percent(.x,accuracy=.1) )) %&gt;% dplyr::select(-method_input_data) %&gt;% # table it kableExtra::kbl( caption = paste0( &quot;Structural only&quot; , &quot;&lt;br&gt;predicted pile detection and form quantification accuracy metrics&quot; , &quot;&lt;br&gt;using optimal parameter settings based on both detection and quantification accuracy&quot; ) , col.names = c( &quot;CHM Resolution&quot;, &quot;metric&quot; , c(&quot;median&quot;, &quot;HDI low&quot;, &quot;HDI high&quot;) ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;predicted value&quot; = 3 )) %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 9.27: Structural onlypredicted pile detection and form quantification accuracy metricsusing optimal parameter settings based on both detection and quantification accuracy predicted value CHM Resolution metric median HDI low HDI high 0.1m CHM F-score 82.4% 81.7% 83.2% diameter MAPE 11.0% 10.8% 11.1% height MAPE 16.0% 15.9% 16.2% 0.15m CHM F-score 79.1% 78.4% 79.9% diameter MAPE 14.3% 14.1% 14.4% height MAPE 15.7% 15.5% 15.8% 0.2m CHM F-score 75.9% 75.2% 76.6% diameter MAPE 18.0% 17.9% 18.2% height MAPE 15.6% 15.4% 15.7% 0.25m CHM F-score 72.9% 72.2% 73.5% diameter MAPE 22.2% 22.0% 22.4% height MAPE 15.7% 15.6% 15.8% 0.3m CHM F-score 70.2% 69.4% 70.7% diameter MAPE 26.8% 26.6% 27.1% height MAPE 16.0% 15.9% 16.1% 0.35m CHM F-score 67.0% 66.2% 67.6% diameter MAPE 31.4% 31.1% 31.7% height MAPE 16.4% 16.3% 16.5% 0.4m CHM F-score 64.3% 63.4% 65.1% diameter MAPE 35.8% 35.5% 36.2% height MAPE 17.0% 16.9% 17.2% 0.45m CHM F-score 61.8% 60.8% 62.8% diameter MAPE 39.8% 39.3% 40.2% height MAPE 17.9% 17.8% 18.1% 0.5m CHM F-score 59.8% 58.5% 61.0% diameter MAPE 43.0% 42.5% 43.6% height MAPE 19.1% 18.9% 19.3% 9.5 Balanced Accuracy Validation let’s test these optimal settings on the actual data to see how close our model came to properly predicting the accuracies. we’ll test using the data fusion method since we have the RGB data 9.5.1 Detection remember the optimal parameter settings we identified assuming we have spectral data for a data fusion approach? we’ll use those settings for the structural parameters and set the spectral_weight parameter to the lower end of it’s 95% HDI to be less restrictive with the spectral filtering (e.g. if HDI includes ‘4’ and ‘5’, use ‘4’) while maintaining high anticipated accuracy because these HDI’s include the full range of optimal settings based on our balanced accuracy. # remember the optimal_param_settings! optimal_temp &lt;- optimal_param_settings %&gt;% dplyr::filter(method_input_data == &quot;structural+spectral&quot;) %&gt;% dplyr::mutate( median_hdi_est = dplyr::case_when( name == &quot;spectral_weight&quot; ~ median_hdi_lower , T ~ median_hdi_est ) ) %&gt;% dplyr::select(name,median_hdi_est) %&gt;% tidyr::pivot_wider(names_from = name, values_from = median_hdi_est) %&gt;% # add on the fixed values dplyr::bind_cols( structural_params_settings %&gt;% dplyr::select(max_ht_m,max_area_m2) ) # huh? optimal_temp %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 6 ## $ chm_res_m &lt;dbl&gt; 0.1 ## $ circle_fit_iou_pct &lt;dbl&gt; 0.46 ## $ convexity_pct &lt;dbl&gt; 0.08 ## $ spectral_weight &lt;dbl&gt; 4 ## $ max_ht_m &lt;dbl&gt; 2.3 ## $ max_area_m2 &lt;dbl&gt; 46 first, we need to read in the CHM data at the optimal resolution as predicted by the model # set chm res chm_res_m_temp &lt;- optimal_temp$chm_res_m dir_temp &lt;- paste0(&quot;../data/point_cloud_processing_delivery_chm&quot;,chm_res_m_temp,&quot;m&quot;) # do it if(!dir.exists(dir_temp)){ # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = &quot;../data&quot; , input_las_dir = &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.25 , chm_res_m = chm_res_m_temp , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = &quot;../data/point_cloud_processing_delivery&quot;, to = dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(dir_temp, &quot;dtm_0.25m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(dir_temp, paste0(&quot;chm_&quot;, chm_res_m_temp,&quot;m.tif&quot;)) ) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } we’ll only work with the CHM in the study unit boundary plus a buffer to limit the amount of data we process chm_rast_temp &lt;- cloud2raster_ans$chm_rast %&gt;% terra::crop( stand_boundary %&gt;% sf::st_buffer(2) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) ) %&gt;% terra::mask( stand_boundary %&gt;% sf::st_buffer(2) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) ) # # huh? # chm_rast_temp %&gt;% # terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% # terra::plot(col = viridis::plasma(100), axes = F) # terra::plot( # stand_boundary %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 # ) # terra::plot( # slash_piles_polys %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 # ) we’re going to use our handy-dandy slash_pile_detect_watershed() function we defined in this earlier section. outdir_temp &lt;- &quot;../data/PFDP_Data/PFDP_SlashPiles/&quot; fnm_temp &lt;- file.path(outdir_temp,&quot;structural_candidate_segments.gpkg&quot;) if(!file.exists(fnm_temp)){ set.seed(77) slash_pile_detect_watershed_ans &lt;- slash_pile_detect_watershed( chm_rast = chm_rast_temp #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = optimal_temp$max_ht_m # set the max expected pile height , min_ht_m = 0.5 # set the min expected pile height , min_area_m2 = 2 # set the min expected pile area # (5*0.3048)^2 = prescription minimum = 2.322 # ((5*0.95)*0.3048)^2 = 2.1 = 5% less than minimum , max_area_m2 = optimal_temp$max_area_m2 # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = optimal_temp$convexity_pct # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = optimal_temp$circle_fit_iou_pct #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) # save slash_pile_detect_watershed_ans %&gt;% sf::st_write(fnm_temp, append = F) }else{ slash_pile_detect_watershed_ans &lt;- sf::st_read(fnm_temp, quiet=T) } # what did we get? slash_pile_detect_watershed_ans %&gt;% dplyr::glimpse() ## Rows: 162 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ area_m2 &lt;dbl&gt; 16.610, 40.330, 5.985, 8.365, 45.635, 18.900, 38.120, … ## $ volume_m3 &lt;dbl&gt; 10.676970, 40.098363, 5.079741, 9.044556, 46.122434, 1… ## $ max_height_m &lt;dbl&gt; 2.235, 2.300, 2.219, 2.300, 2.300, 2.300, 2.300, 2.300… ## $ volume_per_area &lt;dbl&gt; 0.6428037, 0.9942565, 0.8487454, 1.0812380, 1.0106811,… ## $ pct_chull &lt;dbl&gt; 0.6688742, 0.6020332, 0.7084378, 0.7136880, 0.7242248,… ## $ diameter_m &lt;dbl&gt; 7.564390, 9.323626, 3.511410, 3.832754, 8.475848, 6.35… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((499475 4317902, 4..., POLYGON ((4994… Now we’ll filter the structurally-detected candidate slash piles using the RGB spectral data with the polygon_spectral_filtering() function we defined in this earlier section. if you were wondering, yes, this function is also handy-dandy. final_predicted_slash_piles &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_watershed_ans , rgb_rast = ortho_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = optimal_temp$spectral_weight ) # add is_in_stand final_predicted_slash_piles &lt;- final_predicted_slash_piles %&gt;% dplyr::mutate( is_in_stand = pred_id %in% ( final_predicted_slash_piles %&gt;% sf::st_intersection(stand_boundary %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles))) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(pred_id) ) ) what did we get? # huh? final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 138 ## Columns: 24 ## $ pred_id &lt;int&gt; 1, 2, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 20, 23,… ## $ area_m2 &lt;dbl&gt; 16.610, 40.330, 45.635, 18.900, 38.120, 24.750, 27.76… ## $ volume_m3 &lt;dbl&gt; 10.676970, 40.098363, 46.122434, 16.298983, 44.237940… ## $ max_height_m &lt;dbl&gt; 2.235, 2.300, 2.300, 2.300, 2.300, 2.300, 2.300, 2.29… ## $ volume_per_area &lt;dbl&gt; 0.6428037, 0.9942565, 1.0106811, 0.8623801, 1.1604916… ## $ pct_chull &lt;dbl&gt; 0.6688742, 0.6020332, 0.7242248, 0.6248677, 0.7678384… ## $ diameter_m &lt;dbl&gt; 7.564390, 9.323626, 8.475848, 6.350591, 7.564390, 6.3… ## $ rast_agg_grvi &lt;dbl&gt; 0.015843167, 0.019939091, -0.025123385, 0.025851542, … ## $ rast_agg_rgri &lt;dbl&gt; 0.9688079, 0.9609014, 1.0515417, 0.9495998, 1.0410348… ## $ rast_agg_vdvi &lt;dbl&gt; 0.057569480, 0.062395341, 0.005857862, -0.021179659, … ## $ rast_agg_rgbvi &lt;dbl&gt; 0.11875952, 0.12856891, 0.01387664, -0.03608864, -0.0… ## $ rast_agg_exg &lt;dbl&gt; 0.078261125, 0.084960841, 0.007825763, -0.028041575, … ## $ rast_agg_exr &lt;dbl&gt; 0.12790022, 0.12446414, 0.15849203, 0.10745823, 0.148… ## $ rast_agg_exgr &lt;dbl&gt; -0.050100114, -0.040813919, -0.150284529, -0.13186515… ## $ rast_agg_bi &lt;dbl&gt; 0.37303904, 0.39702669, 0.53180724, 0.11501748, 0.455… ## $ rast_agg_sat &lt;dbl&gt; 0.18757563, 0.20254081, 0.11597003, 0.15812179, 0.054… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((499475 4317902, 4..., POLYGON ((499… ## $ inrange_th_exgr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_rgri &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_vdvi &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_bi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,… ## $ inrange_th_sat &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_votes &lt;dbl&gt; 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5,… ## $ is_in_stand &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,… # final_predicted_slash_piles %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::count(inrange_th_votes) how many piles were removed? # how many piles were removed? nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles) ## [1] 24 # what proportion were removed? scales::percent( (nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles))/nrow(slash_pile_detect_watershed_ans) , accuracy=0.1 ) ## [1] &quot;14.8%&quot; 9.5.2 Instance Match &amp; Accuracy Assessment now apply the instance matching process we outlined in this earlier section to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions) # ground truth and prediction matching process ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # add area of gt dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m , field_gt_volume_m3 , height_m , field_diameter_m ) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 , gt_volume_m3 = field_gt_volume_m3 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_field_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_field_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # image diameter , diff_image_diameter_m = pred_diameter_m-image_gt_diameter_m , pct_diff_image_diameter_m = (image_gt_diameter_m-pred_diameter_m)/image_gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # huh? ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 151 ## Columns: 23 ## $ pile_id &lt;dbl&gt; 194, 82, 76, 8, 187, 77, 189, 132, 111, 131,… ## $ i_area &lt;dbl&gt; 44.907459, 36.745987, 19.083370, 27.643199, … ## $ u_area &lt;dbl&gt; 54.767766, 41.666730, 22.405358, 30.096676, … ## $ iou &lt;dbl&gt; 0.8199615, 0.8819024, 0.8517324, 0.9184802, … ## $ pred_id &lt;int&gt; 6, 8, 115, 13, 12, 10, 26, 104, 47, 141, 150… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive,… ## $ gt_area_m2 &lt;dbl&gt; 54.040225, 40.292717, 21.308728, 28.909875, … ## $ image_gt_diameter_m &lt;dbl&gt; 8.966741, 7.892174, 5.909959, 7.595808, 6.88… ## $ gt_volume_m3 &lt;dbl&gt; 183.079674, 97.299997, 91.178437, 75.349118,… ## $ gt_height_m &lt;dbl&gt; 6.4008, 4.2672, 4.7244, 4.2672, 3.2004, 2.43… ## $ gt_diameter_m &lt;dbl&gt; 8.53440, 7.62000, 7.01040, 6.70560, 6.46176,… ## $ pred_area_m2 &lt;dbl&gt; 45.635, 38.120, 20.180, 28.830, 24.930, 27.7… ## $ pred_volume_m3 &lt;dbl&gt; 46.122434, 44.237940, 16.008302, 30.692573, … ## $ pred_height_m &lt;dbl&gt; 2.300, 2.300, 1.731, 2.298, 2.299, 2.300, 2.… ## $ pred_diameter_m &lt;dbl&gt; 8.475848, 7.564390, 5.679789, 7.375636, 6.64… ## $ diff_height_m &lt;dbl&gt; -4.10080005, -1.96720005, -2.99340005, -1.96… ## $ pct_diff_height_m &lt;dbl&gt; 0.6406699237, 0.4610048856, 0.6336042785, 0.… ## $ diff_field_diameter_m &lt;dbl&gt; -0.05855196, -0.05560974, -1.33061127, 0.670… ## $ pct_diff_field_diameter_m &lt;dbl&gt; 0.006860700, 0.007297866, 0.189805328, -0.09… ## $ diff_image_diameter_m &lt;dbl&gt; -0.49089339, -0.32778417, -0.23016998, -0.22… ## $ pct_diff_image_diameter_m &lt;dbl&gt; 0.05474602, 0.04153281, 0.03894612, 0.028986… ## $ diff_area_m2 &lt;dbl&gt; -8.4052248, -2.1727174, -1.1287281, -0.07987… ## $ pct_diff_area_m2 &lt;dbl&gt; 0.155536452, 0.053923327, 0.052970225, 0.002… # diff_diameter_m &gt; diff_field_diameter_m # pct_diff_diameter_m &gt; pct_diff_field_diameter_m Now we’ll aggregate the instance matching results to calculate overall performance assessment metrics. Here, we take the counts of True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions), to determine overall accuracy. This aggregation will give us two types of results: detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified agg_ground_truth_match_ans &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans = ground_truth_prediction_match_ans) # huh? # agg_ground_truth_match_ans %&gt;% dplyr::glimpse() let’s table the relevant accuracy metrics kbl_agg_gt_match &lt;- function( agg_ground_truth_match_df , caption = &quot;pile detection and form quantification accuracy metrics&quot; ) { # let&#39;s table the most relevant metrics agg_ground_truth_match_df %&gt;% # first select to arrange eval_metric dplyr::select( # detection cnt tp_n, fn_n, fp_n # detection , f_score, recall, precision # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) # , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( # detection cnt tp_n, fn_n, fp_n # detection , f_score, recall, precision # quantification , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% dplyr::mutate( dplyr::across( .cols = c(f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;)) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_n&quot;)) , .fn = ~ scales::comma(.x, accuracy = 1) ) ) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::ends_with(&quot;_n&quot;) , f_score, recall, precision , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_rrmse&quot;) , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( eval_metric = metric %&gt;% stringr::str_extract(&quot;(_rmse|_rrmse|_mean|_mape|f_score|recall|precision|tp_n|fn_n|fp_n)$&quot;) %&gt;% stringr::str_remove_all(&quot;_n$&quot;) %&gt;% stringr::str_remove_all(&quot;_&quot;) %&gt;% stringr::str_replace_all(&quot;mean&quot;,&quot;me&quot;) %&gt;% toupper() %&gt;% factor( ordered = T , levels = c(&quot;TP&quot;,&quot;FN&quot;,&quot;FP&quot;, &quot;FSCORE&quot;,&quot;RECALL&quot;,&quot;PRECISION&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) , labels = c(&quot;TP&quot;,&quot;FN&quot;,&quot;FP&quot;, &quot;F-score&quot;,&quot;Recall&quot;,&quot;Precision&quot;, &quot;ME&quot;,&quot;RMSE&quot;,&quot;RRMSE&quot;,&quot;MAPE&quot;) ) , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% stringr::str_c( dplyr::case_when( stringr::str_detect(metric,&quot;(field|image)&quot;) ~ paste0(&quot; (&quot;, stringr::str_extract(metric,&quot;(field|image)&quot;), &quot;)&quot;) , T ~ &quot;&quot; ) ) %&gt;% stringr::str_replace(&quot;area&quot;, &quot;area m&lt;sup&gt;2&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;volume&quot;, &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;diameter&quot;, &quot;diameter m&quot;) %&gt;% stringr::str_replace(&quot;height&quot;, &quot;height m&quot;) %&gt;% stringr::str_to_sentence() ) %&gt;% dplyr::mutate( pile_metric = dplyr::case_when( pile_metric == &quot;Detection&quot; &amp; eval_metric %in% c(&quot;TP&quot;,&quot;FN&quot;,&quot;FP&quot;) ~ &quot;Detection Count&quot; , T ~ pile_metric ) , sorter = dplyr::case_when( pile_metric==&quot;Detection Count&quot; ~ 1 , pile_metric==&quot;Detection&quot; ~ 2 , T ~ 3 ) ) %&gt;% dplyr::arrange(sorter, pile_metric, eval_metric) %&gt;% dplyr::select(pile_metric,eval_metric,value) %&gt;% kableExtra::kbl( caption = caption , col.names = c( &quot;.&quot;, &quot;&quot; , &quot;value&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 12) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) } use the function we just defined to make a nice summary table # do it kbl_agg_gt_match( agg_ground_truth_match_ans , caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;data fusion PSINF ponderosa pine training site&quot; ) Table 9.28: pile detection and form quantification accuracy metricsdata fusion PSINF ponderosa pine training site . value Detection Count TP 107 FN 14 FP 30 Detection F-score 83% Recall 88% Precision 78% Area m2 ME -0.63 RMSE 2.1 MAPE 12% Diameter m (field) ME 0.21 RMSE 0.6 MAPE 11% Diameter m (image) ME -0.17 RMSE 0.4 MAPE 8% Height m ME -0.20 RMSE 0.7 MAPE 15% # save the table for full comparison at the very end all_agg_ground_truth_match_ans_fp &lt;- file.path(&quot;../data/&quot;,&quot;all_agg_ground_truth_match_ans.gpkg&quot;) # make a function to convert the sf data to the same format for all all_agg_ground_truth_sf_format &lt;- function(stand_boundary, site = &quot;you didn&#39;t name this site&quot;) { ret &lt;- stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_sf() %&gt;% dplyr::mutate(site_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_centroid() %&gt;% sf::st_sf() %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::mutate(site = site) return(ret) } # write data all_agg_ground_truth_sf_format( stand_boundary = stand_boundary , site = &quot;PSINF ponderosa pine training site&quot; ) %&gt;% dplyr::bind_cols( agg_ground_truth_match_ans # join on aggregated form quantifications that we have for all , ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(image_gt_diameter_m, pred_diameter_m, gt_area_m2, pred_area_m2, pred_volume_m3, pred_height_m) , ~ sum(.x, na.rm = TRUE) ) ) ) %&gt;% # dplyr::glimpse() # readr::write_csv(file = all_agg_ground_truth_match_ans_fp, append = F, progress = F) sf::st_write(dsn = all_agg_ground_truth_match_ans_fp, append = F, quiet = T) let’s compare these with the predicted accuracies from the model best_balanced_accuracy_combos %&gt;% # get rid of vars we fixed dplyr::select(-c(max_ht_m, max_area_m2)) %&gt;% dplyr::mutate( spectral_weight = spectral_weight %&gt;% as.character() %&gt;% as.numeric() ) %&gt;% tidyr::pivot_longer(cols = -c(.draw,method_input_data)) %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) %&gt;% dplyr::filter(method_input_data == &quot;structural+spectral&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value)) + tidybayes::stat_dotsinterval( point_interval = &quot;median_hdci&quot;, .width = c(0.99) , quantiles = 100 , point_size = 3 ) + ggplot2::geom_vline( data = agg_ground_truth_match_ans %&gt;% dplyr::select(f_score,pct_diff_field_diameter_m_mape,pct_diff_height_m_mape) %&gt;% dplyr::rename( diameter_mape=pct_diff_field_diameter_m_mape , height_mape=pct_diff_height_m_mape ) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::ungroup() %&gt;% # filter for accuracy metrics dplyr::filter(name==&quot;f_score&quot; | stringr::str_ends(name, &quot;_mape&quot;)) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;_mape&quot;, &quot;_MAPE&quot;) %&gt;% stringr::str_replace_all(&quot;f_score&quot;, &quot;F-score&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;, &quot; &quot;) %&gt;% stringr::str_squish() %&gt;% factor(ordered = T) %&gt;% forcats::fct_relevel(&quot;F-score&quot;) ) , mapping = ggplot2::aes(xintercept=value) , color = &quot;navy&quot;, lwd = 2, alpha = 0.7 ) + ggplot2::facet_grid( cols = dplyr::vars(name) , scales = &quot;free_x&quot; , axes = &quot;all_x&quot; ) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::scale_x_continuous(labels = scales::percent, expand = ggplot2::expansion(mult = c(1.1,1.1))) + ggplot2::labs( x=&quot;&quot; , subtitle = paste0( &quot;Data Fusion predictions with actual results in blue&quot; , &quot;\\npredicted pile detection and form quantification accuracy metrics&quot; , &quot;\\nusing optimal parameter settings based on both detection and quantification accuracy&quot; ) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 8, angle = 90) ) pretty close! let’s now look at the summary stats of ground truth piles kbl_form_sum_stats( slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) , caption = &quot;Ground Truth Piles: summary statistics for form measurements&lt;br&gt;PSINF ponderosa pine training site&quot; ) Table 9.29: Ground Truth Piles: summary statistics for form measurementsPSINF ponderosa pine training site # piles Metric Mean Std Dev q 10% Median q 90% Range 121 Height m 2.2 0.8 1.7 2.0 2.3 1.5—6.4 Diameter m (image) 3.8 1.3 3.0 3.5 4.5 2.6—10.2 Diameter m (field) 3.4 1.2 2.8 3.1 4.0 2.4—9.0 Area m2 (image) 9.8 9.4 5.6 7.1 11.9 3.9—59.3 Area m2 (field) 10.5 10.2 6.2 7.6 12.3 4.7—63.1 and let’s look at the summary stats of the predicted piles kbl_form_sum_stats( final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , caption = &quot;Predicted Piles: summary statistics for form measurements&lt;br&gt;PSINF ponderosa pine training site&quot; ) Table 9.30: Predicted Piles: summary statistics for form measurementsPSINF ponderosa pine training site # piles Metric Mean Std Dev q 10% Median q 90% Range 137 Height m 1.9 0.4 1.5 2.0 2.3 0.7—2.3 Diameter m 3.6 1.2 2.6 3.3 4.7 2.0—9.3 Area m2 8.2 6.8 3.6 6.4 13.1 2.4—45.6 Volume m3 7.0 7.6 2.6 5.0 10.8 0.8—46.1 let’s look at these on the RGB # plot it ortho_plt_fn(my_ortho_rast = ortho_rast, stand = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), buffer = 10) + # ggplot2::ggplot() + ggplot2::geom_sf(data = stand_boundary %&gt;% sf::st_transform(sf::st_crs(ortho_rast)), fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(ortho_rast)) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.3 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) ## |---------|---------|---------|---------|========================================= there are many TP matches there! agg_ground_truth_match_ans %&gt;% dplyr::select(tidyselect::ends_with(&quot;_n&quot;)) ## # A tibble: 1 × 3 ## tp_n fp_n fn_n ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 107 30 14 let’s look at some examples on our RGB image commissions (false positives) predicted pile outlined in brown plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=ortho_rast, stand=sf::st_union(pr), buffer=6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) there are rocks, shadows, root bundles, downed trees with branches… omissions (false negatives) actual piles outlined in blue plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fn_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=ortho_rast, stand=sf::st_union(gt), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) for the most part, those are irregularly shaped or have unexpected spectral signatures (e.g. very white or entirely in dark shadows). however, the machine piles might have been larger than our expected area threshold max_area_m2 or taller than our expected height threshold max_ht_m 9.5.3 Volume Comparison The ground truth dataset used for developing and tuning all slash pile detection parameters includes direct data for field-measured height, field-measured diameter, and image-annotated area (based on pile perimeters). Accuracy and error metrics, such as ME, RMSE, and MAPE, will be only calculated for these direct measurements. We excluded quantification accuracy metrics for derived volume because the resulting value would not constitute a true “error”. Comparing our predicted volume to a volume that was not directly measured, but instead calculated using a geometric assumption (like assuming a perfectly circular base and paraboloid shape) would be inappropriate. This is because any resulting difference between the prediction and the ground truth would be a blend of three inseparable factors: the error of the remote-sensing prediction method, the error in the direct field measurements (diameter/height), and the error introduced by the geometric shape assumption. Reporting such combined errors would be misleading, as it would be impossible to isolate the true performance of our remote-sensing method alone. Instead, data involving derived values of volume based on field measurements and a shape assumption and its comparison to our irregularly shaped CHM-derived volume will be treated simply as data points for insight into the differences. Using geometric shape assumptions for estimating pile volume is the standard practice when implementing prescriptions or preparing for slash pile burning (Hardy 1996; Long &amp; Boston 2014). This comparison will help us understand the discrepancy between our irregularly shaped CHM-derived volume and the volume calculated assuming a perfectly circular base and paraboloid shape with field-measured height and diameter. This approach will still provide valuable context about the impact of the perfectly circular base and paraboloid geometric assumptions without falsely attributing the error of the simplified model to the remote-sensing method itself. let’s do that now field-measured piles volume assumes a paraboloid shape, with volume calculated using the field-measured diameter (as the width) and height. we’ll refer to this as “Allometric Field Volume” to indicate the field measurement is derived using a shape assumption. predicted piles volume calculated from the elevation profile of the irregular predicted pile footprint, without assuming a specific geometric shape. we’ll refer to this as “Predicted Volume” to indicate the predicted measurement is from our CHM-based detection methodology We would generally expect that the allometric field volume is larger than the predicted volume because the allometric calculation assumes a perfectly regular geometric shape (circular base and paraboloid) based on maximum field dimensions (height and diameter). this process effectively encloses the actual, irregular pile form within a simplified geometric dome which inherently neglects and sits above the actual irregularities and voids in the pile structure, likely leading to an overestimation of the volume. we already added volume measurements to the TP matches for both the ground truth and predicted piles, summary of that data ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(gt_volume_m3, pred_volume_m3) %&gt;% summary() ## gt_volume_m3 pred_volume_m3 ## Min. : 4.270 Min. : 1.109 ## 1st Qu.: 6.564 1st Qu.: 4.276 ## Median : 7.497 Median : 5.216 ## Mean : 12.375 Mean : 7.136 ## 3rd Qu.: 8.746 3rd Qu.: 7.054 ## Max. :183.080 Max. :46.122 those don’t really look like they match up well…let’s explore ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(diff_volume_m3 = gt_volume_m3 - pred_volume_m3) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = gt_volume_m3, x = pred_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + # ggplot2::geom_point(ggplot2::aes(color = diff_volume_m3)) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::labs( y = latex2exp::TeX(&quot;allometric field volume $m^3$&quot;) , x = latex2exp::TeX(&quot;predicted volume $m^3$&quot;) # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison&quot;) ) + ggplot2::theme_light() this is exactly what we expected: for true positive matches, there is a clear systematic difference with the plot showing that the volume calculated using the idealized, regular shape assumption (allometric field volume) is consistently larger than the predicted volume derived from the CHM let’s check these using lm() lm_temp &lt;- lm(gt_volume_m3 ~ pred_volume_m3, data = ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;)) summary(lm_temp) ## ## Call: ## lm(formula = gt_volume_m3 ~ pred_volume_m3, data = ground_truth_prediction_match_ans %&gt;% ## dplyr::filter(match_grp == &quot;true positive&quot;)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.174 -3.524 0.247 3.327 66.142 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -6.7649 1.5273 -4.429 2.33e-05 *** ## pred_volume_m3 2.6820 0.1517 17.682 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.15 on 105 degrees of freedom ## Multiple R-squared: 0.7486, Adjusted R-squared: 0.7462 ## F-statistic: 312.6 on 1 and 105 DF, p-value: &lt; 2.2e-16 These linear model results (intercept = -6.76, slope = 2.68) indicate a strong proportional bias that significantly increases with pile size. The high slope (2.68) coupled with the negative intercept (-6.76) indicate that the volume difference is not a simple constant offset (e.g. slope of ~1.0 and intercept of &gt;0 if our hypothesis of consistently higher allometric field volume is true), but rather a scaling issue that is driven by the largest piles. The much larger allometric field volume estimates relative to the CHM-predicted volumes for the largest piles exert a strong influence on the predicted form of the liner model, pulling the slope steeply upward and forcing the intercept below zero as a mathematical artifact. Despite the predicted negative intercept, visual inspection of the data shows that most allometric field volumes are larger than the CHM-predicted volumes, even for smaller piles. The slope value indicates that for every 1 m3 increase in predicted volume, the allometric field volume increases by nearly 2.68 m3. This data suggests that the geometric assumptions of the allometric model potentially introduce substantial scaling error which may limit its reliability (especially for larger piles) for accurately estimating the volume of real-world piles which have heterogeneous footprints and elevation profiles. before we compare the volume measurements in aggregate, let’s look at the distributions vol_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,gt_volume_m3,pred_volume_m3) %&gt;% tidyr::pivot_longer(cols = -c(pile_id)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_volume_m3&quot;,&quot;pred_volume_m3&quot;) , labels = c( &quot;allometric field volume&quot; , &quot;predicted volume&quot; ) ) ) # plot dist vol_df_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = name, fill = name)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=latex2exp::TeX(&quot;volume $m^3$&quot;) , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison of distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) slope plots are neat too vol_df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) what if we only look at the smaller piles? vol_df_temp %&gt;% dplyr::filter( value &lt; quantile(vol_df_temp$value, probs = 0.938) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level for the smaller piles&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) let’s compare aggregated volume measurements for the true positive matches Mean Difference (MD): \\[\\text{MD} = \\frac{1}{N} \\sum_{i=1}^{N} (\\text{Allometric Volume}_i - \\text{Predicted Volume}_i)\\] Percent Mean Difference: \\[\\%\\text{MD} = \\frac{\\text{MD}}{\\text{Mean}(\\text{Predicted Volume})} \\times 100\\] vol_agg_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( mean_diff = mean(gt_volume_m3-pred_volume_m3) , sd_diff = sd(gt_volume_m3-pred_volume_m3) , mean_gt_volume_m3 = mean(gt_volume_m3,na.rm = T) , mean_pred_volume_m3 = mean(pred_volume_m3,na.rm = T) ) %&gt;% dplyr::mutate( pct_mean_diff = mean_diff/mean_pred_volume_m3 ) what did we get? vol_agg_df_temp %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( value = dplyr::case_when( stringr::str_starts(name, &quot;pct_&quot;) ~ scales::percent(value, accuracy = 0.1) , T ~ scales::comma(value, accuracy = 0.1) ) ) %&gt;% kableExtra::kbl( caption = &quot;comparison of aggregated allometric field volume and predicted volume&quot; , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 9.31: comparison of aggregated allometric field volume and predicted volume metric value mean_diff 5.2 sd_diff 16.3 mean_gt_volume_m3 12.4 mean_pred_volume_m3 7.1 pct_mean_diff 73.4% we’ll dig into the MD shortly but before we move on let’s focus on the percent mean difference. We calcualted a %MD of 73.4% which indicates a major systematic difference where the allometric field volume is, on average, 73.4% larger than our CHM-predicted volume. This large relative difference shows how much the geometric assumptions inflate the volume compared to the irregular volumes measured by our remote sensing-based method. let’s make a Bland-Altman plot to compare the two measurement methods. this plot uses the average of the two measurements (approximate size) on the x-axis and the difference (bias) between the two measurements on the y-axis ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( mean_vol = (gt_volume_m3+pred_volume_m3)/2 , diff_vol = (gt_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp , scale_diff = ifelse(diff_vol &lt; 0, -abs(diff_vol) / abs(min(diff_vol)), diff_vol / max(diff_vol)) ) %&gt;% # ggplot() + geom_point(aes(x=diff_vol,y=0, color=scale_diff)) + scale_color_gradient2(mid = &quot;gray&quot;, midpoint = 0, low = &quot;red&quot;, high = &quot;blue&quot;) # plot ggplot2::ggplot( mapping = ggplot2::aes(x = mean_vol, y = diff_vol) ) + ggplot2::geom_hline(yintercept = 0, color = &quot;black&quot;, lwd = 1.2) + # mean difference (bias) ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff , linetype = &quot;dashed&quot;, color = &quot;blue&quot;, lwd = 1 ) + # upper limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # lower limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # annotations ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff , label = latex2exp::TeX( paste0( &quot;mean difference (bias): &quot; , scales::comma(vol_agg_df_temp$mean_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;blue&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;+1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;-1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = 1.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + # points ggplot2::geom_point(mapping = ggplot2::aes(color = scale_diff), size = 1.9, alpha = 0.8) + ggplot2::scale_color_steps2(mid = &quot;gray&quot;, midpoint = 0) + ggplot2::labs( subtitle = &quot;Bland-Altman plot: allometric field volume vs predicted volume&quot; , x = latex2exp::TeX(&quot;mean volume ($m^3$)&quot;) , y = latex2exp::TeX(&quot;difference (allometric - predicted volume $m^3$)&quot;) ) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;none&quot;) That’s a lot of plotting to show that the mean difference is 5.24 m3. Points falling outside the 95% interval on the plot are instances of significant disagreement between the two volume measurements for those specific data points. These outliers indicate that, for a particular pile, the difference between the allometric field volume and the predicted volume is unusually large, suggesting a potential failure in either the CHM segmentation process, the quality of the original field measurements, the geometric shape assumption, or a combination thereof. We should investigate these extreme disagreements further to see what is happening before we do that, let’s use a paired t-test to determine if the mean difference (MD) between the allometric field volume and the predicted volume is statistically significant (i.e. significantly different from zero) # is the mean difference between the two volumes significantly different from zero ttest_temp &lt;- t.test( ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) , ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) and ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) ## t = 3.3155, df = 106, p-value = 0.001253 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 2.106105 8.371658 ## sample estimates: ## mean difference ## 5.238881 that’s neat, the test gave us the same mean difference (MD) of 5.24 m3 that we calculated above. also, the p-value of 0.00125 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where allometric volume is larger than our predicted volume is statistically significant and not due to random chance. 9.5.3.1 Extreme Volume Disagreements let’s investigate the extreme disagreements further to see what is happening bad_vol_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( diff_vol = (gt_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp ) %&gt;% dplyr::filter( diff_vol &lt; (vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff) | diff_vol &gt; (vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff) ) %&gt;% dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id, comment) %&gt;% dplyr::rename(pile_type = comment) , by = &quot;pile_id&quot; ) # what are the differences? bad_vol_df_temp %&gt;% dplyr::select( pile_id, pile_type , gt_height_m, pred_height_m, diff_height_m , gt_diameter_m, pred_diameter_m, diff_field_diameter_m , gt_volume_m3, pred_volume_m3 ) %&gt;% dplyr::mutate( dplyr::across( .cols = -c(pile_id,pile_type) , .fns = ~ scales::comma(.x,accuracy=0.01) ) ) %&gt;% kableExtra::kbl( caption = &quot;Volume measurement outliers: comparison of ground truth and predicted piles&quot; # , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling(font_size = 9.8) Table 9.32: Volume measurement outliers: comparison of ground truth and predicted piles pile_id pile_type gt_height_m pred_height_m diff_height_m gt_diameter_m pred_diameter_m diff_field_diameter_m gt_volume_m3 pred_volume_m3 194 Mechanical Pile 6.40 2.30 -4.10 8.53 8.48 -0.06 183.08 46.12 82 Mechanical Pile 4.27 2.30 -1.97 7.62 7.56 -0.06 97.30 44.24 76 Mechanical Pile 4.72 1.73 -2.99 7.01 5.68 -1.33 91.18 16.01 8 Mechanical Pile 4.27 2.30 -1.97 6.71 7.38 0.67 75.35 30.69 All these instances of extreme volume disagreement at the PSINF ponderosa pine training site are specific to mechanical piles and it looks like the field-measured height is much different than the CHM height. This suggests that the optimal max_ht_m parameter determined during sensitivity and statistical testing was set too low to properly include the upper extent of these taller machine piles. The parameter was optimized this way because the training data featured a much higher frequency of smaller, shorter hand piles, causing the statistical tuning to be inherently biased toward those dominant smaller objects. This finding highlights the difficulty of creating a single-stage process capable of simultaneously detecting distinct pile forms such as small hand piles and larger machine piles. A workaround for this challenge is to execute the pile detection process in two stages: the first parameterized specifically for the expected size, form, and spectral signature of the hand piles, and a second stage parameterized for the expectations of the larger machine piles and then combine the predictions into a final prediction set. bad_vol_df_temp %&gt;% dplyr::select( pile_id , gt_height_m, pred_height_m , gt_diameter_m, pred_diameter_m , gt_volume_m3, pred_volume_m3 ) %&gt;% tidyr::pivot_longer( cols = -c(pile_id) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground &#39;truth&#39;&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume (m3)&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = which_data, y = value, label = scales::comma(value,accuracy=0.1), group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = which_data), alpha = 0.8, size = 2.5) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 , show.legend = FALSE ) + ggplot2::facet_grid(rows = dplyr::vars(pile_metric), scales = &quot;free_y&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0.05,.32))) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot; , subtitle = &quot;Volume measurement outliers: comparison of measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) RGB with the predicted piles (brown) and the ground-truth piles (blue) # plot RGB plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=ortho_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/PFDP_Data/bad_vol.jpg&quot;, height = 8.5, width = 8.5) just looking at the RGB, the pile footprints are in good alignment let’s look at the CHM # cloud2raster_ans$chm_rast %&gt;% # terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% # terra::plot() # bad_vol_df_temp %&gt;% dplyr::glimpse() # plot RGB + CHM plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=ortho_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_tile( data = cloud2raster_ans$chm_rast %&gt;% terra::crop( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) + ggplot2::labs( subtitle = paste0( &quot;GT ht: &quot;, round(dta$gt_height_m,1) , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) The predicted diameters generally align well with the field-measured diameters. However, the field-measured heights for some piles appear unusually high compared to the CHM-derived data. Our pile detection methodology uses a specific height slice of the CHM based on the max_ht_m parameter. This process then keeps only predicted piles that meet the height threshold across the majority of their area. The convexity_pct parameter functions to filter out predictions where excessive pile top area was removed by the CHM slicing and acts as a safeguard against misclassifying tall objects (like trees) as piles that would have the majority of their top removed by the slicing. After filtering for expected height, our detection methodology calculates the predicted height as the maximum CHM cell value within the expected height range (i.e. up to the max_ht_m setting), which effectively caps any actual height values above this threshold. For our training data, we assumed a maximum height of 2.30m. The field data contains heights up to 6.40m for these volume outliers, which would only be expected of the largest machine piles. In these extreme cases, the significant volume difference observed in the outliers is magnified by both potentially incorrect field measurements and the systematic capping of the predicted height. To mitigate the risk of vastly underpredicted heights for these tall outliers, one can increase the convexity_pct parameter. Making this filtering more strict will remove the outlier height predictions and improve height quantification accuracy for true positive matches, but will likely reduce the detection rate as these piles become false negatives (omissions). Alternatively, one could increase the max_ht_m setting to be less restrictive with the height filtering; this would have the effect of estimating a more accurate height value for these tall piles but would potentially introduce new false positive predictions that are actually trees (or yurts?). If spectral data is available to filter these after structural segmentation, then this might be the preferred path to improve height quantification accuracy while maintaining detection accuracy. The choice ultimately depends on whether the user prioritizes detection rate or height quantification accuracy. There is precedent for smoothing the height of piles from aerial data point cloud data. Trofymow et al. (2013) calculated pile height as the 95th percentile height of the height-normalized points within the pile polygon. This method was chosen after their preliminary analysis showed it best excluded points from isolated logs extending above the pile while retaining the main pile structure. Our method achieves a functionally similar result for the largest piles by capping the maximum CHM value and smoothing out extreme height measurements. we can look a the full CHM without capping the height to see how the field-measured values compare to the unfiltered CHM height profile within the pile footprint # cloud2raster_ans$chm_rast %&gt;% # terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% # terra::plot() # bad_vol_df_temp %&gt;% dplyr::glimpse() # plot RGB + CHM plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=ortho_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_tile( data = cloud2raster_ans$chm_rast %&gt;% terra::crop( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% # DON&#39;T slice the chm below our desired height # terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;, breaks = scales::breaks_extended(n=7)) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) + ggplot2::labs( subtitle = paste0( &quot;GT ht: &quot;, round(dta$gt_height_m,1) , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) Visual inspection of the unfiltered CHM (note the CHM scale range) within the footprint of these volume outliers confirms that the field-measured values are misaligned with the CHM profile by at least 1m for some of the most extreme outliers, supporting the theory that the significant volume and height differences observed are magnified by potentially incorrect field measurements. 9.5.3.2 Allometric Volume Comparison The volume comparison immediately above compared the allometric field volume using a geometric shape assumption (paraboloid) with the predicted volume based on the irregular CHM elevation profile. Thus, the volume difference included the impact of the shape assumption. In an attempt to remove the influence of comparing a regular shape (field measured) to an irregular shape (predicted volume), we’ll perform a comparison analysis where both volume calculations are based on the same paraboloid shape assumption. This should provide insight into the differences related only to the predicted versus field-measured maximum dimensions of height and diameter. In the following section, we compare volume predictions against field measured data where both volume calculations utilize the same paraboloid shape assumption. For this analysis, we’ll update the predicted volume only using the following volume definitions: field-measured piles volume assumes a paraboloid shape, with volume calculated using the field-measured diameter (as the width) and height. we’ll refer to this as “Allometric Field Volume” to indicate the field measurement is derived using a shape assumption. predicted piles volume assumes a paraboloid shape, with volume calculated using the predicted diameter (as the width) and height. we’ll refer to this as “Allometric Predicted Volume” to indicate the measurement is derived using a shape assumption. We would generally expect that the allometric field volume will not be uniformly larger or smaller than the predicted allometric volume, as the volume difference will be the net result of two competing influences: the observed overestimation of diameter (0.21 m mean error) and the observed underestimation of height (-0.20 m mean error) propagating through the volume calculation formula. let’s first update the predicted volume to calculate the allometric predicted volume where the volume formula for a paraboloid is: \\[ V = \\frac{1}{8}\\pi \\cdot width^2 \\cdot height \\] we expect the allometric predicted volume to be larger than the predicted volume calculated based on the irregular elevation profile in the CHM because assuming a geometric shape smooths all the voids and irregularities ( which more accurately reflect reality ;) ) ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::mutate( pred_allom_volume_m3 = (1/8) * pi * (pred_diameter_m^2) * pred_height_m ) # summarize it ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(gt_volume_m3, pred_volume_m3, pred_allom_volume_m3) %&gt;% summary() ## gt_volume_m3 pred_volume_m3 pred_allom_volume_m3 ## Min. : 4.270 Min. : 1.109 Min. : 2.822 ## 1st Qu.: 6.564 1st Qu.: 4.276 1st Qu.: 6.547 ## Median : 7.497 Median : 5.216 Median : 7.785 ## Mean : 12.375 Mean : 7.136 Mean :10.732 ## 3rd Qu.: 8.746 3rd Qu.: 7.054 3rd Qu.: 9.782 ## Max. :183.080 Max. :46.122 Max. :64.886 nice, the allometric predicted volume is larger than the predicted volume calculated based on the irregular elevation profile in the CHM ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(diff_volume_m3 = gt_volume_m3 - pred_allom_volume_m3) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = gt_volume_m3, x = pred_allom_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_allom_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_allom_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::labs( y = latex2exp::TeX(&quot;allometric field volume $m^3$&quot;) , x = latex2exp::TeX(&quot;allometric predicted volume $m^3$&quot;) # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison&quot;) ) + ggplot2::theme_light() the differences between the predictions for the larger field measured piles are pulling the slope of the line upwards but for the smaller piles, the volume differences are clustered around the line of equality before we compare the volume measurements in aggregate, let’s look at the distributions vol_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,gt_volume_m3,pred_allom_volume_m3) %&gt;% tidyr::pivot_longer(cols = -c(pile_id)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_volume_m3&quot;,&quot;pred_allom_volume_m3&quot;) , labels = c( &quot;allometric field volume&quot; , &quot;allometric predicted volume&quot; ) ) ) # plot dist vol_df_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = name, fill = name)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=latex2exp::TeX(&quot;allometric volume $m^3$&quot;) , subtitle = latex2exp::TeX(&quot;Allometric bulk volume ($m^3$) comparison of distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) nice, the distributions overlap much more than the volume comparison between the allometric field value and the irregular, CHM-derived prediction slope plots are neat too vol_df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;allometric volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;Allometric bulk volume ($m^3$) comparison at the pile level&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) what if we only look at the smaller piles? vol_df_temp %&gt;% dplyr::filter( value &lt; quantile(vol_df_temp$value, probs = 0.938) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;allometric volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;Allometric bulk volume ($m^3$) comparison at the pile level for the smaller piles&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) there is much more variability in this slope plot than the volume comparison between the allometric field value and the irregular, CHM-derived prediction let’s compare aggregated volume measurements for the true positive matches vol_agg_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( mean_diff = mean(gt_volume_m3-pred_allom_volume_m3) , sd_diff = sd(gt_volume_m3-pred_allom_volume_m3) , mean_gt_volume_m3 = mean(gt_volume_m3,na.rm = T) , mean_pred_allom_volume_m3 = mean(pred_allom_volume_m3,na.rm = T) ) %&gt;% dplyr::mutate( pct_mean_diff = mean_diff/mean_pred_allom_volume_m3 ) what did we get? vol_agg_df_temp %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( value = dplyr::case_when( stringr::str_starts(name, &quot;pct_&quot;) ~ scales::percent(value, accuracy = 0.1) , T ~ scales::comma(value, accuracy = 0.1) ) ) %&gt;% kableExtra::kbl( caption = &quot;comparison of aggregated allometric field volume and allometric predicted volume&quot; , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 9.33: comparison of aggregated allometric field volume and allometric predicted volume metric value mean_diff 1.6 sd_diff 14.8 mean_gt_volume_m3 12.4 mean_pred_allom_volume_m3 10.7 pct_mean_diff 15.3% we’ll dig into the MD shortly but before we move on let’s focus on the percent mean difference. We calcualted a %MD of 15.3% which indicates a slight systematic difference where the allometric field volume is, on average, 15.3% larger than our predicted allometric volume. let’s make a Bland-Altman plot to compare the two measurement methods. this plot uses the average of the two measurements (approximate size) on the x-axis and the difference (bias) between the two measurements on the y-axis ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( mean_vol = (gt_volume_m3+pred_allom_volume_m3)/2 , diff_vol = (gt_volume_m3-pred_allom_volume_m3) # match the order used in vol_agg_df_temp , scale_diff = ifelse(diff_vol &lt; 0, -abs(diff_vol) / abs(min(diff_vol)), diff_vol / max(diff_vol)) ) %&gt;% # ggplot() + geom_point(aes(x=diff_vol,y=0, color=scale_diff)) + scale_color_gradient2(mid = &quot;gray&quot;, midpoint = 0, low = &quot;red&quot;, high = &quot;blue&quot;) # plot ggplot2::ggplot( mapping = ggplot2::aes(x = mean_vol, y = diff_vol) ) + ggplot2::geom_hline(yintercept = 0, color = &quot;black&quot;, lwd = 1.2) + # mean difference (bias) ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff , linetype = &quot;dashed&quot;, color = &quot;blue&quot;, lwd = 1 ) + # upper limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # lower limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # annotations ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff , label = latex2exp::TeX( paste0( &quot;mean difference (bias): &quot; , scales::comma(vol_agg_df_temp$mean_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;blue&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;+1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;-1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = 1.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + # points ggplot2::geom_point(mapping = ggplot2::aes(color = scale_diff), size = 1.9, alpha = 0.8) + ggplot2::scale_color_steps2(mid = &quot;gray&quot;, midpoint = 0) + ggplot2::labs( subtitle = &quot;Bland-Altman plot: allometric field volume vs allometric predicted volume&quot; , x = latex2exp::TeX(&quot;mean allometric volume ($m^3$)&quot;) , y = latex2exp::TeX(&quot;difference (allometric field - allometric predicted volume $m^3$)&quot;) ) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;none&quot;) That’s a lot of plotting to show that the mean difference is 1.64 m3. This is a significant improvement over our comparison between the allometric field value and the irregular, CHM-derived prediction let’s use a paired t-test to determine if the mean difference (MD) between the allometric field volume and the allometric predicted volume is statistically significant (i.e. significantly different from zero) # is the mean difference between the two volumes significantly different from zero ttest_temp &lt;- t.test( ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) , ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_allom_volume_m3) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) and ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_allom_volume_m3) ## t = 1.1504, df = 106, p-value = 0.2526 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -1.188974 4.475875 ## sample estimates: ## mean difference ## 1.64345 Wow, the p-value of 0.253 is greater than 0.05 (even 0.10), meaning we fail to reject the null hypothesis that the true mean difference is zero. That is, the mean difference between the field-measured volume and the predicted volume is not different than zero when both are forced to use the same paraboloid shape assumption. This contrasts sharply with the previously observed major systematic difference between the allometric field volume and the predicted irregular, CHM-derived volume. The non-significant difference strongly suggests that the major volume discrepancy noted earlier was primarily due to the geometric irregularity of the actual piles, and not to systematic prediction bias in our CHM-derived height and diameter measurements. 9.5.4 Stand-level Aggregation before we leave, let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory) sum_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::mutate(gt_allom_volume_m3 = gt_volume_m3) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(pred_id)) %&gt;% dplyr::summarise( dplyr::across( .cols = tidyselect::starts_with(&quot;gt_&quot;) | tidyselect::starts_with(&quot;pred_&quot;) , ~sum(.x,na.rm=T) ) ) %&gt;% tidyr::pivot_longer( cols = dplyr::everything() , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground truth&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(allom_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; , &quot;allom_volume&quot; , &quot;volume&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; , &quot;Allometric Volume (m3)&quot; , &quot;Irregular Volume (m3)&quot; ) ) ) %&gt;% dplyr::group_by(pile_metric) %&gt;% dplyr::arrange(pile_metric,which_data) %&gt;% dplyr::mutate( pct_diff = (value-dplyr::lag(value))/dplyr::lag(value) ) %&gt;% dplyr::ungroup() # dplyr::filter(pile_metric!=&quot;Irregular Volume (m3)&quot;) plot # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric), scales = &quot;free_y&quot;, axes = &quot;all_x&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated measurements at the stand level&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table it sum_df_temp %&gt;% dplyr::select(pile_metric, which_data, value, pct_diff) %&gt;% dplyr::mutate( value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated measurements at the stand level&quot; , col.names = c( &quot;.&quot;, &quot;measurement source&quot; , &quot;stand-level total&quot;, &quot;% difference&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.34: Comparison of aggregated measurements at the stand level . measurement source stand-level total % difference Height (m) ground truth 263.7 NA prediction 263.0 -0.2% Diameter (m) ground truth 417.1 NA prediction 486.6 16.7% Area (m2) ground truth 1,185.5 NA prediction 1,121.2 -5.4% Allometric Volume (m3) ground truth 1,813.8 NA prediction 1,526.9 -15.8% Irregular Volume (m3) ground truth 1,813.8 NA prediction 952.5 -47.5% "],["method-validation-pinyon-juniper.html", "Section 10 Method Validation: Pinyon-Juniper 10.1 Site Introduction 10.2 Data Processing 10.3 Pile Detection: Data Fusion 10.4 Pile Detection: Structural Only", " Section 10 Method Validation: Pinyon-Juniper This project progressed through several phases to develop and validate a rigorous rules-based methodology for slash pile detection using UAS-collected data. The following summarizes the analysis project upon completion. Phase 1: Methodology Development and Sensitivity Testing This phase involved using ground truth data to perform sensitivity testing on the rules-based detection methodology. We first demonstrated a structural-only method, which uses a CHM raster generated from aerial point cloud data to identify candidate piles based on structural metrics like height, area, and shape. This method can be used when spectral data is unavailable. We then demonstrated a data fusion approach, which builds on the structural method by integrating spectral data as an additional filtering step. This approach takes the structurally-detected candidates and filters out potential false positive predictions by applying a set of spectral index thresholds. We then performed parameter sensitivity testing to systematically vary parameterizations on both approaches and quantify the resulting changes in detection and form quantification accuracy. This sensitivity testing provided a set of individual point estimates of detection accuracy (F-score) and quantification accuracy (e.g. RMSE and MAPE) for each parameter combination tested. These point estimates then served as the input dataset for subsequent statistical modeling to quantify the influence of parameters and input data on accuracy. Phase 2: Statistical Modeling Following sensitivity testing, a Bayesian Generalized Linear Model (GLM) was used to build a statistical framework for understanding the methodology’s performance. Unlike the sensitivity testing, which generate a range of detection and quantification accuracies based on parameter combinations tested, the statistical modeling does not calculate accuracy itself but instead uses these point estimates as dependent variables to statistically model the functional relationship between the tested detection parameters and the resulting accuracy. This provided a principled way to understand uncertainty and the complex interactions between parameters by providing posterior distributions for each parameter estimate rather than simple point estimates as obtained via sensitivity testing. This statistical modeling enabled the quantification of Bayesian credible intervals, which provide a direct measure of the uncertainty in each relationship, and allowed us to explicitly model interactions between parameters (e.g., the combined effect of CHM resolution and spectral data). Understanding these relationships and their associated uncertainty is critical for making more informed and confident decisions about the method’s optimal settings. Phase 3: Method Validation The final phase of this study involves three validation sites to assess the methodology’s real-world generalizability and transferability. Crucially, our detection methodology’s parameter setup (i.e. size, shape, and spectral filters) will be adjusted for each validation site based on its unique treatment and pile construction prescription, mimicking real-life application where optimal settings vary by implementation and forest type. The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how those features were expected to influence our methodology. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site. Site Name Pile Type Data Use Unique Features &amp; Ecology Methodology Parameter Influence PSINF Ponderosa Pine Training Site Mostly Hand Piles (some smaller machine piles) Training Located in the Pike and San Isabel National Forest (PSINF). Ponderosa pine stand with mixed ground cover and varying canopy density. This site was used to fully develop and tune all slash pile detection parameters, including setting initial values for pile size thresholds and geometric shape regularity. TRFO-BLM Pinyon-Juniper Validation Site Hand Piles Validation Located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM). Arid environment with dry vegetation appearing less green including standing dead pinyon-juniper vegetation. Piles are smaller, simpler, and hand-stacked. The dry, senescent vegetation might spectrally mimic dead wood thereby reducing the effectiveness of the spectral filter. This shifts the primary detection burden to the expected pile size and geometric shape filters to control false positives. BHEF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Black Hills Experimental Forest (BHEF). Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected based on local precipitation and typical regrowth response. The large, irregular pile geometry requires setting high minimum size thresholds and relaxing geometric parameters. The presence of dense regeneration requires a highly restrictive spectral filter to distinguish dead slash from live biomass. ARNF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Arapahoe and Roosevelt National Forest (ARNF). Ponderosa pine forest with a climate similar to the training site and drier than BHEF. Piles are massive but more circular and regular. Less regeneration is expected due to more recent treatment and drier climate. The massive size requires high minimum size thresholds while more regular, circular shape allows for tighter geometric filters. Reduced expected regeneration means the spectral filter can be less strictly applied than at BHEF. The unreliability of field-measured height and diameter data at the TRFO-BLM pinyon-juniper validation site was only discovered when initial prediction comparisons failed to meet expectations set by the training data. Consequently, we expanded our validation data set to include the additional sites listed above and will base the detection and quantification performance assessment solely on comparison against image-annotated footprints. This includes: Detection Accuracy: Comparing predicted pile locations against image-annotation locations (using metrics like F-score). Form Quantification Accuracy: Comparing predicted diameter and area against the image-annotated values (using metrics like MAPE). The application of the methodology to these structurally distinct, unseen sites ranging from hand piles to massive machine piles with complex geometries will provide compelling evidence of its transferability. Acceptable performance despite the challenges posed by differing forest types, terrain, and construction prescriptions will demonstrate the method’s viability across diverse forest management environments. 10.1 Site Introduction The present section validates the detection methodology against a pinyon-juniper validation site, which is located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM). This validation site is ecologically distinct from the PSINF ponderosa pine training area, featuring typically denser stands composed of smaller trees and an increased shrub presence, which creates a more complex background canopy structure. Furthermore, this site exclusively utilized hand-piling for slash pile construction, producing smaller piles than the machine piles present in the training data and other validation sites we’ll introduce later in this analysis. To effectively assess the method’s transferability, the detection methodology’s parameters will be adjusted from the training site’s optimal settings—mimicking real-world application—based on the specific treatment prescription and onsite implementation feedback. Ground truth validation data from the TRFO-BLM site will be used to calculate performance metrics (e.g., F-score and MAPE) to determine how well the method generalizes; if the resulting accuracy is acceptable despite these ecological and structural challenges, it would provide compelling evidence that the methodology is transferable across different forest types. from field crew leader (G.O.): Height and width were measured with a retractable height pole from the north side of each pile. We completed all piles (to the best of our knowledge) in the uniform high portion of unit 10. The prescription called for 30 ft spacing between trees and minimum 5x5x5 ft piles. As you can see from the photos and pile dimensions, there are no piles even remotely close to being that small. Others on the project expressed that they were too big. Lastly, no piles had been burned in the unit. The CRS is NAD83(2011) / UTM zone 13N (EPSG:6342). U10 is the highlighted one in the screenshot, but the unit shape file is attached as well. 10.2 Data Processing 10.2.1 Vector Data load vector data pile point locations were collected on the ground using highly accurate Emlid Reach RTK-GPS units. The perimeter of each pile was then digitized in a Geographic Information System (GIS) using these point locations overlaid on a 0.026 m RGB orthomosaic. In this digitization process, the perimeter was based on the main footprint of the pile at ground level, excluding isolated logs or debris extending beyond the primary boundary. These ground truth polygons will be compared to the predicted pile boundaries using the intersection over union (IoU) metric, with a minimum threshold required for a true positive match. # these piles were collected twice in the same location and have different measurements :\\ bad_pile_ids &lt;- c( 142 , 146 , 99 , 96 , 50 ) ############################################################### # read pile points collected in field ############################################################### pj_slash_piles_points &lt;- readr::read_csv(&quot;../data/Dawson_data/PJ_Piles_Unit_10.csv&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% dplyr::mutate( pile_id = tidyr::extract_numeric(name) ) %&gt;% dplyr::filter( !(pile_id %in% bad_pile_ids) ) pj_slash_piles_points %&gt;% dplyr::glimpse() ## Rows: 274 ## Columns: 40 ## $ name &lt;chr&gt; &quot;Pile 1&quot;, &quot;Pile 2&quot;, &quot;Pile 3&quot;, &quot;Pile 4&quot;, &quot;Pile … ## $ height_m &lt;dbl&gt; 2.12, 1.90, 1.80, 1.90, 2.10, 2.30, 2.00, 2.50… ## $ width_m &lt;dbl&gt; 6.20, 5.70, 4.50, 4.60, 5.60, 6.20, 5.30, 5.40… ## $ code &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ easting &lt;dbl&gt; 180356.3, 180371.2, 180374.8, 180382.1, 180391… ## $ northing &lt;dbl&gt; 4197064, 4197059, 4197050, 4197054, 4197043, 4… ## $ elevation &lt;dbl&gt; 2166.320, 2165.338, 2165.820, 2165.022, 2165.5… ## $ description &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ longitude &lt;dbl&gt; -108.6334, -108.6333, -108.6332, -108.6331, -1… ## $ latitude &lt;dbl&gt; 37.86502, 37.86497, 37.86490, 37.86493, 37.864… ## $ ellipsoidal_height &lt;dbl&gt; 2166.320, 2165.338, 2165.820, 2165.022, 2165.5… ## $ origin &lt;chr&gt; &quot;Global&quot;, &quot;Global&quot;, &quot;Global&quot;, &quot;Global&quot;, &quot;Globa… ## $ easting_rms &lt;dbl&gt; 0.087, 0.038, 0.066, 0.073, 0.014, 0.016, 0.03… ## $ northing_rms &lt;dbl&gt; 0.058, 0.082, 0.116, 0.023, 0.022, 0.016, 0.02… ## $ elevation_rms &lt;dbl&gt; 0.011, 0.010, 0.012, 0.011, 0.010, 0.010, 0.01… ## $ lateral_rms &lt;dbl&gt; 0.105, 0.091, 0.134, 0.077, 0.026, 0.023, 0.04… ## $ antenna_height &lt;dbl&gt; 2.134, 2.134, 2.134, 2.134, 2.134, 2.134, 2.13… ## $ antenna_height_units &lt;chr&gt; &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;… ## $ solution_status &lt;chr&gt; &quot;FIX&quot;, &quot;FIX&quot;, &quot;FIX&quot;, &quot;FIX&quot;, &quot;FIX&quot;, &quot;FIX&quot;, &quot;FIX… ## $ correction_type &lt;chr&gt; &quot;RTK&quot;, &quot;RTK&quot;, &quot;RTK&quot;, &quot;RTK&quot;, &quot;RTK&quot;, &quot;RTK&quot;, &quot;RTK… ## $ averaging_start &lt;chr&gt; &quot;2025-05-30 13:18:45.8 UTC-06:00&quot;, &quot;2025-05-30… ## $ averaging_end &lt;chr&gt; &quot;2025-05-30 13:18:55.8 UTC-06:00&quot;, &quot;2025-05-30… ## $ samples &lt;dbl&gt; 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51… ## $ pdop &lt;dbl&gt; 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.3, 1… ## $ gdop &lt;dbl&gt; 1.2, 1.3, 1.2, 1.3, 1.2, 1.2, 1.2, 1.2, 1.5, 1… ## $ base_easting &lt;dbl&gt; 180353.5, 180353.5, 180353.5, 180353.5, 180353… ## $ base_northing &lt;dbl&gt; 4197071, 4197071, 4197071, 4197071, 4197071, 4… ## $ base_elevation &lt;dbl&gt; 2168.024, 2168.024, 2168.024, 2168.024, 2168.0… ## $ base_longitude &lt;dbl&gt; -108.6335, -108.6335, -108.6335, -108.6335, -1… ## $ base_latitude &lt;dbl&gt; 37.86507, 37.86507, 37.86507, 37.86507, 37.865… ## $ base_ellipsoidal_height &lt;dbl&gt; 2168.024, 2168.024, 2168.024, 2168.024, 2168.0… ## $ baseline &lt;dbl&gt; 6.968, 21.397, 29.772, 33.082, 46.927, 61.878,… ## $ mount_point &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cs_name &lt;chr&gt; &quot;NAD83(2011) / UTM zone 13N&quot;, &quot;NAD83(2011) / U… ## $ gps_satellites &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 9… ## $ glonass_satellites &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 7… ## $ galileo_satellites &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 9, 8, 8, 7, 8… ## $ beidou_satellites &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6, 6, 5, 6… ## $ qzss_satellites &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ pile_id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,… pj_slash_piles_points &lt;- pj_slash_piles_points %&gt;% sf::st_as_sf(coords = c(&quot;easting&quot;,&quot;northing&quot;), crs = 6342, remove = F) %&gt;% # sf::st_as_sf(coords = c(&quot;longitude&quot;,&quot;latitude&quot;), crs = 4326) %&gt;% # mapview::mapview(zcol = &quot;height..m.&quot;) dplyr::select(pile_id,name,height_m,width_m,easting,northing,latitude,longitude,code,description,elevation) %&gt;% sf::st_make_valid() # sf::st_write(&quot;N:/MyFiles/Dawson_data/pj_piles_unit_10.gpkg&quot;, append = F) # mapview::mapview(pj_slash_piles_points, zcol = &quot;height_m&quot;) ############################################################### # read unit boundary ############################################################### pj_stand_boundary &lt;- sf::st_read(&quot;../data/Dawson_data/units/units.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_points)) %&gt;% dplyr::filter(tolower(unit)==&quot;u10&quot;) %&gt;% dplyr::slice(1) what is the area of the treatment unit boundaries we are looking over? pj_stand_boundary %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.1) ## [1] &quot;5.2 ha&quot; that’s great now load in the pile boundary polygons. because each point does not necessarily fall within the polygon boundary (e.g. due to misalignment between the imagery and point locations or slight inaccuracies in either the point or pile boundaries) we need to perform a matching process to tie the points to the polygons so that we get the height and diameter measured during the point collection attached to the polygons. to do this, we’ll use a two-stage process that first attaches the points data frame to polygons where points fall within, using a spatial intersection. It then finds and assigns the remaining, unjoined points to their nearest polygon. The final output includes all polygons from the original data, ensuring that every polygon is represented even if no points were matched. # read in polys pj_slash_piles_polys &lt;- sf::st_read(&quot;../data/Dawson_Data/piles/pj_pile_polys.shp&quot;, quiet=T) %&gt;% # sf::st_as_sf() %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate( row_number = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID,id)) %&gt;% dplyr::filter(row_number!=62) # pj_slash_piles_polys %&gt;% dplyr::glimpse() # pj_slash_piles_polys %&gt;% ggplot()+geom_sf()+geom_sf(data=pj_slash_piles_points) # function to perform a two-step spatial join # first matching points that fall inside polygons and # then assigning the remaining points to the nearest polygon # all original polygons are returned in the final output # let&#39;s do it pj_slash_piles_polys &lt;- match_points_to_polygons( points_sf = pj_slash_piles_points , polygons_sf = pj_slash_piles_polys , point_id = &quot;pile_id&quot; , polygon_id = &quot;row_number&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # calculate area and volume dplyr::mutate( field_diameter_m = width_m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() # , field_gt_area_m2 = pi*field_radius_m^2 # volume , image_gt_volume_m3 = (1/8) * pi * ( (sqrt(image_gt_area_m2/pi)*2)^2 ) * height_m # (1/8) * pi * (shape_length^2) * max_height_m # (sqrt(image_gt_area_m2/pi)*2) = diameter assuming of circle covering same area , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * height_m # (1/8) * pi * (shape_length^2) * max_height_m ) %&gt;% # area st_calculate_diameter() %&gt;% dplyr::rename( image_gt_diameter_m = diameter_m ) %&gt;% # fix blank pile_id dplyr::mutate( pile_id = dplyr::case_when( is.na(pile_id) ~ max(pile_id,na.rm = T)+1000+row_number , T ~ pile_id ) ) # add a flag for if a pile is in the stand or not based on a spatial intersection pj_slash_piles_polys &lt;- pj_slash_piles_polys %&gt;% dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_intersection( pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_polys)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pile_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) huh? pj_slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 277 ## Columns: 20 ## $ row_number &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,… ## $ pile_id &lt;dbl&gt; 150, 149, 151, 152, 145, 144, 178, 143, 147, 141, … ## $ name &lt;chr&gt; &quot;Pile 150&quot;, &quot;Pile 149&quot;, &quot;Pile 151&quot;, &quot;Pile 152&quot;, &quot;P… ## $ height_m &lt;dbl&gt; 2.38, 2.55, 2.50, 2.11, 2.51, 2.31, 3.00, 2.39, 2.… ## $ width_m &lt;dbl&gt; 6.24, 6.72, 6.38, 5.75, 5.13, 5.53, 6.55, 5.46, 6.… ## $ easting &lt;dbl&gt; 180146.7, 180151.7, 180139.5, 180145.2, 180155.8, … ## $ northing &lt;dbl&gt; 4197109, 4197101, 4197095, 4197089, 4197087, 41970… ## $ latitude &lt;dbl&gt; 37.86535, 37.86528, 37.86521, 37.86517, 37.86515, … ## $ longitude &lt;dbl&gt; -108.6358, -108.6358, -108.6359, -108.6358, -108.6… ## $ code &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ description &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ elevation &lt;dbl&gt; 2171.823, 2172.045, 2172.957, 2173.210, 2172.660, … ## $ field_diameter_m &lt;dbl&gt; 6.24, 6.72, 6.38, 5.75, 5.13, 5.53, 6.55, 5.46, 6.… ## $ field_radius_m &lt;dbl&gt; 3.120, 3.360, 3.190, 2.875, 2.565, 2.765, 3.275, 2… ## $ image_gt_area_m2 &lt;dbl&gt; 13.595434, 15.383318, 10.232298, 13.364827, 12.325… ## $ image_gt_volume_m3 &lt;dbl&gt; 16.178567, 19.613730, 12.790373, 14.099893, 15.468… ## $ field_gt_volume_m3 &lt;dbl&gt; 36.39201, 45.22084, 39.96145, 27.39542, 25.93990, … ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((707958.5 4193509,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 4.728407, 5.192360, 4.276639, 4.549041, 4.469193, … ## $ is_in_stand &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… map mapview::mapview( pj_stand_boundary , color = &quot;black&quot; , lwd = 1 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE , layer.name = &quot;stand boundary&quot; ) + # mapview::mapview(pj_slash_piles_points, zcol = &quot;height_m&quot;) mapview::mapview(pj_slash_piles_polys, zcol = &quot;width_m&quot;) 10.2.2 RGB Data RGB ############################################################### # read/crop RGB raster ############################################################### rgb_fnm_temp &lt;- &quot;../data/dawson_data/dawson_rgb.tif&quot; if(!file.exists(rgb_fnm_temp)){ # terra handles large files on disk automatically rgb_rast_temp &lt;- terra::rast(&quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/Ortho/BLM_CO_SWDF_DawsonFuelsTreatment_Ortho_202504.tif&quot;) # Read the polygon file (e.g., a shapefile) polygon_border_temp &lt;- pj_stand_boundary %&gt;% sf::st_buffer(50) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(rgb_rast_temp)) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- terra::crop(rgb_rast_temp, polygon_border_temp, filename = tempfile(fileext = &quot;.tif&quot;), overwrite = TRUE) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size pj_rgb_rast &lt;- terra::mask(crop_rgb_rast_temp, polygon_border_temp, filename = rgb_fnm_temp, overwrite = TRUE) }else{ pj_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } terra::res(pj_rgb_rast) ## [1] 0.025883 0.025883 ## function to change the resolution of RGB change_res_fn &lt;- function(r, my_res=1, m = &quot;bilinear&quot;){ r2 &lt;- r terra::res(r2) &lt;- my_res r2 &lt;- terra::resample(r, r2, method = m) return(r2) } ## apply the function pj_rgb_rast &lt;- change_res_fn(pj_rgb_rast, my_res=0.08) terra::res(pj_rgb_rast) ## [1] 0.08 0.08 plot RGB with the ground-truth piles (blue) terra::plotRGB(pj_rgb_rast, stretch=&quot;lin&quot;) terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( pj_slash_piles_polys %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 10.2.3 Process Raw Point Cloud read crop point cloud since the full point cloud data we have covers a much larger extent than the treatment unit used for this study ############################################################### # read/crop point cloud ############################################################### # output dir for clipped las las_dir_temp &lt;- &quot;../data/Dawson_Data/point_cloud&quot; if(!dir.exists(las_dir_temp)){dir.create(las_dir_temp, showWarnings = F)} # do it if not already done if(dplyr::coalesce(length(list.files(las_dir_temp)),0)&lt;1){ # this reads the metadata from all files in the folder, not the points themselves. las_ctg &lt;- lidR::readLAScatalog(&quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/PointCloud/Tiles/&quot;) las_ctg # set ctg opts lidR::opt_select(las_ctg) &lt;- &quot;xyzainrcRGBNC&quot; lidR::opt_progress(las_ctg) &lt;- T # write generated results to disk storage rather than keeping everything in memory. This option can be activated with opt_output_files() lidR::opt_output_files(las_ctg) &lt;- paste0(normalizePath(las_dir_temp),&quot;/&quot;, &quot;_{XLEFT}_{YBOTTOM}&quot;) # label outputs based on coordinates lidR::opt_filter(las_ctg) &lt;- &quot;-drop_duplicates&quot; # clip the point cloud using the polygon and write to a new file # the lidR::opt_output_files is key to writing the output to disk without loading the entire clipped result into memory. clip_las_ctg &lt;- lidR::clip_roi( las = las_ctg , geometry = pj_stand_boundary %&gt;% sf::st_buffer(100) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% sf::st_transform(sf::st_crs(las_ctg)) ) }else{ clip_las_ctg &lt;- lidR::readLAScatalog(las_dir_temp) } clip_las_ctg ## class : LAScatalog (v1.2 format 2) ## extent : 707813.6, 708409.9, 4193155, 4193638 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83(2011) / UTM zone 12N ## area : 288106.3 m² ## points : 163.84 million points ## type : terrestrial ## density : 568.7 points/m² ## density : 568.7 pulses/m² ## num. files : 1 clip_las_ctg$filename ## [1] &quot;../data/Dawson_Data/point_cloud/_707813.5_4193155.las&quot; We’ll use cloud2trees::cloud2raster() to process the raw point cloud data # output dir c2t_output_dir &lt;- &quot;../data/Dawson_Data/&quot; dir_temp &lt;- file.path(c2t_output_dir, &quot;point_cloud_processing_delivery&quot;) # do it if(!dir.exists(dir_temp)){ # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_output_dir , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = F , dtm_res_m = 0.2 , chm_res_m = 0.1 , min_height = 0 # effectively generates a DSM based on non-ground points ) }else{ dtm_temp &lt;- terra::rast( file.path(dir_temp, &quot;dtm_0.2m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(dir_temp, paste0(&quot;chm_&quot;, 0.1,&quot;m.tif&quot;)) ) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } plot CHM with the ground-truth piles (blue) cloud2raster_ans$chm_rast %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( pj_slash_piles_polys %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) plot DTM with the ground-truth piles (blue) cloud2raster_ans$dtm_rast %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = harrypotter::hp(option = &quot;mischief&quot;, n = 100, direction = -1), axes = F) terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( pj_slash_piles_polys %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) 10.3 Pile Detection: Data Fusion since we have both structural and spectral data, we’ll start by using the data fusion approach and do a full walk-through of our detection results after which we’ll circle back to explore results obtained using structural data only. we’ll work with the CHM in the study unit boundary plus a buffer to limit the amount of data we process chm_rast_stand &lt;- cloud2raster_ans$chm_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) ) %&gt;% terra::mask( pj_stand_boundary %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) ) # # huh? # chm_rast_stand %&gt;% # terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% # terra::plot(col = viridis::plasma(100), axes = F) # terra::plot( # pj_stand_boundary %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 # ) # terra::plot( # pj_slash_piles_polys %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 # ) 10.3.1 Structural Candidate Segments we’ll start by detecting candidate slash piles based on the structural CHM data alone with our slash_pile_detect_watershed() function we defined in this earlier section. we’re going to set the four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) which are used to determine candidate slash piles from the CHM data alone based on our expectations from the treatment prescription and it’s implementation on the ground. the treatment prescription for the unit of interest called for thinning to create a residual structure with “uniform gaps between trees” with via a “heavy intensity thinning” that called for gaps of “at least 30 feet between tree crowns” with “70% of the retained (i.e. leave) trees should be over 8 inches basal diameter if present and 30% should be between 2 inches and 8 inches in basal diameter.” Here is the exact wording of the slash pile construction prescription: No less than 90% of all cut trees, live limbs and slash shall be piled. Piles are to be constructed to facilitate burning by the government at a later date. Minimum pile size is 5x5x5 feet. The contractor shall construct piles that are sufficiently compacted to allow for a high percentage of consumption from burning, this may require multiple cutting of stems, compacting the pile with equipment or other approved techniques. Piles should be constructed with branches and smaller diameter fuels piled on bottom and larger limbs/bole wood piled on top. Piles should be spaced appropriately away from leave trees to avoid damage from burning. Anticipate flame lengths twice the piled fuel height when placing piles i.e (5 ft tall pile will have 10 ft flame lengths so pile should be placed at least 10 ft away from the nearest reserve trees). Piles will be constructed in a way to prevent toppling. Piles may be placed on stumps. Oak and other brush cut will need to be added to the piles. Piles shall not be constructed in swales, streams, springs, or within 15 feet any recreational trail within the units. Piles shall not be placed on or near any cadastral survey markers. Piles may not be built under any electrical transmission line or utility line. Piles shall be free of soil. Site managers also provided anecdotal feedback about the on-the-ground prescription implementation, noting that the piles were “larger than expected” and “messy,” and were constructed too close to residual trees. The prescription specified a minimum pile size of 1.5 meters (5 feet) long, wide, and tall, but provided no explicit maximum size. This absence of a maximum size makes the anecdotal feedback particularly relevant for setting up our pile detection methodology. The close proximity of piles to trees, which resulted in tree mortality on other units when piles were burned, may also complicate our detection methodology, as the structural and spectral signatures of the piles and trees may merge in both the CHM and RGB raster data. We also have the benefit of using spectral data to further filter the candidate piles detected from the structural data. This allows us to set less restrictive structural parameters which will increase the number of structurally-detected piles. To compensate for this less restrictive filtering on the structural side, we will set the spectral_weight parameter to ‘4’, which applies four of the five thresholds and represents the optimal spectral filtering identified in by the training data set. This reliance on the spectral data helps to filter out false positives that may be shrubs, lower tree branches, or boulders. Based on the prescription and anecdotal feedback, the following parameter settings will be used: max_ht_m: This parameter will be set to 2.3 m (7.5 feet). This represents a 53% increase over the 1.5 m (5 ft) minimum height specified in the prescription, to account for the feedback that piles were larger than expected. min_ht_m: This parameter will be set to 0.3 m (1.0 foot). This creates a large 1.7 m (5.6 feet) vertical range for structural detection. This setting allows for the acceptance of piles up to 1.2 m (4.0 feet) smaller than the prescribed minimum of 1.5 m but this low threshold will be offset by the subsequent strict spectral filtering min_area_m2: This parameter will be set to 2.0 square meters (21.5 square feet). This provides a small buffer below the prescribed 2.3 square meters (25 square feet) minimum area to account for minor segmentation errors or slight settling of the pile, without deviating significantly from the horizontal prescription. max_area_m2: This parameter will be set to 17 square meters (183 square feet). This represents a nearly eight-fold increase compared to the 2.3 square meters minimum. The rationale for this significant increase compared to the upper height threshold is because it is physically easier to construct piles that are wider and more irregular in the horizontal direction than the vertical direction convexity_pct: To account for the “messy” and irregularly shaped piles, this parameter will be set to 0.08 which is in the the optimal range identified in the ponderosa pine training data. This less restrictive threshold will allow for the structural detection of more irregular pile footprints circle_fit_iou_pct: This parameter will be set to 0.30, which is approximately 14 percentage points lower than the optimal value identified in the ponderosa pine training data. This value is used in conjunction with convexity_pct to allow for a wider range of non-circular, irregular shapes CHM Resolution (chm_res_m): A 0.1 m (0.33 feet; 3.9 inches) CHM raster will be used. This fine resolution will enhance the granular distinction between piles and lower tree branches which is important given the close proximity of piles to residual trees noted by managers slash_pile_detect_watershed() that CHM outdir_temp &lt;- &quot;../data/Dawson_data&quot; fnm_temp &lt;- file.path(outdir_temp,&quot;pj_structural_candidate_segments.gpkg&quot;) # &quot;new_pj_structural_candidate_segments.gpkg&quot; = convexity_pct = 0.06; circle_fit_iou_pct = 0.35 if(!file.exists(fnm_temp)){ set.seed(111) slash_pile_detect_watershed_ans &lt;- slash_pile_detect_watershed( chm_rast = chm_rast_stand #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = 2.3 # set the max expected pile height , min_ht_m = 0.3 # set the min expected pile height , min_area_m2 = 2.0 # set the min expected pile area , max_area_m2 = 17 # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.08 # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = 0.30 #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) # save slash_pile_detect_watershed_ans %&gt;% sf::st_write(fnm_temp, append = F) }else{ slash_pile_detect_watershed_ans &lt;- sf::st_read(fnm_temp, quiet=T) } # what did we get? slash_pile_detect_watershed_ans %&gt;% dplyr::glimpse() ## Rows: 397 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 24… ## $ area_m2 &lt;dbl&gt; 12.410, 9.145, 16.630, 9.715, 8.560, 2.820, 9.775, 4.1… ## $ volume_m3 &lt;dbl&gt; 7.611119, 11.283464, 18.274028, 16.730727, 11.332464, … ## $ max_height_m &lt;dbl&gt; 1.500000, 2.300000, 2.290000, 2.300000, 2.300000, 2.30… ## $ volume_per_area &lt;dbl&gt; 0.6133054, 1.2338397, 1.0988592, 1.7221541, 1.3238860,… ## $ pct_chull &lt;dbl&gt; 0.7687349, 0.6790596, 0.7257968, 0.5795162, 0.6810748,… ## $ diameter_m &lt;dbl&gt; 5.223983, 5.292447, 5.554278, 4.272002, 4.565085, 2.64… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((707989.7 4193402,..., POLYGON ((7081… CHM with the predicted piles (brown) and the ground-truth piles (blue) chm_rast_stand %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( pj_slash_piles_polys %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_pile_detect_watershed_ans %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.3 ) we can also use mapview::mapview() to interactively plot the CHM with the predicted piles (brown) and the ground-truth piles (blue) chm_rast_stand %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% mapview::mapview() + mapview::mapview( pj_stand_boundary , alpha.regions = 0, color = &quot;black&quot;, lwd = 1 , legend=F,label=F,popup=F ) + mapview::mapview( pj_slash_piles_polys , alpha.regions = 0, color = &quot;blue&quot;, lwd = 1.2 , legend=F,label=F ) + mapview::mapview( slash_pile_detect_watershed_ans , alpha.regions = 0, color = &quot;brown&quot;, lwd = 1.3 , legend=F,label=F ) ## |---------|---------|---------|---------|========================================= let’s focus in on a specific area to plot the ground truth and the predicted piles overlaid on the RGB. aoi_for_plt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id == 210) %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(sf::st_crs(slash_pile_detect_watershed_ans)) %&gt;% sf::st_buffer(55) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() # all gt piles that intersect gt_temp &lt;- pj_slash_piles_polys %&gt;% dplyr::inner_join( pj_slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(aoi_for_plt)) %&gt;% sf::st_intersection(aoi_for_plt) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(aoi_for_plt)) # all pred piles that intersect pred_temp &lt;- slash_pile_detect_watershed_ans %&gt;% dplyr::inner_join( slash_pile_detect_watershed_ans %&gt;% sf::st_intersection(aoi_for_plt) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) # plot it ortho_plt_temp &lt;- ortho_plt_fn( my_ortho_rast = pj_rgb_rast , stand = aoi_for_plt , buffer = 5 ) # ortho_plt_temp plot a sample of the RGB with the predicted piles (brown) and the ground-truth piles (blue) ortho_plt_temp + # ggplot2::ggplot() + ggplot2::geom_sf( data = gt_temp , color = &quot;blue&quot; , fill = NA , lwd = 1 ) + ggplot2::geom_sf( data = pred_temp , color = &quot;brown&quot; , fill = NA , lwd = 1 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) plot the same sample of the CHM with the predicted piles (brown) and the ground-truth piles (blue) cloud2raster_ans$chm_rast %&gt;% terra::crop(aoi_for_plt %&gt;% terra::vect() %&gt;% terra::project(cloud2raster_ans$chm_rast)) %&gt;% terra::mask(aoi_for_plt %&gt;% terra::vect() %&gt;% terra::project(cloud2raster_ans$chm_rast)) %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) terra::plot( gt_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) terra::plot( pred_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.3 ) 10.3.2 Accuracy of these structural settings let’s quickly look at the accuracy of the pile detection if we were to only use the structural data to identify piles with these specific settings. note, that if we only had structural data, we would be much more restrictive in setting the pile detection parameters as we’ll demonstrate below. we aren’t going to fully discuss this accuracy assessment, it is presented only for the curious # add filter for those in stand # pred struct_temp &lt;- slash_pile_detect_watershed_ans %&gt;% dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_intersection( pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(slash_pile_detect_watershed_ans)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) # ground truth and prediction matching process gt_pred_match_temp &lt;- ground_truth_prediction_match( ground_truth = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(struct_temp)) , gt_id = &quot;pile_id&quot; , predictions = struct_temp %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles gt_pred_match_temp &lt;- gt_pred_match_temp %&gt;% # add area of gt dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m , field_gt_volume_m3 , height_m , field_diameter_m ) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 , gt_volume_m3 = field_gt_volume_m3 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( struct_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_field_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_field_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # image diameter , diff_image_diameter_m = pred_diameter_m-image_gt_diameter_m , pct_diff_image_diameter_m = (image_gt_diameter_m-pred_diameter_m)/image_gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # # volume diffs # , diff_image_volume_m3 = pred_volume_m3-image_gt_volume_m3 # , pct_diff_image_volume_m3 = (image_gt_volume_m3-pred_volume_m3)/image_gt_volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_gt_volume_m3 # , pct_diff_field_volume_m3 = (field_gt_volume_m3-pred_volume_m3)/field_gt_volume_m3 ) # huh? agg_ground_truth_match(ground_truth_prediction_match_ans = gt_pred_match_temp) %&gt;% kbl_agg_gt_match(caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;structural only prior to data fusion&quot;) Table 10.1: pile detection and form quantification accuracy metricsstructural only prior to data fusion . value Detection Count TP 262 FN 15 FP 79 Detection F-score 85% Recall 95% Precision 77% Area m2 ME -1.19 RMSE 2.0 MAPE 15% Diameter m (field) ME -1.71 RMSE 1.8 MAPE 31% Diameter m (image) ME -0.26 RMSE 0.5 MAPE 8% Height m ME -1.17 RMSE 1.2 MAPE 51% 10.3.3 Spectral Filtering of Candidate Segments Now we’ll filter the structurally-detected candidate slash piles using the RGB spectral data with the polygon_spectral_filtering() function we defined in this earlier section The spectral filtering approach is a data fusion method used to filter candidate slash pile detections first identified using structural data alone. After initial candidates are identified based on structural data, this method applies a set of five spectral index thresholds to the candidate segments. The spectral_weight parameter is an integer from 1 to 5 that directly controls the number of thresholds that are applied. For example, a value of “3” means a candidate pile must pass at least three of the five thresholds to be retained. This process helps to filter out objects like shrubs, lower tree branches, or boulders that may have been structurally misidentified as piles. we will set the spectral_weight parameter to ‘4’, which applies four of the five thresholds and represents the optimal spectral filtering identified in by the training data set. This reliance on the spectral data helps to filter out false positives that may be shrubs, lower tree branches, or boulders. final_predicted_slash_piles &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_watershed_ans , rgb_rast = pj_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = 4 ) what did we get? # huh? final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 397 ## Columns: 23 ## $ pred_id &lt;int&gt; 1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 2… ## $ area_m2 &lt;dbl&gt; 12.410, 9.145, 16.630, 9.715, 8.560, 2.820, 9.775, 4.… ## $ volume_m3 &lt;dbl&gt; 7.611119, 11.283464, 18.274028, 16.730727, 11.332464,… ## $ max_height_m &lt;dbl&gt; 1.500000, 2.300000, 2.290000, 2.300000, 2.300000, 2.3… ## $ volume_per_area &lt;dbl&gt; 0.6133054, 1.2338397, 1.0988592, 1.7221541, 1.3238860… ## $ pct_chull &lt;dbl&gt; 0.7687349, 0.6790596, 0.7257968, 0.5795162, 0.6810748… ## $ diameter_m &lt;dbl&gt; 5.223983, 5.292447, 5.554278, 4.272002, 4.565085, 2.6… ## $ rast_agg_grvi &lt;dbl&gt; -0.0242606787, -0.0046708129, -0.0325958568, -0.01224… ## $ rast_agg_rgri &lt;dbl&gt; 1.0497278, 1.0093855, 1.0673883, 1.0247954, 1.0838725… ## $ rast_agg_vdvi &lt;dbl&gt; -0.003656942, 0.039179734, -0.010469513, 0.023582234,… ## $ rast_agg_rgbvi &lt;dbl&gt; -0.006476210, 0.083397656, -0.019700427, 0.049979234,… ## $ rast_agg_exg &lt;dbl&gt; -0.004869986, 0.052930918, -0.013910804, 0.031692102,… ## $ rast_agg_exr &lt;dbl&gt; 0.1556979, 0.1459419, 0.1625862, 0.1491834, 0.1692692… ## $ rast_agg_exgr &lt;dbl&gt; -0.160947212, -0.093805306, -0.176345140, -0.11713800… ## $ rast_agg_bi &lt;dbl&gt; 0.4539163, 0.4429114, 0.4957423, 0.4909618, 0.4905459… ## $ rast_agg_sat &lt;dbl&gt; 0.08239188, 0.17601331, 0.08864828, 0.16517131, 0.100… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((707989.7 4193402,..., POLYGON ((708… ## $ inrange_th_exgr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_rgri &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_vdvi &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,… ## $ inrange_th_bi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_sat &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,… ## $ inrange_th_votes &lt;dbl&gt; 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 4, 4, 4, 4, 4,… # final_predicted_slash_piles %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::count(inrange_th_votes) how many piles were removed? # how many piles were removed? nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles) ## [1] 0 # what proportion were removed? scales::percent( (nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles))/nrow(slash_pile_detect_watershed_ans) , accuracy=0.1 ) ## [1] &quot;0.0%&quot; The outcome of 0 candidate piles removed by the spectral filter, despite requiring at least four of the five spectral index thresholds be met, is a surprising result. This indicates that integrating spectral data did not alter the final retained pile count compared to the structural-only detection, even though the spectral component is designed specifically to reduce False Positive (FP) predictions. This finding suggests that the detection method using structural data alone would achieve a similar overall accuracy to the data fusion approach. This result is attributable to the specific spectral signatures at this site, leading to the spectral filter’s ineffectiveness (see primary possibilities below). We intentionally set less restrictive structural (min_ht_m, max_ht_m, min_area_m2, and max_area_m2) and geometric (circle_fit_iou_pct, convexity_pct) parameters for this validation, anticipating that the spectral data would successfully compensate for this looser structural filtering—a compensation that did not actualize here. In practice, if spectral data were truly unavailable, we would recommend setting these structural and geometric parameters more strictly. The unexpected outcome suggests two primary possibilities for the filter’s failure to remove incorrect pile predictions: Minimal Spectral Difference between Piles and False Positives (FPs): The spectral signatures of the actual True Positive (TP) piles and the structurally detected FPs are likely too similar. For instance, many FPs might be senescent vegetation (dead shrubs or short trees lacking greenness) whose spectral appearance closely mimics the dead wood expected in slash piles. The similar signatures occur even though three of the five thresholds target the removal of healthy, green vegetation. Insufficient Sensitivity of Spectral Thresholds: The spectral index thresholds themselves may lack the sensitivity needed to differentiate vegetation in this arid environment. The native vegetation here may naturally exhibit lower greenness than the typical healthy vegetation used to define the thresholds in the source studies (Wang et al. 2025; Riehle et al. 2020). 10.3.3.1 Maximum spectral filtering Given this lack of impact, we will test increasing the spectral_weight parameter to ‘5’ which is the maximum possible strictness requiring all five spectral index thresholds to be met. While statistical analysis on the ponderosa pine training data showed similar overall detection accuracies between a setting of ‘4’ and ‘5’, this maximum setting presents an increased risk of removing True Positive piles that have atypical spectral signatures. Such atypical signatures could result from piles that are heavily sun-bleached (appearing bright white spectrally) or those that are in the shadow of surrounding canopy at the time of image capture (appearing very dark). we aren’t going to fully discuss this accuracy assessment, it is presented only for the curious polygon_spectral_filtering_temp &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_watershed_ans , rgb_rast = pj_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = 5 ) # add filter for those in stand # pred struct_temp &lt;- polygon_spectral_filtering_temp %&gt;% dplyr::left_join( polygon_spectral_filtering_temp %&gt;% sf::st_intersection( pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(polygon_spectral_filtering_temp)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) # ground truth and prediction matching process gt_pred_match_temp &lt;- ground_truth_prediction_match( ground_truth = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(struct_temp)) , gt_id = &quot;pile_id&quot; , predictions = struct_temp %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles gt_pred_match_temp &lt;- gt_pred_match_temp %&gt;% # add area of gt dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m , field_gt_volume_m3 , height_m , field_diameter_m ) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 , gt_volume_m3 = field_gt_volume_m3 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( struct_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_field_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_field_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # image diameter , diff_image_diameter_m = pred_diameter_m-image_gt_diameter_m , pct_diff_image_diameter_m = (image_gt_diameter_m-pred_diameter_m)/image_gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # # volume diffs # , diff_image_volume_m3 = pred_volume_m3-image_gt_volume_m3 # , pct_diff_image_volume_m3 = (image_gt_volume_m3-pred_volume_m3)/image_gt_volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_gt_volume_m3 # , pct_diff_field_volume_m3 = (field_gt_volume_m3-pred_volume_m3)/field_gt_volume_m3 ) # huh? agg_ground_truth_match(ground_truth_prediction_match_ans = gt_pred_match_temp) %&gt;% kbl_agg_gt_match(caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;exploration data fusion `spectral_weight` set to &#39;5&#39;&quot;) we can compare this to the detection and quantification accuracy results of the spectral_weight parameter set to ‘4’ which is what we will present in the manuscript of this project 10.3.4 Detection and Quantification Accuracy let’s see how we did given the list of predictions compared to the ground truth data using the confusion matrix matching process we outlined in this earlier section. we’ll filter both ground truth and predicted piles to keep only those that actually intersect with the study unit boundary for comparison # add filter # pred final_predicted_slash_piles &lt;- final_predicted_slash_piles %&gt;% dplyr::left_join( final_predicted_slash_piles %&gt;% sf::st_intersection( pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) 10.3.4.1 Instance matching now apply the instance matching process we outlined in this earlier section to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions) # ground truth and prediction matching process ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # add area of gt dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m , field_gt_volume_m3 , height_m , field_diameter_m ) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 , gt_volume_m3 = field_gt_volume_m3 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_field_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_field_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # image diameter , diff_image_diameter_m = pred_diameter_m-image_gt_diameter_m , pct_diff_image_diameter_m = (image_gt_diameter_m-pred_diameter_m)/image_gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # # volume diffs # , diff_image_volume_m3 = pred_volume_m3-image_gt_volume_m3 # , pct_diff_image_volume_m3 = (image_gt_volume_m3-pred_volume_m3)/image_gt_volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_gt_volume_m3 # , pct_diff_field_volume_m3 = (field_gt_volume_m3-pred_volume_m3)/field_gt_volume_m3 ) # huh? # ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() that’s a lot of great detail at the individual pile instance level for us to dig into. before we do that, let’s aggregate the instances to see how we did at the stand level overall 10.3.4.2 Overall (stand level) Now we’ll aggregate the instance matching results to calculate overall performance assessment metrics. Here, we take the counts of True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions), to determine overall accuracy. This aggregation will give us two types of results: detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified agg_ground_truth_match_ans &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans = ground_truth_prediction_match_ans) let’s table the most relevant metrics agg_ground_truth_match_ans %&gt;% kbl_agg_gt_match( caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;data fusion pinyon-juniper validation site&quot; ) Table 10.2: pile detection and form quantification accuracy metricsdata fusion pinyon-juniper validation site . value Detection Count TP 262 FN 15 FP 79 Detection F-score 85% Recall 95% Precision 77% Area m2 ME -1.19 RMSE 2.0 MAPE 15% Diameter m (field) ME -1.71 RMSE 1.8 MAPE 31% Diameter m (image) ME -0.26 RMSE 0.5 MAPE 8% Height m ME -1.17 RMSE 1.2 MAPE 51% # save the table for full comparison at the very end # save the table for full comparison at the very end sf::st_read(dsn = all_agg_ground_truth_match_ans_fp, quiet = T) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::filter( site != &quot;TRFO-BLM pinyon-juniper validation site&quot; ) %&gt;% dplyr::bind_rows( all_agg_ground_truth_sf_format( stand_boundary = pj_stand_boundary , site = &quot;TRFO-BLM pinyon-juniper validation site&quot; ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::bind_cols( agg_ground_truth_match_ans # join on aggregated form quantifications that we have for all , ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(image_gt_diameter_m, pred_diameter_m, gt_area_m2, pred_area_m2, pred_volume_m3, pred_height_m) , ~ sum(.x, na.rm = TRUE) ) ) ) ) %&gt;% # dplyr::glimpse() # readr::write_csv(file = all_agg_ground_truth_match_ans_fp, append = F, progress = F) sf::st_write(dsn = all_agg_ground_truth_match_ans_fp, append = F, quiet = T) We obtained strong results for detection accuracy which were in-line with the best results we achieved with the training data. our data fusion slash pile detection method achieved an F-score of 85% with a recall (i.e. detection rate) of 95% and a precision of 77% (indicating a low rate of commission errors or False Positives). These results support our data fusion method’s use for accurately identifying slash piles using UAS-collected, remote sensing data alone and parameterizing the method based on expectations guided by the on-the-ground prescription and observational feedback about the implementation of that prescription. The form quantification accuracy metrics were notably worse than optimal training results. A critical difference is highlighted by comparing the “field” diameter error metrics, which represent comparisons against physical field measurements, against the “image” diameter error metrics, which represent comparisons against the pile perimeters digitized from the image annotations. For the same form measurement, the “field” error metrics are substantially larger than the “image” error metrics, suggesting a strong systematic bias. The diameter RMSE is 1.8 m with an accompanying MAPE of 31% when compared to field measurements, but only a 0.5 m diameter RMSE and MAPE of 8% when calculated using the footprint from the image annotations. The area MAPE of 15% with an accompanying RMSE of 2.0 m2 when compared to the footprint from the image annotations. This error is in-line with both the field-measured and image-annotated comparisons made using the data from the training site. By contrast, the height MAPE of 51% with an accompanying RMSE of 1.2 m against field measurements while the diameter MAPE is (RMSE of m) against field measurements. For the training data, both the diameter and height were predicted with sub-meter (&lt;1 m RMSE) accuracy. The large negative Mean Errors (ME) for field-compared height (-1.2 m) and diameter ( m) indicate a consistent systematic underestimation by the remote-sensing based method of the pile size relative to the field measurements. These results suggest that the data fusion pile detection method is precise and consistent in segmenting the visible pile base shape, as supported by the relatively low image-compared area and diameter errors. However, the large discrepancy between the field-measured and image-annotated values highlights a significant challenge in aligning the two data sources, which could stem from several factors. These alignment challenges include fundamental differences in measurement definitions (the visible aerial footprint versus the field-measured diameter), poor field measurement technique, poor image-annotation technique, or a combination of these. It is important to remember that inaccuracies and systemic biases are common in field-measured data. These biases can occur due to factors like inappropriate measurement guidelines, inconsistent application of measurement rules, imprecise or faulty measurement devices, or improper measurement device usage. Thus, the large difference in errors may not solely be a reflection of the performance of the remote-sensing pile detection method but could also be highlighting the inherent noise and potential systematic errors present in the field-collected and/or image-annotated “ground truth” data itself. whew. 10.3.4.3 Field measurement evaluation let’s check the field-collected and image-annotated measurements of diameter pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate(diff = field_diameter_m - image_gt_diameter_m) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = field_diameter_m, x = image_gt_diameter_m)) + ggplot2::geom_abline(lwd = 1.5) + # ggplot2::geom_point(ggplot2::aes(color = diff_volume_m3)) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(pj_slash_piles_polys$image_gt_diameter_m,na.rm=T), max(pj_slash_piles_polys$field_diameter_m,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(pj_slash_piles_polys$image_gt_diameter_m,na.rm=T), max(pj_slash_piles_polys$field_diameter_m,na.rm=T) ) )) + ggplot2::labs( y = &quot;field-measured diameter (m)&quot; , x = &quot;image-annotated diameter (m)&quot; # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = &quot;field versus image diameter comparison&quot; ) + ggplot2::theme_light() field-collected values are consistently larger than image-annotated values. this indicates a systematic bias in either the image annotation or field collection process (or both) leading to a misalignment of measurements quick summary of these measurements pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(height_m, field_diameter_m, image_gt_diameter_m, image_gt_area_m2) %&gt;% summary() ## height_m field_diameter_m image_gt_diameter_m image_gt_area_m2 ## Min. :1.340 Min. :4.150 Min. :2.644 Min. : 4.147 ## 1st Qu.:2.053 1st Qu.:5.202 1st Qu.:3.734 1st Qu.: 8.355 ## Median :2.310 Median :5.550 Median :4.148 Median :10.402 ## Mean :2.286 Mean :5.616 Mean :4.171 Mean :10.623 ## 3rd Qu.:2.498 3rd Qu.:6.018 3rd Qu.:4.549 3rd Qu.:12.524 ## Max. :3.210 Max. :7.480 Max. :6.384 Max. :25.261 ## NA&#39;s :3 NA&#39;s :3 let’s use a paired t-test to determine if the mean difference (MD) between the field-measured diameter and the image-annotated diameter is statistically significant (i.e. significantly different from zero) # is the mean difference between the two diameters significantly different from zero ttest_temp &lt;- t.test( pj_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) , pj_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: pj_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) and pj_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) ## t = 46.913, df = 273, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 1.387618 1.509181 ## sample estimates: ## mean difference ## 1.448399 yikes, the mean difference (MD) is 1.45 m (field minus image value). also, the p-value of 0.00001 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where field diameter is larger than our image-annotated diameter is statistically significant and not due to random chance. let’s look at some RGB with a circle using the field-measured diameter (white) and the image-annotated piles perimeter (blue) piles_sobad_temp &lt;- pj_slash_piles_polys %&gt;% dplyr::ungroup() %&gt;% dplyr::filter( (field_diameter_m-image_gt_diameter_m) &gt; quantile((field_diameter_m-image_gt_diameter_m),probs=0.9,na.rm=T) , !is.na(field_diameter_m), !is.na(image_gt_diameter_m) ) %&gt;% dplyr::arrange(desc(field_diameter_m)) # plot RGB plts_temp &lt;- 1:nrow(piles_sobad_temp) %&gt;% # .[1] %&gt;% sample(min(12,nrow(piles_sobad_temp))) %&gt;% purrr::map(function(x){ dta &lt;- piles_sobad_temp %&gt;% dplyr::slice(x) # get a line to draw through the center circ_temp &lt;- dta %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(dta$field_diameter_m/2) bbox_temp &lt;- circ_temp %&gt;% sf::st_bbox() # coords line_coords &lt;- matrix(c(bbox_temp[&quot;xmin&quot;], bbox_temp[&quot;ymin&quot;], bbox_temp[&quot;xmax&quot;], bbox_temp[&quot;ymax&quot;]), ncol = 2, byrow = TRUE) line_coords2 &lt;- matrix(c(bbox_temp[&quot;xmax&quot;], bbox_temp[&quot;ymin&quot;], bbox_temp[&quot;xmin&quot;], bbox_temp[&quot;ymax&quot;]), ncol = 2, byrow = TRUE) # create the line from the coordinates desired_line &lt;- sf::st_linestring(line_coords) %&gt;% sf::st_sfc(crs = sf::st_crs(dta)) %&gt;% sf::st_sf() %&gt;% sf::st_intersection(circ_temp) desired_line2 &lt;- sf::st_linestring(line_coords2) %&gt;% sf::st_sfc(crs = sf::st_crs(dta)) %&gt;% sf::st_sf() %&gt;% sf::st_intersection(circ_temp) # return(circ_temp %&gt;% st_calculate_diameter() %&gt;% pull(diameter_m)) # return(desired_line %&gt;% sf::st_length()) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(dta), buffer=6) + ggplot2::geom_sf(data = desired_line, fill = NA, color = &quot;white&quot;, lwd = 0.7) + ggplot2::geom_sf(data = desired_line2, fill = NA, color = &quot;white&quot;, lwd = 0.7) + ggplot2::geom_sf(data = circ_temp, fill = NA, color = &quot;white&quot;, lwd = 0.7) + ggplot2::geom_sf(data = dta, fill = NA, color = &quot;blue&quot;, lwd = 1) }) # plts_temp # piles_sobad_temp$field_diameter_m[1] # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) yeah, those don’t line up very well ;/ … however, we’ll continue using the field-measured height and diameter to further explore our form quantification error what is the distribution of the ground truth and prediction matching classification? # what did we get? ground_truth_prediction_match_ans %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate(pct = (n/sum(n)) %&gt;% scales::percent(accuracy=0.1)) ## # A tibble: 3 × 3 ## match_grp n pct ## &lt;ord&gt; &lt;int&gt; &lt;chr&gt; ## 1 omission 15 4.2% ## 2 commission 79 22.2% ## 3 true positive 262 73.6% let’s look at that spatially pal_match_grp &lt;- c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= &quot;gray77&quot; #viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # plot it ortho_plt_fn( my_ortho_rast = pj_rgb_rast , stand = pj_stand_boundary %&gt;% dplyr::ungroup() %&gt;% sf::st_union() %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(terra::crs(pj_rgb_rast)) , buffer = 3 ) + # ggplot2::ggplot() + ggplot2::geom_sf( data = pj_stand_boundary %&gt;% sf::st_transform(terra::crs(pj_rgb_rast)) , color = &quot;black&quot;, fill = NA ) + ggplot2::geom_sf( data = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(terra::crs(pj_rgb_rast)) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.6 ) + ggplot2::geom_sf( data = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(terra::crs(pj_rgb_rast)) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.3 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) 10.3.4.4 Instance level (pile level) let’s look at the pile-level data directly to evaluate the true positive detections, omissions (false negatives), and commissions (false positives) let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.4124 ## 1st Qu.:0.7523 ## Median :0.8182 ## Mean :0.7944 ## 3rd Qu.:0.8639 ## Max. :0.9326 for the majority (i.e. &gt;95%) of matches, the IoU was above 58.3% here is the distribution of IoU for those matches ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = iou, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.8) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::scale_x_continuous(labels=scales::percent) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;IoU of correct precitions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) is there a difference between the field-measured pile sizes of the true positive detections and the omissions (false negative)? let’s compare the field-measured height and diameter and the image-annotated area for omissions and true positives since those measurements exist for both sets ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;commission&quot;) %&gt;% dplyr::select(pile_id,match_grp,gt_height_m,gt_diameter_m,gt_area_m2) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_height_m&quot;,&quot;gt_diameter_m&quot;,&quot;gt_area_m2&quot;) , labels = c( &quot;height (m)&quot;,&quot;diameter (m)&quot; , &quot;image annotated area (m2)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot; , subtitle = &quot;ground truth form measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) wow! note that we did not inspect the field-collected and image-annotated ground truth measurement data prior to implementing our remote-sensing based pile detection methodology. we purposefully did not look at this data until after making the predictions because we wanted to set up our remote sensing pile detection method without as if we did not measure a single pile in the field so as to not bias our implementation of the method. to implement this remote sensing method slash pile detection framework in practice, we would likely not have any field-measured data on pile structure and if we did it would only be for a very small sample of piles. remember, the entire objective of creating this method is so that time in the field can be minimized to the time needed to visually assess the treatment implementation to acquire quick observational anecdotes and potentially measure some sample piles and then fly a UAS data collection mission to get the data needed to implement this method. compare that minimal time to the traditional, field-based method of slash pile identification and measurement which is much more costly in terms of time and personnel needed. visually, there is minimal difference in the form measurements between the ground truth piles that were correctly identified as true postive matches and those that were missed by the detection method as omissions (i.e. false negatives). if anything the diameter of the omissions were generally more variable than the diameter of the correct predictions. we can also see from these distributions of field-collected height and diameter and pile area from the image-annotated ground truth data that, compared to the pile construction prescription, piles were mostly between 1.75-3m in height with an diameters between 4.5-7m compared to the prescription which called for minimum heights and diameters of 1.5m though no maximum was specified. these measurments validate our decision to use a much larger expected pile area multiplier compared to the prescription minimum than we did for the height multiplier when we parameterized the detection methodology using the max_ht_m and max_area_m2 parameters. let’s now look at the summary stats of ground truth piles kbl_form_sum_stats( pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) , caption = &quot;Ground Truth Piles: summary statistics for form measurements&lt;br&gt;pinyon-juniper validation site&quot; ) Table 10.3: Ground Truth Piles: summary statistics for form measurementspinyon-juniper validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 277 Height m 2.3 0.3 1.9 2.3 2.7 1.3—3.2 Diameter m (field) 5.6 0.6 4.9 5.5 6.5 4.2—7.5 Diameter m (image) 4.2 0.6 3.4 4.1 4.9 2.6—6.4 Area m2 (image) 10.6 3.2 6.8 10.4 14.4 4.1—25.3 and let’s look at the summary stats of the predicted piles kbl_form_sum_stats( final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , caption = &quot;Predicted Piles: summary statistics for form measurements&lt;br&gt;pinyon-juniper validation site&quot; ) Table 10.4: Predicted Piles: summary statistics for form measurementspinyon-juniper validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 341 Height m 1.3 0.5 0.8 1.1 2.1 0.4—2.3 Diameter m 3.7 0.8 2.6 3.8 4.7 2.0—7.3 Area m2 8.3 3.5 3.6 8.5 12.9 2.2—17.0 Volume m3 4.7 2.7 1.9 4.2 7.8 0.5—18.4 let’s look at some examples on our RGB image true positive matches (correct predictions) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;true positive&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$tp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/Dawson_Data/pj_truepositives.jpg&quot;, height = 11, width = 8.5) omissions (false negatives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fn_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/Dawson_Data/pj_omission.jpg&quot;, height = 11, width = 8.5) let’s add the CHM to that plot to see if it helps shed light on why these were missed # plot RGB + CHM plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% sample( min(12,agg_ground_truth_match_ans$fn_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast_stand %&gt;% terra::crop( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does # terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs( subtitle = paste0( &quot;pile ID: &quot;, dta$pile_id , &quot;\\nGT area: &quot;, round(dta$gt_area_m2,1) # , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) # , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/BHEF_202306/pj_omission_chm.jpg&quot;, height = 10, width = 8.5) now, let’s check out the predicted sizes of the commissions (false positives) compared to the predicted sizes of the predicted piles that were correctly matched with the ground truth data let’s compare the predicted height, diameter, area for commissions and true positives since those measurements exist for both sets ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_height_m,pred_diameter_m,pred_area_m2) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;pred_height_m&quot;,&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;) , labels = c( &quot;predicted height (m)&quot;,&quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs(color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) this is interesting, the incorrectly predicted piles generally had a much smaller footprint (i.e diameter and area) than the predicted piles that correctly match to actual piles. in terms of height, there were two distinct groups of incorrect predictions, some that were in-line with the correctly predicted piles and some that were much taller than the correct predictions. let’s table the predicted form measurements ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_height_m,pred_diameter_m,pred_area_m2) %&gt;% dplyr::group_by(match_grp) %&gt;% dplyr::summarise( dplyr::across( c(pred_height_m,pred_diameter_m,pred_area_m2) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c( match_grp,n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) ) %&gt;% dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( metric == &quot;gt_height_m&quot; ~ scales::comma(value,accuracy=0.1) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange( match_grp, desc(n)) %&gt;% dplyr::select(-c(n,min,max)) %&gt;% dplyr::relocate(match_grp) %&gt;% dplyr::mutate( metric = factor( metric , ordered = T , levels = c(&quot;pred_height_m&quot;,&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;) , labels = c( &quot;predicted height (m)&quot;,&quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; ) ) ) %&gt;% kableExtra::kbl( caption = &quot;Predicted Piles: summary statistics for form measurements&quot; , col.names = c( &quot;segmentation&lt;br&gt;classification&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 10.5: Predicted Piles: summary statistics for form measurements segmentationclassification Metric Mean Std Dev q 10% Median q 90% Range commission predicted height (m) 1.7 0.6 0.8 1.9 2.3 0.5—2.3 predicted diameter (m) 3.2 1.1 2.3 3.0 4.6 2.0—7.3 predicted area (m2) 5.4 3.6 2.5 4.1 11.2 2.2—16.6 true positive predicted height (m) 1.1 0.3 0.8 1.1 1.5 0.4—2.3 predicted diameter (m) 3.9 0.6 3.1 3.9 4.7 2.3—5.4 predicted area (m2) 9.2 2.9 5.8 9.1 13.1 2.9—17.0 let’s look at some examples on our RGB image commissions (false positives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(pr), buffer=6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/Dawson_Data/pj_commission.jpg&quot;, height = 11, width = 8.5) it is difficult to tell from the RGB imagery alone what those actually are and why they might have been improperly predicted as slash piles. let’s look at the point cloud for some to see if we can determine what the issue is first the RGB # it&#39;s difficult to see why those false positives were included and not filtered out by the spectral filtering # plot some point clouds # cloud2trees::cloud2raster() output of normalized las norm_las_ctg &lt;- lidR::readLAScatalog( file.path(c2t_output_dir, &quot;point_cloud_processing_temp&quot;,&quot;02_normalize&quot;) ) lidR::opt_progress(norm_las_ctg) &lt;- F # sample piles ex_piles_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% sample(2) # rgb plot pr_temp &lt;- final_predicted_slash_piles %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% dplyr::slice(ex_piles_temp[1]) %&gt;% dplyr::select(pred_id) ) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(pr_temp), buffer=3) + ggplot2::geom_sf(data = pr_temp, fill = NA, color = &quot;brown&quot;, lwd = 0.8) what even is that? i mean, it could be a pile let’s try another sample. first the RGB # rgb plot pr_temp &lt;- final_predicted_slash_piles %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% dplyr::slice(ex_piles_temp[2]) %&gt;% dplyr::select(pred_id) ) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(pr_temp), buffer=3) + ggplot2::geom_sf(data = pr_temp, fill = NA, color = &quot;brown&quot;, lwd = 0.8) huh? id even k. 10.3.5 Volume Comparison Previously, we explored differences in the allometric field volume and predicted volume for the optimal training results. See that section introduction for the full details on what we are doing and why… welcome back…Let’s make the same comparisons for these validation data. We fully expect there to be much larger differences in volume based on the suspicious field-measured height and diameter values. we already added volume measurements to the TP matches for both the ground truth and predicted piles, summary of that data ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::select(gt_volume_m3, pred_volume_m3) %&gt;% summary() ## gt_volume_m3 pred_volume_m3 ## Min. : 9.371 Min. : 0.5414 ## 1st Qu.:22.558 1st Qu.: 3.0780 ## Median :27.826 Median : 4.4526 ## Mean :28.667 Mean : 4.7432 ## 3rd Qu.:33.683 3rd Qu.: 6.2125 ## Max. :57.247 Max. :11.4447 those don’t really look like they match up well…let’s explore ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::mutate(diff_volume_m3 = gt_volume_m3 - pred_volume_m3) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = gt_volume_m3, x = pred_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + # ggplot2::geom_point(ggplot2::aes(color = diff_volume_m3)) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(ground_truth_prediction_match_ans$pred_volume_m3,na.rm=T), max(ground_truth_prediction_match_ans$gt_volume_m3,na.rm=T) ) )) + ggplot2::labs( y = latex2exp::TeX(&quot;allometric field volume $m^3$&quot;) , x = latex2exp::TeX(&quot;predicted volume $m^3$&quot;) # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison&quot;) ) + ggplot2::theme_light() this is exactly what we expected: for true positive matches, there is a clear systematic difference with the plot showing that the volume calculated using the idealized, regular shape assumption (allometric field volume) is consistently larger than the predicted volume derived from the CHM let’s check these using lm() lm_temp &lt;- lm( gt_volume_m3 ~ pred_volume_m3 , data = ground_truth_prediction_match_ans %&gt;% dplyr::filter( match_grp==&quot;true positive&quot; , !is.na(gt_volume_m3), !is.na(pred_volume_m3 ) ) ) summary(lm_temp) ## ## Call: ## lm(formula = gt_volume_m3 ~ pred_volume_m3, data = ground_truth_prediction_match_ans %&gt;% ## dplyr::filter(match_grp == &quot;true positive&quot;, !is.na(gt_volume_m3), ## !is.na(pred_volume_m3))) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.855 -4.688 -1.116 4.148 27.828 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 16.9148 0.9684 17.47 &lt;2e-16 *** ## pred_volume_m3 2.4777 0.1847 13.41 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.638 on 257 degrees of freedom ## Multiple R-squared: 0.4118, Adjusted R-squared: 0.4095 ## F-statistic: 179.9 on 1 and 257 DF, p-value: &lt; 2.2e-16 These linear model results (intercept = 16.91, slope = 2.48) indicate a strong proportional bias that significantly increases with pile size. This data suggests that the geometric assumptions of the allometric model potentially introduce substantial scaling error which may limit its reliability (especially for larger piles) for accurately estimating the volume of real-world piles which have heterogeneous footprints and elevation profiles. before we compare the volume measurements in aggregate, let’s look at their distributions vol_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::select(pile_id,gt_volume_m3,pred_volume_m3) %&gt;% tidyr::pivot_longer(cols = -c(pile_id)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_volume_m3&quot;,&quot;pred_volume_m3&quot;) , labels = c( &quot;allometric field volume&quot; , &quot;predicted volume&quot; ) ) ) # plot dist vol_df_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = name, fill = name)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=latex2exp::TeX(&quot;volume $m^3$&quot;) , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison of distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) slope plots are neat too vol_df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) what if we only look at the smaller piles? vol_df_temp %&gt;% dplyr::filter( value &lt; quantile(vol_df_temp$value, probs = 0.966) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level for the smaller piles&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) let’s compare aggregated volume measurements for the true positive matches Mean Difference (MD): \\[\\text{MD} = \\frac{1}{N} \\sum_{i=1}^{N} (\\text{Allometric Volume}_i - \\text{Predicted Volume}_i)\\] Percent Mean Difference: \\[\\%\\text{MD} = \\frac{\\text{MD}}{\\text{Mean}(\\text{Predicted Volume})} \\times 100\\] vol_agg_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( mean_diff = mean(gt_volume_m3-pred_volume_m3) , sd_diff = sd(gt_volume_m3-pred_volume_m3) , mean_gt_volume_m3 = mean(gt_volume_m3,na.rm = T) , mean_pred_volume_m3 = mean(pred_volume_m3,na.rm = T) ) %&gt;% dplyr::mutate( pct_mean_diff = mean_diff/mean_pred_volume_m3 ) what did we get? vol_agg_df_temp %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( value = dplyr::case_when( stringr::str_starts(name, &quot;pct_&quot;) ~ scales::percent(value, accuracy = 0.1) , T ~ scales::comma(value, accuracy = 0.1) ) ) %&gt;% kableExtra::kbl( caption = &quot;comparison of aggregated allometric field volume and predicted volume&quot; , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 10.6: comparison of aggregated allometric field volume and predicted volume metric value mean_diff 23.9 sd_diff 7.4 mean_gt_volume_m3 28.7 mean_pred_volume_m3 4.7 pct_mean_diff 504.4% we’ll dig into the MD shortly but before we move on let’s focus on the percent mean difference. We calcualted a %MD of 504.4% which indicates a major systematic difference where the allometric field volume is, on average, 504.4% larger than our CHM-predicted volume. This large relative difference shows how much the geometric assumptions inflate the volume compared to the irregular volumes measured by our remote sensing-based method and also point to suspect field measurements of height and diameter let’s make a Bland-Altman plot to compare the two measurement methods. this plot uses the average of the two measurements (approximate size) on the x-axis and the difference (bias) between the two measurements on the y-axis ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( mean_vol = (gt_volume_m3+pred_volume_m3)/2 , diff_vol = (gt_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp , scale_diff = ifelse(diff_vol &lt; 0, -abs(diff_vol) / abs(min(diff_vol)), diff_vol / max(diff_vol)) ) %&gt;% # ggplot() + geom_point(aes(x=diff_vol,y=0, color=scale_diff)) + scale_color_gradient2(mid = &quot;gray&quot;, midpoint = 0, low = &quot;red&quot;, high = &quot;blue&quot;) # plot ggplot2::ggplot( mapping = ggplot2::aes(x = mean_vol, y = diff_vol) ) + ggplot2::geom_hline(yintercept = 0, color = &quot;black&quot;, lwd = 1.2) + # mean difference (bias) ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff , linetype = &quot;dashed&quot;, color = &quot;blue&quot;, lwd = 1 ) + # upper limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # lower limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # annotations ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff , label = latex2exp::TeX( paste0( &quot;mean difference (bias): &quot; , scales::comma(vol_agg_df_temp$mean_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;blue&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;+1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;-1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = 1.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + # points ggplot2::geom_point(mapping = ggplot2::aes(color = scale_diff), size = 1.9, alpha = 0.8) + ggplot2::scale_color_steps2(mid = &quot;gray&quot;, midpoint = 0) + ggplot2::labs( subtitle = &quot;Bland-Altman plot: allometric field volume vs predicted volume&quot; , x = latex2exp::TeX(&quot;mean volume ($m^3$)&quot;) , y = latex2exp::TeX(&quot;difference (allometric - predicted volume $m^3$)&quot;) ) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;none&quot;) yikes. The upward sloping trend on the Bland-Altman plot confirms a severe proportional bias where the difference between the two volume measurements increases dramatically as the piles grow larger. The high mean difference (MD) of 23.92 m3 quantifies this systematic difference. The increasing slope on this plot indicates that the difference is not a constant offset. Instead, the idealized geometric assumptions of the allometric model greatly exaggerate the volume by an increasingly large amount for bigger piles, demonstrating a fundamental size-dependency in the disagreement between the two modeled methods. Points falling outside the 95% interval on the plot are instances of significant disagreement between the two volumes measurements for those specific data points. These outliers indicate that, for a particular pile, the difference between the allometric field volume and the predicted volume is unusually large, suggesting a potential failure in either the CHM segmentation process, the quality of the original field measurements, the geometric shape assumption, or a combination thereof. We should investigate these extreme disagreements further to see what is happening before we do that, let’s use a paired t-test to determine if the mean difference (MD) between the allometric field volume and the predicted volume is statistically significant (i.e. significantly different from zero) # is the mean difference between the two volumes significantly different from zero ttest_temp &lt;- t.test( ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) , ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(gt_volume_m3) and ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) ## t = 51.996, df = 258, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 23.01761 24.82968 ## sample estimates: ## mean difference ## 23.92365 the test gave us a mean difference (MD) of 23.92 m3. also, the p-value of 0.00000 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where allometric volume is larger than our predicted volume is statistically significant and not due to random chance. 10.3.5.1 Extreme Volume Disagreements let’s investigate the extreme disagreements further to see what is happening bad_vol_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;,!is.na(gt_volume_m3), !is.na(pred_volume_m3)) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( diff_vol = (gt_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp ) %&gt;% dplyr::filter( diff_vol &gt; (vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff) ) # what are the differences? bad_vol_df_temp %&gt;% dplyr::select( pile_id , gt_height_m, pred_height_m, diff_height_m , gt_diameter_m, pred_diameter_m, diff_field_diameter_m , gt_volume_m3, pred_volume_m3 ) %&gt;% dplyr::mutate( dplyr::across( .cols = -c(pile_id) , .fns = ~ scales::comma(.x,accuracy=0.01) ) ) %&gt;% kableExtra::kbl( caption = &quot;Volume measurement outliers: comparison of ground truth and predicted piles&quot; # , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 10.7: Volume measurement outliers: comparison of ground truth and predicted piles pile_id gt_height_m pred_height_m diff_height_m gt_diameter_m pred_diameter_m diff_field_diameter_m gt_volume_m3 pred_volume_m3 156 2.58 1.46 -1.12 7.46 4.12 -3.34 56.38 7.24 153 2.59 0.82 -1.77 7.27 4.89 -2.38 53.76 6.16 137 2.77 1.58 -1.19 7.14 4.33 -2.81 55.45 8.34 249 2.90 1.20 -1.70 7.09 4.05 -3.04 57.25 5.05 85 2.44 0.88 -1.56 6.94 4.35 -2.59 46.15 4.15 247 2.38 1.04 -1.34 6.84 4.20 -2.64 43.73 4.37 174 2.56 1.07 -1.49 6.75 4.84 -1.91 45.80 7.01 134 2.44 0.74 -1.70 6.56 3.51 -3.05 41.23 2.63 178 3.00 1.84 -1.16 6.55 4.61 -1.94 50.54 11.16 240 2.59 1.15 -1.44 6.55 4.43 -2.12 43.64 4.06 158 2.95 1.39 -1.56 6.33 4.14 -2.19 46.42 7.32 smokes, it looks like the field-measured height and diameter is much different than the CHM height (we already discovered this above) bad_vol_df_temp %&gt;% dplyr::select( pile_id , gt_height_m, pred_height_m , gt_diameter_m, pred_diameter_m , gt_volume_m3, pred_volume_m3 ) %&gt;% tidyr::pivot_longer( cols = -c(pile_id) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground &#39;truth&#39;&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;paraboloid_volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume (m3)&quot; , &quot;Volume paraboloid&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = which_data, y = value, label = scales::comma(value,accuracy=0.1), group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = which_data), alpha = 0.8, size = 2.5) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 , show.legend = FALSE , size = 0 ) + ggplot2::facet_grid(rows = dplyr::vars(pile_metric), scales = &quot;free_y&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0.05,.32))) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot; , subtitle = &quot;Volume measurement outliers: comparison of measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) RGB with the predicted piles (brown) and the ground-truth piles (blue) # nrow(bad_vol_df_temp) # plot RGB plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% # .[1] %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) just looking at the RGB, the pile footprints are in good alignment let’s look at the CHM # cloud2raster_ans$chm_rast %&gt;% # terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% # terra::plot() # bad_vol_df_temp %&gt;% dplyr::glimpse() # plot RGB + CHM plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- pj_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=pj_rgb_rast, stand=sf::st_union(gt,pr), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = cloud2raster_ans$chm_rast %&gt;% terra::crop( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) + ggplot2::labs( subtitle = paste0( &quot;GT ht: &quot;, round(dta$gt_height_m,1) , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 3 ) The issue here is not with the specific height slice of the CHM based on the max_ht_m parameter as we saw with the training data pile volume comparison. Instead, the issue is the field-measured height and diameter 10.3.6 Stand-level Aggregation before we leave, let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory) sum_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(pred_id)) %&gt;% dplyr::summarise( dplyr::across( .cols = tidyselect::starts_with(&quot;gt_&quot;) | tidyselect::starts_with(&quot;pred_&quot;) , ~sum(.x,na.rm=T) ) ) %&gt;% tidyr::pivot_longer( cols = dplyr::everything() , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground truth&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; , &quot;Volume (m3)&quot; , &quot;Volume paraboloid&quot; ) ) ) %&gt;% dplyr::group_by(pile_metric) %&gt;% dplyr::arrange(pile_metric,which_data) %&gt;% dplyr::mutate( pct_diff = (value-dplyr::lag(value))/dplyr::lag(value) ) %&gt;% dplyr::ungroup() plot # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric), scales = &quot;free_y&quot;, axes = &quot;all_x&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated measurements at the stand level&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table it sum_df_temp %&gt;% dplyr::select(pile_metric, which_data, value, pct_diff) %&gt;% dplyr::mutate( value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated measurements at the stand level&quot; , col.names = c( &quot;.&quot;, &quot;measurement source&quot; , &quot;stand-level total&quot;, &quot;% difference&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 10.8: Comparison of aggregated measurements at the stand level . measurement source stand-level total % difference Height (m) ground truth 626.3 NA prediction 427.6 -31.7% Diameter (m) ground truth 1,538.9 NA prediction 1,274.2 -17.2% Area (m2) ground truth 2,942.6 NA prediction 2,846.4 -3.3% 10.4 Pile Detection: Structural Only we’ll now detail the parameterization of the methodology using structural (CHM data) only as if no spectral data were available. This setup will allow us to compare it with the data fusion approach we reviewed above. Essentially, the availability of complementary spectral data permits the use of more relaxed size and structural thresholds. Conversely, when working exclusively with structural data, users are advised to employ more restrictive structural filters to effectively suppress false positives and ensure reliable pile detection. 10.4.1 Structural Detection we’re going to set the four structural parameters (max_ht_m, max_area_m2, convexity_pct, circle_fit_iou_pct) of the slash_pile_detect_watershed() function (defined here) which are used to determine candidate slash piles from the CHM data alone based on our expectations from the treatment prescription and it’s implementation on the ground. Our settings here will be more restrictive in an attempt to suppress false positives which we do not have the benefit of filtering out using spectral data. the treatment prescription for the unit of interest called for thinning to create a residual structure with “uniform gaps between trees” with via a “heavy intensity thinning” that called for gaps of “at least Based on the prescription and anecdotal feedback, the following parameter settings will be used: max_ht_m: This parameter will be set to 1.8 m (5.9 feet). This represents a 20% increase over the 1.5 m (5 ft) minimum height specified in the prescription, to account for the feedback that piles were larger than expected. min_ht_m: This parameter will be set to 0.6 m (2 foot). This creates a 1.2 m (3.9 feet) vertical range for structural detection. This setting allows for the acceptance of piles up to 0.9 m (3 feet) smaller than the prescribed minimum of 1.5 m to account for variation in construction from the prescription and the settling of pile form over time min_area_m2: This parameter will be set to 2.0 square meters (21.5 square feet). This provides a small buffer below the prescribed 2.3 square meters (25 square feet) minimum area to account for minor segmentation errors or slight settling of the pile, without deviating significantly from the horizontal prescription. max_area_m2: This parameter will be set to 15 square meters (161.5 square feet). This represents a nearly seven-fold increase compared to the 2.3 square meters minimum. The rationale for this significant increase compared to the upper height threshold is because it is physically easier to construct piles that are wider and more irregular in the horizontal direction than the vertical direction. convexity_pct: To account for the “messy” and irregularly shaped piles, this parameter will be set to 0.12 which is in the the optimal range identified in the ponderosa pine training data based on predictions for structural only input data circle_fit_iou_pct: This parameter will be set to 0.39, which is approximately 8 percentage points lower than the optimal value identified in the ponderosa pine training data. This value is used in conjunction with convexity_pct to allow for a wider range of non-circular, irregular shapes CHM Resolution (chm_res_m): A 0.1 m (0.33 feet, 3.9 inches) CHM raster will be used. This fine resolution will enhance the granular distinction between piles and lower tree branches which is important given the close proximity of piles to residual trees noted by managers slash_pile_detect_watershed() that CHM outdir_temp &lt;- &quot;../data/Dawson_data&quot; fnm_temp &lt;- file.path(outdir_temp,&quot;pj_structural_only_predictions.gpkg&quot;) # &quot;new_pj_structural_candidate_segments.gpkg&quot; = convexity_pct = 0.06; circle_fit_iou_pct = 0.35 if(!file.exists(fnm_temp)){ set.seed(88) structural_final_predicted_slash_piles &lt;- slash_pile_detect_watershed( chm_rast = chm_rast_stand #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = 1.8 # set the max expected pile height , min_ht_m = 0.6 # set the min expected pile height , min_area_m2 = 2.0 # set the min expected pile area , max_area_m2 = 15 # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.12 # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = 0.39 #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) # save structural_final_predicted_slash_piles %&gt;% sf::st_write(fnm_temp, append = F) }else{ structural_final_predicted_slash_piles &lt;- sf::st_read(fnm_temp, quiet=T) } # what did we get? structural_final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 325 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20… ## $ area_m2 &lt;dbl&gt; 12.410, 3.500, 11.255, 11.680, 6.810, 12.075, 2.875, 3… ## $ volume_m3 &lt;dbl&gt; 7.611119, 2.956290, 5.879869, 7.763583, 7.834494, 7.48… ## $ max_height_m &lt;dbl&gt; 1.500000, 1.800000, 1.800000, 1.800000, 1.800000, 1.80… ## $ volume_per_area &lt;dbl&gt; 0.6133054, 0.8446542, 0.5224228, 0.6646903, 1.1504396,… ## $ pct_chull &lt;dbl&gt; 0.7687349, 0.8142857, 0.8573967, 0.8672945, 0.7239354,… ## $ diameter_m &lt;dbl&gt; 5.223983, 2.657066, 4.100000, 4.438468, 3.448188, 5.85… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((707989.7 4193402,..., POLYGON ((7082… CHM with the structural-only predicted piles (brown) and the ground-truth piles (blue) chm_rast_stand %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( pj_slash_piles_polys %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) terra::plot( structural_final_predicted_slash_piles %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.3 ) let’s focus in on a specific area to plot the ground truth and the predicted piles overlaid on the RGB # all gt piles that intersect gt_temp &lt;- pj_slash_piles_polys %&gt;% dplyr::inner_join( pj_slash_piles_polys %&gt;% sf::st_transform(sf::st_crs(aoi_for_plt)) %&gt;% sf::st_intersection(aoi_for_plt) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) ) %&gt;% sf::st_transform(sf::st_crs(aoi_for_plt)) # all pred piles that intersect pred_temp &lt;- structural_final_predicted_slash_piles %&gt;% dplyr::inner_join( structural_final_predicted_slash_piles %&gt;% sf::st_intersection(aoi_for_plt) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) ) # plot it ortho_plt_temp &lt;- ortho_plt_fn( my_ortho_rast = pj_rgb_rast , stand = aoi_for_plt , buffer = 5 ) # ortho_plt_temp plot a sample of the RGB with the predicted piles (brown) and the ground-truth piles (blue) ortho_plt_temp + # ggplot2::ggplot() + ggplot2::geom_sf( data = gt_temp , color = &quot;blue&quot; , fill = NA , lwd = 1 ) + ggplot2::geom_sf( data = pred_temp , color = &quot;brown&quot; , fill = NA , lwd = 1 ) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) plot the same sample of the CHM with the predicted piles (brown) and the ground-truth piles (blue) cloud2raster_ans$chm_rast %&gt;% terra::crop(aoi_for_plt %&gt;% terra::vect() %&gt;% terra::project(cloud2raster_ans$chm_rast)) %&gt;% terra::mask(aoi_for_plt %&gt;% terra::vect() %&gt;% terra::project(cloud2raster_ans$chm_rast)) %&gt;% terra::aggregate(fact = 2, na.rm=T) %&gt;% #, fun = &quot;median&quot;, cores = lasR::half_cores(), na.rm = T) %&gt;% terra::plot(col = viridis::plasma(100), axes = F) terra::plot( gt_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 ) terra::plot( pred_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , add = T, border = &quot;brown&quot;, col = NA, lwd = 1.3 ) 10.4.2 Detection and Quantification Accuracy let’s see how we did given the list of predictions compared to the ground truth data using the confusion matrix matching process we outlined in this earlier section. we’ll filter both ground truth and predicted piles to keep only those that actually intersect with the study unit boundary for comparison # add filter # pred structural_final_predicted_slash_piles &lt;- structural_final_predicted_slash_piles %&gt;% dplyr::left_join( structural_final_predicted_slash_piles %&gt;% sf::st_intersection( pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(structural_final_predicted_slash_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) 10.4.2.1 Instance matching now apply the instance matching process we outlined in this earlier section to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions) # ground truth and prediction matching process structural_ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(field_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(structural_final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = structural_final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles structural_ground_truth_prediction_match_ans &lt;- structural_ground_truth_prediction_match_ans %&gt;% # add area of gt dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m , field_gt_volume_m3 , height_m , field_diameter_m ) %&gt;% dplyr::rename( gt_height_m = height_m , gt_diameter_m = field_diameter_m , gt_area_m2 = image_gt_area_m2 , gt_volume_m3 = field_gt_volume_m3 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( structural_final_predicted_slash_piles %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # ht diffs diff_height_m = pred_height_m-gt_height_m , pct_diff_height_m = (gt_height_m-pred_height_m)/gt_height_m # diameter , diff_field_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_field_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # image diameter , diff_image_diameter_m = pred_diameter_m-image_gt_diameter_m , pct_diff_image_diameter_m = (image_gt_diameter_m-pred_diameter_m)/image_gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # # volume diffs # , diff_image_volume_m3 = pred_volume_m3-image_gt_volume_m3 # , pct_diff_image_volume_m3 = (image_gt_volume_m3-pred_volume_m3)/image_gt_volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_gt_volume_m3 # , pct_diff_field_volume_m3 = (field_gt_volume_m3-pred_volume_m3)/field_gt_volume_m3 ) # huh? structural_ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 339 ## Columns: 23 ## $ pile_id &lt;dbl&gt; 156, 73, 137, 249, 85, 247, 174, 149, 218, 7… ## $ i_area &lt;dbl&gt; 10.753418, 13.624855, 11.746210, 9.142921, 1… ## $ u_area &lt;dbl&gt; 11.929006, 17.953926, 15.612023, 12.799369, … ## $ iou &lt;dbl&gt; 0.9014513, 0.7588789, 0.7523823, 0.7143259, … ## $ pred_id &lt;int&gt; 80, 202, 68, 144, 273, 218, 214, 233, 213, 1… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive,… ## $ gt_area_m2 &lt;dbl&gt; 11.112424, 17.303781, 15.228233, 12.767290, … ## $ image_gt_diameter_m &lt;dbl&gt; 4.096896, 5.230641, 5.228979, 4.778329, 4.77… ## $ gt_volume_m3 &lt;dbl&gt; 56.38418, 45.20433, 55.45441, 57.24669, 46.1… ## $ gt_height_m &lt;dbl&gt; 2.58, 2.19, 2.77, 2.90, 2.44, 2.38, 2.56, 2.… ## $ gt_diameter_m &lt;dbl&gt; 7.46, 7.25, 7.14, 7.09, 6.94, 6.84, 6.75, 6.… ## $ pred_area_m2 &lt;dbl&gt; 11.570, 14.275, 12.130, 9.175, 10.180, 9.930… ## $ pred_volume_m3 &lt;dbl&gt; 7.240877, 7.230272, 8.337802, 5.046406, 4.14… ## $ pred_height_m &lt;dbl&gt; 1.46, 1.08, 1.58, 1.20, 0.88, 1.04, 1.07, 1.… ## $ pred_diameter_m &lt;dbl&gt; 4.123106, 5.420332, 4.326662, 4.049691, 4.34… ## $ diff_height_m &lt;dbl&gt; -1.12, -1.11, -1.19, -1.70, -1.56, -1.34, -1… ## $ pct_diff_height_m &lt;dbl&gt; 0.4341085, 0.5068493, 0.4296029, 0.5862069, … ## $ diff_field_diameter_m &lt;dbl&gt; -3.336894, -1.829668, -2.813338, -3.040309, … ## $ pct_diff_field_diameter_m &lt;dbl&gt; 0.4473049, 0.2523680, 0.3940250, 0.4288165, … ## $ diff_image_diameter_m &lt;dbl&gt; 0.02620980, 0.18969070, -0.90231755, -0.7286… ## $ pct_diff_image_diameter_m &lt;dbl&gt; -0.006397478, -0.036265286, 0.172560942, 0.1… ## $ diff_area_m2 &lt;dbl&gt; 0.45757578, -3.02878145, -3.09823340, -3.592… ## $ pct_diff_area_m2 &lt;dbl&gt; -0.041176954, 0.175035813, 0.203453238, 0.28… that’s a lot of great detail at the individual pile instance level for us to dig into. before we do that, let’s aggregate the instances to see how we did at the stand level overall 10.4.2.2 Overall (stand level) Now we’ll aggregate the instance matching results to calculate overall performance assessment metrics. Here, we take the counts of True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions), to determine overall accuracy. This aggregation will give us two types of results: detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified structural_agg_ground_truth_match_ans &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans = structural_ground_truth_prediction_match_ans) # huh? structural_agg_ground_truth_match_ans %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 20 ## $ tp_n &lt;dbl&gt; 236 ## $ fp_n &lt;dbl&gt; 62 ## $ fn_n &lt;dbl&gt; 41 ## $ omission_rate &lt;dbl&gt; 0.1480144 ## $ commission_rate &lt;dbl&gt; 0.2080537 ## $ precision &lt;dbl&gt; 0.7919463 ## $ recall &lt;dbl&gt; 0.8519856 ## $ f_score &lt;dbl&gt; 0.8208696 ## $ diff_area_m2_rmse &lt;dbl&gt; 1.791876 ## $ diff_field_diameter_m_rmse &lt;dbl&gt; 1.78518 ## $ diff_height_m_rmse &lt;dbl&gt; 1.21531 ## $ diff_image_diameter_m_rmse &lt;dbl&gt; 0.406211 ## $ diff_area_m2_mean &lt;dbl&gt; -1.14091 ## $ diff_field_diameter_m_mean &lt;dbl&gt; -1.704 ## $ diff_height_m_mean &lt;dbl&gt; -1.188069 ## $ diff_image_diameter_m_mean &lt;dbl&gt; -0.2504122 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.1364955 ## $ pct_diff_field_diameter_m_mape &lt;dbl&gt; 0.3052607 ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.5192491 ## $ pct_diff_image_diameter_m_mape &lt;dbl&gt; 0.0746874 notice how there is only one row for the single stand we had ground truth data for to evaluate our method against let’s table the most relevant metrics structural_agg_ground_truth_match_ans %&gt;% kbl_agg_gt_match( caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;structural only pinyon-juniper validation site&quot; ) Table 10.9: pile detection and form quantification accuracy metricsstructural only pinyon-juniper validation site . value Detection Count TP 236 FN 41 FP 62 Detection F-score 82% Recall 85% Precision 79% Area m2 ME -1.14 RMSE 1.8 MAPE 14% Diameter m (field) ME -1.70 RMSE 1.8 MAPE 31% Diameter m (image) ME -0.25 RMSE 0.4 MAPE 7% Height m ME -1.19 RMSE 1.2 MAPE 52% "],["method-validation-bhef-machine-piles.html", "Section 11 Method Validation: BHEF Machine Piles 11.1 Site Introduction 11.2 Data Processing 11.3 Pile Detection: Data Fusion", " Section 11 Method Validation: BHEF Machine Piles 11.1 Site Introduction Here, we’ll be working with a ponderosa pine evaluation site from the Black Hills Experimental Forest (BHEF) which will serve as a critical test of the slash pile detection methodology’s generalizability against massive machine piles. While ecologically similar to the training site, this location features a fundamentally different pile construction, resulting in massive machine piles that exhibit a high degree of geometric irregularity, with observed shapes ranging from circular to rectangular perimeters and numerous complex deviations. The treatment that created these piles occurred approximately two years prior to data collection. Based on local precipitation and forest type, significant tree regeneration is expected, which introduces a challenge for our spectral filtering methodology for minimizing false positives. Given these novel structural and ecological conditions, the detection parameters will be adjusted from the training site’s optimal settings. For the BHEF site, parameter adjustments will focus on relaxing the geometric filters (e.g. circle_fit_iou_pct) to accommodate the varied footprints of these machine-built piles. We will rely on strict size and scale filters (e.g. min_ht_m and min_area_m2) to exclude smaller non-pile objects such as shrubs and trees. As with the Pinyon-Juniper site, image-annotated pile footprints will be used as ground truth data to calculate performance metrics (e.g., F-score and MAPE) to determine how well the methodology generalizes to these large, unprecedented, and structurally complex structures. insert prescription detail 11.2 Data Processing 11.2.1 RGB Data The RGB data is spread across many different files so we’ll need to read those files individually, adjust and standardize the resolution, and then mosaic them together ## function to change the resolution of RGB change_res_fn &lt;- function( r , my_res=1 , m = &quot;bilinear&quot; # , ofile = tempfile(fileext = &quot;.tif&quot;) , ofile = NULL ){ r2 &lt;- r terra::res(r2) &lt;- my_res if(!inherits(ofile,&quot;character&quot;)){ r2 &lt;- terra::resample(r, r2, method = m) }else{ r2 &lt;- terra::resample(r, r2, method = m, filename=ofile, overwrite = T) } return(r2) } ############################################################### # read and compile RGB raster ############################################################### las_dir_temp &lt;- &quot;F:/UAS_Collections/BHEF_202306&quot; # where is the raw las and rgb data? c2t_output_dir &lt;- &quot;../data/BHEF_202306/&quot; # where do you want to save processed data to? rgb_fnm_temp &lt;- file.path(c2t_output_dir,&quot;bhef_rgb.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(c2t_output_dir)){dir.create(c2t_output_dir, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # read list of orthos ortho_list_temp &lt;- list.files( las_dir_temp , pattern = &quot;.*(_RGB|_RBG)\\\\.(tif|tiff)$&quot; , full.names = T, recursive = T ) %&gt;% purrr::map(function(x){terra::rast(x)}) ## apply the change_res_fn ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.04)}) ######## mosaic the raster list bhef_rgb_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works , filename = rgb_fnm_temp , overwrite = T ) # bhef_rgb_rast %&gt;% # terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } names(bhef_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;alpha&quot;) terra::res(bhef_rgb_rast) ## [1] 0.04 0.04 11.2.2 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data # output dir dir_temp &lt;- file.path(c2t_output_dir, &quot;point_cloud_processing_delivery&quot;) # check out the point cloud data really quick # list.files(normalizePath(las_dir_temp), pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = TRUE, recursive = T) las_flist_temp &lt;- c( &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit1and3Processing.files/BHEF_202306_Unit1and3_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit2Processing.files/BHEF_202306_Unit2_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit4Processing.files/BHEF_202306_Unit4_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit5Processing.files/BHEF_202306_Unit5_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit6Processing.files/BHEF_202306_Unit6_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit7Processing.files/BHEF_202306_Unit7_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit8Processing.files/BHEF_202306_Unit8_laz.laz&quot; ) # read header with catalog lidR::readLAScatalog(las_flist_temp) ## class : LAScatalog (v1.2 format 2) ## extent : 608233.4, 610968.2, 4888216, 4889418 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83 / UTM zone 13N ## area : 3.94 km² ## points : 1.63 billion points ## type : airborne ## density : 412.5 points/m² ## density : 412.5 pulses/m² ## num. files : 7 # do it if(!dir.exists(dir_temp)){ # ctg_temp &lt;- lidR::readLAScatalog(las_flist_temp) # ctg_temp@data %&gt;% dplyr::glimpse() # remove(ctg_temp) # gc() # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_output_dir , input_las_dir = las_flist_temp , accuracy_level = 2 , keep_intrmdt = F , dtm_res_m = 0.2 , chm_res_m = 0.1 , min_height = 0 # effectively generates a DSM based on non-ground points ) # cloud2raster_ans$chm_rast # pc_ext_temp &lt;- sf::st_read(file.path(c2t_output_dir,&quot;point_cloud_processing_delivery&quot;,&quot;raw_las_ctg_info.gpkg&quot;)) }else{ dtm_temp &lt;- terra::rast( file.path(dir_temp, &quot;dtm_0.2m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(dir_temp, paste0(&quot;chm_&quot;, 0.1,&quot;m.tif&quot;)) ) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } # huh? cloud2raster_ans ## $dtm_rast ## class : SpatRaster ## size : 6006, 13674, 1 (nrow, ncol, nlyr) ## resolution : 0.2, 0.2 (x, y) ## extent : 608233.4, 610968.2, 4888216, 4889418 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83 / UTM zone 13N (EPSG:26913) ## source : dtm_0.2m.tif ## name : 1_dtm_0.2m ## min value : 1633.414 ## max value : 1736.891 ## ## $chm_rast ## class : SpatRaster ## size : 12011, 27348, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 608233.4, 610968.2, 4888217, 4889418 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83 / UTM zone 13N (EPSG:26913) ## source : chm_0.1m.tif ## name : focal_mean ## min value : 0.00 ## max value : 31.98 11.2.3 Vector Data cloud2trees::cloud2raster() wrote out a file with the spatial coverage of the point cloud data, let’s read that in. # pc extent pc_ext_temp &lt;- sf::st_read(file.path(c2t_output_dir,&quot;point_cloud_processing_delivery&quot;,&quot;raw_las_ctg_info.gpkg&quot;), quiet=T) %&gt;% sf::st_union() %&gt;% # inward buffer to remove edge effects sf::st_buffer(-15) # mapview::mapview(pc_ext_temp) what is the area of the point cloud extent we are looking over? sf::st_area(pc_ext_temp) %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.01) ## [1] &quot;278.36 ha&quot; read in the treatment unit boundaries ############################################################### # read unit boundary ############################################################### bhef_stand_boundary &lt;- sf::st_read(&quot;../data/BHEF_202306/bhef_harvests.gpkg&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% dplyr::filter( year_id == 2021 &amp; !(treatment_type_grp %in% c(&quot;Improvement/Liberation Cut&quot;, &quot;Other&quot;, &quot;Sanitation Cut&quot;)) &amp; suid %in% c(&quot;0203088082660004000&quot;,&quot;0203088082660003000&quot;) # these were the only units with machine piles in prescription ) %&gt;% sf::st_transform(sf::st_crs(pc_ext_temp)) now we need to make sure our point cloud data and treatment unit data overlap. we only want to analyze treatment units that have full coverage of point cloud data how does this all line up? # how does this compare to the unit boundaries? ggplot2::ggplot() + ggplot2::geom_sf( data = bhef_stand_boundary , mapping = ggplot2::aes(color = &quot;treatments&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = pc_ext_temp , mapping = ggplot2::aes(color = &quot;point cloud ext.&quot;) , fill = NA, lwd = 2 ) + ggplot2::scale_color_manual(values = c(&quot;gold2&quot;,&quot;cyan2&quot;),name=&quot;&quot;) + ggplot2::scale_x_continuous(NULL,breaks = NULL) + ggplot2::scale_y_continuous(NULL,breaks = NULL) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) let’s keep only the units that have full coverage from the point cloud data after buffering the units to reduce edge effects # get indices of those entierly covered by pc ext covered_indices_temp &lt;- sf::st_covered_by( x = bhef_stand_boundary %&gt;% sf::st_buffer(15) , y = pc_ext_temp , sparse = FALSE ) # convert the logical matrix to a single logical vector, since we want to keep an x polygon if it is covered by any of the polygons in y is_covered_temp &lt;- rowSums(covered_indices_temp) &gt; 0 # subset to keep only the covered polygons # nrow(bhef_stand_boundary) bhef_stand_boundary &lt;- bhef_stand_boundary %&gt;% dplyr::slice( which(is_covered_temp) ) # sf::st_union() # nrow(bhef_stand_boundary) what did we get? # how does this compare to the unit boundaries? ggplot2::ggplot() + ggplot2::geom_sf( data = bhef_stand_boundary , mapping = ggplot2::aes(color = &quot;treatments&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = pc_ext_temp , mapping = ggplot2::aes(color = &quot;point cloud ext.&quot;) , fill = NA, lwd = 2 ) + ggplot2::scale_color_manual(values = c(&quot;gold2&quot;,&quot;cyan2&quot;),name=&quot;&quot;) + ggplot2::scale_x_continuous(NULL,breaks = NULL) + ggplot2::scale_y_continuous(NULL,breaks = NULL) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) what is the area of the treatment unit boundaries we are looking over? bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.1) ## [1] &quot;103.1 ha&quot; that’s great The perimeter of each pile was digitized in a Geographic Information System (GIS) overlaid on a 0.04 m RGB orthomosaic. In this digitization process, the perimeter was based on the main footprint of the pile at ground level, excluding isolated logs or debris extending beyond the primary boundary. These ground truth polygons will be compared to the predicted pile boundaries using the intersection over union (IoU) metric, with a minimum threshold required for a true positive match. load in the pile boundary polygons. # read in polys bhef_slash_piles_polys &lt;- sf::st_read(&quot;../data/BHEF_202306/piles/bhef_pile_polys.shp&quot;, quiet=T) %&gt;% # sf::st_as_sf() %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) %&gt;% # area st_calculate_diameter() %&gt;% dplyr::rename( image_gt_diameter_m = diameter_m ) %&gt;% sf::st_transform(sf::st_crs(pc_ext_temp)) # add a flag for if a pile is in the stand or not based on a spatial intersection bhef_slash_piles_polys &lt;- bhef_slash_piles_polys %&gt;% dplyr::left_join( bhef_slash_piles_polys %&gt;% sf::st_intersection( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(bhef_slash_piles_polys)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pile_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) huh? bhef_slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 26 ## Columns: 7 ## $ shape_leng &lt;dbl&gt; 46.62793, 48.54183, 52.30751, 51.47470, 66.51802, … ## $ shape_area &lt;dbl&gt; 76.30865, 133.64823, 144.94465, 135.03140, 220.586… ## $ pile_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,… ## $ image_gt_area_m2 &lt;dbl&gt; 76.03950, 133.30759, 144.67638, 134.76650, 220.403… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((608553.4 4889262,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 15.27058, 14.95721, 16.11087, 14.77658, 20.57680, … ## $ is_in_stand &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… map # option to put satellite imagery as base layer of mapview maps mapview::mapviewOptions( homebutton = FALSE # , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) ) # map it mapview::mapview( bhef_stand_boundary %&gt;% sf::st_union() , color = &quot;black&quot; , lwd = 1 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE , layer.name = &quot;stand boundary&quot; ) + # mapview::mapview(bhef_slash_piles_points, zcol = &quot;height_m&quot;) mapview::mapview(bhef_slash_piles_polys, zcol = &quot;image_gt_area_m2&quot;,layer.name=&quot;machine piles&quot;) we’ll work with the CHM in the study unit boundary plus a buffer to limit the amount of data we process Given the expected massive size of these piles, we utilize a slightly coarser CHM resolution, aggregating the raster to 0.15m. This is sufficient detail for identification and quantification of large objects, and previous analysis of the training data indicated that this 0.15m resolution provided similarly high detection and form quantification accuracies as the finer 0.1m CHM. first, we’ll borrow from the cloud2trees codebase to get a function to change the resolution of a raster exactly ###___________________________________________### # adjust the resolution of a raster to be in exactly the target resolution ###___________________________________________### adjust_raster_resolution &lt;- function( raster_object , target_resolution , fun = mean , resample_method = &quot;bilinear&quot; , ofile = NULL ) { # check if the input is a spatraster object if (!inherits(raster_object, &quot;SpatRaster&quot;)) { stop(&quot;Input must be a SpatRaster object.&quot;) } current_resolution &lt;- terra::res(raster_object)[1] # get current resolution (assuming square pixels) result_raster &lt;- NULL # aggregating (decreasing resolution) if (target_resolution &gt; current_resolution) { # calculate the aggregation factor # we aim for an integer factor for aggregate, but then refine with resample fact &lt;- max(1, floor(target_resolution / current_resolution)) # aggregate the raster if(inherits(ofile,&quot;character&quot;)){ aggregated_raster &lt;- terra::aggregate(raster_object, fact = fact, fun = fun, filename = ofile, overwrite = TRUE) }else{ aggregated_raster &lt;- terra::aggregate(raster_object, fact = fact, fun = fun) } result_raster &lt;- aggregated_raster }else if(target_resolution &lt; current_resolution) { # disaggregating (increasing resolution) # calculate the disaggregation factor # we aim for an integer factor for disaggregate, but then refine with resample fact &lt;- max(1, floor(current_resolution / target_resolution)) # round down to ensure disagg factor is not too large # disaggregate the raster if(inherits(ofile,&quot;character&quot;)){ disaggregated_raster &lt;- terra::disagg(raster_object, fact = fact, filename = ofile, overwrite = TRUE) }else{ disaggregated_raster &lt;- terra::disagg(raster_object, fact = fact) } result_raster &lt;- disaggregated_raster }else if(target_resolution == current_resolution){ return(raster_object) } else { stop(&quot;this resolution is unresovable D: &quot;) } # check if the resulting resolution is exactly the target resolution if (abs(terra::res(result_raster)[1] - target_resolution) &gt; 0.0001) { # Using a small tolerance for comparison message(&quot;the initial aggregation/disaggregation did not result in the exact target resolution. resampling to achieve the precise target resolution.&quot;) # create a dummy raster with the desired resolution and extent for resampling template_raster &lt;- terra::rast(result_raster) terra::res(template_raster) &lt;- target_resolution # resample the result_raster to the exact target resolution if(inherits(ofile,&quot;character&quot;)){ result_raster &lt;- terra::resample(result_raster, template_raster, method = resample_method, filename = tempfile(fileext = &quot;.tif&quot;), overwrite = TRUE) terra::writeRaster(result_raster, filename = ofile, overwrite=T) }else{ result_raster &lt;- terra::resample(result_raster, template_raster, method = resample_method) } } return(result_raster) } ############################################################### # crop/mask RGB raster ############################################################### rgb_fnm_temp &lt;- &quot;../data/BHEF_202306/bhef_rgb_small.tif&quot; if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- bhef_rgb_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size bhef_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... bhef_rgb_rast &lt;- change_res_fn(bhef_rgb_rast, my_res=0.08, ofile = rgb_fnm_temp) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } # terra::res(bhef_rgb_rast) # terra::plotRGB(bhef_rgb_rast, stretch=&quot;lin&quot;) # terra::plot( # bhef_stand_boundary %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(bhef_rgb_rast)) # , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 # ) # terra::plot( # bhef_slash_piles_polys %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(bhef_rgb_rast)) # , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 # ) # terra::inMemory(bhef_rgb_rast) ############################################################### # crop/mask CHM raster ############################################################### chm_fnm_temp &lt;- &quot;../data/BHEF_202306/bhef_chm_small.tif&quot; if(!file.exists(chm_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_chm_rast_temp &lt;- cloud2raster_ans$chm_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size chm_rast_stand &lt;- terra::mask( crop_chm_rast_temp , bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # aggregate chm_rast_stand &lt;- adjust_raster_resolution(chm_rast_stand, target_resolution = 0.15, ofile = chm_fnm_temp) }else{ chm_rast_stand &lt;- terra::rast(chm_fnm_temp) } # put raster in memory # chm_rast_stand &lt;- chm_rast_stand*1 # terra::inMemory(chm_rast_stand) # # huh? # chm_rast_stand %&gt;% # terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) %&gt;% # terra::plot(col = viridis::plasma(100), axes = F) # terra::plot( # bhef_stand_boundary %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 # ) # terra::plot( # bhef_slash_piles_polys %&gt;% # terra::vect() %&gt;% # terra::project(terra::crs(cloud2raster_ans$chm_rast)) # , add = T, border = &quot;blue&quot;, col = NA, lwd = 1.2 # ) 11.3 Pile Detection: Data Fusion since we have both structural and spectral data, we’ll start by using the data fusion approach and do a full walk-through of our detection results 11.3.1 Structural Candidate Segments we’ll start by detecting candidate slash piles based on the structural CHM data alone with our slash_pile_detect_watershed() function we defined in this earlier section. the treatment prescription for the unit of interest called for… insert prescription description To apply the detection methodology to the massive machine pile site, we first set the four primary structural parameters (min_ht_m, max_ht_m, min_area_m2, and max_area_m2) based on expectations derived from the specific treatment prescription and its implementation on the ground. These parameters, along with the two shape filters, are used to define the expected pile geometric form. Onsite observations indicated that these piles are uniformly massive, leading us to rely on strict size and scale filters to exclude smaller non-pile objects like shrubs and boulders. To establish these thresholds, we utilized familiar objects as anchors for contextualizing scale: a standard US parking spot is approximately 16.7 square meters, with maneuvering space increasing the footprint up to 26.7 square meters; common human heights range from approximately 1.61 m (average adult female) to 1.75 m (average adult male). The geometric filters are critical for distinguishing man-made piles from naturally irregular canopy clumps, especially given the observed variability in pile perimeter (from circular to rectangular). Because we do not expect machine piles to adhere to a circular shape, we disregard the circularity check entirely by setting the circle_fit_iou_pct to zero (‘0’) and instead rely on the convexity_pct filter to identify regular-shaped segments that would be consistent with a man-made objects. The convexity_pct filter ensures the smoothness of the segment’s boundary by removing objects that are too irregularly shaped with many inward angles and also ensures that the candidate segment does not have internal holes (i.e., is not shaped like a doughnut), which would typically indicate that the object’s top has been removed by the CHM height thresholding (or “slice”). The specific structural and geometric settings used are: Height and Area Filters (Scale-based): max_ht_m = 4.0 (more than twice the height of an average adult male) min_ht_m = 1.5 (almost the average adult female height) min_area_m2 = 54 (two large parking spaces) max_area_m2 = 432 (16 large parking spaces) Geometric Filters (Shape-based): circle_fit_iou_pct = 0 (disregards circularity, round piles are not expected) convexity_pct = 0.14 (filters out highly irregular segments, set to the training-optimization value for the given CHM resolution) As noted above, we will also use a slightly coarser CHM resolution than we used for the training data and Pinyon-Juniper validation site. Given the expected massive size of these piles, we utilize a slightly coarser CHM resolution, aggregating the raster to 0.15m. This is sufficient detail for identification and quantification of large objects, and our previous analysis of the training data indicated that this 0.15m resolution provided similarly high detection and form quantification accuracies as the finer 0.1m CHM. Finally, recognizing the prolific tree regeneration in this ecosystem, which can result in large, dense, and continuous tree clumps, we will rely on spectral filtering to help discriminate between genuine large piles and aggregated vegetation that might otherwise appear as a singular object in the CHM. To achieve this, the spectral_weight parameter will be set to its maximum setting of ‘5’ (which applies all of the five spectral thresholds) based on the expectation of incorrect detection of clumped small trees using the structural data. slash_pile_detect_watershed() that CHM outdir_temp &lt;- &quot;../data/BHEF_202306/&quot; fnm_temp &lt;- file.path(outdir_temp,&quot;bhef_structural_candidate_segments.gpkg&quot;) if(!file.exists(fnm_temp)){ set.seed(22) # we&#39;ll process each stand separately and bring the segments together slash_pile_detect_watershed_ans &lt;- 1:nrow(bhef_stand_boundary) %&gt;% rev() %&gt;% purrr::map( function(x){ # crop to boundary chm_temp &lt;- chm_rast_stand %&gt;% terra::crop( bhef_stand_boundary %&gt;% dplyr::slice(x) %&gt;% sf::st_buffer(5) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( bhef_stand_boundary %&gt;% dplyr::slice(x) %&gt;% sf::st_buffer(5) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) # get in my memory chm_temp &lt;- chm_temp*1 # slash_pile_detect_watershed ans_temp &lt;- slash_pile_detect_watershed( chm_rast = chm_temp #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = 4 # set the max expected pile height , min_ht_m = 1.5 # set the min expected pile height , min_area_m2 = (27*2) # 66 # set the min expected pile area , max_area_m2 = (27*16) # 444 # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.14 # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = 0 #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) return(ans_temp) } ) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate(pred_id = dplyr::row_number()) # save slash_pile_detect_watershed_ans %&gt;% sf::st_write(fnm_temp, append = F) }else{ slash_pile_detect_watershed_ans &lt;- sf::st_read(fnm_temp, quiet=T) } # what did we get? slash_pile_detect_watershed_ans %&gt;% dplyr::glimpse() ## Rows: 303 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,… ## $ area_m2 &lt;dbl&gt; 357.1650, 373.4325, 186.5025, 347.5013, 375.1312, 185.… ## $ volume_m3 &lt;dbl&gt; 1082.1780, 986.4124, 404.8439, 1050.6005, 974.9271, 41… ## $ max_height_m &lt;dbl&gt; 3.999975, 3.999148, 3.991482, 3.999136, 4.000000, 3.99… ## $ volume_per_area &lt;dbl&gt; 3.0299105, 2.6414743, 2.1707159, 3.0233000, 2.5988961,… ## $ pct_chull &lt;dbl&gt; 0.4918105, 0.6169187, 0.6529135, 0.3911425, 0.5213375,… ## $ diameter_m &lt;dbl&gt; 32.60111, 26.64137, 19.20234, 26.96831, 28.31148, 22.6… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((608427.5 4888468,..., POLYGON ((6086… 11.3.2 Accuracy of these structural settings let’s quickly look at the accuracy of the pile detection if we were to only use the structural data to identify piles with these specific settings. note, that if we only had structural data, we would be much more restrictive in setting the pile detection parameters as we’ll demonstrate below. we aren’t going to fully discuss this accuracy assessment, it is presented only for the curious # add filter for those in stand # pred struct_temp &lt;- slash_pile_detect_watershed_ans %&gt;% dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_intersection( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(slash_pile_detect_watershed_ans)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) # ground truth and prediction matching process gt_pred_match_temp &lt;- ground_truth_prediction_match( ground_truth = bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(struct_temp)) , gt_id = &quot;pile_id&quot; , predictions = struct_temp %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles gt_pred_match_temp &lt;- gt_pred_match_temp %&gt;% # add area of gt dplyr::left_join( bhef_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m ) %&gt;% dplyr::rename( gt_diameter_m = image_gt_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( struct_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas diff_image_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_image_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # huh? agg_ground_truth_match(ground_truth_prediction_match_ans = gt_pred_match_temp) %&gt;% kbl_agg_gt_match(caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;structural only prior to data fusion&quot;) Table 11.1: pile detection and form quantification accuracy metricsstructural only prior to data fusion . value Detection Count TP 22 FN 4 FP 281 Detection F-score 13% Recall 85% Precision 7% Area m2 ME -17.98 RMSE 49.4 MAPE 9% Diameter m (image) ME -1.52 RMSE 4.0 MAPE 7% 11.3.3 Spectral Filtering of Candidate Segments Now we’ll filter the structurally-detected candidate slash piles using the RGB spectral data with the polygon_spectral_filtering() function we defined in this earlier section The spectral filtering approach is a data fusion method used to filter candidate slash pile detections first identified using structural data alone. After initial candidates are identified based on structural data, this method applies a set of five spectral index thresholds to the candidate segments. The spectral_weight parameter is an integer from 1 to 5 that directly controls the number of thresholds that are applied. For example, a value of “3” means a candidate pile must pass at least three of the five thresholds to be retained. This process helps to filter out objects like shrubs, lower tree branches, or boulders that may have been structurally misidentified as piles. Given that the BHEF ponderosa pine validation site has a high likelihood of structural false positives from clumps of small tree regeneration, we set this parameter to its highest level (‘5’) to require all available spectral criteria to be met for retention in a attempt to maximize the removal of vegetation candidate segments. final_predicted_slash_piles &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_watershed_ans , rgb_rast = bhef_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = 5 ) what did we get? # huh? final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 27 ## Columns: 23 ## $ pred_id &lt;int&gt; 12, 14, 184, 205, 206, 207, 213, 214, 219, 220, 221, … ## $ area_m2 &lt;dbl&gt; 243.06750, 412.02000, 83.17125, 85.57875, 129.21750, … ## $ volume_m3 &lt;dbl&gt; 190.17413, 459.41608, 51.64908, 80.33105, 163.93064, … ## $ max_height_m &lt;dbl&gt; 2.279373, 3.280074, 3.951835, 3.233303, 3.229062, 3.1… ## $ volume_per_area &lt;dbl&gt; 0.7823923, 1.1150334, 0.6209969, 0.9386799, 1.2686412… ## $ pct_chull &lt;dbl&gt; 0.7291493, 0.7536588, 0.7212228, 0.6465098, 0.7912241… ## $ diameter_m &lt;dbl&gt; 25.53571, 34.47162, 15.40917, 14.71224, 15.59207, 21.… ## $ rast_agg_grvi &lt;dbl&gt; -0.000884844, -0.016909355, -0.003707689, 0.015903159… ## $ rast_agg_rgri &lt;dbl&gt; 1.0017713, 1.0344004, 1.0074430, 0.9686916, 1.0625240… ## $ rast_agg_vdvi &lt;dbl&gt; -0.0123371137, -0.0278193671, 0.0146187926, 0.0118513… ## $ rast_agg_rgbvi &lt;dbl&gt; -0.023686998, -0.054847319, 0.030401412, 0.024209474,… ## $ rast_agg_exg &lt;dbl&gt; -0.016382098, -0.036751658, 0.019587159, 0.015864551,… ## $ rast_agg_exr &lt;dbl&gt; 0.1316969, 0.1437417, 0.1398499, 0.1200436, 0.1580908… ## $ rast_agg_exgr &lt;dbl&gt; -0.1493897, -0.1811858, -0.1194634, -0.1097121, -0.18… ## $ rast_agg_bi &lt;dbl&gt; 0.3627696, 0.4615124, 0.5071353, 0.3606289, 0.3293038… ## $ rast_agg_sat &lt;dbl&gt; 0.07652807, 0.08524459, 0.10809455, 0.10115670, 0.093… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((609317.3 4888606,..., POLYGON ((609… ## $ inrange_th_exgr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_rgri &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_vdvi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_bi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_sat &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_votes &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,… # final_predicted_slash_piles %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::count(inrange_th_votes) how many piles were removed? # how many piles were removed? nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles) ## [1] 276 # what proportion were removed? scales::percent( (nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles))/nrow(slash_pile_detect_watershed_ans) , accuracy=0.1 ) ## [1] &quot;91.1%&quot; This result contrasts sharply with the Pinyon-Juniper site where the spectral filter removed 0% of candidate piles. The 91.1% removal rate at the BHEF ponderosa pine validation site indicates that the strict spectral_weight setting of ‘5’, which was chosen specifically to combat the high risk of False Positives (FPs) from dense clumps of small tree regeneration, was highly effective at identifying and rejecting vegetation based on its spectral signature. This disparity between the spectral data inclusion performance suggests that the green vegetation in the BHEF ponderosa pine validation site environment had a sufficiently distinct spectral signature from the pile material, unlike the senescent or arid vegetation at the Pinyon-Juniper site that mimicked dead wood. 11.3.4 Detection and Quantification Accuracy let’s see how we did given the list of predictions compared to the ground truth data using the confusion matrix matching process we outlined in this earlier section. we’ll filter both ground truth and predicted piles to keep only those that actually intersect with the study unit boundary for comparison # add filter # pred final_predicted_slash_piles &lt;- final_predicted_slash_piles %&gt;% dplyr::left_join( final_predicted_slash_piles %&gt;% sf::st_intersection( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) 11.3.4.1 Instance matching now apply the instance matching process we outlined in this earlier section to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions) # ground truth and prediction matching process ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # add area of gt dplyr::left_join( bhef_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m ) %&gt;% dplyr::rename( gt_diameter_m = image_gt_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # image diameter diff_image_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_image_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # huh? ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 31 ## Columns: 16 ## $ pile_id &lt;dbl&gt; 16, 8, 20, 17, 23, 26, 11, 9, 18, 25, 12, 21… ## $ i_area &lt;dbl&gt; 157.52972, 374.58214, 279.73937, 228.63537, … ## $ u_area &lt;dbl&gt; 387.05356, 446.11688, 333.30108, 285.22402, … ## $ iou &lt;dbl&gt; 0.4069972, 0.8396502, 0.8392993, 0.8015993, … ## $ pred_id &lt;int&gt; 299, 14, 296, 297, 300, 292, 12, 214, 286, 2… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive,… ## $ gt_area_m2 &lt;dbl&gt; 378.00453, 408.67902, 323.15045, 269.47564, … ## $ gt_diameter_m &lt;dbl&gt; 37.95325, 34.78950, 27.83942, 27.58500, 25.9… ## $ pred_area_m2 &lt;dbl&gt; 166.57875, 412.02000, 289.89000, 244.38375, … ## $ pred_volume_m3 &lt;dbl&gt; 146.45512, 459.41608, 354.32158, 267.35027, … ## $ pred_height_m &lt;dbl&gt; 2.390827, 3.280074, 2.989531, 2.818481, 2.34… ## $ pred_diameter_m &lt;dbl&gt; 20.81598, 34.47162, 26.88182, 26.76649, 25.7… ## $ diff_image_diameter_m &lt;dbl&gt; -17.13726617, -0.31788093, -0.95759390, -0.8… ## $ pct_diff_image_diameter_m &lt;dbl&gt; 0.451536249, 0.009137266, 0.034397051, 0.029… ## $ diff_area_m2 &lt;dbl&gt; -211.4257811, 3.3409830, -33.2604520, -25.09… ## $ pct_diff_area_m2 &lt;dbl&gt; 0.559320759, -0.008175078, 0.102925593, 0.09… that’s a lot of great detail at the individual pile instance level for us to dig into. before we do that, let’s aggregate the instances to see how we did at the stand level overall 11.3.4.2 Overall (stand level) Now we’ll aggregate the instance matching results to calculate overall performance assessment metrics. Here, we take the counts of True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions), to determine overall accuracy. This aggregation will give us two types of results: detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified agg_ground_truth_match_ans &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans = ground_truth_prediction_match_ans) let’s table the most relevant metrics agg_ground_truth_match_ans %&gt;% kbl_agg_gt_match( caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;data fusion BHEF ponderosa pine validation site&quot; ) Table 11.2: pile detection and form quantification accuracy metricsdata fusion BHEF ponderosa pine validation site . value Detection Count TP 22 FN 4 FP 5 Detection F-score 83% Recall 85% Precision 81% Area m2 ME -17.98 RMSE 49.4 MAPE 9% Diameter m (image) ME -1.52 RMSE 4.0 MAPE 7% # save the table for full comparison at the very end # save the table for full comparison at the very end sf::st_read(dsn = all_agg_ground_truth_match_ans_fp, quiet = T) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::filter( site != &quot;BHEF ponderosa pine validation site&quot; ) %&gt;% dplyr::bind_rows( all_agg_ground_truth_sf_format( stand_boundary = bhef_stand_boundary , site = &quot;BHEF ponderosa pine validation site&quot; ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::bind_cols( agg_ground_truth_match_ans # join on aggregated form quantifications that we have for all , ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::rename(image_gt_diameter_m = gt_diameter_m) %&gt;% dplyr::summarise( dplyr::across( c(image_gt_diameter_m, pred_diameter_m, gt_area_m2, pred_area_m2, pred_volume_m3, pred_height_m) , ~ sum(.x, na.rm = TRUE) ) ) ) ) %&gt;% # dplyr::glimpse() # readr::write_csv(file = all_agg_ground_truth_match_ans_fp, append = F, progress = F) sf::st_write(dsn = all_agg_ground_truth_match_ans_fp, append = F, quiet = T) The detection performance at the BHEF ponderosa pine validation site, using the data fusion approach, demonstrates strong generalizability of our method despite the novel pile structure and site conditions. With only 26 actual piles in the validation area, each False Positive (FP) or False Negative (FN) prediction exerted a significant influence on the overall accuracy metrics. The 84.6% recall rate means the method successfully identified approximately 8 out of every 10 actual piles, indicating the structural and spectral filters were effective at retaining most true piles. A strong precision rate of 81.5% confirms the methodology did well at excluding spurious False Positive predictions, successfully distinguishing genuine piles from non-pile objects like dense small tree regeneration clumps. The combined accuracy, quantified by an F-score of 83.0%, is a desirable result that further indicates the methodology is transferable across varied treatments, prescriptions, and pile constructions over highly varied landscapes. Statistical testing on the original ponderosa pine training data predicted an F-score range of 79.7% to 82.3% when using 0.15m CHM data as input, demonstrating that the achieved 83.0% accuracy is aligned with the method’s predicted performance limits even when applied to a fundamentally different treatment site with novel pile construction and challenging vegetation response. 11.3.4.3 Instance level (pile level) let’s look at the pile-level data directly to evaluate the true positive detections, omissions (false negatives), and commissions (false positives) let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.4070 ## 1st Qu.:0.7985 ## Median :0.8406 ## Mean :0.8256 ## 3rd Qu.:0.9006 ## Max. :0.9211 for the majority (i.e. &gt;95%) of matches, the IoU was above 71.0% here is the distribution of IoU for those matches ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = iou, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.8) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::scale_x_continuous(labels=scales::percent) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;IoU of correct precitions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) is there a difference between the image-annotated pile sizes of the true positive detections and the omissions (false negative)? let’s compare the image-annotated area and diameter for omissions and true positives since those measurements exist for both sets ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;commission&quot;) %&gt;% dplyr::select(pile_id,match_grp,gt_diameter_m,gt_area_m2) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_diameter_m&quot;,&quot;gt_area_m2&quot;) , labels = c( &quot;image annotated diameter (m)&quot; , &quot;image annotated area (m2)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot; , subtitle = &quot;ground truth form measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) wow! note that we did not inspect the image-annotated ground truth measurement data prior to implementing our remote-sensing based pile detection methodology. we purposefully did not look at this data until after making the predictions because we wanted to set up our remote sensing pile detection method without as if we did not measure a single pile in the field so as to not bias our implementation of the method. to implement this remote sensing method slash pile detection framework in practice, we would likely not have any field-measured data on pile structure and if we did it would only be for a very small sample of piles. remember, the entire objective of creating this method is so that time in the field can be minimized to the time needed to visually assess the treatment implementation to acquire quick observational anecdotes and potentially measure some sample piles and then fly a UAS data collection mission to get the data needed to implement this method. compare that minimal time to the traditional, field-based method of slash pile identification and measurement which is much more costly in terms of time and personnel needed. there are so few omissions (i.e. FPs) for this validation data set that it’s difficult to make any inference from this comparison let’s now look at the summary stats of ground truth piles kbl_form_sum_stats( bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) , caption = &quot;Ground Truth Piles: summary statistics for form measurements&lt;br&gt;BHEF ponderosa pine validation site&quot; ) Table 11.3: Ground Truth Piles: summary statistics for form measurementsBHEF ponderosa pine validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 26 Diameter m (image) 21.0 6.5 14.3 20.8 27.7 13.3—38.0 Area m2 (image) 199.9 85.8 106.7 200.3 296.3 76.0—408.7 and let’s look at the summary stats of the predicted piles kbl_form_sum_stats( final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , caption = &quot;Predicted Piles: summary statistics for form measurements&lt;br&gt;BHEF ponderosa pine validation site&quot; ) Table 11.4: Predicted Piles: summary statistics for form measurementsBHEF ponderosa pine validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 27 Height m 2.7 0.5 2.1 2.7 3.3 1.9—4.0 Diameter m 20.0 5.4 14.2 20.0 26.4 12.6—34.5 Area m2 178.1 76.8 89.4 164.8 265.7 73.8—412.0 Volume m3 187.6 104.5 79.3 157.2 359.6 51.6—459.4 let’s look at some examples on our RGB image true positive matches (correct predictions) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;true positive&quot;)) %&gt;% sample( min(20,agg_ground_truth_match_ans$tp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=bhef_rgb_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/BHEF_202306/bhef_truepositives.jpg&quot;, height = 11, width = 8.5) oh snap! there’s a pile with a vehicle next to it to provide context on the size of these massive piles. let’s plot that with details on it’s form measurements #plt ortho_plt_fn( my_ortho_rast=bhef_rgb_rast , stand= bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==8) %&gt;% sf::st_union() , buffer=9 ) + ggplot2::geom_sf(data = bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==8), fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs( subtitle = paste0( # &quot;pile ID: &quot;,8 &quot;area: &quot;, bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==8) %&gt;% dplyr::pull(image_gt_area_m2) %&gt;% scales::comma(accuracy = 0.1,suffix = &quot; m2&quot;) , &quot;\\n diameter: &quot;, bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==8) %&gt;% dplyr::pull(image_gt_diameter_m) %&gt;% scales::comma(accuracy = 0.1,suffix = &quot; m&quot;) ) ) + ggplot2::theme(plot.subtitle = ggplot2::element_text(size = 10)) that thing is massive… omissions (false negatives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% # sample( min(16,agg_ground_truth_match_ans$fn_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=bhef_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs(subtitle = paste0(&quot;pile ID: &quot;,dta$pile_id)) }) # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/BHEF_202306/bhef_omission.jpg&quot;, height = 6, width = 8.5) let’s add the CHM to that plot to see if it helps shed light on why these were missed # plot RGB + CHM plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- bhef_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=bhef_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast_stand %&gt;% terra::crop( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does # terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs( subtitle = paste0( &quot;pile ID: &quot;, dta$pile_id , &quot;\\nGT area: &quot;, round(dta$gt_area_m2,1) # , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) # , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/BHEF_202306/bhef_omission_chm.jpg&quot;, height = 6.6, width = 8.5) The review of the image-annotated footprints for all False Negative (FN) piles confirmed that none were filtered out based on area thresholds, as their footprints fell within the defined search range. The omissions stemmed from either incomplete data capture or issues within the segmentation and filtering pipeline.Two of the missed piles show incomplete CHM data within their footprints. This lack of data can be attributed to three potential causes: insufficient SfM point cloud density; the Cloth Simulation Filter (CSF), used to derive the Digital Terrain Model (DTM), incorrectly classified the pile area as ground; or the piles were constructed in a sprawling manner with limited vertical aggregation, meaning the resulting low CHM height values failed to meet the required minimum height thresholds (min_ht_m). The remaining missed piles, which had full CHM coverage, visually displayed more than one distinct vertical peak. The CHM-based watershed segmentation approach may have interpreted these multiple peaks as separate, unique objects and split the actual single large pile into multiple candidate segments. Our structural detection methodology includes a smoothing option (smooth_segs) which we used for this validation data (set to TRUE). This smoothing option includes a step designed for shape refinement and overlap removal. Activating this parameter initiates a sequence: candidate segments that pass all size and shape checks first are combined if their perimeters touch but do not overlap. The combined shape is then smoothed using its convex hull to remove the “blocky” raster edges. Lastly, overlapping convex hull shapes are removed to prevent false positives from clustered small trees or shrubs. Given the distinct peaks in these FN piles, it is highly likely they were initially split by the watershed segmentation, and then one or more of the resulting smaller segments failed to meet the required size or shape thresholds. Because a significant area of the pile was removed in this filtering step, the remaining segments even if successfully combined were deemed insufficient in overall size (min_area_m2) to be retained in the final structural detection output. now, let’s check out the predicted sizes of the commissions (false positives) compared to the predicted sizes of the predicted piles that were correctly matched with the ground truth data let’s compare the predicted height, diameter, area for commissions and true positives since those measurements exist for both sets ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_diameter_m,pred_area_m2,pred_height_m) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;,&quot;pred_height_m&quot;) , labels = c( &quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; , &quot;predicted height (m)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs(color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) this is interesting let’s table the predicted form measurements ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_diameter_m,pred_area_m2,pred_height_m) %&gt;% dplyr::group_by(match_grp) %&gt;% dplyr::summarise( dplyr::across( c(pred_diameter_m,pred_area_m2,pred_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c( match_grp,n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) ) %&gt;% dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange( match_grp, desc(n)) %&gt;% dplyr::select(-c(n,min,max)) %&gt;% dplyr::relocate(match_grp) %&gt;% dplyr::mutate( metric = factor( metric , ordered = T , levels = c(&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;,&quot;pred_height_m&quot;) , labels = c( &quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; , &quot;predicted height (m)&quot; ) ) ) %&gt;% kableExtra::kbl( caption = &quot;Predicted Piles: summary statistics for form measurements&quot; , col.names = c( &quot;segmentation&lt;br&gt;classification&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 11.5: Predicted Piles: summary statistics for form measurements segmentationclassification Metric Mean Std Dev q 10% Median q 90% Range commission predicted diameter (m) 18.5 5.0 15.0 15.4 24.1 14.7—26.2 predicted area (m2) 125.3 45.9 84.1 110.4 175.5 83.2—182.6 predicted height (m) 3.2 0.5 2.7 3.2 3.7 2.5—4.0 true positive predicted diameter (m) 20.3 5.5 14.2 20.2 26.7 12.6—34.5 predicted area (m2) 190.1 78.0 114.7 177.6 267.8 73.8—412.0 predicted height (m) 2.6 0.5 2.1 2.5 3.2 1.9—3.7 let’s look at some examples on our RGB image commissions (false positives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=bhef_rgb_rast, stand=sf::st_union(pr), buffer=6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 3 ) ggplot2::ggsave(&quot;../data/BHEF_202306/bhef_commission.jpg&quot;, height = 6, width = 8.5) what even is that? let’s add the CHM to that plot to see if it helps shed light on why these were incorrectly included in the predictions # plot RGB + CHM plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=bhef_rgb_rast, stand=sf::st_union(pr), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast_stand %&gt;% terra::crop( sf::st_union(pr) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(pr) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does # terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.7) + ggplot2::labs( subtitle = paste0( &quot;pred ID: &quot;, dta$pred_id , &quot;\\nPred area: &quot;, round(dta$pred_area_m2,1) # , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nPred dia: &quot;, round(dta$pred_diameter_m,1) # , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 3 ) ggplot2::ggsave(&quot;../data/BHEF_202306/bhef_commission_chm.jpg&quot;, height = 6.6, width = 8.5) these are clearly erroneous CHM values which look like they may be at the edge of the stand unit which suggests errors at the edges of the SfM generated point cloud which flowed through to the CHM # Start with the RGB plot as the base layer terra::plotRGB(bhef_rgb_rast, stretch = &quot;lin&quot;, axes = F) # overlay the chm terra::plot(chm_rast_stand, col = viridis::plasma(100), axes = F, alpha=0.5, add=TRUE, legend=TRUE) # add the erroneous pile outline as the final layer terra::plot( final_predicted_slash_piles %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp %in% c(&quot;commission&quot;)) %&gt;% dplyr::select(pred_id) ) %&gt;% sf::st_transform(terra::crs(bhef_rgb_rast)) %&gt;% terra::vect() , col=NA, border=&quot;yellow&quot;, lwd=3, add=TRUE ) that CHM has so many edge effects or cloud interference :/ it is likely that none of these would have been included if not for this bad data 11.3.5 Stand-level Aggregation before we leave, let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory) sum_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(pred_id)) %&gt;% dplyr::summarise( dplyr::across( .cols = tidyselect::starts_with(&quot;gt_&quot;) | tidyselect::starts_with(&quot;pred_&quot;) , ~sum(.x,na.rm=T) ) ) %&gt;% tidyr::pivot_longer( cols = dplyr::everything() , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% ### !!!! we don&#39;t have height for this data dplyr::filter( !stringr::str_detect(metric, &quot;height&quot;) &amp; !stringr::str_detect(metric, &quot;volume&quot;) ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground truth&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; , &quot;Volume (m3)&quot; , &quot;Volume paraboloid&quot; ) ) ) %&gt;% dplyr::group_by(pile_metric) %&gt;% dplyr::arrange(pile_metric,which_data) %&gt;% dplyr::mutate( pct_diff = (value-dplyr::lag(value))/dplyr::lag(value) ) %&gt;% dplyr::ungroup() plot # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric), scales = &quot;free_y&quot;, axes = &quot;all_x&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated measurements at the stand level&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table it sum_df_temp %&gt;% dplyr::select(pile_metric, which_data, value, pct_diff) %&gt;% dplyr::mutate( value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated measurements at the stand level&quot; , col.names = c( &quot;.&quot;, &quot;measurement source&quot; , &quot;stand-level total&quot;, &quot;% difference&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 11.6: Comparison of aggregated measurements at the stand level . measurement source stand-level total % difference Diameter (m) ground truth 545.7 NA prediction 539.3 -1.2% Area (m2) ground truth 5,198.6 NA prediction 4,808.9 -7.5% "],["method-validation-arnf-machine-piles.html", "Section 12 Method Validation: ARNF Machine Piles 12.1 Site Introduction 12.2 Data Processing 12.3 Pile Detection: Data Fusion", " Section 12 Method Validation: ARNF Machine Piles 12.1 Site Introduction Here, we’ll be working with another ponderosa pine evaluation site, this one on the Arapahoe-Roosevelt National Forest (ARNF) which serves as an important validation site for testing the influence of pile geometry and local ecology on detection. The ARNF site features massive machine piles that are notably more circular and geometrically regular than the highly irregular piles at the BHEF site. This high regularity differentiates it from the BHEF’s structural complexity, while the massive, mechanically built nature distinguishes it from the circular, but small hand piles at the Pinyon-Juniper site. The ARNF is in a drier climate than BHEF, and the treatment was more recent (one year prior), meaning less tree regeneration is expected. This unique combination of massive size, simple geometry, and low regeneration allows us to isolate the methodology’s performance against large, regularly-shaped targets and further validate the generalizability of the detection method across a wide spectrum of pile size, shape, and setting amongst different terrain and vegetation which has different spectral characteristics. Given these favorable geometric and ecological conditions, parameter adjustments for the ARNF site will leverage the high minimum size filters (e.g., min_ht_m and min_area_m2) to focus on the expected large pile size, but will employ tighter geometric filters (e.g., circle_fit_iou_pct) than those used for the BHEF site to capitalize on the more regular, circular pile shapes. The reduced expected regeneration means the spectral filter may not need to be as strictly applied as at the BHEF site. As with the other validation sites, image-annotated pile footprints will be used as ground truth data to calculate performance metrics (e.g., F-score and MAPE) to determine how well the methodology performs under these specific conditions. insert prescription detail 12.2 Data Processing 12.2.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data las_dir_temp &lt;- &quot;F:/UAS_Collections/ARNF_DiamondView_202510/point_cloud_high_density&quot; # where is the raw las c2t_output_dir &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; # where do you want to save processed data to? if(!dir.exists(c2t_output_dir)){dir.create(c2t_output_dir, showWarnings = F)} # output dir dir_temp &lt;- file.path(c2t_output_dir, &quot;point_cloud_processing_delivery&quot;) # check out the point cloud data really quick # list.files(normalizePath(las_dir_temp), pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = TRUE, recursive = T) # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 455073.8, 456582.3, 4535127, 4536067 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1.24 km² ## points : 1.37 billion points ## type : airborne ## density : 1102.8 points/m² ## density : 39.9 pulses/m² ## num. files : 44 # do it if(!dir.exists(dir_temp)){ # ctg_temp &lt;- lidR::readLAScatalog(las_flist_temp) # ctg_temp@data %&gt;% dplyr::glimpse() # remove(ctg_temp) # gc() # cloud2trees cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_output_dir , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = F , dtm_res_m = 0.2 , chm_res_m = 0.1 , min_height = 0 # effectively generates a DSM based on non-ground points ) # cloud2raster_ans$chm_rast # pc_ext_temp &lt;- sf::st_read(file.path(c2t_output_dir,&quot;point_cloud_processing_delivery&quot;,&quot;raw_las_ctg_info.gpkg&quot;)) }else{ dtm_temp &lt;- terra::rast( file.path(dir_temp, &quot;dtm_0.2m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(dir_temp, paste0(&quot;chm_&quot;, 0.1,&quot;m.tif&quot;)) ) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } # huh? cloud2raster_ans ## $dtm_rast ## class : SpatRaster ## size : 4704, 7544, 1 (nrow, ncol, nlyr) ## resolution : 0.2, 0.2 (x, y) ## extent : 455073.6, 456582.4, 4535127, 4536068 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source : dtm_0.2m.tif ## name : 1_dtm_0.2m ## min value : 2385.600 ## max value : 2501.163 ## ## $chm_rast ## class : SpatRaster ## size : 9406, 15085, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 455073.8, 456582.3, 4535127, 4536067 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source : chm_0.1m.tif ## name : focal_mean ## min value : 0.000 ## max value : 27.899 12.2.2 Vector Data cloud2trees::cloud2raster() wrote out a file with the spatial coverage of the point cloud data, let’s read that in. # pc extent pc_ext_temp &lt;- sf::st_read(file.path(c2t_output_dir,&quot;point_cloud_processing_delivery&quot;,&quot;raw_las_ctg_info.gpkg&quot;), quiet=T) %&gt;% sf::st_union() %&gt;% # inward buffer to remove edge effects sf::st_buffer(-10) # mapview::mapview(pc_ext_temp) what is the area of the point cloud extent we are looking over? sf::st_area(pc_ext_temp) %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.01) ## [1] &quot;97.15 ha&quot; read in the treatment unit boundaries ############################################################### # read unit boundary ############################################################### arnf_stand_boundary &lt;- sf::st_read(&quot;../data/ARNF_DiamondView_202510/Diamond_View_Boundary.gpkg&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) %&gt;% sf::st_union() # we have a single unit boundary what is the area of the treatment unit boundaries we are looking over? arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% `/`(10000) %&gt;% scales::comma(suffix = &quot; ha&quot;, accuracy = 0.1) ## [1] &quot;73.6 ha&quot; that’s great The perimeter of each pile was digitized in a Geographic Information System (GIS) overlaid on a 0.04 m RGB orthomosaic. In this digitization process, the perimeter was based on the main footprint of the pile at ground level, excluding isolated logs or debris extending beyond the primary boundary. These ground truth polygons will be compared to the predicted pile boundaries using the intersection over union (IoU) metric, with a minimum threshold required for a true positive match. load in the pile boundary polygons. # read in polys arnf_slash_piles_polys &lt;- sf::st_read(&quot;../data/ARNF_DiamondView_202510/arnf_diamond_view_pile_polys.shp&quot;, quiet=T) %&gt;% # sf::st_as_sf() %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) %&gt;% # area st_calculate_diameter() %&gt;% dplyr::rename( image_gt_diameter_m = diameter_m ) %&gt;% sf::st_transform(terra::crs(cloud2raster_ans$chm_rast)) # add a flag for if a pile is in the stand or not based on a spatial intersection arnf_slash_piles_polys &lt;- arnf_slash_piles_polys %&gt;% dplyr::left_join( arnf_slash_piles_polys %&gt;% sf::st_intersection( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(arnf_slash_piles_polys)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pile_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) huh? arnf_slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 19 ## Columns: 7 ## $ shape_leng &lt;dbl&gt; 76.34086, 84.32555, 104.68118, 94.75513, 81.94145,… ## $ shape_area &lt;dbl&gt; 293.7914, 371.0813, 593.1854, 494.0396, 341.3929, … ## $ pile_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,… ## $ image_gt_area_m2 &lt;dbl&gt; 293.5056, 370.7583, 593.0898, 493.8871, 341.3122, … ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((455382.7 4535558,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 22.56549, 24.13478, 31.83121, 29.52870, 24.25567, … ## $ is_in_stand &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… 12.2.3 RGB Data The RGB data is in a single file, so all we need to do is load it and resample ## function to change the resolution of RGB change_res_fn &lt;- function( r , my_res=1 , m = &quot;bilinear&quot; # , ofile = tempfile(fileext = &quot;.tif&quot;) , ofile = NULL ){ r2 &lt;- r terra::res(r2) &lt;- my_res if(!inherits(ofile,&quot;character&quot;)){ r2 &lt;- terra::resample(r, r2, method = m) }else{ r2 &lt;- terra::resample(r, r2, method = m, filename=ofile, overwrite = T) } return(r2) } ############################################################### # read/crop RGB raster ############################################################### rgb_fnm_temp &lt;- &quot;../data/ARNF_DiamondView_202510/arnf_diamond_view_rgb_0.08m.tif&quot; if(!file.exists(rgb_fnm_temp)){ # terra handles large files on disk automatically rgb_rast_temp &lt;- terra::rast(&quot;f:/UAS_Collections/ARNF_DiamondView_202510/DiamondPeak_Switchblade_transparent_mosaic_group1.tif&quot;) # Read the polygon file (e.g., a shapefile) polygon_border_temp &lt;- arnf_stand_boundary %&gt;% sf::st_buffer(50) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(rgb_rast_temp)) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- terra::crop(rgb_rast_temp, polygon_border_temp, filename = tempfile(fileext = &quot;.tif&quot;), overwrite = TRUE) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size arnf_rgb_rast &lt;- terra::mask(crop_rgb_rast_temp, polygon_border_temp, filename = tempfile(fileext = &quot;.tif&quot;), overwrite = TRUE) ## apply the change_res_fn function arnf_rgb_rast &lt;- change_res_fn(arnf_rgb_rast, my_res=0.08, ofile = rgb_fnm_temp) }else{ arnf_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } terra::res(arnf_rgb_rast) ## [1] 0.08 0.08 # terra::plotRGB(arnf_rgb_rast, stretch=&quot;lin&quot;) Given the expected massive size of these piles, we utilize a slightly coarser CHM resolution, aggregating the raster to 0.15m. This is sufficient detail for identification and quantification of large objects, and previous analysis of the training data indicated that this 0.15m resolution provided similarly high detection and form quantification accuracies as the finer 0.1m CHM. we’ll borrow from the cloud2trees codebase to get a function to change the resolution of a raster exactly ############################################################### # crop/mask CHM raster ############################################################### chm_fnm_temp &lt;- &quot;../data/ARNF_DiamondView_202510/arnf_chm_small.tif&quot; if(!file.exists(chm_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_chm_rast_temp &lt;- cloud2raster_ans$chm_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size chm_rast_stand &lt;- terra::mask( crop_chm_rast_temp , arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(cloud2raster_ans$chm_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # aggregate chm_rast_stand &lt;- adjust_raster_resolution(chm_rast_stand, target_resolution = 0.15, ofile = chm_fnm_temp) }else{ chm_rast_stand &lt;- terra::rast(chm_fnm_temp) } now that we have all the data, let’s plot the RGB + CHM really quick terra::plotRGB(arnf_rgb_rast, stretch=&quot;lin&quot;, axes=F) terra::plot(chm_rast_stand, col = viridis::plasma(n=55,alpha = 0.3), add = T, axes=F, legend=F) and let’s map it # option to put satellite imagery as base layer of mapview maps mapview::mapviewOptions( homebutton = FALSE # , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) ) # map it mapview::mapview( arnf_stand_boundary %&gt;% sf::st_union() , color = &quot;black&quot; , lwd = 1 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE , layer.name = &quot;stand boundary&quot; ) + # mapview::mapview(arnf_slash_piles_points, zcol = &quot;height_m&quot;) mapview::mapview(arnf_slash_piles_polys, zcol = &quot;image_gt_area_m2&quot;,layer.name=&quot;machine piles&quot;) 12.3 Pile Detection: Data Fusion since we have both structural and spectral data, we’ll start by using the data fusion approach and do a full walk-through of our detection results after which we’ll circle back to explore results obtained using structural data only. 12.3.1 Structural Candidate Segments we’ll start by detecting candidate slash piles based on the structural CHM data alone with our slash_pile_detect_watershed() function we defined in this earlier section. the treatment prescription for the unit of interest called for… insert prescription description To apply the detection methodology to the massive machine pile site, we first set the four primary structural parameters (min_ht_m, max_ht_m, min_area_m2, and max_area_m2) based on expectations derived from the specific treatment prescription and its implementation on the ground. These parameters, along with the two shape filters, are used to define the expected pile geometric form. Onsite observations indicated that these piles are uniformly massive, leading us to rely on strict size and scale filters to exclude smaller non-pile objects like shrubs and boulders. To establish these thresholds, we utilized familiar objects as anchors for contextualizing scale: a standard US parking spot is approximately 16.7 square meters, with maneuvering space increasing the footprint up to 26.7 square meters. We also took photos of a work truck (a lifted Dodge Ram 2500 Mega Cab turbo diesel) from the ground parked next to the pile to aid us in estimating pile height and area. Google’s AI search mode tells us that a lifted Dodge Ram 2500 Mega Cab turbo diesel typically has an overall height of approximately 2.4 m (8 feet) and the pile we parked next to was at least twice that height. We’ll set our expected height thresholds based on these estimates. The geometric filters are critical for distinguishing man-made piles from naturally irregular canopy clumps, especially given the observed variability in pile perimeter (from circular to rectangular). Because we do expect these ARNF machine piles to be roughly circular in shape, we’ll set the circle_fit_iou_pct and convexity_pct parameter near the recommended settings based on our ponderosa pine training data site and the optimal parameter settings analysis The specific structural and geometric settings used are: Height and Area Filters (Scale-based): max_ht_m = 9.12 (3.8 times the height of our lifted Dodge Ram 2500 Mega Cab turbo diesel) min_ht_m = 2.16 (90% the height of our lifted Dodge Ram 2500 Mega Cab turbo diesel) min_area_m2 = 67.5 (2.5 large parking spaces) max_area_m2 = 594 (22 large parking spaces) Geometric Filters (Shape-based): circle_fit_iou_pct = set to 0.21, which is approximately 25 percentage points lower than the optimal value (0.44-0.48) identified using the training data to reflect the loss in precision when using machines to create large piles versus manually hand piling material convexity_pct = set to 0.08 which is in the the optimal range identified in the Ponderosa Pine training data. As noted above, we will also use a slightly coarser CHM resolution than we used for the training data and Pinyon-Juniper validation site. Given the expected massive size of these piles, we utilize a slightly coarser CHM resolution, aggregating the raster to 0.15m. This is sufficient detail for identification and quantification of large objects, and our previous analysis of the training data indicated that this 0.15m resolution provided similarly high detection and form quantification accuracies as the finer 0.1m CHM. Finally, given the expected reduction in tree regeneration due to the more recent treatment date, the risk of misclassifying clumped small trees is lower than at the BHEF site. Therefore, we will rely on spectral filtering to help discriminate between genuine large piles and aggregated vegetation, setting the spectral_weight parameter to a less restrictive value of ‘4’ (which applies four of the five spectral thresholds) based on the training site’s recommended value and the reduced expectation of high false positive rates from dense tree regeneration. slash_pile_detect_watershed() that CHM outdir_temp &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; fnm_temp &lt;- file.path(outdir_temp,&quot;arnf_structural_candidate_segments.gpkg&quot;) if(!file.exists(fnm_temp)){ set.seed(11) slash_pile_detect_watershed_ans &lt;- slash_pile_detect_watershed( chm_rast = chm_rast_stand #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , max_ht_m = (2.4*3.8) # set the max expected pile height , min_ht_m = (2.4*0.9) # set the min expected pile height , min_area_m2 = (27*2.5) # set the min expected pile area , max_area_m2 = (27*22) # set the max expected pile area #### irregularity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity and later smoothed to remove blocky edges # and most inward angles by applying a convex hull to the original detected segment , convexity_pct = 0.08 # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required IoU between the predicted pile and the best fit circle of the predicted pile , circle_fit_iou_pct = 0.21 #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ) # save slash_pile_detect_watershed_ans %&gt;% sf::st_write(fnm_temp, append = F) }else{ slash_pile_detect_watershed_ans &lt;- sf::st_read(fnm_temp, quiet=T) } # what did we get? slash_pile_detect_watershed_ans %&gt;% dplyr::glimpse() ## Rows: 22 ## Columns: 8 ## $ pred_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,… ## $ area_m2 &lt;dbl&gt; 413.2013, 552.1725, 470.6887, 350.4488, 369.3375, 430.… ## $ volume_m3 &lt;dbl&gt; 1477.3873, 2308.8399, 1605.4099, 1483.9100, 883.8572, … ## $ max_height_m &lt;dbl&gt; 8.417358, 9.116704, 7.826457, 8.310950, 6.352087, 9.11… ## $ volume_per_area &lt;dbl&gt; 3.575467, 4.181374, 3.410768, 4.234314, 2.393088, 4.12… ## $ pct_chull &lt;dbl&gt; 0.7988783, 0.7817122, 0.9076699, 0.7363488, 0.7859275,… ## $ diameter_m &lt;dbl&gt; 27.85480, 29.51038, 27.37243, 25.58281, 24.30787, 25.3… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((455598.7 4535228,..., POLYGON ((4556… 12.3.2 Accuracy of these structural settings let’s quickly look at the accuracy of the pile detection if we were to only use the structural data to identify piles with these specific settings. note, that if we only had structural data, we would be much more restrictive in setting the pile detection parameters as we’ll demonstrate below. we aren’t going to fully discuss this accuracy assessment, it is presented only for the curious # add filter for those in stand # pred struct_temp &lt;- slash_pile_detect_watershed_ans %&gt;% dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_intersection( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(slash_pile_detect_watershed_ans)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) # ground truth and prediction matching process gt_pred_match_temp &lt;- ground_truth_prediction_match( ground_truth = arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(struct_temp)) , gt_id = &quot;pile_id&quot; , predictions = struct_temp %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles gt_pred_match_temp &lt;- gt_pred_match_temp %&gt;% # add area of gt dplyr::left_join( arnf_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m ) %&gt;% dplyr::rename( gt_diameter_m = image_gt_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( struct_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas diff_image_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_image_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # huh? agg_ground_truth_match(ground_truth_prediction_match_ans = gt_pred_match_temp) %&gt;% kbl_agg_gt_match(caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;structural only prior to data fusion&quot;) Table 12.1: pile detection and form quantification accuracy metricsstructural only prior to data fusion . value Detection Count TP 17 FN 2 FP 4 Detection F-score 85% Recall 89% Precision 81% Area m2 ME -56.50 RMSE 84.3 MAPE 15% Diameter m (image) ME -1.72 RMSE 2.4 MAPE 7% 12.3.3 Spectral Filtering of Candidate Segments Now we’ll filter the structurally-detected candidate slash piles using the RGB spectral data with the polygon_spectral_filtering() function we defined in this earlier section The spectral filtering approach is a data fusion method used to filter candidate slash pile detections first identified using structural data alone. After initial candidates are identified based on structural data, this method applies a set of five spectral index thresholds to the candidate segments. The spectral_weight parameter is an integer from 1 to 5 that directly controls the number of thresholds that are applied. For example, a value of “3” means a candidate pile must pass at least three of the five thresholds to be retained. This process helps to filter out objects like shrubs, lower tree branches, or boulders that may have been structurally misidentified as piles. Given that the BHEF ponderosa pine validation site has a high likelihood of structural false positives from clumps of small tree regeneration, we set this parameter to its highest level (‘5’) to require all available spectral criteria to be met for retention in a attempt to maximize the removal of vegetation candidate segments. f_temp &lt;- &quot;../data/ARNF_DiamondView_202510/final_predicted_slash_piles.gpkg&quot; if(!file.exists(f_temp)){ final_predicted_slash_piles &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_watershed_ans , rgb_rast = arnf_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # spectral weighting , spectral_weight = 4 ) final_predicted_slash_piles %&gt;% sf::st_write(f_temp,append = F, quiet = T) }else{ final_predicted_slash_piles &lt;- sf::st_read(f_temp,quiet=T) } what did we get? # huh? final_predicted_slash_piles %&gt;% dplyr::glimpse() ## Rows: 19 ## Columns: 23 ## $ pred_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 1… ## $ area_m2 &lt;dbl&gt; 413.2013, 552.1725, 470.6887, 350.4488, 369.3375, 430… ## $ volume_m3 &lt;dbl&gt; 1477.3873, 2308.8399, 1605.4099, 1483.9100, 883.8572,… ## $ max_height_m &lt;dbl&gt; 8.417358, 9.116704, 7.826457, 8.310950, 6.352087, 9.1… ## $ volume_per_area &lt;dbl&gt; 3.575467, 4.181374, 3.410768, 4.234314, 2.393088, 4.1… ## $ pct_chull &lt;dbl&gt; 0.7988783, 0.7817122, 0.9076699, 0.7363488, 0.7859275… ## $ diameter_m &lt;dbl&gt; 27.85480, 29.51038, 27.37243, 25.58281, 24.30787, 25.… ## $ rast_agg_grvi &lt;dbl&gt; 0.009463723, -0.005617978, -0.004115226, -0.008968610… ## $ rast_agg_rgri &lt;dbl&gt; 0.9812500, 1.0112995, 1.0082644, 1.0180995, 1.0875000… ## $ rast_agg_vdvi &lt;dbl&gt; -0.002288329, -0.003412969, -0.002493766, -0.00273972… ## $ rast_agg_rgbvi &lt;dbl&gt; -0.002581326, -0.005107823, -0.002967236, -0.00302114… ## $ rast_agg_exg &lt;dbl&gt; -3.048748e-03, -4.545420e-03, -3.322244e-03, -3.64965… ## $ rast_agg_exr &lt;dbl&gt; 0.1243986, 0.1382114, 0.1369565, 0.1413386, 0.1732456… ## $ rast_agg_exgr &lt;dbl&gt; -0.1352518, -0.1479126, -0.1468560, -0.1522613, -0.18… ## $ rast_agg_bi &lt;dbl&gt; 0.3885423, 0.4733860, 0.4782020, 0.4554864, 0.4665147… ## $ rast_agg_sat &lt;dbl&gt; 0.12195122, 0.07843138, 0.09677419, 0.11764706, 0.193… ## $ inrange_th_exgr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_rgri &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_vdvi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_bi &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_sat &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ inrange_th_votes &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,… ## $ geom &lt;POLYGON [m]&gt; POLYGON ((455598.7 4535228,..., POLYGON ((455… # final_predicted_slash_piles %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::count(inrange_th_votes) how many piles were removed? # how many piles were removed? nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles) ## [1] 3 # what proportion were removed? scales::percent( (nrow(slash_pile_detect_watershed_ans)-nrow(final_predicted_slash_piles))/nrow(slash_pile_detect_watershed_ans) , accuracy=0.1 ) ## [1] &quot;13.6%&quot; 12.3.4 Detection and Quantification Accuracy let’s see how we did given the list of predictions compared to the ground truth data using the confusion matrix matching process we outlined in this earlier section. we’ll filter both ground truth and predicted piles to keep only those that actually intersect with the study unit boundary for comparison # add filter # pred final_predicted_slash_piles &lt;- final_predicted_slash_piles %&gt;% dplyr::left_join( final_predicted_slash_piles %&gt;% sf::st_intersection( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(pred_id) %&gt;% dplyr::mutate(is_in_stand=T) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate(is_in_stand=dplyr::coalesce(is_in_stand, F)) 12.3.4.1 Instance matching now apply the instance matching process we outlined in this earlier section to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions) # ground truth and prediction matching process ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% sf::st_transform(sf::st_crs(final_predicted_slash_piles)) , gt_id = &quot;pile_id&quot; , predictions = final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.05 ) # add data from gt and pred piles ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # add area of gt dplyr::left_join( arnf_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( pile_id , image_gt_area_m2 , image_gt_diameter_m ) %&gt;% dplyr::rename( gt_diameter_m = image_gt_diameter_m , gt_area_m2 = image_gt_area_m2 ) %&gt;% dplyr::mutate(pile_id=as.numeric(pile_id)) , by = &quot;pile_id&quot; ) %&gt;% # add info from predictions dplyr::left_join( slash_pile_detect_watershed_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( pred_id , area_m2, volume_m3, max_height_m, diameter_m ) %&gt;% dplyr::rename( pred_area_m2 = area_m2, pred_volume_m3 = volume_m3 , pred_height_m = max_height_m, pred_diameter_m = diameter_m ) , by = dplyr::join_by(pred_id) ) %&gt;% dplyr::mutate( ### calculate these based on the formulas below...agg_ground_truth_match() depends on those formulas # image diameter diff_image_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_image_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # area diffs , diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # huh? ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 21 ## Columns: 16 ## $ pile_id &lt;dbl&gt; 7, 3, 8, 4, 6, 9, 15, 18, 13, 10, 11, 19, 5,… ## $ i_area &lt;dbl&gt; 395.2768, 498.7346, 532.4088, 374.2285, 448.… ## $ u_area &lt;dbl&gt; 575.5674, 600.8527, 572.9455, 503.9698, 482.… ## $ iou &lt;dbl&gt; 0.6867602, 0.8300447, 0.9292486, 0.7425614, … ## $ pred_id &lt;int&gt; 1, 13, 2, 16, 3, 4, 6, 19, 20, 5, 17, 8, 18,… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive,… ## $ gt_area_m2 &lt;dbl&gt; 557.6430, 593.0898, 553.1818, 493.8871, 460.… ## $ gt_diameter_m &lt;dbl&gt; 32.91111, 31.83121, 29.75881, 29.52870, 28.6… ## $ pred_area_m2 &lt;dbl&gt; 413.2013, 506.4975, 552.1725, 384.3112, 470.… ## $ pred_volume_m3 &lt;dbl&gt; 1477.3873, 2131.7240, 2308.8399, 1569.0321, … ## $ pred_height_m &lt;dbl&gt; 8.417358, 8.782186, 9.116704, 8.221604, 7.82… ## $ pred_diameter_m &lt;dbl&gt; 27.85480, 30.22900, 29.51038, 24.54231, 27.3… ## $ diff_image_diameter_m &lt;dbl&gt; -5.056309222, -1.602212264, -0.248426498, -4… ## $ pct_diff_image_diameter_m &lt;dbl&gt; 0.1536353231, 0.0503346276, 0.0083479995, 0.… ## $ diff_area_m2 &lt;dbl&gt; -144.441766, -86.592288, -1.009317, -109.575… ## $ pct_diff_area_m2 &lt;dbl&gt; 0.259021922, 0.146001987, 0.001824566, 0.221… that’s a lot of great detail at the individual pile instance level for us to dig into. before we do that, let’s aggregate the instances to see how we did at the stand level overall 12.3.4.2 Overall (stand level) Now we’ll aggregate the instance matching results to calculate overall performance assessment metrics. Here, we take the counts of True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions), to determine overall accuracy. This aggregation will give us two types of results: detection accuracy metrics: such as Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified agg_ground_truth_match_ans &lt;- agg_ground_truth_match(ground_truth_prediction_match_ans = ground_truth_prediction_match_ans) let’s table the most relevant metrics agg_ground_truth_match_ans %&gt;% kbl_agg_gt_match( caption = &quot;pile detection and form quantification accuracy metrics&lt;br&gt;data fusion ARNF ponderosa pine validation site&quot; ) Table 12.2: pile detection and form quantification accuracy metricsdata fusion ARNF ponderosa pine validation site . value Detection Count TP 17 FN 2 FP 2 Detection F-score 89% Recall 89% Precision 89% Area m2 ME -56.50 RMSE 84.3 MAPE 15% Diameter m (image) ME -1.72 RMSE 2.4 MAPE 7% # save the table for full comparison at the very end # save the table for full comparison at the very end sf::st_read(dsn = all_agg_ground_truth_match_ans_fp, quiet = T) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::filter( site != &quot;ARNF ponderosa pine validation site&quot; ) %&gt;% dplyr::bind_rows( all_agg_ground_truth_sf_format( stand_boundary = arnf_stand_boundary , site = &quot;ARNF ponderosa pine validation site&quot; ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::bind_cols( agg_ground_truth_match_ans # join on aggregated form quantifications that we have for all , ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::rename(image_gt_diameter_m = gt_diameter_m) %&gt;% dplyr::summarise( dplyr::across( c(image_gt_diameter_m, pred_diameter_m, gt_area_m2, pred_area_m2, pred_volume_m3, pred_height_m) , ~ sum(.x, na.rm = TRUE) ) ) ) ) %&gt;% # dplyr::glimpse() # readr::write_csv(file = all_agg_ground_truth_match_ans_fp, append = F, progress = F) sf::st_write(dsn = all_agg_ground_truth_match_ans_fp, append = F, quiet = T) The detection performance at the ARNF ponderosa pine validation site, using the data fusion approach, demonstrates strong generalizability of our method despite the novel pile structure and site conditions. With only 19 actual piles in the validation area, each False Positive (FP) or False Negative (FN) prediction exerted a significant influence on the overall accuracy metrics. The 89.5% recall rate means the method successfully identified approximately 9 out of every 10 actual piles, indicating the structural and spectral filters were effective at retaining most true piles. A strong precision rate of 89.5% confirms the methodology did well at excluding spurious False Positive predictions, successfully distinguishing genuine piles from non-pile objects like dense small tree clumps and rock outcroppings. The combined accuracy, quantified by an F-score of 89.5%, is a desirable result that further indicates the methodology is transferable across varied treatments, prescriptions, and pile constructions over highly varied landscapes. let’s look at our predictions compared to the actual piles overlaid on the RGB with the ground truth piles as the filled shapes (omissions in blue and true positive matches in yellow) and the predicted piles outlined in yellow (true positive) or white (false positive) pal_match_grp &lt;- c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= &quot;white&quot; #viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # we have to save the data to plot it with terra terra_gt_piles_temp &lt;- arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::inner_join( ground_truth_prediction_match_ans %&gt;% # dplyr::filter(match_grp = &quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(terra::crs(arnf_rgb_rast)) %&gt;% terra::vect() terra_pred_piles_temp &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(terra::crs(arnf_rgb_rast)) %&gt;% terra::vect() ##################################### # terra plot is much faster ##################################### terra::plotRGB(arnf_rgb_rast, stretch=&quot;lin&quot;, axes=F, colNA=&quot;white&quot;) terra::plot( arnf_stand_boundary %&gt;% sf::st_transform(terra::crs(arnf_rgb_rast)) %&gt;% terra::vect() , border = &quot;black&quot; , col = NA , lwd = 1.6 , add = T , axes=F, legend=F ) terra::plot( terra_gt_piles_temp , border = NA , col = pal_match_grp[terra_gt_piles_temp$match_grp] , add = T, axes=F, legend=F , alpha = 0.6 ) terra::plot( terra_pred_piles_temp , border = pal_match_grp[terra_pred_piles_temp$match_grp] , col = NA , lwd = 2.2 , add = T, axes=F, legend=F ) Visual inspection reveals that one false positive prediction is within the footprint of an actual pile but the predictions were split over two segments, suggesting that the pile had more than one distinct “peak” which resulted in the watershed method splitting this one true pile. The other false positive prediction appears to be a pile of rocks that was not removed as it should have been by the spectral threshold filtering. This indicates that this particular rock grouping has a spectral signature similar to our expectations for slash piles, or that the spectral filtering thresholds are not sensitive enough to distinguish the types of rocks in this area. 12.3.4.3 Instance level (pile level) let’s look at the pile-level data directly to evaluate the true positive detections, omissions (false negatives), and commissions (false positives) let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.4528 ## 1st Qu.:0.7426 ## Median :0.8622 ## Mean :0.7931 ## 3rd Qu.:0.8913 ## Max. :0.9379 for the majority (i.e. &gt;95%) of matches, the IoU was above 47.3% here is the distribution of IoU for those matches ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = iou, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.8) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::scale_x_continuous(labels=scales::percent) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;IoU of correct precitions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) is there a difference between the image-annotated pile sizes of the true positive detections and the omissions (false negative)? let’s compare the image-annotated area and diameter for omissions and true positives since those measurements exist for both sets ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;commission&quot;) %&gt;% dplyr::select(pile_id,match_grp,gt_diameter_m,gt_area_m2) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;gt_diameter_m&quot;,&quot;gt_area_m2&quot;) , labels = c( &quot;image annotated diameter (m)&quot; , &quot;image annotated area (m2)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot; , subtitle = &quot;ground truth form measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) wow! note that we did not inspect the image-annotated ground truth measurement data prior to implementing our remote-sensing based pile detection methodology. we purposefully did not look at this data until after making the predictions because we wanted to set up our remote sensing pile detection method without as if we did not measure a single pile in the field so as to not bias our implementation of the method. to implement this remote sensing method slash pile detection framework in practice, we would likely not have any field-measured data on pile structure and if we did it would only be for a very small sample of piles. remember, the entire objective of creating this method is so that time in the field can be minimized to the time needed to visually assess the treatment implementation to acquire quick observational anecdotes and potentially measure some sample piles and then fly a UAS data collection mission to get the data needed to implement this method. compare that minimal time to the traditional, field-based method of slash pile identification and measurement which is much more costly in terms of time and personnel needed. there are so few omissions (i.e. FPs) for this validation data set that it’s difficult to make any inference from this comparison let’s now look at the summary stats of ground truth piles kbl_form_sum_stats( arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) , caption = &quot;Ground Truth Piles: summary statistics for form measurements&lt;br&gt;ARNF ponderosa pine validation site&quot; ) Table 12.3: Ground Truth Piles: summary statistics for form measurementsARNF ponderosa pine validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 19 Diameter m (image) 25.9 3.6 22.3 25.9 30.2 18.4—32.9 Area m2 (image) 409.0 97.1 289.2 401.8 554.1 221.5—593.1 and let’s look at the summary stats of the predicted piles kbl_form_sum_stats( final_predicted_slash_piles %&gt;% dplyr::filter(is_in_stand) , caption = &quot;Predicted Piles: summary statistics for form measurements&lt;br&gt;ARNF ponderosa pine validation site&quot; ) Table 12.4: Predicted Piles: summary statistics for form measurementsARNF ponderosa pine validation site # piles Metric Mean Std Dev q 10% Median q 90% Range 19 Height m 7.6 1.6 6.0 8.0 8.9 2.6—9.1 Diameter m 23.6 4.3 16.9 24.5 28.2 14.8—30.2 Area m2 333.4 130.5 113.7 359.2 477.9 108.6—552.2 Volume m3 1,177.4 582.0 450.5 1,094.9 1,844.9 144.0—2,308.8 let’s look at some examples on our RGB image true positive matches (correct predictions) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;true positive&quot;)) %&gt;% sample( min(20,agg_ground_truth_match_ans$tp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- arnf_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=arnf_rgb_rast, stand=sf::st_union(gt,pr), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 4 ) ggplot2::ggsave(&quot;../data/ARNF_DiamondView_202510/arnf_truepositives.jpg&quot;, height = 11, width = 8.5) it looks like there was more than one predicted pile that covers only a portion of the actual pile due to the CHM-based watershed segmentation approach possibly interpreting multiple peaks as separate, unique objects and split the actual single large pile into multiple candidate segments. These multiple candidate segments were either filtered out based on the minimum size thresholds or included in the final prediction data set and classified as commissions (false positives) because the other, larger predicted pile within the footprint of the actual pile was matched as the true positive prediction. omissions (false negatives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% # sample( min(16,agg_ground_truth_match_ans$fn_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- arnf_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=arnf_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs(subtitle = paste0(&quot;pile ID: &quot;,dta$pile_id)) }) # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/ARNF_DiamondView_202510/arnf_omission.jpg&quot;, height = 6, width = 8.5) it is not immediately clear why these piles were missed by our predictions, let’s add the CHM to that plot to see if it helps shed light on why these were missed # plot RGB + CHM plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;omission&quot;)) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) gt &lt;- arnf_slash_piles_polys %&gt;% dplyr::filter(pile_id==dta$pile_id) #plt ortho_plt_fn(my_ortho_rast=arnf_rgb_rast, stand=sf::st_union(gt), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast_stand %&gt;% terra::crop( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(gt) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does # terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;blue&quot;, lwd = 0.6) + ggplot2::labs( subtitle = paste0( &quot;pile ID: &quot;, dta$pile_id , &quot;\\nGT area: &quot;, round(dta$gt_area_m2,1) # , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nGT dia: &quot;, round(dta$gt_diameter_m,1) # , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/ARNF_DiamondView_202510/arnf_omission_chm.jpg&quot;, height = 6.6, width = 8.5) The review of the image-annotated footprints for these false negative (FN; omission) piles confirmed that none were filtered out based on area thresholds, as their footprints fell within the defined search range. These omissions likely stemmed from issues within the segmentation and filtering pipeline. These missed piles, which had full CHM coverage, visually display more than one distinct vertical peak. The CHM-based watershed segmentation approach may have interpreted these multiple peaks as separate, unique objects and split the actual single large pile into multiple candidate segments. Our structural detection methodology includes a smoothing option (smooth_segs) which we used for this validation data (set to TRUE). This smoothing option includes a step designed for shape refinement and overlap removal. Activating this parameter initiates a sequence: candidate segments that pass all size and shape checks first are combined if their perimeters touch but do not overlap. The combined shape is then smoothed using its convex hull to remove the “blocky” raster edges. Lastly, overlapping convex hull shapes are removed to prevent false positives from clustered small trees or shrubs. Given the distinct peaks in these FN piles, it is highly likely they were initially split by the watershed segmentation, and then one or more of the resulting smaller segments failed to meet the required size or shape thresholds. Because a significant area of the pile was removed in this filtering step, the remaining segments even if successfully combined were deemed insufficient in overall size (min_area_m2) to be retained in the final structural detection output. now, let’s check out the predicted sizes of the commissions (false positives) compared to the predicted sizes of the predicted piles that were correctly matched with the ground truth data let’s compare the predicted height, diameter, area for commissions and true positives since those measurements exist for both sets pal_match_grp &lt;- c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= &quot;gray77&quot; #viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_diameter_m,pred_area_m2,pred_height_m) %&gt;% tidyr::pivot_longer(cols = -c(pile_id,match_grp)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;,&quot;pred_height_m&quot;) , labels = c( &quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; , &quot;predicted height (m)&quot; ) ) ) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid(cols = dplyr::vars(name), scales = &quot;free_x&quot;) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs(color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) remember, we only had 2 commissions (false positives), so viewing a distribution for so few data points is not very insightful let’s table the predicted form measurements ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp!=&quot;omission&quot;) %&gt;% dplyr::select(pile_id,match_grp,pred_diameter_m,pred_area_m2,pred_height_m) %&gt;% dplyr::group_by(match_grp) %&gt;% dplyr::summarise( dplyr::across( c(pred_diameter_m,pred_area_m2,pred_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c( match_grp,n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) ) %&gt;% dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange( match_grp, desc(n)) %&gt;% dplyr::select(-c(n,min,max)) %&gt;% dplyr::relocate(match_grp) %&gt;% dplyr::mutate( metric = factor( metric , ordered = T , levels = c(&quot;pred_diameter_m&quot;,&quot;pred_area_m2&quot;,&quot;pred_height_m&quot;) , labels = c( &quot;predicted diameter (m)&quot; , &quot;predicted area (m2)&quot; , &quot;predicted height (m)&quot; ) ) ) %&gt;% kableExtra::kbl( caption = &quot;Predicted Piles: summary statistics for form measurements&quot; , col.names = c( &quot;segmentation&lt;br&gt;classification&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 12.5: Predicted Piles: summary statistics for form measurements segmentationclassification Metric Mean Std Dev q 10% Median q 90% Range commission predicted diameter (m) 16.0 1.8 15.0 16.0 17.1 14.8—17.3 predicted area (m2) 111.8 4.5 109.2 111.8 114.3 108.6—114.9 predicted height (m) 5.7 4.4 3.2 5.7 8.2 2.6—8.8 true positive predicted diameter (m) 24.5 3.5 21.5 25.0 28.5 15.1—30.2 predicted area (m2) 359.5 110.9 237.0 366.6 485.0 108.7—552.2 predicted height (m) 7.8 1.0 6.2 8.0 8.9 5.8—9.1 the 2 commissions (false positives) are generally smaller than most correct predictions but are still within the size range of the correctly matched predictions let’s look at some examples on our RGB image commissions (false positives) plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% sample( min(16,agg_ground_truth_match_ans$fp_n) ) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=arnf_rgb_rast, stand=sf::st_union(pr), buffer=6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.5) }) # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/ARNF_DiamondView_202510/arnf_commission.jpg&quot;, height = 6, width = 8.5) so much sadness that that rock outcropping was not filtered out but it is easy to see how its spectral profile is similar to the actual piles. the other commission is clearly a portion of an actual pile that was split during the CHM-based watershed segmentation due to multiple distinct peaks in the CHM let’s add the CHM to that plot to see if it helps shed light on why these were incorrectly included in the predictions # plot RGB + CHM plts_temp &lt;- which(ground_truth_prediction_match_ans$match_grp %in% c(&quot;commission&quot;)) %&gt;% purrr::map(function(x){ dta &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::slice(x) pr &lt;- final_predicted_slash_piles %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn(my_ortho_rast=arnf_rgb_rast, stand=sf::st_union(pr), buffer=6) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast_stand %&gt;% terra::crop( sf::st_union(pr) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% terra::mask( sf::st_union(pr) %&gt;% sf::st_transform(terra::crs(chm_rast_stand)) %&gt;% terra::vect() ) %&gt;% # slice the chm below our desired height # this is what slash_pile_detect_watershed() does # terra::clamp(upper = 2.3, lower = 0, values = F) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot;) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;brown&quot;, lwd = 0.7) + ggplot2::labs( subtitle = paste0( &quot;pred ID: &quot;, dta$pred_id , &quot;\\nPred area: &quot;, round(dta$pred_area_m2,1) # , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nPred dia: &quot;, round(dta$pred_diameter_m,1) # , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme(legend.text = ggplot2::element_text(size = 6),legend.title = ggplot2::element_text(size = 6)) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 2 ) ggplot2::ggsave(&quot;../data/ARNF_DiamondView_202510/arnf_commission_chm.jpg&quot;, height = 6.6, width = 8.5) the distinct peak on the predicted pile that is part of an actual pile is evident 12.3.5 Stand-level Aggregation before we leave, let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory) sum_df_temp &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::select(!tidyselect::contains(&quot;volume_m3&quot;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(pred_id)) %&gt;% dplyr::summarise( dplyr::across( .cols = tidyselect::starts_with(&quot;gt_&quot;) | tidyselect::starts_with(&quot;pred_&quot;) , ~sum(.x,na.rm=T) ) ) %&gt;% tidyr::pivot_longer( cols = dplyr::everything() , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% ### !!!! we don&#39;t have height for this data dplyr::filter( !stringr::str_detect(metric, &quot;height&quot;) &amp; !stringr::str_detect(metric, &quot;volume&quot;) ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;ground truth&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; , &quot;volume&quot; , &quot;paraboloid_volume&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; , &quot;Volume (m3)&quot; , &quot;Volume paraboloid&quot; ) ) ) %&gt;% dplyr::group_by(pile_metric) %&gt;% dplyr::arrange(pile_metric,which_data) %&gt;% dplyr::mutate( pct_diff = (value-dplyr::lag(value))/dplyr::lag(value) ) %&gt;% dplyr::ungroup() plot # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + ggplot2::scale_color_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;blue&quot;,&quot;brown&quot;)) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_wrap(facets = dplyr::vars(pile_metric), scales = &quot;free_y&quot;, axes = &quot;all_x&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated measurements at the stand level&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table it sum_df_temp %&gt;% dplyr::select(pile_metric, which_data, value, pct_diff) %&gt;% dplyr::mutate( value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated measurements at the stand level&quot; , col.names = c( &quot;.&quot;, &quot;measurement source&quot; , &quot;stand-level total&quot;, &quot;% difference&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 12.6: Comparison of aggregated measurements at the stand level . measurement source stand-level total % difference Diameter (m) ground truth 492.8 NA prediction 448.9 -8.9% Area (m2) ground truth 7,770.4 NA prediction 6,335.1 -18.5% "],["validation_summary.html", "Section 13 Method Validation: Summary", " Section 13 Method Validation: Summary Lastly, we will examine the aggregated performance achieved by the data fusion approach across all tested study sites. This comparison involves three distinct metric types: Detection Accuracy Metrics: These metrics are calculated by aggregating the raw counts of True Positives (TP), False Positives (FP), and False Negatives (FN) from all sites. They quantify the method’s ability to successfully locate and identify the piles. Quantification Accuracy Metrics: Calculated for instances classified as TP, these metrics (e.g., RMSE, MAPE, Mean Error) aggregate the differences between the predicted pile attributes (Area, Diameter) and the ground truth values. These metrics assess the method’s ability to accurately quantify the form of the piles it successfully identified. Overall Total Quantification Comparison: This involves summarizing the predicted and ground truth pile form measurements (area, diameter) for all instances across the entire study area, regardless of whether individual piles were successfully matched between datasets. This overall comparison provides insight into the method’s aggregated performance in predicting total pile size in an area. Such totals are often required for administrative needs like submitting burn permits which do not typically focus on individual pile quantification differences. For all form quantification performance assessment, we will rely solely on comparison against image-annotated footprints by comparing predicted diameter and area against the image-annotated values. This consistency is required because image-annotated data is available for all sites, whereas field-measured height and diameter data were only available for the training site. We already provided this information when introducing our method validation but here it is again: The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how those features were expected to influence our methodology. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site. Site Name Pile Type Data Use Unique Features &amp; Ecology Methodology Parameter Influence PSINF Ponderosa Pine Training Site Mostly Hand Piles (some smaller machine piles) Training Located in the Pike and San Isabel National Forest (PSINF). Ponderosa pine stand with mixed ground cover and varying canopy density. This site was used to fully develop and tune all slash pile detection parameters, including setting initial values for pile size thresholds and geometric shape regularity. TRFO-BLM Pinyon-Juniper Validation Site Hand Piles Validation Located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM). Arid environment with dry vegetation appearing less green including standing dead pinyon-juniper vegetation. Piles are smaller, simpler, and hand-stacked. The dry, senescent vegetation might spectrally mimic dead wood thereby reducing the effectiveness of the spectral filter. This shifts the primary detection burden to the expected pile size and geometric shape filters to control false positives. BHEF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Black Hills Experimental Forest (BHEF). Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected based on local precipitation and typical regrowth response. The large, irregular pile geometry requires setting high minimum size thresholds and relaxing geometric parameters. The presence of dense regeneration requires a highly restrictive spectral filter to distinguish dead slash from live biomass. ARNF Ponderosa Pine Validation Site Massive Machine Piles Validation Located in the Arapahoe and Roosevelt National Forest (ARNF). Ponderosa pine forest with a climate similar to the training site and drier than BHEF. Piles are massive but more circular and regular. Less regeneration is expected due to more recent treatment and drier climate. The massive size requires high minimum size thresholds while more regular, circular shape allows for tighter geometric filters. Reduced expected regeneration means the spectral filter can be less strictly applied than at BHEF. read in the file with the aggregated results we wrote in each section # read in the file with the aggregated results we wrote in each section all_agg_ground_truth_match_ans &lt;- sf::st_read(dsn = all_agg_ground_truth_match_ans_fp, quiet = T) %&gt;% # readr::read_csv(file = all_agg_ground_truth_match_ans_fp, progress = F, show_col_types = F) %&gt;% dplyr::mutate( site = ordered(site) %&gt;% forcats::fct_relevel(&quot;PSINF ponderosa pine training site&quot;) %&gt;% forcats::fct_rev() , pct_diff_diameter = (pred_diameter_m-image_gt_diameter_m)/image_gt_diameter_m , pct_diff_area = (pred_area_m2-gt_area_m2)/gt_area_m2 ) %&gt;% dplyr::arrange(site) # huh? all_agg_ground_truth_match_ans %&gt;% dplyr::glimpse() ## Rows: 4 ## Columns: 31 ## $ site_area_m2 &lt;dbl&gt; 51825.21, 1030502.12, 735508.69, 174835… ## $ site &lt;ord&gt; TRFO-BLM pinyon-juniper validation site… ## $ tp_n &lt;dbl&gt; 262, 22, 17, 107 ## $ fp_n &lt;dbl&gt; 79, 5, 2, 30 ## $ fn_n &lt;dbl&gt; 15, 4, 2, 14 ## $ omission_rate &lt;dbl&gt; 0.05415162, 0.15384615, 0.10526316, 0.1… ## $ commission_rate &lt;dbl&gt; 0.2316716, 0.1851852, 0.1052632, 0.2189… ## $ precision &lt;dbl&gt; 0.7683284, 0.8148148, 0.8947368, 0.7810… ## $ recall &lt;dbl&gt; 0.9458484, 0.8461538, 0.8947368, 0.8842… ## $ f_score &lt;dbl&gt; 0.8478964, 0.8301887, 0.8947368, 0.8294… ## $ diff_area_m2_rmse &lt;dbl&gt; 1.967614, 49.433509, 84.344929, 2.100498 ## $ diff_field_diameter_m_rmse &lt;dbl&gt; 1.7995497, NA, NA, 0.5539741 ## $ diff_height_m_rmse &lt;dbl&gt; 1.2064009, NA, NA, 0.6546709 ## $ diff_image_diameter_m_rmse &lt;dbl&gt; 0.4527556, 4.0095773, 2.4229219, 0.4440… ## $ diff_area_m2_mean &lt;dbl&gt; -1.1914491, -17.9769566, -56.4997462, -… ## $ diff_field_diameter_m_mean &lt;dbl&gt; -1.7127948, NA, NA, 0.2124978 ## $ diff_height_m_mean &lt;dbl&gt; -1.1668889, NA, NA, -0.2023439 ## $ diff_image_diameter_m_mean &lt;dbl&gt; -0.2584928, -1.5220128, -1.7228389, -0.… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.14541068, 0.08594908, 0.15073981, 0.1… ## $ pct_diff_field_diameter_m_mape &lt;dbl&gt; 0.3055677, NA, NA, 0.1121629 ## $ pct_diff_height_m_mape &lt;dbl&gt; 0.5146757, NA, NA, 0.1548135 ## $ pct_diff_image_diameter_m_mape &lt;dbl&gt; 0.08139310, 0.06837243, 0.06580834, 0.0… ## $ image_gt_diameter_m &lt;dbl&gt; 1155.4669, 545.7089, 492.8276, 463.7905 ## $ pred_diameter_m &lt;dbl&gt; 1274.2344, 539.3018, 448.9317, 486.6239 ## $ gt_area_m2 &lt;dbl&gt; 2942.573, 5198.640, 7770.433, 1185.542 ## $ pred_area_m2 &lt;dbl&gt; 2846.445, 4808.925, 6335.122, 1121.190 ## $ pred_volume_m3 &lt;dbl&gt; 1613.947, 5066.225, 22369.854, 952.529 ## $ pred_height_m &lt;dbl&gt; 427.64159, 72.98016, 144.57194, 263.021… ## $ pct_diff_diameter &lt;dbl&gt; 0.10278747, -0.01174094, -0.08906938, 0… ## $ pct_diff_area &lt;dbl&gt; -0.03266808, -0.07496482, -0.18471433, … ## $ geom &lt;POINT [m]&gt; POINT (-1097708 1720721), POINT (-60821… Let’s map the study sites on a single map sites_pal &lt;- RColorBrewer::brewer.pal(n = nrow(all_agg_ground_truth_match_ans), name = &quot;Dark2&quot;) # option to put satellite imagery as base layer of mapview maps mapview::mapviewOptions( homebutton = T # , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) , basemaps = c(&quot;OpenStreetMap&quot;, &quot;Esri.WorldImagery&quot;) ) # map it mapview::mapview( all_agg_ground_truth_match_ans , zcol=&quot;site&quot; , col.regions = sites_pal , cex = 8 , layer.name = &quot;study sites&quot; ) static map for printing let’s make a pretty image for use in the journal article. we’ll use the ggmap package to get a nice background map and do some transformation to actually work with the map. We’ll add a map scale using ggspatial library(ggmap) library(ggspatial) ######################################################################### ######################################################################### # Make each plot individually by landscape as solution to small multiples # this block defines function ######################################################################### ##################hack to align plots for ggmap ggmap_bbox_fn &lt;- function(map, my_crs=3857) { if (!inherits(map, &quot;ggmap&quot;)) stop(&quot;map must be a ggmap object&quot;) # Extract the bounding box (in lat/lon) from the ggmap to a numeric vector, # and set the names to what sf::st_bbox expects: map_bbox &lt;- setNames(unlist(attr(map, &quot;bb&quot;)), c(&quot;ymin&quot;, &quot;xmin&quot;, &quot;ymax&quot;, &quot;xmax&quot;)) # Convert the bbox to an sf polygon, transform it to 3857, # and convert back to a bbox (convoluted, but it works) bbox_3857 &lt;- st_bbox(st_transform(st_as_sfc(st_bbox(map_bbox, crs = 4326)), my_crs)) # Overwrite the bbox of the ggmap object with the transformed coordinates attr(map, &quot;bb&quot;)$ll.lat &lt;- bbox_3857[&quot;ymin&quot;] attr(map, &quot;bb&quot;)$ll.lon &lt;- bbox_3857[&quot;xmin&quot;] attr(map, &quot;bb&quot;)$ur.lat &lt;- bbox_3857[&quot;ymax&quot;] attr(map, &quot;bb&quot;)$ur.lon &lt;- bbox_3857[&quot;xmax&quot;] map } plt_crs &lt;- 3857 ######################################################################### ######################################################################### ######################################################################### my_ggmap_basemap &lt;- function(sf_data, zoom_level = 14, buffer_box = 2600, my_crs = plt_crs, scale_location = &quot;bl&quot;, my_maptype = &quot;stamen_terrain&quot;) { # # should zoom in? # zoom_level &lt;- 14 # 11 # # should buffer extend? # buffer_box &lt;- 2600 # 20000 # bounding box bb_temp &lt;- sf_data %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(crs=5070) %&gt;% sf::st_buffer(as.numeric(buffer_box)) %&gt;% sf::st_transform(crs=4326) %&gt;% # same as get_map return sf::st_bbox() # set bbox for get call bbox_temp &lt;- c( bottom = bb_temp[[2]] , top = bb_temp[[4]] , right = bb_temp[[3]] , left = bb_temp[[1]] ) hey_ggmap &lt;- ggmap::get_stadiamap( bbox = bbox_temp , zoom = zoom_level , maptype = my_maptype #&quot;stamen_terrain&quot; #&quot;stamen_toner_lite&quot; , crop = T ) # ggmap::ggmap(hey_ggmap) # apply align function hey_ggmap_aligned &lt;- ggmap_bbox_fn(hey_ggmap, my_crs) # Use the function # plot plt_basemap &lt;- ggmap::ggmap(hey_ggmap_aligned) + ggplot2::coord_sf( expand = FALSE ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , plot.title = ggplot2::element_blank() , strip.text = ggplot2::element_blank() , axis.title = ggplot2::element_blank() , axis.text = ggplot2::element_blank() , axis.ticks = ggplot2::element_blank() , panel.grid = ggplot2::element_blank() , plot.margin = ggplot2::margin(0, 0, 0, 0, &quot;cm&quot;) ) if(scale_location %in% c(&quot;bl&quot;, &quot;br&quot;, &quot;tr&quot;, &quot;tl&quot;)){ plt_basemap &lt;- plt_basemap + ggspatial::annotation_scale( location = scale_location , style = &quot;ticks&quot; , pad_x = unit(0.1, &quot;cm&quot;) , pad_y = unit(0.1, &quot;cm&quot;) ) } return(plt_basemap) } plt_basemap &lt;- my_ggmap_basemap( sf_data = all_agg_ground_truth_match_ans , buffer_box = 190000 , zoom_level = 7 , my_maptype = &quot;stamen_terrain&quot; ) # plt_basemap plot it with the points # plot plt2_temp &lt;- plt_basemap + ggplot2::geom_sf( data = all_agg_ground_truth_match_ans %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(fill = site) , size = 4.5 , inherit.aes = F , shape = 21 , color = &quot;gray88&quot; , fill = &quot;blue2&quot; ) + ggplot2::geom_sf_label( data = all_agg_ground_truth_match_ans %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(label = stringr::str_wrap(site, width = 40)) , size = 2.5 , hjust = -0.055 , vjust = 0.4 , inherit.aes = F ) + ggplot2::scale_fill_manual(values = sites_pal) plt2_temp make a quick plot to look across study sites at the aggregated accuracy metrics all_agg_ground_truth_match_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( site ## detection ,omission_rate,commission_rate,precision,recall,f_score ## quantification # ,diff_area_m2_rmse,diff_field_diameter_m_rmse,diff_height_m_rmse,diff_image_diameter_m_rmse # ,diff_area_m2_mean,diff_field_diameter_m_mean,diff_height_m_mean,diff_image_diameter_m_mean # ,pct_diff_field_diameter_m_mape,pct_diff_height_m_mape ,pct_diff_area_m2_mape,pct_diff_image_diameter_m_mape ## totals # ,image_gt_diameter_m,pred_diameter_m,gt_area_m2,pred_area_m2,site ,pct_diff_diameter,pct_diff_area ) %&gt;% tidyr::pivot_longer(cols = -c(site)) %&gt;% dplyr::mutate( metric_type = dplyr::case_when( name %in% c(&quot;omission_rate&quot;,&quot;commission_rate&quot;,&quot;precision&quot;,&quot;recall&quot;,&quot;f_score&quot;) ~ &quot;Detection Accuracy&quot; , name %in% c(&quot;pct_diff_area_m2_mape&quot;,&quot;pct_diff_image_diameter_m_mape&quot;) ~ &quot;Quantification Accuracy&quot; , name %in% c(&quot;pct_diff_diameter&quot;,&quot;pct_diff_area&quot;) ~ &quot;Site Aggregate Totals&quot; , T ~ &quot;error&quot; ) , label = scales::percent(value, accuracy = 0.1) , name = dplyr::case_when( name == &quot;f_score&quot; ~ &quot;F-score&quot; , stringr::str_starts(name,&quot;pct_diff_&quot;) &amp; metric_type == &quot;Site Aggregate Totals&quot; ~ stringr::str_replace_all(name,&quot;pct_diff_&quot;,&quot;% Diff. &quot;) %&gt;% stringr::str_to_sentence() , stringr::str_ends(name,&quot;_mape&quot;) ~ stringr::str_extract(name,&quot;(area|diameter)&quot;) %&gt;% stringr::str_c(&quot; MAPE&quot;) , T ~ stringr::str_replace_all(name,&quot;_&quot;,&quot; &quot;) %&gt;% stringr::str_to_sentence() ) ) %&gt;% dplyr::mutate( label = dplyr::case_when( metric_type == &quot;Site Aggregate Totals&quot; &amp; value&gt;0 ~ paste0(&quot;+&quot;, label) , T ~ label ) # , label_pos = ifelse(value &gt; 0, 0.005, -0.0073) , name2 = forcats::fct_cross(ordered(metric_type),ordered(name), sep = &quot;: &quot;) ) %&gt;% dplyr::arrange(metric_type, site) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = site, color = metric_type, fill = metric_type) ) + ggplot2::geom_col( width = 0.6 , color = NA ) + # ggplot2::geom_text( # mapping = ggplot2::aes(label = label, x = label_pos, fontface = &quot;bold&quot;) # , vjust = 0 # , hjust = 0 # , color = &quot;white&quot;, size = 3 # ) + ggplot2::geom_text( mapping = aes( label = ifelse(value&lt;0, label, &quot;&quot;) , fontface = &quot;bold&quot; ) , color = &quot;black&quot;, size = 2.0 , hjust = +1 ) + ggplot2::geom_text( mapping = aes( label = ifelse(value&gt;=0, label, &quot;&quot;) , fontface = &quot;bold&quot; ) , color = &quot;black&quot;, size = 2.0 , hjust = 0 ) + ggplot2::facet_wrap(facets = dplyr::vars(name2), ncol = 2, scales = &quot;free&quot;) + harrypotter::scale_fill_hp_d(option = &quot;ronweasley2&quot;, direction = -1) + ggplot2::scale_x_continuous(labels = scales::percent, expand = ggplot2::expansion(mult = c(0.1,0.1))) + ggplot2::labs(fill = &quot;&quot;, x = &quot;&quot;, y = &quot;&quot;) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 6) ) and a table all_agg_ground_truth_match_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( ref_trees = tp_n+fn_n , det_trees = tp_n+fp_n ) %&gt;% dplyr::select( site , site_area_m2 , ref_trees , det_trees , tp_n , omission_rate,commission_rate,recall,precision,f_score , pct_diff_area_m2_mape , pct_diff_area ) %&gt;% dplyr::mutate( site_area_m2 = round(site_area_m2/10000) %&gt;% scales::comma(accuracy = 1) , dplyr::across( .cols = c(omission_rate,commission_rate,recall,precision,f_score) , .fns = ~scales::percent(.x,accuracy=0.1) ) , pct_diff_area_m2_mape = scales::percent(pct_diff_area_m2_mape,accuracy=0.1) , pct_diff_area = scales::percent(pct_diff_area,accuracy=0.1) ) %&gt;% dplyr::arrange(desc(site)) %&gt;% kableExtra::kbl( caption = &quot;Data fusion method slash pile segmentation results for each study site&quot; , col.names = c( &quot;site&quot;, &quot;hectares&quot; , &quot;reference&lt;br&gt;piles&quot;, &quot;detected&lt;br&gt;piles&quot;, &quot;correct&lt;br&gt;piles&quot; , &quot;omission&lt;br&gt;rate&quot; , &quot;commission&lt;br&gt;rate&quot; ,&quot;recall&quot;,&quot;precision&quot;,&quot;F-score&quot; , &quot;MAPE&lt;br&gt;area m&lt;sup&gt;2&lt;/sup&gt;&quot; , &quot;% aggregated&lt;br&gt;area difference&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 9.5) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 13.1: Data fusion method slash pile segmentation results for each study site site hectares referencepiles detectedpiles correctpiles omissionrate commissionrate recall precision F-score MAPEarea m2 % aggregatedarea difference PSINF ponderosa pine training site 17 121 137 107 11.6% 21.9% 88.4% 78.1% 82.9% 12.0% -5.4% ARNF ponderosa pine validation site 74 19 19 17 10.5% 10.5% 89.5% 89.5% 89.5% 15.1% -18.5% BHEF ponderosa pine validation site 103 26 27 22 15.4% 18.5% 84.6% 81.5% 83.0% 8.6% -7.5% TRFO-BLM pinyon-juniper validation site 5 277 341 262 5.4% 23.2% 94.6% 76.8% 84.8% 14.5% -3.3% The aggregated results across all three study sites, including the complex, out-of-sample validation sites, demonstrate the consistent transferability and dependability of our data fusion slash pile methodology. All sites achieved consistently high detection performance, with F-scores ranging narrowly from 83% to 89%, confirming the method’s overall effectiveness despite vast differences in pile sizes, vegetation, terrain, and construction techniques. The specific composition of errors (false positives and false negatives) highlights the success of the site-specific parameter adjustments. The pinyon-juniper validation site (277 piles) recorded the highest F-score (85%), driven by a very high recall rate (95%) which suggests the structural parameters effectively located the many smaller, hand-piled objects, even with less restrictive structural filters. However, this high recall came at the expense of the lowest precision (77%), confirming our observation that the spectral filter failed to exclude numerous false positives (FPs) because the site’s senescent, arid vegetation mimicked the spectral signature of dead wood in piles. In contrast, the BHEF ponderosa pine evaluation site (26 piles) achieved a strong F-score (83%) which is notable given the low pile count amplifies the influence of each error. This site had the lowest recall (85%) due to the complexities of segmenting the massive, irregular pile shapes, but it maintained the highest precision (81%), demonstrating that the strict spectral filtering (spectral_weight set to its maximum value of ‘5’) successfully minimized FPs from the dense ponderosa pine regeneration groups, validating that parameter choice for environments with dense regeneration or shrub cover. Consistent pile form quantification accuracy indicates the method reliably extracts of pile form measurements (e.g., area, height) for use in planning the management of the piles. The MAPE on pile area, which measures the average error in sizing individual, successfully matched piles, was below 15% across all sites, ranging from 9% to 15%. This result suggests that the methodology can consistently quantify the form of individual piles with high accuracy regardless of the extensive differences in pile sizes, terrain, and construction forms. The BHEF ponderosa pine evaluation site recorded the lowest MAPE on pile area (9%), meaning the piles it did find were sized most accurately of the sites measured. Analysis of the site aggregate totals revealed a systematic underprediction of the total area across all sites. This systematic underestimation, with errors ranging only from -18.5% to -3.3%, is an important result for administrative needs (such as burn permits), as it avoids overstating the total quantity of fuel (area or volume) on a site. The BHEF ponderosa pine evaluation site had the largest aggregate pile area underestimation (-7.5%). This was likely caused by lower recall rates resulting from the watershed algorithm splitting single massive piles due to their irregular elevation profile or from CHM artifacts produced by cloud cover and SfM flight stitching. The pinyon-juniper site had the highest individual pile area MAPE (14.5%), indicating the worst individual sizing accuracy, but it achieved the closest match to the true total pile area over the entire site (-3.3%), implying that the individual sizing errors of the retained piles compensated for each other across the entire site extent. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
