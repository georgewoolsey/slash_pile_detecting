[["index.html", "Aerial Imagery and Point Cloud Data for Slash Pile Quantification Section 1 Introduction 1.1 Objective 1.2 Data and Site Descriptions 1.3 Analysis Plan", " Aerial Imagery and Point Cloud Data for Slash Pile Quantification George Woolsey 04 February, 2026 Section 1 Introduction Code in support of “A General Method using UAS Data for Automated Slash Pile Detection and Quantification” Increasing active forest management activities generate non-commercial residues (slash) that are often aggregated into piles for disposal. However, pile burning is associated with increased operational costs and significant external environmental costs (Mott et al., 2021; Barker et al., 2025; Axlund et al., 2025), motivating the need for improved quantification and management. While remote sensing techniques using point clouds consistently offer improved pile quantification accuracy over traditional field methods (Trofymow et al., 2014; Guth et al., 2025), there is a lack of automated methods for simultaneously detecting and quantifying piles across an broad treatment extents. To overcome this we propose a geometry-based, rules-based framework that leverages the proven success of object segmentation frameworks in CWD (e.g. dos Santos et al., 2025) and tree detection (e.g. Tinkham &amp; Woolsey, 2024) and offers superior managerial relevance due to its inherent traceability and direct alignment with known pile construction parameters defined in silvicultural prescriptions. 1.1 Objective The objective of this study is to present a training-free, rules-based methodology for identifying slash piles from UAS data. The presented approach aims to enable high transferability by using user-defined geometric and size thresholds to identify pile candidates from aerial point cloud data, which can then be refined through a data fusion process incorporating spectral (i.e. RGB) data when available. 1.2 Data and Site Descriptions We have remote sensing data acquired from a UAS platform and accompanying ground truth data for four different study sites. For all study sites we have: Aerial RGB imagery captured by a UAS platform Aerial point cloud data generated by processing the UAS imagery using digital aerial photogrammetry (DAP) techniques (specifically, structure from motion [SfM]) Image-annotated slash pile perimeters digitized in a Geographic Information System (GIS) using field-collected point locations as a guide overlaid on the UAS-collected RGB imagery For the one study site only we have: * Field-collected slash pile point locations with height and diameter measurements Data from all study sites will be used to validate the slash pile detection methodology. Data from the study site with field-collected pile measurements will be used to test the slash pile quantification accuracies acheived by the proposed methodology. The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how the data was collected. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site. Site Name Pile Type Validation Data Type Unique Features &amp; Ecology Data Collection (UAS Platform &amp; Parameters) PSINF Mixed Conifer Site Hand Piles and smaller machine piles Image-annotated footprints and field-measured height and diameter Located in the Pike and San Isabel National Forest (PSINF) in CO, US. Mixed conifer stand with variable ground cover and canopy density. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. TRFO-BLM Pinyon-Juniper Site Hand Piles Image-annotated footprints based on field collected point locations Located on BLM land in CO, US. Arid environment with dry vegetation including standing dead pinyon-juniper. Piles are smaller, simpler, and hand-stacked. Freefly Astro with Sony ILX-LR1 (35mm lens). Altitude 243.84 m (terrain following), 85% forward and 80% side overlap. BHEF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Black Hills Experimental Forest (BHEF) in SD, US. Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected. DJI Phantom 4 Pro with 20 MP RGB sensor (8.8 mm lens). Altitude 80 m, 90% forward and 85% side overlap, 4 m/s speed. ARNF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Arapahoe and Roosevelt National Forest (ARNF) in CO, US. Ponderosa pine forest with a climate similar to PSINF. Machine piles are massive but more circular and regular. Less regeneration is expected. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. 1.2.1 Silvicultural Prescriptions Below, we summarize the silvicultural prescriptions from the study sites with a specific focus on highlighting information on slash pile construction while also providing information on management objectives. 1.2.1.1 PSINF Mixed Conifer Site Information is from the silvicultural prescriptions for the “Carroll Lakes Project” (unit 4) administered by the Pikes Peak Ranger District. The PSINF site is classified as Ponderosa pine (Pinus ponderosa) and dry-mesic mixed conifer, where a “free thin” prescription was implemented across an 8.9 ha (22-acre) treatment unit using a combination of mechanical equipment and hand-thinning. The pre-treatment overstory consisted of Engelmann spruce (Picea engelmannii), blue spruce (Picea pungens), Ponderosa pine, and Douglas-fir (Pseudotsuga menziesii), alongside a quaking aspen (Populus tremuloides) component. Management objectives focused on transitioning the forest from mid-closed to more open and complex structural stages by promoting a heterogeneous, “groupy” spatial arrangement. These efforts prioritized the retention of large or old-growth trees and the expansion of aspen to create a landscape capable of supporting natural wildfire and insect disturbance regimes within their historical ranges. For the harvesting process, larger trees were whole-tree yarded and skidded to landings for processing with residual waste mechanically piled, while smaller material was hand-piled throughout the site. Additionally, the prescription required the retention of 50 linear feet per acre of downed coarse woody debris (at least 12 inches in diameter) independent of the piled material. 1.2.1.2 TRFO-BLM Pinyon-Juniper Site Located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM) the treatment was part of a “Pinyon-Juniper Adaptive Silviculture Project” with a uniform thinning treatment prescription. In this heavy intensity uniform thinning treatment unit, the prescription was designed to reduce fuel loads by maintaining significant spacing between residual tree crowns. The prescription prioritizes the retention of healthy, productive, and large-diameter pinyon pine (Pinus edulis) and Rocky Mountain juniper (Juniperus scopulorum) trees. This thinning strategy aims for a residual forest structure characterized by open interspaces with uniform gaps between trees that minimize vertical and horizontal fuel continuity. Fortunately for the present research, we have the exact, detailed wording of the slash pile construction prescription: No less than 90% of all cut trees, live limbs and slash shall be piled. Piles are to be constructed to facilitate burning by the government at a later date. Minimum pile size is 5x5x5 feet. The contractor shall construct piles that are sufficiently compacted to allow for a high percentage of consumption from burning, this may require multiple cutting of stems, compacting the pile with equipment or other approved techniques. Piles should be constructed with branches and smaller diameter fuels piled on bottom and larger limbs/bole wood piled on top. Piles should be spaced appropriately away from leave trees to avoid damage from burning. Anticipate flame lengths twice the piled fuel height when placing piles i.e (5 ft tall pile will have 10 ft flame lengths so pile should be placed at least 10 ft away from the nearest reserve trees). Piles will be constructed in a way to prevent toppling. Piles may be placed on stumps. Oak and other brush cut will need to be added to the piles. Piles shall not be constructed in swales, streams, springs, or within 15 feet any recreational trail within the units. Piles shall not be placed on or near any cadastral survey markers. Piles may not be built under any electrical transmission line or utility line. Piles shall be free of soil. Site managers also provided anecdotal feedback about the on-the-ground prescription implementation, noting that the piles were “larger than expected” and “messy,” and were constructed too close to residual trees. The prescription specified a minimum pile size of 1.5 meters (5 feet) long, wide, and tall, but provided no explicit maximum size. This absence of a maximum size makes the anecdotal feedback particularly relevant for setting up our pile detection methodology. The close proximity of piles to trees, which resulted in tree mortality on other units when piles were burned, may also complicate our detection methodology, as the structural and spectral signatures of the piles and trees may merge in both the CHM and RGB raster data. 1.2.1.3 BHEF Ponderosa Pine Site The study at the Black Hills Experimental Forest included a series of ponderosa pine (Pinus ponderosa) mechanical treatments designed to transition stands from uniform densities to a heterogeneous mosaic of individuals, clumps, and openings. The silvicultural objectives prioritize both horizontal and vertical complexity, using varying tree-marking strategies to recreate historical stand structures and spatial distributions. Five distinct marking approaches were implemented to promote a “groupy” forest structure, ranging from fixed cut-to-leave ratios to a specialized Individuals, Clumps, and Openings (ICO) prescription. Following the marking process, the units were mechanically thinned using whole-tree removal with trees skidded to designated landing areas for processing and all residual material mechanically piled at the landings. 1.2.1.4 ARNF Ponderosa Pine Site Information is from the silvicultural prescriptions for the “Cherokee Park Project” (units 18, 19) administered by the Canyon Lakes Ranger District. The ARNF site is classified as predominantly a Ponderosa pine (Pinus ponderosa) and Douglas-fir (Pseudotsuga menziesii) forest. Treatment objectives are to restore ecosystems to a state representative of natural disturbance regimes while reducing crown fire risk. The silvicultural prescription, characterized as group selection with retention and variable matrix thinning, aims to create a heterogeneous, multi-aged stand structure defined by irregular openings and clusters of interlocking tree crowns. Mechanical thinning was focused on removing smaller diameter classes and competing Douglas-fir to prioritize the retention of the largest, healthiest, and oldest Ponderosa pine across the treatment area. The desired residual structure is horizontally and vertically diverse where untreated patches and variable tree densities create a complex arrangement of individual trees, clumps, and clearings. During mechanical harvest, trees were whole-tree yarded and skidded to landings for processing with residual waste mechanically piled for future prescribed burning. 1.3 Analysis Plan We will follow the general analysis outline in five distinct sections: Data Overview: We will detail the study sites, summarize the number of piles and the pile size based on available measurements, and review the RGB orthomosaic data Point Cloud Processing: We will demonstrate how to process the point cloud data to generate the required inputs for the propose pile detection method. Geometry-based Slash Pile Detection: We will detail the geometry-based slash pile detection method which uses user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-DAP point cloud data. Spectral Refinement Methodology: We will detail the complementary spectral refinement methodology which uses RGB data to filter the structurally-detected candidate piles. Method Evaluation Detail: We will detail and demonstrate our method evaluation process in which we review detection accuracy metrics (e.g. Precision, Recall, F-Score) and quantification accuracy metrics (e.g. height MAPE, diameter RMSE, etc.) Experimental Methodology Predictions: We will make predictions using our proposed training-free, rules-based methodology for identifying slash piles from UAS data with the structural and spectral data fusion approach. Detection Accuracy: We will evaluate the accuracy of the structural-plus-spectral data fusion methodology in terms of slash pile detection (F-score, Recall, Precision). Quantification Accuracy: We will evaluate the accuracy of the structural-plus-spectral data fusion methodology in terms of slash pile form quantification (e.g. height and diameter MAPE, RMSE, ME). "],["data_load.html", "Section 2 Data Overview 2.1 Study Units Vector Data 2.2 Slash Pile Vector Data 2.3 RGB orthomosaic 2.4 Slash Pile RGB Imagery", " Section 2 Data Overview We will detail the study sites and summarize the number of piles and the pile size based on available measurements. Site Name Pile Type Validation Data Type Unique Features &amp; Ecology Data Collection (UAS Platform &amp; Parameters) PSINF Mixed Conifer Site Hand Piles and smaller machine piles Image-annotated footprints and field-measured height and diameter Located in the Pike and San Isabel National Forest (PSINF) in CO, US. Mixed conifer stand with variable ground cover and canopy density. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. TRFO-BLM Pinyon-Juniper Site Hand Piles Image-annotated footprints based on field collected point locations Located on BLM land in CO, US. Arid environment with dry vegetation including standing dead pinyon-juniper. Piles are smaller, simpler, and hand-stacked. Freefly Astro with Sony ILX-LR1 (35mm lens). Altitude 243.84 m (terrain following), 85% forward and 80% side overlap. BHEF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Black Hills Experimental Forest (BHEF) in SD, US. Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected. DJI Phantom 4 Pro with 20 MP RGB sensor (8.8 mm lens). Altitude 80 m, 90% forward and 85% side overlap, 4 m/s speed. ARNF Ponderosa Pine Site Machine Piles Image-annotated footprints Located in the Arapahoe and Roosevelt National Forest (ARNF) in CO, US. Ponderosa pine forest with a climate similar to PSINF. Machine piles are massive but more circular and regular. Less regeneration is expected. Switchblade-Elite (Vision Aerial) with 24.2 MP RGB sensor (16 mm lens). Altitude xx m, 90% forward and 85% side overlap, 4 m/s speed. Load the standard libraries we use to do work # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(ggnewscale) # new scale library(ggrepel) # repel labels library(grDevices) # default graphics # spatial analysis library(terra) # raster library(sf) # simple features library(lwgeom) # advanced functions for spatial operations library(lidR) # lidar data library(rgl) # 3d plots library(cloud2trees) # the cloud2trees 2.1 Study Units Vector Data let’s load in all the vector data containing the study units we’ll combine the study unit boundaries for all sites to create a spatial data set that contains all units for plotting in a single map # read the data # stand boundary all_stand_boundary &lt;- dplyr::bind_rows( psinf_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , pj_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , bhef_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) , arnf_stand_boundary %&gt;% sf::st_transform(crs = 5070) %&gt;% dplyr::select(site) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) ) %&gt;% dplyr::group_by(site) %&gt;% dplyr::summarise( geometry = sf::st_union(geometry) ) %&gt;% dplyr::ungroup() %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( site_area_m2 = sf::st_area(geometry) %&gt;% as.numeric() , site_area_ha = site_area_m2/10000 , site_data_lab = dplyr::case_match( site , &quot;PSINF Mixed Conifer Site&quot; ~ &quot;psinf&quot; , &quot;TRFO-BLM Pinyon-Juniper Site&quot; ~ &quot;pj&quot; , &quot;BHEF Ponderosa Pine Site&quot; ~ &quot;bhef&quot; , &quot;ARNF Ponderosa Pine Site&quot; ~ &quot;arnf&quot; ) ) # sf::st_centroid() %&gt;% # sf::st_sf() %&gt;% Let’s map the study sites on a single map sites_pal &lt;- RColorBrewer::brewer.pal(n = nrow(all_stand_boundary), name = &quot;Dark2&quot;) # option to put satellite imagery as base layer of mapview maps mapview::mapviewOptions( homebutton = T # , basemaps = c(&quot;Esri.WorldImagery&quot;,&quot;OpenStreetMap&quot;) , basemaps = c(&quot;OpenStreetMap&quot;, &quot;Esri.WorldImagery&quot;) ) # map it mapview::mapview( all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_centroid() , zcol=&quot;site&quot; , col.regions = sites_pal , cex = 8 , layer.name = &quot;study sites&quot; ) static map for printing let’s make a pretty image for use in the journal article. we’ll use the ggmap package to get a nice background map and do some transformation to actually work with the map. We’ll add a map scale using ggspatial library(ggmap) library(ggspatial) ######################################################################### ######################################################################### # Make each plot individually by landscape as solution to small multiples # this block defines function ######################################################################### ##################hack to align plots for ggmap ggmap_bbox_fn &lt;- function(map, my_crs=3857) { if (!inherits(map, &quot;ggmap&quot;)) stop(&quot;map must be a ggmap object&quot;) # Extract the bounding box (in lat/lon) from the ggmap to a numeric vector, # and set the names to what sf::st_bbox expects: map_bbox &lt;- setNames(unlist(attr(map, &quot;bb&quot;)), c(&quot;ymin&quot;, &quot;xmin&quot;, &quot;ymax&quot;, &quot;xmax&quot;)) # Convert the bbox to an sf polygon, transform it to 3857, # and convert back to a bbox (convoluted, but it works) bbox_3857 &lt;- st_bbox(st_transform(st_as_sfc(st_bbox(map_bbox, crs = 4326)), my_crs)) # Overwrite the bbox of the ggmap object with the transformed coordinates attr(map, &quot;bb&quot;)$ll.lat &lt;- bbox_3857[&quot;ymin&quot;] attr(map, &quot;bb&quot;)$ll.lon &lt;- bbox_3857[&quot;xmin&quot;] attr(map, &quot;bb&quot;)$ur.lat &lt;- bbox_3857[&quot;ymax&quot;] attr(map, &quot;bb&quot;)$ur.lon &lt;- bbox_3857[&quot;xmax&quot;] map } plt_crs &lt;- 3857 ######################################################################### ######################################################################### ######################################################################### my_ggmap_basemap &lt;- function(sf_data, zoom_level = 14, buffer_box = 2600, my_crs = plt_crs, scale_location = &quot;bl&quot;, my_maptype = &quot;stamen_terrain&quot;) { # # should zoom in? # zoom_level &lt;- 14 # 11 # # should buffer extend? # buffer_box &lt;- 2600 # 20000 # bounding box bb_temp &lt;- sf_data %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_transform(crs=5070) %&gt;% sf::st_buffer(as.numeric(buffer_box)) %&gt;% sf::st_transform(crs=4326) %&gt;% # same as get_map return sf::st_bbox() # set bbox for get call bbox_temp &lt;- c( bottom = bb_temp[[2]] , top = bb_temp[[4]] , right = bb_temp[[3]] , left = bb_temp[[1]] ) hey_ggmap &lt;- ggmap::get_stadiamap( bbox = bbox_temp , zoom = zoom_level , maptype = my_maptype #&quot;stamen_terrain&quot; #&quot;stamen_toner_lite&quot; , crop = T ) # ggmap::ggmap(hey_ggmap) # apply align function hey_ggmap_aligned &lt;- ggmap_bbox_fn(hey_ggmap, my_crs) # Use the function # plot plt_basemap &lt;- ggmap::ggmap(hey_ggmap_aligned) + ggplot2::coord_sf( expand = FALSE ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , plot.title = ggplot2::element_blank() , strip.text = ggplot2::element_blank() , axis.title = ggplot2::element_blank() , axis.text = ggplot2::element_blank() , axis.ticks = ggplot2::element_blank() , panel.grid = ggplot2::element_blank() , plot.margin = ggplot2::margin(0, 0, 0, 0, &quot;cm&quot;) ) if(scale_location %in% c(&quot;bl&quot;, &quot;br&quot;, &quot;tr&quot;, &quot;tl&quot;)){ plt_basemap &lt;- plt_basemap + ggspatial::annotation_scale( location = scale_location , style = &quot;ticks&quot; , pad_x = unit(0.1, &quot;cm&quot;) , pad_y = unit(0.1, &quot;cm&quot;) ) } return(plt_basemap) } plot the fancy basemap with the points # get the basemap with our my_ggmap_basemap() plt_basemap &lt;- my_ggmap_basemap( sf_data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() , buffer_box = 190000 , zoom_level = 7 , my_maptype = &quot;stamen_terrain&quot; ) # plt_basemap # plot plt2_temp &lt;- plt_basemap + ggplot2::geom_sf( data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(fill = site) , size = 4.5 , inherit.aes = F , shape = 21 , color = &quot;gray88&quot; , fill = &quot;blue2&quot; ) + ggplot2::geom_sf_label( data = all_stand_boundary %&gt;% dplyr::group_by(site) %&gt;% sf::st_point_on_surface() %&gt;% sf::st_transform(crs=plt_crs) , mapping = ggplot2::aes(label = stringr::str_wrap(site, width = 40)) , size = 2.5 , hjust = -0.055 , vjust = 0.4 , inherit.aes = F ) + ggplot2::scale_fill_manual(values = sites_pal) plt2_temp what is the area of the treatment unit boundaries we are looking over? all_stand_boundary %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(site, site_area_ha) %&gt;% dplyr::mutate( site_area_ha = scales::comma(site_area_ha, suffix = &quot; ha&quot;, accuracy = 0.1) ) %&gt;% kableExtra::kbl( caption = &quot;Study site area&quot; , col.names = c( &quot;site&quot;, &quot;hectares&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 2.1: Study site area site hectares ARNF Ponderosa Pine Site 73.6 ha BHEF Ponderosa Pine Site 103.1 ha PSINF Mixed Conifer Site 17.5 ha TRFO-BLM Pinyon-Juniper Site 5.2 ha 2.2 Slash Pile Vector Data Image-annotated pile footprints at each study site were created in a GIS by outlining pile boundaries on the RGB orthomosaic and confirming the vertical structure using fine-resolution CHM data (e.g., 0.15m resolution). Field-collected points were used to ensure pile census completeness at the hand-pile study sites (PSINF Mixed Conifer Site and TRFO-BLM Pinyon-Juniper Site) to pinpoint piles that were otherwise challenging to delineate from the aerial imagery and CHM data alone. Across all sites, machine piles were easily distinguishable using the RGB and CHM data. Let’s load in those image-annotated pile polygons now for each study site. ####################################### # polygons annotated using RGB and field-collected points ####################################### ########################### # PSINF Mixed Conifer Site ########################### psinf_slash_piles_polys &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/manitou_pile_polys.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::ungroup() %&gt;% dplyr::mutate(treeID = dplyr::row_number()) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID, shape_leng, shape_area)) %&gt;% dplyr::mutate(site = &quot;PSINF Mixed Conifer Site&quot;) # points recorded in field psinf_slash_piles_points &lt;- sf::st_read( &quot;../data/PFDP_Data/PFDP_SlashPiles/SlashPiles.shp&quot; , quiet = T ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_zm() %&gt;% sf::st_transform(sf::st_crs(psinf_slash_piles_polys)) %&gt;% dplyr::filter( !(objectid %in% c(43)) ) %&gt;% # duplicate field points dplyr::mutate(row_number = dplyr::row_number()) %&gt;% dplyr::select(-c(objectid)) %&gt;% dplyr::rename( height_ft = height , diameter_ft = diameter ) # update unit boundary to pile proj psinf_stand_boundary &lt;- psinf_stand_boundary %&gt;% sf::st_transform(sf::st_crs(psinf_slash_piles_polys)) # attach flag for spatial overlap with unit boundary psinf_slash_piles_polys &lt;- psinf_slash_piles_polys %&gt;% dplyr::left_join( psinf_slash_piles_polys %&gt;% sf::st_intersection(psinf_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # TRFO-BLM Pinyon-Juniper Site ########################### pj_slash_piles_polys &lt;- sf::st_read(&quot;../data/Dawson_Data/piles/pj_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID,id)) %&gt;% dplyr::filter(pile_id!=62) %&gt;% dplyr::mutate(site = &quot;TRFO-BLM Pinyon-Juniper Site&quot;) # points recorded in field # these piles were collected twice in the same location and have different measurements :\\ bad_pile_ids_temp &lt;- c( 142 , 146 , 99 , 96 , 50 ) pj_slash_piles_points &lt;- readr::read_csv(&quot;../data/Dawson_data/PJ_Piles_Unit_10.csv&quot;, progress = T, show_col_types = F) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename_with(stringr::str_squish) %&gt;% dplyr::rename_with(make.names) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.{2,}&quot;, &quot;.&quot;)) %&gt;% dplyr::rename_with(~stringr::str_remove(.x, &quot;\\\\.$&quot;)) %&gt;% dplyr::rename_with(~stringr::str_replace_all(.x, &quot;\\\\.&quot;, &quot;_&quot;)) %&gt;% dplyr::mutate( orig_pile_id = readr::parse_number(name) ) %&gt;% dplyr::filter( !(orig_pile_id %in% bad_pile_ids_temp) ) %&gt;% sf::st_as_sf(coords = c(&quot;easting&quot;,&quot;northing&quot;), crs = 6342, remove = F) %&gt;% dplyr::select(orig_pile_id,name,height_m,width_m,easting,northing,latitude,longitude,code,description,elevation) %&gt;% sf::st_make_valid() %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_polys)) # update unit boundary to pile proj pj_stand_boundary &lt;- pj_stand_boundary %&gt;% sf::st_transform(sf::st_crs(pj_slash_piles_polys)) # attach flag for spatial overlap with unit boundary pj_slash_piles_polys &lt;- pj_slash_piles_polys %&gt;% dplyr::left_join( pj_slash_piles_polys %&gt;% sf::st_intersection(pj_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # BHEF Ponderosa Pine Site ########################### bhef_slash_piles_polys &lt;- sf::st_read(&quot;../data/BHEF_202306/piles/bhef_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% dplyr::mutate(site = &quot;BHEF Ponderosa Pine Site&quot;) # update unit boundary to pile proj bhef_stand_boundary &lt;- bhef_stand_boundary %&gt;% sf::st_transform(sf::st_crs(bhef_slash_piles_polys)) # attach flag for spatial overlap with unit boundary bhef_slash_piles_polys &lt;- bhef_slash_piles_polys %&gt;% dplyr::left_join( bhef_slash_piles_polys %&gt;% sf::st_intersection(bhef_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) ########################### # ARNF Ponderosa Pine Site ########################### arnf_slash_piles_polys &lt;- sf::st_read(&quot;../data/ARNF_DiamondView_202510/arnf_diamond_view_pile_polys.shp&quot;, quiet=T) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # fix multipolygons dplyr::mutate( pile_id = dplyr::row_number() , treeID = dplyr::row_number() ) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-c(treeID)) %&gt;% dplyr::mutate(site = &quot;ARNF Ponderosa Pine Site&quot;) # update unit boundary to pile proj arnf_stand_boundary &lt;- arnf_stand_boundary %&gt;% sf::st_transform(sf::st_crs(arnf_slash_piles_polys)) # attach flag for spatial overlap with unit boundary arnf_slash_piles_polys &lt;- arnf_slash_piles_polys %&gt;% dplyr::left_join( arnf_slash_piles_polys %&gt;% sf::st_intersection(arnf_stand_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate( is_in_stand = dplyr::coalesce(is_in_stand, F) ) 2.2.1 Standardize Pile Data For the sites with field-collected point data, each point may not necessarily fall within the polygon boundary (e.g. due to misalignment between the imagery and point locations or slight inaccuracies in either the point or pile boundaries). So, we need to perform a matching process to tie the points to the polygons so that we get the height and diameter measured during the point collection attached to the polygons. to do this, we’ll use a two-stage process that first attaches the points data frame to polygons where points fall within, using a spatial intersection. It then finds and assigns the remaining, unjoined points to their nearest polygon. The final output includes all polygons from the original data, ensuring that every polygon is represented even if no points were matched. # function to perform a two-step spatial join # first matching points that fall inside polygons and # then assigning the remaining points to the nearest polygon # all original polygons are returned in the final output match_points_to_polygons &lt;- function( points_sf , polygons_sf , point_id , polygon_id ) { # check if point_id column exists in points_sf if (!point_id %in% names(points_sf)) { stop(paste0(&quot;column &#39;&quot;, point_id, &quot;&#39; not found in points_sf.&quot;)) } # check if polygon_id column exists in polygons_sf if (!polygon_id %in% names(polygons_sf)) { stop(paste0(&quot;column &#39;&quot;, polygon_id, &quot;&#39; not found in polygons_sf.&quot;)) } # 1. ensure the crs are the same. if (sf::st_crs(points_sf) != sf::st_crs(polygons_sf)) { points_sf &lt;- sf::st_transform(points_sf, sf::st_crs(polygons_sf)) } # 2. Perform a standard spatial join for points within polygons. # Use an inner join (`left = FALSE`) to get only points that fall inside. points_within &lt;- sf::st_join( x = points_sf , y = polygons_sf , join = sf::st_intersects , left = FALSE ) # 3. Identify points that were not matched in the first step. matched_points_ids &lt;- points_within[[point_id]] unmatched_points &lt;- points_sf[!points_sf[[point_id]] %in% matched_points_ids, ] if (nrow(unmatched_points) &gt; 0) { # 4. For the remaining points, find the index of the nearest polygon. nearest_polygon_index &lt;- sf::st_nearest_feature(unmatched_points, polygons_sf) # 5. Extract the nearest polygons and join their attributes to the unmatched points. nearest_polygons &lt;- polygons_sf[nearest_polygon_index, ] points_nearest &lt;- data.frame(unmatched_points, sf::st_drop_geometry(nearest_polygons)) # Preserve the geometry from the original unmatched points for the nearest matches. points_nearest &lt;- sf::st_set_geometry(points_nearest, sf::st_geometry(unmatched_points)) # 6. Combine the results from the &quot;points_within&quot; and &quot;points_nearest&quot; joins. combined_points &lt;- dplyr::bind_rows(points_within, points_nearest) } else { # If all points were matched in step 2. combined_points &lt;- points_within } # names diff cols_add &lt;- c( base::setdiff( names(combined_points) , names(polygons_sf) ) , polygon_id ) # 7. Perform a left join to ensure all original polygons are included in the final output. # Polygons without any matched points will have `NA` values for the point attributes. final_result &lt;- polygons_sf %&gt;% dplyr::left_join( combined_points %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(cols_add)) , by = polygon_id ) return(final_result) } we’ll also define a function to get the diameter of the polygon which we will use to extract diameter from our predicted segments to compare with the field-measured diameter values. we can also compare the field-measured diameter to the image-annotated diameter as a sanity check. let’s define a function to get polygon diameter that accurately reflects the measurement for potentially irregular shapes. we’ll calculate the diameter by finding the maximum distance across the footprint of the entire polygon ###___________________________________________### # calculate diameter of single polygon ###___________________________________________### # function to calculate the diamater of an sf polygon that is potentially irregularly shaped # using the distance between the farthest points st_calculate_diameter_polygon &lt;- function(polygon) { # get the convex hull ch &lt;- sf::st_convex_hull(polygon) # cast to multipoint then point to get individual vertices ch_points &lt;- sf::st_cast(ch, &#39;MULTIPOINT&#39;) %&gt;% sf::st_cast(&#39;POINT&#39;) # calculate the distances between all pairs of points distances &lt;- sf::st_distance(ch_points) # find the maximum distance, which is the diameter diameter &lt;- as.numeric(max(distances,na.rm=T)) return(diameter) } # apply st to sf data st_calculate_diameter &lt;- function(sf_data) { if(!inherits(sf_data,&quot;sf&quot;)){stop(&quot;st_calculate_diameter() requires polygon sf data&quot;)} if( !all( sf::st_is(sf_data, c(&quot;POLYGON&quot;,&quot;MULTIPOLYGON&quot;)) ) ){ stop(&quot;st_calculate_diameter() requires polygon sf data&quot;) } # get the geometry column name geom_col_name &lt;- attr(sf_data, &quot;sf_column&quot;) # calculate diameter # !!rlang::sym() unquotes the geometry column return_dta &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate(diameter_m = st_calculate_diameter_polygon( !!rlang::sym(geom_col_name) )) %&gt;% dplyr::ungroup() return(return_dta) } let’s apply our match_points_to_polygons() and st_calculate_diameter() functions For only the PSINF mixed conifer site, slash pile field measurements were taken by measuring the height and diameter (longest side of pile) using a laser hypsometer For volume estimation, we’ll model the ground truth slash piles as a paraboloid, specifically a parabolic dome, assuming a perfectly circular base and sides curved smoothly to a peak. Assuming a paraboloid shape is common for quantifying slash pile volume (Hardy 1996; Long &amp; Boston 2014) and may better represent the diverse shapes of real-world slash piles than assuming a conical or half-sphere form. A paraboloid can represent a variety of shapes including those that are taller and more conical, or flatter and more spread out, because it allows the measured height and width to influence the volume calculation independently. This makes the paraboloid potentially more robust for estimating volumes of piles with varying aspect ratios. the volume formula for a paraboloid is: \\[ V = \\frac{1}{8}\\pi \\cdot width^2 \\cdot height \\] # PSINF Mixed Conifer Site psinf_slash_piles_polys &lt;- match_points_to_polygons( points_sf = psinf_slash_piles_points , polygons_sf = psinf_slash_piles_polys , point_id = &quot;row_number&quot; , polygon_id = &quot;pile_id&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( # height field_height_m = height_ft*0.3048 , field_diameter_m = diameter_ft*0.3048 # *0.3048 or /3.281 to convert to m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() , field_gt_area_m2 = pi*field_radius_m^2 # volume ASSUMING PERFECT GEOMETRIC SHAPE :/ , image_gt_volume_m3 = (1/8) * pi * (image_gt_diameter_m^2) * field_height_m , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * field_height_m ) # TRFO-BLM Pinyon-Juniper Site pj_slash_piles_polys &lt;- match_points_to_polygons( points_sf = pj_slash_piles_points , polygons_sf = pj_slash_piles_polys , point_id = &quot;orig_pile_id&quot; , polygon_id = &quot;pile_id&quot; ) %&gt;% dplyr::ungroup() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_calculate_diameter() %&gt;% dplyr::rename( image_gt_diameter_m = diameter_m , field_height_m = height_m ) %&gt;% # calculate area and volume dplyr::mutate( # height field_diameter_m = width_m , field_radius_m = (field_diameter_m/2) , image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() , field_gt_area_m2 = pi*field_radius_m^2 # volume ASSUMING PERFECT GEOMETRIC SHAPE :/ , image_gt_volume_m3 = (1/8) * pi * (image_gt_diameter_m^2) * field_height_m , field_gt_volume_m3 = (1/8) * pi * (field_diameter_m^2) * field_height_m ) # BHEF Ponderosa Pine Site bhef_slash_piles_polys &lt;- bhef_slash_piles_polys %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) # ARNF Ponderosa Pine Site arnf_slash_piles_polys &lt;- arnf_slash_piles_polys %&gt;% st_calculate_diameter() %&gt;% dplyr::rename(image_gt_diameter_m = diameter_m) %&gt;% # calculate area and volume dplyr::mutate( image_gt_area_m2 = sf::st_area(.) %&gt;% as.numeric() ) 2.2.2 Pile Form Measurements let’s make some reusable functions to make the same tables throughout the analysis # aggregate agg_piles_temp &lt;- function(df) { df %&gt;% dplyr::filter(is_in_stand) %&gt;% # dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( dplyr::any_of(c(&quot;site&quot;, &quot;pile_type&quot;)) , tidyselect::contains(&quot;area_m2&quot;) | tidyselect::contains(&quot;diameter_m&quot;) | tidyselect::contains(&quot;height_m&quot;) # | tidyselect::contains(&quot;volume_m3&quot;) ) %&gt;% dplyr::summarise( dplyr::across( dplyr::where(~ is.character(.x) | is.factor(.x)) , .fns = dplyr::first ) , dplyr::across( dplyr::where(is.numeric) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) # , q10 = ~quantile(.x,na.rm=T,probs=0.1) # , q50 = ~quantile(.x,na.rm=T,probs=0.5) # , q90 = ~quantile(.x,na.rm=T,probs=0.9) # , min = ~min(.x,na.rm=T) # , max = ~max(.x,na.rm=T) , range = ~paste0( scales::comma(min(.x,na.rm=T), accuracy = 0.1) ,&quot;-&quot; , scales::comma(max(.x,na.rm=T), accuracy = 0.1) ) ) ) , n = dplyr::n() ) %&gt;% dplyr::ungroup() } # function to kableExtra kbl_form_sum_stats_wide &lt;- function(df, by_lab = &quot;&quot;) { df %&gt;% dplyr::mutate( n = scales::comma(n,accuracy=1) , dplyr::across( dplyr::where(is.numeric) , ~scales::comma(.x,accuracy=0.1) ) ) %&gt;% kableExtra::kbl( caption = paste0( &quot;Slash pile image-annotated and field-collected form measurements&quot; ,&quot;&lt;br&gt;&quot; , by_lab ) , col.names = c( &quot; &quot;, &quot;Piles&quot; , rep(c(&quot;Mean&quot;,&quot;Std Dev&quot;,&quot;Range&quot;), times = 4) ) , escape = F ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above( c( &quot; &quot;=2 , &quot;Image-Ann. Area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; = 3 , &quot;Image-Ann. Diam (m)&quot; = 3 , &quot;Field-Meas. Diam (m)&quot; = 3 , &quot;Field-Meas. Height (m)&quot; = 3 ) , escape = F ) %&gt;% kableExtra::column_spec(seq(2,14,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% kableExtra::column_spec( column = 2:14 , extra_css = &quot;font-size: 11px;&quot; , include_thead = T ) %&gt;% kableExtra::scroll_box(width = &quot;740px&quot;) } ## for a single site kbl_form_sum_stats_long &lt;- function( pile_df , caption = &quot;Ground Truth Piles: summary statistics for form measurements&quot; ) { pile_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( tidyselect::contains(&quot;area_m2&quot;) | tidyselect::contains(&quot;diameter_m&quot;) | tidyselect::contains(&quot;height_m&quot;) | tidyselect::contains(&quot;volume_m3&quot;) ) %&gt;% dplyr::summarise( dplyr::across( dplyr::everything() , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , q10 = ~quantile(.x,na.rm=T,probs=0.1) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , q90 = ~quantile(.x,na.rm=T,probs=0.9) , min = ~min(.x,na.rm=T) , max = ~max(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% # dplyr::ungroup() %&gt;% tidyr::pivot_longer(cols = -c(n)) %&gt;% dplyr::mutate( agg = stringr::word(name,-1,sep = &quot;_&quot;) , metric = stringr::str_remove_all(name, paste0(&quot;_&quot;,agg)) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% dplyr::coalesce(&quot;detection&quot;) %&gt;% stringr::str_c( dplyr::case_when( stringr::str_detect(name,&quot;(field|image)&quot;) ~ paste0(&quot; (&quot;, stringr::str_extract(name,&quot;(field|image)&quot;), &quot;)&quot;) , T ~ &quot;&quot; ) ) %&gt;% stringr::str_replace(&quot;area&quot;, &quot;area m&lt;sup&gt;2&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;volume&quot;, &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&quot;) %&gt;% stringr::str_replace(&quot;diameter&quot;, &quot;diameter m&quot;) %&gt;% stringr::str_replace(&quot;height&quot;, &quot;height m&quot;) %&gt;% stringr::str_to_sentence() ) %&gt;% # dplyr::count(metric) dplyr::select(-name) %&gt;% dplyr::mutate( value = dplyr::case_when( # metric == &quot;gt_height_m&quot; ~ scales::comma(value,accuracy=0.1) T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = agg, values_from = value) %&gt;% dplyr::mutate( range = paste0(min, &quot;—&quot;, max) ) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::select(-c(min,max)) %&gt;% kableExtra::kbl( caption = caption , col.names = c( &quot;# piles&quot;, &quot;Metric&quot; , &quot;Mean&quot; , &quot;Std Dev&quot; , &quot;q 10%&quot;, &quot;Median&quot;, &quot;q 90%&quot; , &quot;Range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 13) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) } summary statistics for the form measurements for all study sites agg_piles_temp( psinf_slash_piles_polys %&gt;% dplyr::select(-tidyselect::starts_with(&quot;field_gt_area&quot;)) ) %&gt;% dplyr::bind_rows( agg_piles_temp( pj_slash_piles_polys %&gt;% dplyr::select( -tidyselect::contains(&quot;field&quot;) , -tidyselect::contains(&quot;height&quot;) ) ) , agg_piles_temp(bhef_slash_piles_polys) , agg_piles_temp(arnf_slash_piles_polys) ) %&gt;% dplyr::select( site, n , tidyselect::starts_with(&quot;image_&quot;) , tidyselect::starts_with(&quot;field_&quot;) ) %&gt;% kbl_form_sum_stats_wide(by_lab = &quot;by study site&quot;) Table 2.2: Slash pile image-annotated and field-collected form measurementsby study site Image-Ann. Area (m2) Image-Ann. Diam (m) Field-Meas. Diam (m) Field-Meas. Height (m) Piles Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range PSINF Mixed Conifer Site 121 9.8 9.4 3.9-59.3 3.8 1.3 2.6-10.2 3.4 1.2 2.4-9.0 2.2 0.8 1.5-6.4 TRFO-BLM Pinyon-Juniper Site 277 10.6 3.2 4.1-25.3 4.2 0.6 2.6-6.4 NA NA NA NA NA NA BHEF Ponderosa Pine Site 26 199.9 85.8 76.0-408.7 21.0 6.5 13.3-38.0 NA NA NA NA NA NA ARNF Ponderosa Pine Site 19 409.0 97.1 221.5-593.1 25.9 3.6 18.4-32.9 NA NA NA NA NA NA All sites except PSINF have only mechanical or only hand piles whereas PSINF has both hand piles and mechanical piles. Let’s look at the summary statistics for the form measurements for only PSINF based on pile construction type psinf_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::select( -tidyselect::contains(&quot;volume_m3&quot;) , -tidyselect::starts_with(&quot;field_gt_area&quot;) , -c(site) ) %&gt;% dplyr::rename(pile_type = comment) %&gt;% dplyr::group_by(pile_type) %&gt;% agg_piles_temp() %&gt;% dplyr::select( pile_type, n , tidyselect::starts_with(&quot;image_&quot;) , tidyselect::starts_with(&quot;field_&quot;) ) %&gt;% kbl_form_sum_stats_wide(by_lab = &quot;PSINF Mixed Conifer Site by pile type&quot;) Table 2.3: Slash pile image-annotated and field-collected form measurementsPSINF Mixed Conifer Site by pile type Image-Ann. Area (m2) Image-Ann. Diam (m) Field-Meas. Diam (m) Field-Meas. Height (m) Piles Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Mean Std Dev Range Hand Pile 111 7.2 1.7 3.9-14.3 3.5 0.4 2.6-5.0 3.1 0.3 2.4-4.3 2.0 0.2 1.5-2.4 Mechanical Pile 10 38.3 12.7 21.3-59.3 8.0 1.3 5.9-10.2 7.2 1.1 5.5-9.0 4.4 1.2 2.4-6.4 2.2.3 Image-Annotation Comparison For only the PSINF site, let’s check the field-collected and image-annotated measurements of diameter which will serve as a good sanity check for our image-annotation process (assuming diameter was accurately measured in the field…might be a perilous assumption) psinf_slash_piles_polys %&gt;% dplyr::mutate(diff_diameter_m = image_gt_diameter_m - field_diameter_m) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = image_gt_diameter_m, y = field_diameter_m)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(ggplot2::aes(color = diff_diameter_m)) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(psinf_slash_piles_polys$field_diameter_m,na.rm=T), max(psinf_slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(psinf_slash_piles_polys$field_diameter_m,na.rm=T), max(psinf_slash_piles_polys$image_gt_diameter_m,na.rm=T) ) )) + ggplot2::labs( x = &quot;image-annotated diameter (m)&quot;, y = &quot;field-collected diameter (m)&quot; , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = &quot;diameter (m) comparison&quot; ) + ggplot2::theme_light() the plot makes these values look very similar with the image-annotated diameter generally larger than the field-collected value. let’s check these using lm() lm_temp &lt;- lm(field_diameter_m ~ image_gt_diameter_m, data = psinf_slash_piles_polys) summary(lm_temp) ## ## Call: ## lm(formula = field_diameter_m ~ image_gt_diameter_m, data = psinf_slash_piles_polys) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.18985 -0.16525 0.01416 0.16807 1.76883 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.13522 0.09891 1.367 0.174 ## image_gt_diameter_m 0.86403 0.02436 35.471 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3593 on 119 degrees of freedom ## (66 observations deleted due to missingness) ## Multiple R-squared: 0.9136, Adjusted R-squared: 0.9129 ## F-statistic: 1258 on 1 and 119 DF, p-value: &lt; 2.2e-16 Our slope of 0.86 is close to 1 and, along with our high R-squared value of 91%, indicate our image- and field-measured diameters are well-calibrated let’s use a paired t-test to determine if the mean difference (MD) between the field-measured diameter and the image-annotated diameter is statistically significant (i.e. significantly different from zero) # is the mean difference between the two diameters significantly different from zero ttest_temp &lt;- t.test( psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) , psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(field_diameter_m) and psinf_slash_piles_polys %&gt;% dplyr::filter(!is.na(field_diameter_m), !is.na(image_gt_diameter_m)) %&gt;% dplyr::pull(image_gt_diameter_m) ## t = -10.563, df = 120, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -0.4583169 -0.3136208 ## sample estimates: ## mean difference ## -0.3859688 the mean difference (MD) is -0.39 m (field-measured minus image-annotated value). also, the p-value of 0.00001 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where image-annotated diameter is larger than the field-measured diameter is statistically significant and not due to random chance 2.3 RGB orthomosaic Orthomosaic tif files from UAS flight imagery were created in the photogrammetry software (e.g. Agisoft Metashape). Each of our study sites have RGB data available covering the study area extent. We’re going to standardize the raster resolution of these RGB data across study sites. The RGB orthomosaics created from UAS photogrammetry processing generally have very fine resolutions of 4 cm or finer and we will standardize the data to make it slightly more coarse (6 cm) to reduce the computational processing burden. my_rgb_res_m &lt;- 0.06 2.3.1 PSINF Mixed Conifer Site load the original data #### read RGB data keep only RGB psinf_rgb_rast &lt;- terra::rast( file.path( &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , &quot;P4Pro_06_17_2021_half_half_optimal_transparent_mosaic_group1.tif&quot; ) ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(psinf_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(psinf_rgb_rast) ## [1] 0.02632 0.02632 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ## function to change the resolution of RGB change_res_fn &lt;- function( r , my_res=1 , m = &quot;bilinear&quot; # , ofile = tempfile(fileext = &quot;.tif&quot;) , ofile = NULL ){ if(terra::res(r)[1] == my_res){ return(r) }else{ r2 &lt;- r terra::res(r2) &lt;- my_res if(!inherits(ofile,&quot;character&quot;)){ r2 &lt;- terra::resample(r, r2, method = m) }else{ r2 &lt;- terra::resample(r, r2, method = m, filename=ofile, overwrite = T) } return(r2) } } ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/PFDP_Data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;psinf_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- psinf_rgb_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size psinf_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , psinf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... psinf_rgb_rast &lt;- change_res_fn(psinf_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ psinf_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } # terra::res(psinf_rgb_rast) # terra::plotRGB(bhef_rgb_rast, stretch = &quot;lin&quot;) make a function to plot the RGB imagery as a background for ggplot2 plots. ggplot2 offers capabilities to build multi-layered, publication-quality figures by stacking multiple vector overlays on an RGB background. however, it can be computationally expensive since it requires the conversion to a data frame first. # make a function to plot these detected crowns with rgb data ortho_plt_fn &lt;- function(rgb_rast, stand, add_stand = F, buffer = 10, plt_lwd = 1, plt_line_col = &quot;black&quot;){ if(!inherits(rgb_rast,&quot;SpatRaster&quot;)){stop(&quot;rgb_rast must be terra SpatRaster data&quot;)} if(terra::nlyr(rgb_rast)&lt;3){stop(&quot;rgb_rast must have 3 layers with RGB data&quot;)} if(!inherits(stand,&quot;sf&quot;) &amp;&amp; !inherits(stand,&quot;sfc&quot;)){stop(&quot;stand must be sf data&quot;)} # crop crp_rgb_rast_temp &lt;- rgb_rast %&gt;% terra::crop( stand %&gt;% dplyr::ungroup() %&gt;% sf::st_union() %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(buffer) %&gt;% sf::st_transform(terra::crs(rgb_rast)) %&gt;% terra::vect() ) # convert raster to a data frame and create hex colors # ?grDevices::rgb rgb_df_temp &lt;- crp_rgb_rast_temp %&gt;% terra::as.data.frame(xy = TRUE) %&gt;% dplyr::rename( red = 3, green = 4, blue = 5 ) %&gt;% dplyr::mutate( # rows that have missing color data is_missing = is.na(red) | is.na(green) | is.na(blue) # hex using 0s for NAs to avoid grDevices::rgb error , hex_col = grDevices::rgb( ifelse(is_missing, 0, red) , ifelse(is_missing, 0, green) , ifelse(is_missing, 0, blue) , maxColorValue = 255 ) # back to NA , hex_col = ifelse(is_missing, as.character(NA), hex_col) ) %&gt;% dplyr::select(-c(is_missing)) # plt plt &lt;- ggplot2::ggplot() + # add rgb base map ggplot2::geom_tile(data = rgb_df_temp, mapping = ggplot2::aes(x = x, y = y, fill = hex_col), color = NA) + # use identity scale so the hex codes are used directly ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::coord_sf(expand = F) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; ) # add stand if(add_stand){ # overlay polygons plt &lt;- plt + # ggplot2::geom_sf(data = polys, fill = NA, color = &quot;red&quot;, linewidth = 0.5) + ggplot2::geom_sf( data = stand %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% sf::st_transform(terra::crs(rgb_rast)) , fill = NA , color = plt_line_col , lwd = plt_lwd , inherit.aes = F ) } return(plt) } test our plotting function on a zoomed-in portion of the study area ortho_plt_fn( psinf_rgb_rast , psinf_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (cyan) terra::plotRGB(psinf_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(psinf_rgb_rast)) , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) 2.3.2 TRFO-BLM Pinyon-Juniper Site load the original data #### read RGB data keep only RGB pj_rgb_rast &lt;- terra::rast( # &quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/Ortho/BLM_CO_SWDF_DawsonFuelsTreatment_Ortho_202504.tif&quot; &quot;../data/dawson_data/dawson_rgb.tif&quot; ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(pj_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(pj_rgb_rast) ## [1] 0.025883 0.025883 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/dawson_data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;pj_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- pj_rgb_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) # Mask the cropped raster to the precise shape of the polygon # This function will also be processed on disk due to the file size pj_rgb_rast &lt;- terra::mask( crop_rgb_rast_temp , pj_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... pj_rgb_rast &lt;- change_res_fn(pj_rgb_rast, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ pj_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } test our ggplot2 plotting function on a zoomed-in portion of the study area ortho_plt_fn( pj_rgb_rast , pj_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (cyan) terra::plotRGB(pj_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( pj_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(pj_rgb_rast)) , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) 2.3.3 BHEF Ponderosa Pine Site load the original data. for this site, the orthomosaics are split across multiple files. we’ll read in each, align the resolutions, and use terra::moasaic() to combine ############################################################### # compile RGB raster ############################################################### rgb_dir_temp &lt;- &quot;F:/UAS_Collections/BHEF_202306&quot; # where is the raw las and rgb data? dir_temp &lt;- &quot;../data/BHEF_202306/&quot; # where do you want to save processed data to? rgb_fnm_temp &lt;- file.path(dir_temp,&quot;bhef_rgb.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # read list of orthos ortho_list_temp &lt;- list.files( rgb_dir_temp , pattern = &quot;.*(_RGB|_RBG)\\\\.(tif|tiff)$&quot; , full.names = T, recursive = T ) %&gt;% purrr::map(function(x){terra::rast(x)}) ## apply the change_res_fn ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.04)}) ######## mosaic the raster list bhef_rgb_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works , filename = rgb_fnm_temp , overwrite = T ) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) %&gt;% terra::subset(c(1,2,3)) } # rename bands names(bhef_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(bhef_rgb_rast) ## [1] 0.04 0.04 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse). for the sites with machine piles only (BHEF and ARNF), we’ll only slightly increase the RGB resolution to 0.08m compared to the sites with hand piles which use a 0.06m resolution my_rgb_res_m &lt;- 0.08 ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/BHEF_202306/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;bhef_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- bhef_rgb_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , mask = T , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... bhef_rgb_rast &lt;- change_res_fn(crop_rgb_rast_temp, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ bhef_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (cyan) terra::plotRGB(bhef_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(bhef_rgb_rast)) , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) 2.3.4 ARNF Ponderosa Pine Site load the original data #### read RGB data keep only RGB arnf_rgb_rast &lt;- terra::rast( &quot;f:/UAS_Collections/ARNF_DiamondView_202510/DiamondPeak_Switchblade_transparent_mosaic_group1.tif&quot; ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(arnf_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) what is the resolution of the original RGB data? terra::res(arnf_rgb_rast) ## [1] 0.02101 0.02101 let’s reduce the resolution (i.e. increase the raster cell size; make more coarse) ############################################################### # clip to boundary and resample to change resolution ############################################################### dir_temp &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;arnf_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- arnf_rgb_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(10) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , mask = T , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... arnf_rgb_rast &lt;- change_res_fn(crop_rgb_rast_temp, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) }else{ arnf_rgb_rast &lt;- terra::rast(rgb_fnm_temp) } test our ggplot2 plotting function on a zoomed-in portion of the study area ortho_plt_fn( arnf_rgb_rast , arnf_stand_boundary %&gt;% sf::st_centroid() %&gt;% sf::st_buffer(11) ) for the entire study area, plotting with terra is much more computationally efficient. let’s plot the RGB data with the stand boundary (black) and image annotated pile footprints (cyan) terra::plotRGB(arnf_rgb_rast, stretch=&quot;lin&quot;) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) # add pile boundaries terra::plot( arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(arnf_rgb_rast)) , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) 2.4 Slash Pile RGB Imagery let’s look at the RGB imagery and pile locations. we’ll make a panel of plots for each pile at each study site and place a one square meter box in the middle of each pile to distinguish size plt_fn_temp &lt;- function(vect, rgb){ # get vector d &lt;- vect %&gt;% dplyr::slice(1) %&gt;% sf::st_transform(terra::crs(rgb)) # make a box sqm &lt;- d %&gt;% sf::st_centroid() %&gt;% sf::st_buffer( sqrt(1/4) ## numerator = desired plot size in m2 , endCapStyle = &quot;SQUARE&quot; ) %&gt;% dplyr::mutate(dummy=1) # buff buff &lt;- dplyr::case_when( d$image_gt_diameter_m &lt; 4 ~ 4 , d$image_gt_diameter_m &gt; 10 ~ 2.5 , T ~ d$image_gt_diameter_m*(2/3) ) # plt ortho_plt_fn( rgb_rast = rgb , stand = sf::st_union(d, sqm) , buffer = buff , add_stand = F ) + ggplot2::geom_sf(data = sqm, fill = NA, color = &quot;white&quot;, inherit.aes = F) + ggplot2::geom_sf(data = d, fill = NA, lwd = 1, color = &quot;cyan&quot;, inherit.aes = F) + ggplot2::labs( subtitle = base::bquote( &quot;pile area: &quot; ~ .(scales::comma(d$image_gt_area_m2, accuracy = 0.1)) ~ m^2 ) ) + ggplot2::theme( plot.subtitle = ggplot2::element_text(hjust = 0.5, size = 7) , plot.title = ggplot2::element_text(hjust = 0.5, size = 8) ) } # plot largest, smallest, and median samp_plt_fn_temp &lt;- function(piles, ortho) { min_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_min(n = 1, order_by = image_gt_area_m2, na_rm = T, with_ties = F) , rgb = ortho ) + ggplot2::labs(title = &quot;smallest&quot;) med_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_min( n = 1 , order_by = abs(image_gt_area_m2 - median(image_gt_area_m2, na.rm = TRUE)) , na_rm = T, with_ties = F ) , rgb = ortho ) + ggplot2::labs(title = &quot;median&quot;) max_temp &lt;- plt_fn_temp( vect = piles %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::ungroup() %&gt;% dplyr::slice_max(n = 1, order_by = image_gt_area_m2, na_rm = T, with_ties = F) , rgb = ortho ) + ggplot2::labs(title = &quot;largest&quot;) # combine patchwork::wrap_plots( list(min_temp, med_temp, max_temp) , ncol = 3 ) } 2.4.1 PSINF Mixed Conifer Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference psinf_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = psinf_slash_piles_polys, ortho = psinf_rgb_rast) psinf_samp_plt_fn_temp 2.4.2 TRFO-BLM Pinyon-Juniper Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference pj_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = pj_slash_piles_polys, ortho = pj_rgb_rast) pj_samp_plt_fn_temp 2.4.3 BHEF Ponderosa Pine Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference bhef_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = bhef_slash_piles_polys, ortho = bhef_rgb_rast) bhef_samp_plt_fn_temp 2.4.4 ARNF Ponderosa Pine Site example smallest, median, and largest slash pile (red) with a one square meter box for size reference arnf_samp_plt_fn_temp &lt;- samp_plt_fn_temp(piles = arnf_slash_piles_polys, ortho = arnf_rgb_rast) arnf_samp_plt_fn_temp 2.4.5 All patchwork::wrap_plots( patchwork::wrap_elements( psinf_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;PSINF Mixed Conifer Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( pj_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;TRFO-BLM Pinyon-Juniper Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( bhef_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;BHEF Ponderosa Pine Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , patchwork::wrap_elements( arnf_samp_plt_fn_temp + patchwork::plot_annotation( title = &quot;ARNF Ponderosa Pine Site&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10)) ) ) , ncol = 1 ) "],["ptcld_process.html", "Section 3 Point Cloud Processing 3.1 Process Raw Point Cloud 3.2 Clean Up", " Section 3 Point Cloud Processing We’ll use the cloud2trees package to perform all preprocessing of point cloud data which includes: ground classification and noise removal raster data (DTM and CHM) generation point cloud height normalization All of this can be accomplished using the cloud2trees::cloud2raster() function. After generating these products from the raw point cloud we’ll perform object segmentation to attempt to detect slash piles from the CHM which we’ll generate by setting the minimum height to zero (essentially a digital surface model [DSM] with the ground removed). To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation or DBSCAN (Density-Based Spatial Clustering of Applications with Noise), for example. Both of these methods are common in segmenting individual trees and coarse woody debris from CHM data. 3.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data. For each site we’ll generate a fine-resolution (0.1 m) CHM data set which can be aggregated to coarser resolution for sensitivity testing. Fine resolution CHM data would include granular details which may be important for delineating smaller slash piles while more coarse resolution data may help smooth out noise in the data to reduce false positive pile detections and potentially better represent the form of the actual piles # set chm res my_chm_res_m &lt;- 0.1 3.1.1 PSINF Mixed Conifer Site look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/PFDP_Data/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) las_dir_temp &lt;- &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## type : terrestrial ## density : 375.4 points/m² ## num. files : 1 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees psinf_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.25 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.25m.tif&quot;) ) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine psinf_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM psinf_cloud2raster_ans$dtm_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM psinf_cloud2raster_ans$chm_rast %&gt;% terra::crop( psinf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( psinf_stand_boundary %&gt;% sf::st_transform(terra::crs(psinf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.1.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid. we’ll make some functions to use for the different study areas plt_rast_fn &lt;- function( rn , df , rast , my_title = &quot;&quot; , vopt = &quot;viridis&quot; , lim = NULL , buff = 10 ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(desc(image_gt_diameter_m)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(terra::crs(rast)) # convert rast to df comp_st &lt;- rast %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(buff) %&gt;% terra::vect() ) %&gt;% terra::as.data.frame(xy = T) %&gt;% dplyr::rename(f=3) # ggplot comp_temp &lt;- ggplot2::ggplot() + ggplot2::geom_tile(data = comp_st, ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;cyan&quot;, lwd = 0.4) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , subtitle = my_title ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) if(!is.null(lim)){ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt, limits = lim) }else{ comp_temp &lt;- comp_temp + ggplot2::scale_fill_viridis_c(option = vopt) } plt_temp &lt;- comp_temp return(list(&quot;plt&quot;=plt_temp,&quot;d&quot;=d_temp)) } # plt_rast_fn(rn = 9, df = psinf_slash_piles_polys, rast = psinf_cloud2raster_ans$dtm_rast, vopt = &quot;viridis&quot;) # combine 3 plt_rast_combine &lt;- function( rn , df , dtm_rast , dtm_rast_vopt = &quot;viridis&quot; , chm_rast , chm_rast_vopt = &quot;plasma&quot; , rgb_rast , buffer = 10 ) { # composite 1 ans1 &lt;- plt_rast_fn( rn = rn , df = df , rast = dtm_rast , my_title = &quot;DTM&quot; , vopt = dtm_rast_vopt , buff = buffer ) # composite 2 ans2 &lt;- plt_rast_fn( rn = rn , df = df , rast = chm_rast , my_title = &quot;CHM&quot; , vopt = chm_rast_vopt , buff = buffer ) # plt rgb rgb_temp &lt;- ortho_plt_fn( rgb_rast = rgb_rast , stand =ans1$d , buffer = buffer , add_stand = F ) + ggplot2::geom_sf(data = ans1$d, fill = NA, color = &quot;cyan&quot;, lwd = 0.3) # combine r &lt;- patchwork::wrap_plots(list(rgb_temp,ans1$plt,ans2$plt), nrow = 1) return(r) } # plt_rast_combine( # rn = 11 # , df = psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) # , dtm_rast = psinf_cloud2raster_ans$dtm_rast # , chm_rast = psinf_cloud2raster_ans$chm_rast # , rgb_rast = psinf_rgb_rast # ) use this handy plotting function for some piles # add pile locations plt_list_rast_temp &lt;- 1:sum(psinf_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(psinf_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = psinf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = psinf_cloud2raster_ans$dtm_rast , chm_rast = psinf_cloud2raster_ans$chm_rast , rgb_rast = psinf_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) a few things are noteworthy in these examples: Piles are clearly visible in some areas of the DTM but less visible in other areas Piles are delineated in the CHM but with varying degrees of definition based on surrounding terrain and pile structure The DTM and CHM were rarely impacted by shadows in the RGB imagery It is interesting to see coarse woody debris occasionally visible in the CHM 3.1.2 TRFO-BLM Pinyon-Juniper Site for this site, the full point cloud data we have covers a much larger extent than the treatment unit used for this study. we will therefore crop point cloud to a buffered area of interest so that we limit the amount of data processed ############################################################### # read/crop point cloud ############################################################### # output dir for clipped las las_dir_temp &lt;- &quot;../data/Dawson_Data/point_cloud&quot; if(!dir.exists(las_dir_temp)){dir.create(las_dir_temp, showWarnings = F)} # do it if not already done if(dplyr::coalesce(length(list.files(las_dir_temp)),0)&lt;1){ # this reads the metadata from all files in the folder, not the points themselves. las_ctg_temp &lt;- lidR::readLAScatalog(&quot;d:/BLM_CO_SWDF_DawsonFuelsTreatment/Final/PointCloud/Tiles/&quot;) las_ctg_temp cloud2trees:::check_las_ctg_empty(las_ctg_temp) # set ctg opts lidR::opt_select(las_ctg_temp) &lt;- &quot;xyzainrcRGBNC&quot; lidR::opt_progress(las_ctg_temp) &lt;- T # write generated results to disk storage rather than keeping everything in memory. This option can be activated with opt_output_files() lidR::opt_output_files(las_ctg_temp) &lt;- paste0(normalizePath(las_dir_temp),&quot;/&quot;, &quot;_{XLEFT}_{YBOTTOM}&quot;) # label outputs based on coordinates lidR::opt_filter(las_ctg_temp) &lt;- &quot;-drop_duplicates&quot; # clip the point cloud using the polygon and write to a new file # the lidR::opt_output_files is key to writing the output to disk without loading the entire clipped result into memory. clip_las_ctg_temp &lt;- lidR::clip_roi( las = las_ctg_temp , geometry = pj_stand_boundary %&gt;% sf::st_buffer(100) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% sf::st_transform(sf::st_crs(las_ctg_temp)) ) }else{ clip_las_ctg_temp &lt;- lidR::readLAScatalog(las_dir_temp) } # clip_las_ctg_temp # clip_las_ctg_temp$filename look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/Dawson_Data/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) # las_dir_temp &lt;- las_dir_temp # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 2) ## extent : 707813.6, 708409.9, 4193155, 4193638 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83(2011) / UTM zone 12N ## area : 288106.3 m² ## points : 163.84 million points ## type : terrestrial ## density : 568.7 points/m² ## density : 568.7 pulses/m² ## num. files : 1 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees pj_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine pj_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM pj_cloud2raster_ans$dtm_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( pj_stand_boundary %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM pj_cloud2raster_ans$chm_rast %&gt;% terra::crop( pj_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( pj_stand_boundary %&gt;% sf::st_transform(terra::crs(pj_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.2.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(pj_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(pj_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = pj_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = pj_cloud2raster_ans$dtm_rast , chm_rast = pj_cloud2raster_ans$chm_rast , rgb_rast = pj_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.1.3 BHEF Ponderosa Pine Site for this site, the point cloud files are dispersed across different folders. so, we’ll manually specify which files to use. look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/BHEF_202306/&quot; out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) # las_dir_temp &lt;- &quot;where/are/the/pointcloud&quot; las_flist_temp &lt;- c( &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit1and3Processing.files/BHEF_202306_Unit1and3_laz.laz&quot; , &quot;F:\\\\UAS_Collections\\\\BHEF_202306/Unit2Processing.files/BHEF_202306_Unit2_laz.laz&quot; , list.files( &quot;F:\\\\UAS_Collections\\\\BHEF_202306\\\\00good_simplified_point_clouds_reduced_overlap&quot; , pattern = &quot;.*\\\\.(laz|las)$&quot; , full.names = TRUE, recursive = T ) ) # read header with catalog lidR::readLAScatalog(las_flist_temp) ## class : LAScatalog (v1.2 format 2) ## extent : 608234, 610968.2, 4888216, 4889418 (xmin, xmax, ymin, ymax) ## coord. ref. : NAD83 / UTM zone 13N ## area : 3.48 km² ## points : 1.42 billion points ## type : airborne ## density : 408 points/m² ## density : 408 pulses/m² ## num. files : 7 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees bhef_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_flist_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine bhef_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM bhef_cloud2raster_ans$dtm_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM bhef_cloud2raster_ans$chm_rast %&gt;% terra::crop( bhef_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( bhef_stand_boundary %&gt;% sf::st_transform(terra::crs(bhef_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.3.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(bhef_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(bhef_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = bhef_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = bhef_cloud2raster_ans$dtm_rast , chm_rast = bhef_cloud2raster_ans$chm_rast , rgb_rast = bhef_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.1.4 ARNF Ponderosa Pine Site look at the summary of the point cloud data we’ll be processing # processing dirs c2t_out_dir_temp &lt;- &quot;../data/ARNF_DiamondView_202510/&quot; # where do you want to save processed data to? out_dir_temp &lt;- file.path(c2t_out_dir_temp, paste0(&quot;point_cloud_processing_delivery_chm&quot;,my_chm_res_m,&quot;m&quot;) ) las_dir_temp &lt;- &quot;F:/UAS_Collections/ARNF_DiamondView_202510/point_cloud_high_density&quot; # where is the raw las # read header with catalog lidR::readLAScatalog(las_dir_temp) ## class : LAScatalog (v1.2 format 3) ## extent : 455073.8, 456582.3, 4535127, 4536067 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1.24 km² ## points : 1.37 billion points ## type : airborne ## density : 1102.8 points/m² ## density : 39.9 pulses/m² ## num. files : 44 process the point cloud with the cloud2trees::cloud2raster() workflow # do it if(!dir.exists(out_dir_temp)){ # cloud2trees arnf_cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = c2t_out_dir_temp , input_las_dir = las_dir_temp , accuracy_level = 2 , keep_intrmdt = T , dtm_res_m = 0.2 , chm_res_m = my_chm_res_m , min_height = 0 # effectively generates a DSM based on non-ground points ) # rename file.rename(from = file.path(c2t_out_dir_temp,&quot;point_cloud_processing_delivery&quot;), to = out_dir_temp) }else{ dtm_temp &lt;- terra::rast( file.path(out_dir_temp, &quot;dtm_0.2m.tif&quot;) ) %&gt;% terra::aggregate(fact = 2, na.rm=T, cores = lasR::half_cores()) chm_temp &lt;- terra::rast( file.path(out_dir_temp, paste0(&quot;chm_&quot;, my_chm_res_m,&quot;m.tif&quot;)) ) # combine arnf_cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM arnf_cloud2raster_ans$dtm_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() ) %&gt;% terra::plot( col = viridis::viridis(n = 100) , axes = F , main = &quot;DTM (m)&quot; ) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$dtm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) and CHM arnf_cloud2raster_ans$chm_rast %&gt;% terra::crop( arnf_stand_boundary %&gt;% sf::st_buffer(22) %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() ) %&gt;% terra::aggregate(fact = 2, na.rm = T, cores = lasR::half_cores()) %&gt;% terra::plot( col = viridis::plasma(100) , axes = F , main = &quot;CHM (m)&quot; ) # add stand boundary terra::plot( arnf_stand_boundary %&gt;% sf::st_transform(terra::crs(arnf_cloud2raster_ans$chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) 3.1.4.1 DTM and CHM + piles let’s visually inspect the DTM and CHM with the pile outlines overlaid for a sample of piles # add pile locations plt_list_rast_temp &lt;- 1:sum(arnf_slash_piles_polys$is_in_stand) %&gt;% sample( min(10, sum(arnf_slash_piles_polys$is_in_stand)) ) %&gt;% purrr::map( \\(x) plt_rast_combine( rn = x , df = arnf_slash_piles_polys %&gt;% dplyr::filter(is_in_stand) , dtm_rast = arnf_cloud2raster_ans$dtm_rast , chm_rast = arnf_cloud2raster_ans$chm_rast , rgb_rast = arnf_rgb_rast ) ) # plt_list_rast_temp[[2]] combine the plots with patchwork patchwork::wrap_plots( plt_list_rast_temp , ncol = 2 ) 3.2 Clean Up going forward, we only need the CHM data, so we can drop the DTM data from our session "],["geom_detect.html", "Section 4 Geometry-based Slash Pile Detection 4.1 Demonstration Area 4.2 Segmentation Methods 4.3 Candidate Shape Refinement and Area filtering 4.4 Candidate Geometric filtering 4.5 Structural Metrics from CHM 4.6 Final Shape Refinement 4.7 Pile Detection Function", " Section 4 Geometry-based Slash Pile Detection In this section, we will demonstrate the geometry-based slash pile detection method which relies upon user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-DAP point cloud data. Since this is only a demonstration of the method, we will work with only a sample area from one of the study sites which we know includes slash piles. Full evaluation of the methodology will be performed later in the analysis. We’ll attempt to detect slash piles using raster-based methods with the CHM. These raster-based approaches are simple and efficient but rasterization simplifies/removes some of the rich 3D information in the point cloud. However, raster-based approaches for detecting individual trees in forest stands and coarse woody debris are common. Here is a section from the draft manuscript: These geometry-based approaches are supported by the demonstrated successes of object segmentation frameworks for both CWD and individual trees, which consistently provide high detection and quantification accuracy by utilizing rules to define expected target object morphology. Beyond their technical performance, the geometry-based methods utilizing a set of rules offer some key advantages. The inherent traceability of these methods ensures that reporting for regulatory oversight is more transparent and easier to describe compared to the “black box” nature of many model-based approaches. Geometry-based frameworks also do not rely on training datasets and can directly align with the explicit pile construction parameters which are generally known by land managers through silvicultural prescriptions. To address the current lack of automated methods for simultaneously detecting and quantifying slash piles from aerial remote sensing data, our objective in this work is to present a geometry-based approach that uses rules and user-defined thresholds applied to geometric features (such as area, shape, and height) to identify and quantify slash piles from UAS-DAP point cloud data. Geometric, rules-based object detection methods offer advantages over model-based approaches, primarily because they eliminate the need for extensive training data which might be limited in it’s transferability to unseen conditions. Models are often considered “black boxes” but rules-based methods rely on the inherent physical properties of the target objects themselves. This transparency allows for a high degree of interpretability as every segmentation result can be traced back to specific geometric constraints. Furthermore, this approach aligns perfectly with the expertise of land managers, as the input parameters like minimum height and area thresholds are the physical metrics commonly used in forest inventories and silvicultural prescriptions. By using these intuitive thresholds, the method becomes accessible to managers who possess a good understanding of the landscape they manage. To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation or DBSCAN (Density-Based Spatial Clustering of Applications with Noise). Both of these methods are common in segmenting individual trees and coarse woody debris from CHM data. 4.1 Demonstration Area we’ll focus on an example area that is outside of the study unit boundary but was captured in our UAS data acquisition of the area. This demonstration area also included slash piles which were annotated in the same manner as previously described but did not have height and diameter measurements taken in the field. # boundary aoi_boundary &lt;- psinf_slash_piles_polys %&gt;% dplyr::filter( !is_in_stand &amp; pile_id %in% c(53,52,63,20,17,11,6,75) ) %&gt;% sf::st_union() %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(1.3, joinStyle = &quot;MITRE&quot;) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(dummy=1) we cropped this section from our original RGB processing, so we’ll get it now dir_temp &lt;- &quot;../data/PFDP_Data/&quot; rgb_fnm_temp &lt;- file.path(dir_temp,&quot;aoi_rgb_rast.tif&quot;) # what should the compiled rgb be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(rgb_fnm_temp)){ #### read RGB data keep only RGB aoi_rgb_rast &lt;- terra::rast( file.path( &quot;f:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , &quot;P4Pro_06_17_2021_half_half_optimal_transparent_mosaic_group1.tif&quot; ) ) %&gt;% terra::subset(c(1,2,3)) # rename bands names(aoi_rgb_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk crop_rgb_rast_temp &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(4) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T , filename = tempfile(fileext = &quot;.tif&quot;) , overwrite = TRUE ) ## apply the change_res_fn for our analysis we don&#39;t need such finery # this takes too long... aoi_rgb_rast &lt;- change_res_fn(crop_rgb_rast_temp, my_res=my_rgb_res_m, ofile = rgb_fnm_temp) aoi_rgb_rast &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T ) }else{ aoi_rgb_rast &lt;- terra::rast(rgb_fnm_temp) aoi_rgb_rast &lt;- aoi_rgb_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , mask = T ) } # terra::res(aoi_rgb_rast) # terra::plotRGB(aoi_rgb_rast, stretch = &quot;lin&quot;) we cropped this section from our original CHM processing, so we’ll get it now dir_temp &lt;- &quot;../data/PFDP_Data/&quot; chm_fnm_temp &lt;- file.path(dir_temp,&quot;aoi_chm_rast.tif&quot;) # what should the compiled chm be called? if(!dir.exists(dir_temp)){dir.create(dir_temp, showWarnings = F)} if(!file.exists(chm_fnm_temp)){ #### read CHM aoi_chm_rast &lt;- terra::rast( file.path( dir_temp , &quot;point_cloud_processing_delivery_chm0.1m&quot; , &quot;chm_0.1m.tif&quot; ) ) %&gt;% terra::subset(1) # Crop the raster to the rectangular extent of the polygon # Specify a filename to ensure the result is written to disk aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_union() %&gt;% sf::st_buffer(4) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T , filename = chm_fnm_temp , overwrite = TRUE ) aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T ) }else{ aoi_chm_rast &lt;- terra::rast(chm_fnm_temp) aoi_chm_rast &lt;- aoi_chm_rast %&gt;% terra::crop( aoi_boundary %&gt;% sf::st_buffer(2) %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , mask = T ) } # terra::res(aoi_chm_rast) # terra::plot(aoi_chm_rast) get the piles that intersect with our AOI boundary # piles aoi_slash_piles_polys &lt;- psinf_slash_piles_polys %&gt;% dplyr::inner_join( psinf_slash_piles_polys %&gt;% sf::st_intersection(aoi_boundary) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id) , by = &quot;pile_id&quot; ) # aoi_slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(is_in_stand) # ggplot base aoi_plt_ortho &lt;- ortho_plt_fn(rgb_rast = aoi_rgb_rast, stand = aoi_boundary, buffer = 3) # aoi_plt_ortho look at the demonstration area (plots using ggplot2 for maximum customization) here is the CHM of the example area. can you pick out the slash piles? plt_aoi_chm &lt;- function(chm, opt=&quot;plasma&quot;) { max_val &lt;- ceiling(terra::minmax(chm)[2]*1.02) rng &lt;- c(0,max(max_val,1)) pretty &lt;- scales::breaks_pretty(n = 4)(rng) thrsh &lt;- 0.10 * (max(rng) - min(rng)) filtered_pretty &lt;- pretty[ abs(pretty - min(rng)) &gt; thrsh &amp; abs(pretty - max(rng)) &gt; thrsh ] brks &lt;- c( rng , filtered_pretty ) %&gt;% unique() %&gt;% sort() chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(mapping = ggplot2::aes(x=x,y=y,fill=f)) + ggplot2::geom_sf(data = aoi_boundary %&gt;% sf::st_buffer(3.8), fill = NA, color = &quot;white&quot;, lwd = 0.0) + # so if chm is missing still same size ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + # ggplot2::scale_fill_viridis_c(option = opt) + ggplot2::scale_fill_viridis_c(option = opt, limits = rng, breaks = brks) + ggplot2::labs(fill = &quot;CHM (m)&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + ggplot2::theme( # legend.position = &quot;top&quot; legend.position = &quot;inside&quot; , legend.position.inside = c(0.05, 0.95) , legend.justification.inside = c(0, 1) , legend.direction = &quot;horizontal&quot; , legend.title = ggplot2::element_text(size = 7) , legend.text = ggplot2::element_text(size = 6.5, margin = ggplot2::margin(t = -0.01)) , legend.key.height = unit(0.35, &quot;cm&quot;) , legend.key.width = unit(0.4, &quot;cm&quot;) , legend.background = ggplot2::element_rect(fill = &quot;gray95&quot;) #, color = &quot;black&quot;) , legend.margin = ggplot2::margin(t = 6, r = 7, b = 6, l = 7, unit = &quot;pt&quot;) ) } plt_aoi_chm(aoi_chm_rast) here is the RGB of the example area. can you pick out the slash piles? aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) we’ll add on the ground truth piles in cyan on the RGB. how many did you find? be honest. aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) would you have done better if you had both the CHM and RGB data? plt_aoi_chm_rgb &lt;- function(chm) { aoi_plt_ortho + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.4 , inherit.aes = F ) + ggplot2::scale_fill_viridis_c(option = &quot;plasma&quot;) + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::theme(legend.position = &quot;none&quot;) } plt_aoi_chm_rgb(aoi_chm_rast) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) 4.2 Segmentation Methods Our slash pile detection approach will align with the land manager knowledge of physical metrics of slash pile form which are commonly used in forest inventories and silvicultural prescriptions. We’ll start with input parameters like height and area thresholds. the first step in this approach is to isolate the lower “slice” of the CHM based on a maximum height threshold defined by the upper limit of the expected slash pile height. the expected height range to search for slash piles should be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion we’ll set a maximum height threshold (max_ht_m) which filters the CHM to only include raster cells lower than this threshold. we’ll also set a lower height limit (min_ht_m) based on the expected slash pile height for use later in removing candidate segments that are shorter than this lower limit. # set the max and min expected pile height max_ht_m &lt;- 6 min_ht_m &lt;- 0.5 # lower CHM slice aoi_chm_rast_slice &lt;- terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F) plot the lower slice, notice how the CHM height scale has changed plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) already, it looks like the piles should be distinguishable objects from this data our rules-based pile detection methodology will also rely on area thresholds to define a search space and filter candidate segments. like height, we’ll also set a minimum (min_area_m2) and maximum (max_area_m2) pile 2D area (in square meters) to search and filter for valid candidate objects. As with the height, these thresholds should be set based on the pile construction prescription or estimates or sample measurements from field visits. # set the max and min expected pile area min_area_m2 &lt;- 1.5 # Two standard US parking spaces, typically measuring 9 feet by 18 feet, # are roughly equivalent to 30.25 square meters. Each space is approximately 15.125 square meters. # 15.125*3 max_area_m2 &lt;- 50 to summarize, the size-based thresholds of our geometric, rules-based approach for detecting slash piles from CHM data are: max_ht_m : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific “slice” of the data, ignoring anything taller than a typical pile. min_ht_m : numeric. The minimum height (in meters) a detected pile must reach to be considered valid. min_area_m2 : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid. max_area_m2 : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid. 4.2.1 Overview of Methods The two primary segmentation methods we’ll test are watershed segmentation and DBSCAN. Watershed segmentation, which we’ll implement with lidR::watershed(), is a raster-based technique that treats a CHM as a topographic surface where height values are inverted to create basins. The algorithm identifies local maxima as “seeds” and expands them until they reach a boundary or “watershed” line. This method requires a tolerance parameter (tol) which defines “the minimum height of the object…between its highest point (seed) and the point where it contacts another object…If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. Tolerance should be chosen according to the range of x.” An extent parameter (ext) is used to define the search window for object seeds. The DBSCAN algorithm, which we’ll implement with dbscan::dbscan(), is typically a point-based clustering algorithm that groups points based on their spatial density but DBSCAN can also be applied to raster data by converting the raster cells into a 2D point set using the cell centroids. The algorithm relies on an epsilon parameter (eps), which defines the search radius around a point, and a minimum points parameter (minPts), which sets the threshold for how many neighbors must exist within that radius to form a core cluster. Dynamically defining these parameters is critical for the usability and scalability of the method because it removes the guesswork typically required when moving between different datasets. For example, point clouds can vary in point density depending on the flight altitude or sensor, and rasters can vary in resolution. If parameters are kept static, a model tuned for a specific data structure or target object will be suboptimal for different data. We can link the segmentation algorithm parameters directly to the input data structure and the expected target object size so that the method automatically recalibrates itself. In applying a similar, rules-based methodology for coarse woody debris detection from point cloud data, dos Santos et al. (2025) recommend setting algorithm parameters based on minimum expected object size to be detected and point density. We developed dynamic logic to automatically bridge the gap between the expectation of the target object form (height and area thresholds) and the representation of the object in the data by using geometric ratios. For watershed segmentation, the tolerance (tol) is scaled to the height range of the target objects to ensure sensitivity to the vertical variability. The extent (ext) is calculated by converting the physical radius of the smallest expected object into a pixel count based on the raster resolution. For DBSCAN, the epsilon parameter (eps) is calculated to bridge the average gap between points (or the distance between raster cell centroids) but is capped to prevent the merging of adjacent objects. The minimum points (minPts) parameter is scaled by the ratio of the search area (eps) to the total object area, ensuring that a cluster only forms if the local point density is representative of a valid target object. Method Parameter Parameter Description Our Dynamic Logic (R-style pseudo-code) Logic Explanation Why our dynamic logic works Watershed tol Minimum height difference to distinguish objects. (max_ht_m - min_ht_m) * 0.50 Sets the vertical threshold at 50% of the target’s defined Z search space. Prevents over-segmentation by requiring vertical “valleys” to be significant relative to the target’s height. Watershed ext Radius of the search window for detecting seeds. max(1, round((target_radius_m * 0.5) / rast_res_m)) Uses 50% of the target radius as the search window, converted to pixels with a 1-pixel minimum. Maintains a consistent physical search area regardless of raster resolution, ensuring seeds are centered on objects. DBSCAN eps Maximum distance to consider points as neighbors. min(1.5 * (1/sqrt(pts_per_m2)), (target_radius_m * 0.5 * 0.5)) Selects the smaller of 1.5-times the point spacing or 50% of the effective radius (25% of target radius). Ensures the point-search stays localized, effectively preventing separate objects from “bridging” together. DBSCAN minPts Minimum points required to form a cluster core. round((min_area_m2 * pts_per_m2) * (eps^2 / (target_radius_m^2))) Scales total expected points by the ratio of the search circle area to the total target area. Dynamically adjusts the density threshold based on the search radius, allowing for consistent detection across varying data densities. let’s define a function to get these parameters based on the user-defined size thresholds and the input data description # function to get segmentation parameters get_segmentation_params &lt;- function( min_ht_m , max_ht_m , min_area_m2 , max_area_m2 , pts_per_m2 = NULL , rast_res_m = NULL ){ # check for missing required values if (missing(max_ht_m) || missing(min_ht_m) || missing(min_area_m2) || missing(max_area_m2)) { stop(&quot;all geometric constraints (max_ht_m, min_ht_m, min_area_m2, max_area_m2) must be defined.&quot;) } # geometric param validation if (max_ht_m &lt;= min_ht_m) { stop(&quot;max_ht_m must be greater than min_ht_m.&quot;) } if (max_area_m2 &lt;= min_area_m2) { stop(&quot;max_area_m2 must be greater than min_area_m2.&quot;) } if (min_ht_m &lt; 0 || min_area_m2 &lt; 0) { stop(&quot;height and area constraints must be positive values.&quot;) } # data structure validation and calculation if (is.null(pts_per_m2) &amp;&amp; is.null(rast_res_m)) { stop(&quot;must provide either &#39;pts_per_m2&#39; (pts/m2) or &#39;rast_res_m&#39; (m/pixel).&quot;) } # calculate and validate data str values if (is.null(pts_per_m2)) { if (rast_res_m &lt;= 0) stop(&quot;rast_res_m must be a positive value.&quot;) pts_per_m2 &lt;- 1 / (rast_res_m^2) } if (is.null(rast_res_m)) { if (pts_per_m2 &lt;= 0) stop(&quot;pts_per_m2 must be a positive value.&quot;) rast_res_m &lt;- 1 / sqrt(pts_per_m2) } ################################################ # lidR::watershed / EBImage::watershed ################################################ # lidR::watershed `tol` # set based on the height range height_range &lt;- max_ht_m - min_ht_m # scale it to increase the sensitivity to distinguish smaller objects tol_val &lt;- height_range * 0.5 # lidR::watershed `ext` # use ~half~ quarter the radius of the minimum object to increase sensitivity # this helps prevent merging nearby objects (under-segmentation) target_radius_m &lt;- sqrt(min_area_m2 / pi) effective_radius_m &lt;- target_radius_m * 0.25 ext_val &lt;- max(1, round(effective_radius_m / rast_res_m)) ################################################ # dbscan::dbscan ################################################ # dbscan::dbscan `eps` (epsilon) # [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) recommended to set this value based: # &quot;on the minimum cluster size to be detected and point density&quot; # start by scaling based on point spacing (1.5x average distance between points). spacing &lt;- 1 / sqrt(pts_per_m2) connectivity_eps &lt;- 1.5 * spacing # eps should not exceed 50% of the minimum object radius to avoid merging separate objects into one cluster. max_allowable_eps &lt;- target_radius_m * 0.25 # cap eps by the object size constraint eps_val &lt;- min(connectivity_eps, max_allowable_eps) # dbscan::dbscan `minPts` # based on expected points within the epsilon neighborhood area # get expected number of points in an object of min_area_m2 expected_pts_in_min_object &lt;- min_area_m2 * pts_per_m2 # ensure a core point is surrounded by a density of points based on min_area_m2 size at point density # scale the total expected points of the minimum object # by the ratio of the epsilon-neighborhood area to the total minimum object area # to ensure a core point meets the expected density of the target object pts_ratio_calc &lt;- expected_pts_in_min_object * (eps_val^2 / target_radius_m^2) min_pts_val &lt;- max( 5 # don&#39;t go any lower than the dbscan::dbscan() default , round(pts_ratio_calc) ) # return return(list( data_summary = list(pts_per_m2 = pts_per_m2, rast_res_m = rast_res_m), watershed = list(tol = tol_val, ext = ext_val), dbscan = list(eps = eps_val, minPts = min_pts_val) )) } let’s test our get_segmentation_params() function using the size threshold parameters we defined above: max_ht_m, min_ht_m, min_area_m2, max_area_m2 and we can get the raster resolution directly from our input CHM # get_segmentation_params get_segmentation_params_ans &lt;- get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(aoi_chm_rast_slice)[1] ) # huh? dplyr::glimpse(get_segmentation_params_ans) ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 100 ## ..$ rast_res_m: num 0.1 ## $ watershed :List of 2 ## ..$ tol: num 2.75 ## ..$ ext: num 2 ## $ dbscan :List of 2 ## ..$ eps : num 0.15 ## ..$ minPts: num 7 we can see how these parameters change if the CHM resolution changes get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = 0.5 ) %&gt;% dplyr::glimpse() ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 4 ## ..$ rast_res_m: num 0.5 ## $ watershed :List of 2 ## ..$ tol: num 2.75 ## ..$ ext: num 1 ## $ dbscan :List of 2 ## ..$ eps : num 0.173 ## ..$ minPts: num 5 and we can see how these parameters change using our CHM data but change the expected minimum pile 2D area get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = 22 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(aoi_chm_rast_slice)[1] ) %&gt;% dplyr::glimpse() ## List of 3 ## $ data_summary:List of 2 ## ..$ pts_per_m2: num 100 ## ..$ rast_res_m: num 0.1 ## $ watershed :List of 2 ## ..$ tol: num 2.75 ## ..$ ext: num 7 ## $ dbscan :List of 2 ## ..$ eps : num 0.15 ## ..$ minPts: num 7 the table summarizes how our rules-based approach creates dynamic parameters for use in watershed and DBSCAN segmentation. The height parameters manage vertical noise, the area parameters manage horizontal separation, and the data resolution parameters ensure the math stays consistent regardless of data density (raster resolution or point cloud point density). Dynamic Parameter Impact of Height (max_ht_m / min_ht_m) Impact of Target Area (min_area_m2) Impact of Data Structure (rast_res_m / pts_per_m2) Watershed tol Direct Driver: Sets the vertical threshold at 50% of the target’s defined Z search space. None: Vertical tolerance is independent of horizontal footprint. None: Vertical sensitivity is independent of horizontal resolution. Watershed ext None: Horizontal search window is independent of vertical range. Geometric Baseline: Defines the physical radius used to scale the search window at a 1:2 ratio. Spatial Divider: Converts the physical radius into a pixel count using rast_res_m with a 1-pixel minimum. DBSCAN eps None: Point-to-point connectivity is independent of height. Physical Cap: Limits search distance to 50% of the effective radius (25% of target radius) to ensure separation. Connectivity Anchor: Sets the search radius at 1.5-times the spacing derived from pts_per_m2 to maintain tight clusters. DBSCAN minPts None: Required point mass is independent of vertical range. Total Mass Baseline: Defines the total expected points for the smallest valid target. Density Multiplier: Calculates the local point count requirement relative to the pts_per_m2 value. sim_df_temp &lt;- tidyr::crossing( rast_res_m = seq(0.1, 1.3, by = 0.1) , min_area_m2 = seq(1, 50, length.out = 33) ) %&gt;% dplyr::mutate( # Call the pre-defined function directly to ensure logic alignment params = purrr::map2( rast_res_m, min_area_m2, ~ get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = .y , max_area_m2 = .y * 5 , rast_res_m = .x ) ) # Extract values into individual columns for plotting , ext = purrr::map_dbl(params, ~ .x$watershed$ext) , eps = purrr::map_dbl(params, ~ .x$dbscan$eps) , min_pts = purrr::map_dbl(params, ~ .x$dbscan$minPts) ) # # Pivot to long format for faceted plotting # tidyr::pivot_longer( # cols = c(ext, eps, min_pts), # names_to = &quot;parameter&quot;, # values_to = &quot;value&quot; # ) # sim_df_temp %&gt;% dplyr::glimpse() # plot p1_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = ext)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;Watershed: `ext` (pixels)&quot;, fill = &quot;pixels&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) p2_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = eps)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;DBSCAN: `eps` (meters)&quot;, fill = &quot;meters&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) p3_temp &lt;- ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = min_pts)) + ggplot2::geom_tile(col = &quot;gray&quot;) + ggplot2::scale_fill_viridis_c(option = &quot;magma&quot;) + ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) + ggplot2::labs(title = &quot;DBSCAN: `minPts` (count)&quot;, fill = &quot;count&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;bottom&quot;, plot.title = ggplot2::element_text(size = 9)) # 5. Combine using patchwork (p1_temp + p2_temp + p3_temp) + patchwork::plot_annotation( title = &quot;Dynamic Watershed and DBSCAN Parameter Definition&quot; , subtitle = &quot;across raster resolution and minimum target area gradients&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10),plot.subtitle = ggplot2::element_text(size = 8)) ) + patchwork::plot_layout(ncol = 3) 4.2.2 Watershed Segmentation Demonstration let’s go through the watershed segmentation process using lidR::watershed() which is based on the bioconductor package EBIimage # ?EBImage::watershed watershed_segs &lt;- lidR::watershed( chm = aoi_chm_rast_slice # th_tree = Threshold below which a pixel cannot be a tree. Default is 2. , th_tree = 0.01 # tol = minimum height of the object in the units of image intensity between its highest point (seed) # and the point where it contacts another object (checked for every contact pixel). # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. # Tolerance should be chosen according to the range of x , tol = get_segmentation_params_ans$watershed$tol # max_ht_m-min_ht_m # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. # Higher value smoothes out small objects. , ext = get_segmentation_params_ans$watershed$ext # 1 )() the result is a raster with cells segmented and given a unique identifier # this is a raster watershed_segs ## class : SpatRaster ## size : 1483, 768, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 499310.2, 499387, 4317710, 4317858 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## varname : aoi_chm_rast ## name : focal_mean ## min value : 1 ## max value : 214 each value should be a unique “segment” which we can refine based on rules of expected size and shape of piles terra::freq(watershed_segs) %&gt;% dplyr::slice_sample(n = 10) ## layer value count ## 1 1 199 9 ## 2 1 177 21 ## 3 1 22 737 ## 4 1 19 26 ## 5 1 143 1785 ## 6 1 6 4 ## 7 1 59 27 ## 8 1 34 6 ## 9 1 40 4 ## 10 1 100 9 where the “value” is the segment identifier and the count is the number of raster cells assigned to that segment how many predicted segments are there? terra::freq(watershed_segs) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() ## [1] 214 let’s plot the raster return from the watershed segmentation watershed_segs %&gt;% terra::as.factor() %&gt;% terra::plot( col = c( viridis::turbo(n = terra::minmax(watershed_segs)[2]) # , viridis::viridis(n = floor(terra::minmax(watershed_segs)[2]/3)) # , viridis::cividis(n = floor(terra::minmax(watershed_segs)[2]/3)) ) %&gt;% sample() , legend = F , axes = F ) plot the watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice…we are getting close. 4.2.3 DBSCAN Segmentation Demonstration let’s go through the DBSCAN segmentation process using dbscan::dbscan() which uses a kd-tree for efficient processing. As an aside, the RANN package enables KD-tree searching/processing using the X and Y coordinates of the entire point cloud to build the tree which is a super-fast way to find the x number of near neighbors for each point in an input dataset (see RANN::nn2()). because the DBSCAN process is a point-based clustering algorithm that groups points based on their spatial density we need to convert the raster cells into a 2D point set using the cell centroids first ## XY df xy_df_temp &lt;- aoi_chm_rast_slice %&gt;% # na.rm = T ensures we only process cells with CHM data terra::as.data.frame(xy = T, na.rm = T) %&gt;% dplyr::rename( X=x,Y=y , f=3 ) %&gt;% dplyr::select(X,Y) # huh? xy_df_temp %&gt;% dplyr::glimpse() ## Rows: 27,616 ## Columns: 2 ## $ X &lt;dbl&gt; 499324.0, 499324.0, 499324.0, 499330.2, 499330.4, 499330.5, 499324.0… ## $ Y &lt;dbl&gt; 4317856, 4317856, 4317856, 4317856, 4317856, 4317856, 4317856, 43178… # ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=&quot;.&quot;) now, we can apply the dbscan::dbscan() function using the parameters we identified using our dynamic process defined in get_segmentation_params() # get_segmentation_params_ans %&gt;% dplyr::glimpse() # ?dbscan::dbscan dbscan_ans_temp &lt;- dbscan::dbscan( x = xy_df_temp # eps primarily controls the spatial extent of a cluster, # as it defines how far points can be from each other to be considered part of the same dense region. , eps = get_segmentation_params_ans$dbscan$eps # minPts primarily controls the minimum density of a cluster, # as it dictates how many points must be packed together within that eps radius. , minPts = get_segmentation_params_ans$dbscan$minPts ) # huh? dbscan_ans_temp %&gt;% str() ## List of 5 ## $ cluster : int [1:27616] 0 0 0 1 1 1 0 1 1 1 ... ## $ eps : num 0.15 ## $ minPts : num 7 ## $ metric : chr &quot;euclidean&quot; ## $ borderPoints: logi TRUE ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;dbscan_fast&quot; &quot;dbscan&quot; the result is a vector with a cluster identifier for each point we provided to the algorithm identical( length(dbscan_ans_temp$cluster) , nrow(xy_df_temp) ) ## [1] TRUE add the cluster identifier to the XY point data # add the cluster to the data xy_df_temp$cluster &lt;- dbscan_ans_temp$cluster # what? xy_df_temp %&gt;% dplyr::count(cluster) %&gt;% dplyr::arrange(desc(n)) %&gt;% head() ## cluster n ## 1 102 2398 ## 2 118 2303 ## 3 119 1821 ## 4 181 1785 ## 5 108 1754 ## 6 107 1539 to maintain processing consistency with the watershed result, we’ll rasterize the XY data back to the original CHM grid. this will result in a raster with cells segmented and given the unique identifier. Note: the cells/segments classified as noise from the dbscan::dbscan() algorithm are marked with a cluster identifier as “0”…we’ll remove these prior to rasterizing # fill the rast with the cluster values dbscan_segs &lt;- terra::rasterize( x = xy_df_temp %&gt;% dplyr::filter(cluster!=0) %&gt;% sf::st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;), crs = terra::crs(aoi_chm_rast_slice), remove = F) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(cluster) %&gt;% terra::vect() , y = aoi_chm_rast_slice , field = &quot;cluster&quot; ) the result is a raster with cells segmented and given a unique identifier # this is a raster dbscan_segs ## class : SpatRaster ## size : 1483, 768, 1 (nrow, ncol, nlyr) ## resolution : 0.1, 0.1 (x, y) ## extent : 499310.2, 499387, 4317710, 4317858 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## varname : aoi_chm_rast ## name : last ## min value : 1 ## max value : 200 each value should be a unique “segment” which we can refine based on rules of expected size and shape of piles terra::freq(dbscan_segs) %&gt;% dplyr::arrange(desc(count)) %&gt;% head() ## layer value count ## 1 1 102 2398 ## 2 1 118 2303 ## 3 1 119 1821 ## 4 1 181 1785 ## 5 1 108 1754 ## 6 1 107 1539 where the “value” is the segment identifier and the count is the number of raster cells assigned to that segment (compare to the count of the segmented points above ;) how many predicted segments are there? terra::freq(dbscan_segs) %&gt;% dplyr::filter(!is.na(value)) %&gt;% nrow() ## [1] 200 let’s plot the raster of the dbscan segmentation dbscan_segs %&gt;% terra::as.factor() %&gt;% terra::plot( col = c( viridis::turbo(n = terra::minmax(dbscan_segs)[2]) ) %&gt;% sample() , legend = F , axes = F ) plot the watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice…we are getting close. 4.2.4 Comparison of Candidate Segments we’ll start by converting the candidate segments to polygons # watershed_segs watershed_segs_poly &lt;- watershed_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs dbscan_segs_poly &lt;- dbscan_segs %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) count the number of unique candidate segments from each method and summarize the area covered by all segments dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments = scales::comma(segments,accuracy=1) , area = scales::comma(area,accuracy=0.01) ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&quot; , col.names = c( &quot;method&quot;, &quot;candidate segments&quot;, &quot;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.1: Demonstration area candidate segments by method method candidate segments area (m2) watershed 214 276.16 DBSCAN 200 274.16 notice the dbscan segments cover a smaller area because noise points are identified and removed as part of the algorithm. in the next stage of our method, we’ll include additional noise removal applied to both methodologies. In fact, all processing will be the same from here forward for both segementation methodologies. 4.2.5 Segmentation Function let’s make a function to perform either the watershed (lidR::watershed()) or DBSCAN (dbscan::dbscan()) segmentation given an input CHM raster, target height range, and target area range. the output will include a raster and sf polygons of the candidate segments ############################################################################ # DBSCAN function # to align input of raster and output of raster as in lidR::watershed() # this enables dbscan, typically a point-based method, # to be implemented with raster input data by using cell centroids ############################################################################ get_segs_dbscan &lt;- function( chm_rast , eps , minPts ) { ######################## # check raster ######################## # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } # first layer only if(terra::nlyr(chm_rast)&gt;1){warning(&quot;...only using first layer of raster stack for segmentation&quot;)} chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) # na check if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } ######################## # get cell centroids as points ######################## ## XY df xy_df_temp &lt;- chm_rast %&gt;% # na.rm = T ensures we only process cells with CHM data terra::as.data.frame(xy = T, na.rm = T) %&gt;% dplyr::rename( X=x,Y=y , f=3 ) %&gt;% dplyr::select(X,Y) # huh? # xy_df_temp %&gt;% dplyr::glimpse() # ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=&quot;.&quot;) if(nrow(xy_df_temp)==0){stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;)} ######################## # dbscan::dbscan() ######################## # ?dbscan::dbscan dbscan_ans_temp &lt;- dbscan::dbscan( x = xy_df_temp # eps primarily controls the spatial extent of a cluster, # as it defines how far points can be from each other to be considered part of the same dense region. , eps = eps # minPts primarily controls the minimum density of a cluster, # as it dictates how many points must be packed together within that eps radius. , minPts = minPts ) # ensure the result is a vector with a `cluster` identifier for each point we provided to the algorithm if( !identical( length(dbscan_ans_temp$cluster) , nrow(xy_df_temp) ) ){ stop(&quot;dbscan::dbscan() length mismatch&quot;) } # add the cluster identifier to the XY point data xy_df_temp$cluster &lt;- dbscan_ans_temp$cluster # # what? # xy_df_temp %&gt;% # dplyr::count(cluster) %&gt;% # dplyr::arrange(desc(n)) %&gt;% # head() if( nrow( xy_df_temp %&gt;% dplyr::filter(cluster!=0) ) == 0 ){ stop(&quot;dbscan::dbscan() result is all noise based on &#39;eps&#39; and &#39;minPts&#39;. try adjusting these parameters.&quot;) } ######################## # back to raster data ######################## # to maintain processing consistency with the watershed result # we&#39;ll rasterize the XY data back to the original CHM grid # this will result in a raster with cells segmented and given the unique identifier. # *Note*: the cells/segments classified as noise from the `dbscan::dbscan()` # algorithm are marked with a cluster identifier as &quot;0&quot;...we&#39;ll remove these prior to rasterizing # fill the rast with the cluster values dbscan_segs &lt;- terra::rasterize( x = xy_df_temp %&gt;% dplyr::filter(cluster!=0) %&gt;% sf::st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;), crs = terra::crs(chm_rast), remove = F) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(cluster) %&gt;% terra::vect() , y = chm_rast , field = &quot;cluster&quot; ) %&gt;% setNames(&quot;cluster&quot;) # the result is a raster with cells segmented and given a unique identifier # this is a raster # dbscan_segs return(dbscan_segs) } # # ?dbscan::dbscan # get_segs_dbscan(aoi_chm_rast_slice, minPts = 5, eps = 1) %&gt;% # terra::as.factor() %&gt;% # terra::plot(legend = F, col = grDevices::rainbow(n=111) %&gt;% sample() ) ############################################################################ ############################################################################ ############################################################################ # handle !inMemory input rasters # !terra::inMemory(rast) means that the raster is not loaded into RAM and is (potentially) too large to do so # `lidR::watershed()` &quot;Cannot segment the trees from a raster stored on disk. Use segment_trees() or load the raster in memory&quot; # make a workflow to: # 1) check terra::inMemory(): # - if already loaded, run lidR::watershed() as-is to bypass tiling step and return watershed segments # 2) if !inMemory, use terra::makeTiles() to make raster chunks with buffers that overlap neighboring tiles # 3) each tile is processed individually using lidR::watershed() with segments converted to polygons # 4) separate segments into &quot;hold out&quot; (entirely within the core, non-buffer) and &quot;boundary&quot; (any overlap with buffer) groups # 5) for boundary segments: any segments that overlap are compared with only the largest segment kept (smaller, overlapping discarded) using terra::pairs() # 6) final set of segments combines the hold outs with the processed boundary segments and return rasterized segments to match lidR::watershed() output ############################################################################ ############################################################################ ############################################################################ # intermediate function to set tile size based on raster size and mem available ############################################################################ get_tile_size &lt;- function( rast , memory_risk = 0.35 # low risk (0.01 – 0.20): creates more tiles but is unlikely to crash R # med risk (0.2-0.5): reserves ~95% of free RAM for the remaining calculations # high risk (0.5-0.7): fewer tiles but more likely to crash R # dangerous (&gt;0.7): very likely to crash R ){ # is file path or current terra obj? if(inherits(rast, &quot;character&quot;) &amp;&amp; stringr::str_ends(rast,&quot;\\\\.tif$|\\\\.tiff$&quot;)) { if(!file.exists(rast)) { stop(&quot;the provided file path does not exist.&quot;) } my_rast &lt;- terra::rast(rast) }else if(inherits(rast, &quot;SpatRaster&quot;)) { my_rast &lt;- rast }else{ stop(&quot;&#39;rast&#39; must be a .tif|.tiff file path string or a SpatRaster object.&quot;) } # terra::free_RAM() returns the amount of RAM that is available in Bytes # ?terra::free_RAM free_ram &lt;- terra::free_RAM() # logic: (available ram * risk tolerance) / bytes per double-precision pixel (8) # higher risk tolerance allows more pixels per tile, reducing total tile count max_pixels &lt;- (free_ram * memory_risk) / 8 # calculate tile dimension # sqrt to define side length in pixels optimal_side &lt;- floor(sqrt(max_pixels)) # specify the number of rows and columns for each tile (1 or 2 numbers if the number of rows and columns is not the same) # ?terra::makeTiles &#39;y&#39; argument # limit the tile size at the actual raster dimensions optimal_side &lt;- min(optimal_side, terra::nrow(my_rast), terra::ncol(my_rast)) # total tile count based on rast size n_tiles_cols &lt;- ceiling(terra::ncol(my_rast) / optimal_side) n_tiles_rows &lt;- ceiling(terra::nrow(my_rast) / optimal_side) # message(paste0(&quot;current free ram: &quot;, round(free_ram / 1e9, 2), &quot; gb&quot;)) # message(paste0(&quot;memory risk: &quot;, memory_risk)) # message(paste0(&quot;my tile size: &quot;, optimal_side, &quot; pixels&quot;)) return(list( # tile_size = number of rows and columns for each zone in terra::makeTiles &#39;y&#39; argument tile_size = optimal_side , total_tiles = n_tiles_cols * n_tiles_rows )) } # get_tile_size(bhef_chm_rast) # get_tile_size(bhef_chm_rast, memory_risk = 0.3) # get_tile_size(psinf_chm_rast, memory_risk = 0.3) # get_tile_size(psinf_chm_rast, memory_risk = 0.3)[[&quot;tile_size&quot;]] ############################################################################ # lidR::watershed or tile and lidR::watershed ############################################################################ # lidR::watershed(chm = aoi_chm_rast)() %&gt;% terra::freq() %&gt;% dplyr::glimpse() get_segs_watershed &lt;- function( chm_rast , tol , ext # in case file is not in-memory, how big should tile buffers be? # set to maximum expected target object diameter , buffer_m = 10 ){ # is file path or current terra obj? if(inherits(chm_rast, &quot;character&quot;) &amp;&amp; stringr::str_ends(chm_rast,&quot;\\\\.tif$|\\\\.tiff$&quot;)) { if(!file.exists(chm_rast)) { stop(&quot;the provided file path does not exist.&quot;) } chm_rast &lt;- terra::rast(chm_rast) }else if(inherits(chm_rast, &quot;SpatRaster&quot;)) { chm_rast &lt;- chm_rast }else{ stop(&quot;&#39;chm_rast&#39; must be a .tif|.tiff file path string or a SpatRaster object.&quot;) } # memory check and direct processing # if the raster is already in memory, process directly to avoid tiling if(terra::inMemory(chm_rast)) { message(&quot;Raster is already in memory. Processing directly with lidR::watershed().&quot;) segs_rast &lt;- lidR::watershed( chm = chm_rast # th_tree = Threshold below which a pixel cannot be a tree. Default is 2. , th_tree = 0.01 # tol = minimum height of the object in the units of image intensity between its highest point (seed) # and the point where it contacts another object (checked for every contact pixel). # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. # Tolerance should be chosen according to the range of x , tol = tol # max_ht_m-min_ht_m # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. # Higher value smoothes out small objects. , ext = ext # 1 )() # match names of get_segs_dbscan() names(segs_rast) &lt;- &quot;cluster&quot; return(segs_rast) } # tiling setup message(&quot;raster is on disk (not inMemory). starting tile processing...&quot;) tile_dir &lt;- tempfile(&quot;tiles_&quot;) dir.create(tile_dir,showWarnings = F) poly_dir &lt;- base::tempfile(&quot;polys_&quot;) dir.create(poly_dir,showWarnings = F) # tile size, dynamically breaks the raster into 10 regions...might not work for realllllly huge rasters # tile_size &lt;- c( # round(terra::nrow(chm_rast)/10) # , round(terra::ncol(chm_rast)/10) # ) # get_tile_size()...might work for realllllly huge rasters tile_size &lt;- get_tile_size(chm_rast, memory_risk = 0.65)[[&quot;tile_size&quot;]] tile_radius_cells &lt;- ceiling( tile_size/2 ) # tile radius # need to make sure the buffer isn&#39;t larger than the tile radius...otherwise there&#39;s no point in tiling because we&#39;re processing a similarly large area # The number of additional rows and columns added to each tile. buffer_size &lt;- min( round(buffer_m/terra::res(chm_rast)[1]) , tile_radius_cells ) # generate buffered tiles on disk # ?terra::makeTiles tile_files &lt;- terra::makeTiles( x = chm_rast # specify rows and columns for tiles in pixels/cells , y = tile_size , filename = file.path(tile_dir, &quot;tile_.tif&quot;) , buffer = buffer_size , overwrite = T , na.rm = T ) # process of each tile and save segmented polygons to disk # result of purrr::map_chr is a list of file names poly_files &lt;- purrr::map_chr( tile_files , function(t_path) { # load tile tile_rast &lt;- terra::rast(t_path) tile_rast &lt;- tile_rast*1 # force tile into memory # if nothing, save no file path if( as.numeric(terra::global(tile_rast, fun = &quot;isNA&quot;)) == terra::ncell(tile_rast) ){ return(as.character(NA)) } # run watershed segs_rast &lt;- lidR::watershed( chm = tile_rast # th_tree = Threshold below which a pixel cannot be a tree. Default is 2. , th_tree = 0.01 # tol = minimum height of the object in the units of image intensity between its highest point (seed) # and the point where it contacts another object (checked for every contact pixel). # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. # Tolerance should be chosen according to the range of x , tol = tol # max_ht_m-min_ht_m # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. # Higher value smoothes out small objects. , ext = ext # 1 )() # match names of get_segs_dbscan() names(segs_rast) &lt;- &quot;cluster&quot; # convert to poly segs_poly &lt;- terra::as.polygons(segs_rast, values = TRUE, aggregate = TRUE) # if nothing, save no file path if(nrow(segs_poly) == 0){ return(as.character(NA)) } # boundary (in buffer) vs interior e &lt;- terra::ext(tile_rast) res &lt;- terra::res(tile_rast) # dimensions in meters of buffer ## where in terra::makeTiles : # buffer = integer. The number of additional rows and columns added to each tile. Can be a single number # , or two numbers to specify a separate number of rows and columns. # This allows for creating overlapping tiles that can be used for computing spatial context dependent # values with e.g. focal. The expansion is only inside x, no rows or columns outside of x are added # ?terra::makeTiles # we added a constant number of rows and columns with buffer_size dist_x &lt;- buffer_size * res[1] # meters dist_y &lt;- buffer_size * res[2] # meters # tile must be wider/taller than 2x buffer can_shrink_x &lt;- (e$xmax - e$xmin) &gt; (2 * dist_x) can_shrink_y &lt;- (e$ymax - e$ymin) &gt; (2 * dist_y) if(can_shrink_x &amp;&amp; can_shrink_y){ core_ext &lt;- terra::ext( e$xmin + dist_x , e$xmax - dist_x , e$ymin + dist_y , e$ymax - dist_y ) # ?terra::relate is_within &lt;- terra::relate(segs_poly, terra::as.polygons(core_ext), relation = &quot;within&quot;) segs_poly$on_buffer &lt;- !as.vector(is_within) # T = boundary segments }else{ # if the tile is too small to have a core everything is a boundary segment segs_poly$on_buffer &lt;- T # T = boundary segments } # add flags for boundary processing segs_poly$poly_area &lt;- terra::expanse(segs_poly) # area of poly # give a unique id to every polygon before merging segs_poly$temp_id &lt;- paste0(basename(t_path), &quot;_&quot;, 1:nrow(segs_poly)) # save as temp gpkg out_path &lt;- file.path(poly_dir, paste0(basename(t_path), &quot;.gpkg&quot;)) terra::writeVector(segs_poly, out_path, overwrite = TRUE) return(out_path) } ) # keep only files with polys poly_files &lt;- poly_files[!is.na(poly_files)] if(length(poly_files)==0 || all(is.na(poly_files))){ stop(&quot;no segments found with `lidR::watershed()` using input data and `tol`, `ext` settings&quot;) } # boundary segments processing # keep all core polygons since they only appear in one tile # for all polygons that are in a boundary (on_buffer), keep the largest if it overlaps with another from a neighbor tile # bring together core and processed boundary segments # message(&quot;merging tile polygons segments and processing buffer overlaps...&quot;) # final datas final_interior &lt;- NULL final_boundary &lt;- NULL for(i in 1:length(poly_files)) { # read current tile polys current_tile_vec &lt;- terra::vect(poly_files[i]) # get core/interior (no olaps possible) tile_interior &lt;- current_tile_vec[!current_tile_vec$on_buffer] # add to final datas if(is.null(final_interior)) { final_interior &lt;- tile_interior } else { final_interior &lt;- rbind(final_interior, tile_interior) } # get boundary (olaps possible) tile_boundary &lt;- current_tile_vec[current_tile_vec$on_buffer] # compare segs in boundary on the current tile to the final, already processed segs if (nrow(tile_boundary) &gt; 0) { if (is.null(final_boundary)) { final_boundary &lt;- tile_boundary }else{ # compare tile_boundary against the accumulated final_boundary adj_matrix &lt;- terra::relate(tile_boundary, final_boundary, relation = &quot;intersects&quot;) # find olaps in current tile with already processed boundary segs has_olap &lt;- rowSums(adj_matrix) &gt; 0 # no olap keep as-is safe_boundary &lt;- tile_boundary[!has_olap] # for olaps, keep the largest seg for overlapping cluster if( any(has_olap) ){ olap_tile_segments &lt;- tile_boundary[has_olap] keeps_from_tile &lt;- c() remove_ids &lt;- c() for(j in 1:nrow(olap_tile_segments)) { # which final segments this tile segment touches match_indxs &lt;- which(adj_matrix[which(has_olap)[j], ] == TRUE) matching_final_segs &lt;- final_boundary[match_indxs] # compare current seg area to the largest matching segment in the final max_final_area &lt;- max(matching_final_segs$poly_area) if(olap_tile_segments$poly_area[j] &gt; max_final_area) { # current segment is larger, mark finals for removal instead keeps_from_tile &lt;- c(keeps_from_tile, olap_tile_segments$temp_id[j]) remove_ids &lt;- c(remove_ids, matching_final_segs$temp_id) } } # update final_boundary: remove smaller, add largest if (length(remove_ids) &gt; 0) { final_boundary &lt;- final_boundary[!(final_boundary$temp_id %in% remove_ids)] } largers &lt;- olap_tile_segments[olap_tile_segments$temp_id %in% keeps_from_tile] final_boundary &lt;- rbind(final_boundary, safe_boundary, largers) }else{ final_boundary &lt;- rbind(final_boundary, safe_boundary) } } } # clean up rm(current_tile_vec) } # combine interior with procerssed boundary segs final_vec &lt;- rbind(final_interior, final_boundary) final_vec$cluster &lt;- 1:nrow(final_vec) final_raster &lt;- terra::rasterize( x = final_vec , y = chm_rast , field = &quot;cluster&quot; ) # clean up temp tiles unlink(tile_dir, recursive = TRUE) unlink(poly_dir, recursive = TRUE) return(final_raster) } # # ?lidR::watershed # terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F) %&gt;% # get_segs_watershed(tol = 1, ext = 1) %&gt;% # terra::plot() # # ceiling( sqrt(max_area_m2/pi)*2 ) # buffer_m # # ceiling( sqrt(666/pi)*2 ) # buffer_m # # round(ceiling( sqrt(666/pi)*2 )/terra::res(bhef_chm_rast)[1]) # # get_tile_size(bhef_chm_rast, memory_risk = 0.35)[[&quot;tile_size&quot;]] # # ceiling( get_tile_size(bhef_chm_rast, memory_risk = 0.35)[[&quot;tile_size&quot;]]/2 ) # tile radius # # # terra::ncell(psinf_chm_rast) # # terra::ncell(pj_chm_rast) # terra::clamp(pj_chm_rast, upper = max_ht_m, lower = 0, values = F) %&gt;% # get_segs_watershed(tol = 1, ext = 1) %&gt;% # terra::plot() # #### ! testing only...this takes a long time # xxx_temp &lt;- terra::clamp(bhef_chm_rast, upper = 5, lower = 0, values = F) %&gt;% # get_segs_watershed(tol = 1, ext = 1, buffer_m = ceiling( sqrt(500/pi)*2 )) ############################################################################ # intermediate function to check string method ############################################################################ # check the `method` argument check_segmentation_method &lt;- function(method) { if(!inherits(method,&quot;character&quot;)){stop(&quot;no method&quot;)} # clean method method &lt;- dplyr::coalesce(method, &quot;&quot;) %&gt;% tolower() %&gt;% stringr::str_squish() %&gt;% unique() # potential methods pot_methods &lt;- c(&quot;watershed&quot;, &quot;dbscan&quot;) %&gt;% unique() find_method &lt;- paste(pot_methods, collapse=&quot;|&quot;) # can i find one? which_methods &lt;- stringr::str_extract_all(string = method, pattern = find_method) %&gt;% unlist() %&gt;% unique() # make sure at least one is selected n_methods_not &lt;- base::setdiff( pot_methods , which_methods ) %&gt;% length() if(n_methods_not&gt;=length(pot_methods)){ stop(paste0( &quot;`method` parameter must be one of:\\n&quot; , &quot; &quot; , paste(pot_methods, collapse=&quot;, &quot;) )) }else{ return(which_methods) } } # check_segmentation_method(c(&quot;watershed&quot;, &quot;dbscn&quot;, &quot;dbsca&quot;)) # check_segmentation_method(&quot;dbscn&quot;) ############################################################################ # intermediate function to convert rast to polygon ############################################################################ rast_to_poly &lt;- function(rast){ # ?terra::as.polygons rast %&gt;% terra::subset(1) %&gt;% terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %&gt;% setNames(&quot;pred_id&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) } ############################################################################ # full segmentation function # given an input CHM raster, target height range, and target area range. # the output will include a raster and `sf` polygons of the candidate segments # automatically adjusts segmentation method parameters using get_segmentation_params() ############################################################################ get_segmentation_candidates &lt;- function( chm_rast , method = &quot;watershed&quot; # &quot;watershed&quot; or &quot;dbscan&quot; , min_ht_m , max_ht_m , min_area_m2 , max_area_m2 ){ ######################## # threshold checks ######################## max_ht_m &lt;- max_ht_m[1] min_ht_m &lt;- min_ht_m[1] min_area_m2 &lt;- min_area_m2[1] max_area_m2 &lt;- max_area_m2[1] if( (is.na(tryCatch(as.numeric(max_ht_m), error = function(e) NA)) || identical(as.numeric(max_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_ht_m), error = function(e) NA)) || identical(as.numeric(min_ht_m), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_ht_m), error = function(e) NA))) || (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || identical(as.numeric(max_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || identical(as.numeric(min_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) || !(as.numeric(max_ht_m) &gt; as.numeric(min_ht_m)) || !(as.numeric(max_area_m2) &gt; as.numeric(min_area_m2)) || as.numeric(max_ht_m)&lt;0 || as.numeric(min_ht_m)&lt;0 || as.numeric(min_area_m2)&lt;0 || as.numeric(max_area_m2)&lt;0 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_ht_m`,`max_ht_m`,`min_area_m2`,`max_area_m2` are not valid numbers, or the conditions max_area_m2&gt;min_area_m2 or max_ht_m&gt;min_ht_m are not met.&quot;) }else{ max_ht_m &lt;- as.numeric(max_ht_m)[1] min_ht_m &lt;- as.numeric(min_ht_m)[1] min_area_m2 &lt;- as.numeric(min_area_m2)[1] max_area_m2 &lt;- as.numeric(max_area_m2)[1] } ######################## # check raster ######################## # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } # first layer only if(terra::nlyr(chm_rast)&gt;1){warning(&quot;...only using first layer of raster stack for segmentation&quot;)} chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) # na check if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } ######################## # check method ######################## check_segmentation_method_ans &lt;- check_segmentation_method(method = method) if(length(check_segmentation_method_ans)&gt;1){ warning( paste0( &quot;...using only &quot;, check_segmentation_method_ans[1], &quot; method for segmentation&quot;) ) } check_segmentation_method_ans &lt;- check_segmentation_method_ans[1] ######################## # slice CHM ######################## # lower CHM slice slice_chm_rast &lt;- terra::clamp(chm_rast, upper = max_ht_m, lower = 0, values = F) # na check if( as.numeric(terra::global(slice_chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(slice_chm_rast) ){ stop(&quot;Input &#39;chm_rast&#39; has no values at or below &#39;max_ht_m&#39; value&quot;) } ######################## # get_segmentation_params ######################## # get_segmentation_params seg_params_ans &lt;- get_segmentation_params( max_ht_m = max_ht_m , min_ht_m = min_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 # , pts_per_m2 = NULL , rast_res_m = terra::res(slice_chm_rast)[1] ) # # huh? # dplyr::glimpse(seg_params_ans) ######################## # segmentation ######################## if(check_segmentation_method_ans==&quot;watershed&quot;){ # ?EBImage::watershed segs_rast &lt;- get_segs_watershed( chm_rast = slice_chm_rast , tol = seg_params_ans$watershed$tol , ext = seg_params_ans$watershed$ext # in case file is not in-memory, how big should tile buffers be? # set to maximum expected target object diameter , buffer_m = ceiling( sqrt(max_area_m2/pi)*2 ) ) }else if(check_segmentation_method_ans==&quot;dbscan&quot;){ segs_rast &lt;- get_segs_dbscan( chm_rast = slice_chm_rast , eps = seg_params_ans$dbscan$eps , minPts = seg_params_ans$dbscan$minPts ) }else{ stop(&quot;incorrect method selected&quot;) } # na check if( as.numeric(terra::global(segs_rast, fun = &quot;isNA&quot;)) == terra::ncell(segs_rast) ){ warning(&quot;no segmentation candidates detected&quot;) } ######################## # rast to poly ######################## segs_sf &lt;- rast_to_poly(segs_rast) ######################## # return ######################## return(list( segs_rast = segs_rast , segs_sf = segs_sf , slice_chm_rast = slice_chm_rast , seg_mthd_params = seg_params_ans )) } # get_segmentation_candidates( # chm_rast = aoi_chm_rast # , method = &quot;dbscan&quot; # , min_ht_m = 1 # , max_ht_m = 4 # , min_area_m2 = 1.5^2 # , max_area_m2 = 55 # ) our get_segmentation_candidates() is the workhorse of our methodology. it includes all input data and parameter (e.g. height, area thresholds) checks and includes the following processing steps: CHM Height Filtering: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a “slice” of the CHM. Segmentation Method Setup: Applies the dynamic parameter logic used in the Watershed or DBSCAN segmentation method. This logic ensures scale-invariant object detection by maintaining constant proportions between the algorithm search windows and the physical dimensions of the target object. This dynamic approach allows the method parameters to adapt automatically to the input data resolution so that the resulting candidate segments remain spatially consistent with target objects. Candidate Segmentation: Watershed or DBSCAN segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form. 4.3 Candidate Shape Refinement and Area filtering to better align the segmentation results with real-world pile construction we’ll now simplify candidate segments composed of multiple separate parts representing a single identified feature (i.e. “multi-polygon” candidate segments. We’ll simplify these segments by retaining only the largest contiguous portion using cloud2trees functionality. Because slash piles are constructed as distinct, isolated objects to prevent tree mortality during burning, this refinement step isolates the primary candidate body to eliminate detached noise and ensure each segment represents a discrete physical object before area-based filtering using the candidate segment polygons, apply the cloud2trees::simplify_multipolygon_crowns() function which keeps only the largest part of multi-polygon geometries and works for all sf polygon data (even though the term “crowns” is in the name) # watershed_segs watershed_segs_poly &lt;- watershed_segs_poly %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) # dbscan_segs dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) we’ll have the same number of unique candidate segments from each method but the area covered by those segments will now be smaller dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments = scales::comma(segments,accuracy=1) , area = scales::comma(area,accuracy=0.01) ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method after removing noise polygon parts&quot; , col.names = c( &quot;method&quot;, &quot;candidate segments&quot;, &quot;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.2: Demonstration area candidate segments by method after removing noise polygon parts method candidate segments area (m2) watershed 214 273.02 DBSCAN 200 274.16 now we’ll remove all candidate segments that do not meet the area criteria based on the user-defined minimum and maximum area thresholds st_filter_area &lt;- function(sf_data, min_area_m2, max_area_m2) { # check input data if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # check thresholds min_area_m2 &lt;- min_area_m2[1] max_area_m2 &lt;- max_area_m2[1] if( (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || identical(as.numeric(max_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || identical(as.numeric(min_area_m2), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) || !(as.numeric(max_area_m2) &gt; as.numeric(min_area_m2)) || as.numeric(min_area_m2)&lt;0 || as.numeric(max_area_m2)&lt;0 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_area_m2`,`max_area_m2` are not valid numbers, or the condition max_area_m2&gt;min_area_m2 not met.&quot;) }else{ min_area_m2 &lt;- as.numeric(min_area_m2)[1] max_area_m2 &lt;- as.numeric(max_area_m2)[1] } # return return( sf_data %&gt;% dplyr::ungroup() %&gt;% # area filter dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% # filter out the segments that don&#39;t meet the size thresholds dplyr::filter( dplyr::coalesce(area_xxxx,0) &gt;= min_area_m2 &amp; dplyr::coalesce(area_xxxx,0) &lt;= max_area_m2 ) %&gt;% dplyr::select(-c(area_xxxx)) ) } apply our st_filter_area() function # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) how many candidate segments were removed? dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , new_segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) , area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment area&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.3: Demonstration area candidate segments by methodfiltered by segment area method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -85.5% 214 31 231.41 DBSCAN -84.5% 200 31 230.74 4.3.1 Watershed Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice…we are getting closer. 4.3.2 DBSCAN Segmentation plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice…we are getting closer. 4.3.3 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) interesting. 4.4 Candidate Geometric filtering slash piles are man-made objects typically constructed into common geometric forms in 2D (e.g. circular base) and 3D space (e.g. paraboloid) to facilitate efficient construction and burning Hardy 1996. Our method leverages these traits by applying independent geometric filters to refine candidate segments. First, we apply a regularity filter to remove candidates with irregularly-shaped bases. Then, an independent circularity filter removes candidates that do not meet expectations for round bases (typical of hand piles). By keeping these filters independent, the our method is flexible and allows users to prioritize generally regular shapes (e.g. circular or rectangular) or apply the circularity filter as an additional filtering step when circular pile bases are expected. 4.4.1 Shape Irregularity: Convexity Our first shape irregularity filter compares the convex hull of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the convexity ratio or “solidity” of the shape (Glasbey and Horgan 1995) by: \\[\\frac{\\text{Area of Polygon}}{\\text{Area of Convex Hull}}\\] This approach is effective for identifying polygons with deep indents, holes, or branching. A perfectly convex shape like a circle, square, or triangle will have a convexity of 1.0 (because they have no indents) and as shapes become more irregular (or concave) the convexity drops toward 0. Convexity is is not sensitive to the overall elongation of a shape as a long, thin rectangle is technically convex and would have a ratio of 1.0, despite being irregular in its proportions. let’s create a convex hull of the candidate segments for comparison and convexity calculation # convex hulls of segments # watershed_segs_poly watershed_segs_poly_chull &lt;- watershed_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs_poly dbscan_segs_poly_chull &lt;- dbscan_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) compare the convex hull shape to the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly_chull, mapping=ggplot2::aes(color=&quot;convex hull&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;magenta&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly_chull, mapping=ggplot2::aes(color=&quot;convex hull&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;magenta&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) patchwork::wrap_plots(list(p1_temp,p2_temp)) now, we’ll calculate the convexity ratio for each remaining candidate segment # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::mutate(poly_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( watershed_segs_poly_chull %&gt;% dplyr::mutate(chull_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, chull_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( convexity_ratio = poly_area_m2/chull_area_m2 ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::mutate(poly_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::inner_join( dbscan_segs_poly_chull %&gt;% dplyr::mutate(chull_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, chull_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( convexity_ratio = poly_area_m2/chull_area_m2 ) what is the convexity ratio for the remaining candidate segments in our demonstration area? # watershed_segs_poly watershed_segs_poly$convexity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4489 0.7686 0.8941 0.8310 0.9279 0.9423 # dbscan_segs_poly dbscan_segs_poly$convexity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4591 0.7611 0.8941 0.8349 0.9279 0.9423 plot the convexity of the candidate segments using the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = watershed_segs_poly , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = dbscan_segs_poly , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) patchwork::wrap_plots( list(p1_temp,p2_temp) , guides = &quot;collect&quot; , ) &amp; ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 7) ) finally, let’s filter the candidate segments with a user-defined expectation of shape irregularity on the 0-100% scale applied to the convexity ratio # # min required overlap between the predicted pile and the convex hull of the predicted pile min_convexity_ratio &lt;- 0.5 what proportion of the remaining segments were filtered using this shape irregularity filter dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( watershed_segs_poly %&gt;% nrow() , dbscan_segs_poly %&gt;% nrow() ) , new_segments = c( watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% nrow() , dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment convexity&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.4: Demonstration area candidate segments by methodfiltered by segment convexity method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -3.2% 31 30 227.19 DBSCAN -3.2% 31 30 226.62 actually apply the filter ;) # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::filter(convexity_ratio&gt;=min_convexity_ratio) 4.4.1.1 Watershed Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) 4.4.1.2 DBSCAN Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) 4.4.1.3 Convexity Filter Function let’s make a function to ingest a spatial data frame and return polygons filtered for irregularity using this convex hull process st_convexity_filter &lt;- function( sf_data # min required overlap between the polygon and the convex hull of the polygon , min_convexity_ratio = 0.7 ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # convex hulls of segments poly_chull &lt;- sf_data %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() # dplyr::filter(sf::st_is_valid(.)) # compare areas if(nrow(poly_chull)!=nrow(sf_data)){ stop(&quot;could not make valid convex hulls from provided polygon data&quot;) }else{ area_comp &lt;- sf_data %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::bind_cols( poly_chull %&gt;% dplyr::mutate(chull_area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::select(chull_area_xxxx) %&gt;% sf::st_drop_geometry() ) %&gt;% dplyr::mutate( convexity_ratio = area_xxxx/chull_area_xxxx ) %&gt;% dplyr::filter( convexity_ratio &gt;= min_convexity_ratio ) %&gt;% dplyr::select(-c(area_xxxx,chull_area_xxxx)) return(area_comp) } } # dbscan_segs_poly$convexity_ratio %&gt;% summary() # dbscan_segs_poly %&gt;% # st_convexity_filter(min_convexity_ratio = 0.9) %&gt;% # dplyr::pull(convexity_ratio) %&gt;% # summary() 4.4.2 Shape Irregularity: Circularity Our second shape irregularity filter compares the minimum bounding circle of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the circularity ratio sometimes referred to as the Reock Compactness Score (Reock 1961) of the shape by: \\[\\frac{\\text{Area of Polygon}}{\\text{Area of Minumum Bounding Circle}}\\] This approach is used to measure how closely a shape is spread around its central point (dispersion) with a perfect circle receiving a score of 1.0 while long, thin shapes (like downed tree boles) will have low values approaching the lower limit of 0. This metric penalizes any shape that does not fill it’s circumcircle (i.e. the smallest circle that contains the polygon). For context, a perfect square has a circularity ratio of \\(\\frac{2}{\\pi}\\approx 0.637\\) while an equilateral triangle has a ratio of \\(\\frac{3\\sqrt{3}}{4\\pi}\\approx 0.414\\) let’s create the minimum bounding circle of the candidate segments using lwgeom::st_minimum_bounding_circle() # MBC of segments # watershed_segs_poly watershed_segs_poly_mbc &lt;- watershed_segs_poly %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) # dbscan_segs_poly dbscan_segs_poly_mbc &lt;- dbscan_segs_poly %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) compare the MBC shape to the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly_mbc, mapping=ggplot2::aes(color=&quot;min. bounding circle&quot;) , fill = NA, lwd = 1.5 ) + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;magenta&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly_mbc, mapping=ggplot2::aes(color=&quot;min. bounding circle&quot;) , fill = NA, lwd = 1.5 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;raw polygons&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;orangered&quot;, &quot;magenta&quot;),name=&quot;&quot;) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) ) patchwork::wrap_plots(list(p1_temp,p2_temp)) now, we’ll calculate the circularity ratio for each remaining candidate segment # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::inner_join( watershed_segs_poly_mbc %&gt;% dplyr::mutate(mbc_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, mbc_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( circularity_ratio = poly_area_m2/mbc_area_m2 ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::inner_join( dbscan_segs_poly_mbc %&gt;% dplyr::mutate(mbc_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id, mbc_area_m2) , by = &quot;pred_id&quot; ) %&gt;% dplyr::mutate( circularity_ratio = poly_area_m2/mbc_area_m2 ) what is the circularity ratio for the remaining candidate segments in our demonstration area? # watershed_segs_poly watershed_segs_poly$circularity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1896 0.4700 0.6431 0.5770 0.6936 0.7991 # dbscan_segs_poly dbscan_segs_poly$circularity_ratio %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1896 0.4783 0.6431 0.5799 0.6936 0.7991 plot the circularity of the candidate segments using the raw polygons p1_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = watershed_segs_poly , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;watershed&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) p2_temp &lt;- ggplot2::ggplot() + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio) , color = NA ) + ggplot2::geom_sf_text( data = dbscan_segs_poly , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1)) , vjust = 1, hjust = 0, size = 3.5 ) + ggplot2::scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent , breaks = seq(0, 1, by = 0.2) , name = &quot;&quot; ) + ggplot2::labs(subtitle = &quot;dbscan&quot;) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;bottom&quot; , plot.subtitle = ggplot2::element_text(hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) patchwork::wrap_plots( list(p1_temp,p2_temp) , guides = &quot;collect&quot; , ) &amp; ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 7) ) finally, let’s filter the candidate segments with a user-defined expectation of shape circularity on the 0-100% scale applied to the circularity ratio # # min required overlap between the predicted pile and the MBC of the predicted pile min_circularity_ratio &lt;- 0.45 what proportion of the remaining segments were filtered using this shape circularity filter dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( watershed_segs_poly %&gt;% nrow() , dbscan_segs_poly %&gt;% nrow() ) , new_segments = c( watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% nrow() , dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% nrow() ) , area = c( watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area = scales::comma(area,accuracy=0.01) ) %&gt;% dplyr::relocate(method,pct_removed) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;filtered by segment circularity&quot; , col.names = c( &quot;method&quot;, &quot;% removed&quot; , &quot;orig. candidate segments&quot; , &quot;filtered candidate segments&quot; , &quot;remaining candidate area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.5: Demonstration area candidate segments by methodfiltered by segment circularity method % removed orig. candidate segments filtered candidate segments remaining candidate area (m2) watershed -20.0% 30 24 214.18 DBSCAN -16.7% 30 25 216.46 actually apply the filter ;) # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% dplyr::filter(circularity_ratio&gt;=min_circularity_ratio) 4.4.2.1 Watershed Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) 4.4.2.2 DBSCAN Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) 4.4.2.3 Circularity Filter Function let’s make a function to ingest a spatial data frame and return polygons filtered for irregularity using this minimum bounding circle process st_circularity_filter &lt;- function( sf_data # min required overlap between the polygon and the minimum bounding circle of the polygon , min_circularity_ratio = 0.6 ) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } # minimum bounding circle of segments poly_mbc &lt;- sf_data %&gt;% lwgeom::st_minimum_bounding_circle() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() # dplyr::filter(sf::st_is_valid(.)) # compare areas if(nrow(poly_mbc)!=nrow(sf_data)){ stop(&quot;could not make valid minimum bounding circle from provided polygon data&quot;) }else{ area_comp &lt;- sf_data %&gt;% dplyr::mutate(area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::bind_cols( poly_mbc %&gt;% dplyr::mutate(mbc_area_xxxx = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::select(mbc_area_xxxx) %&gt;% sf::st_drop_geometry() ) %&gt;% dplyr::mutate( circularity_ratio = area_xxxx/mbc_area_xxxx ) %&gt;% dplyr::filter( circularity_ratio &gt;= min_circularity_ratio ) %&gt;% dplyr::select(-c(area_xxxx,mbc_area_xxxx)) return(area_comp) } } # dbscan_segs_poly$circularity_ratio %&gt;% summary() # dbscan_segs_poly %&gt;% # st_circularity_filter(min_circularity_ratio = 0.7) %&gt;% # dplyr::pull(circularity_ratio) %&gt;% # summary() 4.4.2.4 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot now that we have removed candidate segments that 1) do not meet the area thresholds; 2) do not meet the convexity ratio threshold; and 3) do not meet the circularity ratio threshold # watershed_segs_poly %&gt;% dplyr::glimpse() # dbscan_segs_poly %&gt;% dplyr::glimpse() ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) after all of that, the results of the two methods are essentially the same for this particular demonstration area 4.5 Structural Metrics from CHM We’ll use the CHM raster to calculate area, height, and volume for each candidate pile to reflect the irregular pile footprints and elevation profiles that better represent real-world objects than assuming perfect geometric shapes like traditional pile measurement methods (Long and Boston, 2014; Trofymow et al., 2014; Guth et al., 2025) Candidate slash pile structural metrics are derived from the CHM raster using zonal statistics to aggregate cell-level raster data within the boundaries of each pile. To ensure geodetic accuracy, an area raster is generated (terra::cellSize()) which accounts for minute variations in pixel area caused by the curvature of the Earth and the coordinate reference system. This area raster is then used as input for volume calculation, where it is multiplied by the CHM height values to create a volume raster. Summing the individual volume of every pixel within the candidate pile footprint yields the total pile volume with each cell in the volume raster treated as a rectangular prism with height from the CHM and base area from the area raster. Pile area is calculated by summing the area raster values within the candidate pile boundary and pile height is determined by the maximum CHM pixel value. we’ll make a function to use polygon sf data and an input CHM raster to perform these calculations and return the data with metrics attached ######################################################################################## ## calculate raster-based area, height, and volume using zonal stats ######################################################################################## get_structural_metrics &lt;- function( sf_data , chm_rast # , sf_id = NA ) { # check polygons if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must include `sf` data object in &#39;sf_data&#39;&quot;)} if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } sf_data &lt;- sf_data %&gt;% dplyr::ungroup() # check raster # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(chm_rast, &quot;RasterStack&quot;) || inherits(chm_rast, &quot;RasterBrick&quot;) ){ chm_rast &lt;- terra::rast(chm_rast) }else if(!inherits(chm_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;chm_rast&#39; must be a SpatRaster from the `terra` package&quot;) } chm_rast &lt;- chm_rast %&gt;% terra::subset(subset = 1) if( as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) == terra::ncell(chm_rast) # || as.numeric(terra::global(chm_rast, fun = &quot;isNA&quot;)) &gt;= round(terra::ncell(chm_rast)*0.98) ){ stop(&quot;Input &#39;chm_rast&#39; has all missing values&quot;) } # # check id # if(!inherits(sf_id, &quot;character&quot;)){ # # stop(&quot;must include &#39;sf_id&#39; as the unique identifier&quot;) # sf_data &lt;- sf_data %&gt;% # dplyr::mutate(idxxxxx = dplyr::row_number()) # sf_id &lt;- &quot;idxxxxx&quot; # }else{ # if( !any( stringr::str_equal(names(sf_data), sf_id) ) ){ # stop(paste0(&quot;could not locate &#39;&quot;,sf_id,&quot;&#39; in sf_data&quot;)) # } # } # check overlap # Returns TRUE if any part of the vector geometry intersects the raster extent if( !any(terra::is.related( x = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , y = terra::ext(chm_rast) , relation = &quot;intersects&quot; )) ){ stop(&quot;Input &#39;sf_data&#39; does not overlap with &#39;chm_rast&#39;&quot;) } ################################# # area, volume of each cell ################################# area_rast_temp &lt;- terra::cellSize(chm_rast) names(area_rast_temp) &lt;- &quot;area_m2&quot; # area_rast_temp %&gt;% terra::plot() # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes vol_rast_temp &lt;- area_rast_temp*chm_rast names(vol_rast_temp) &lt;- &quot;volume_m3&quot; # vol_rast_temp %&gt;% terra::plot() ################################# # zonal stats ################################# # sum area within each segment to get the total area area_df_temp &lt;- terra::zonal( x = area_rast_temp , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;sum&quot;, na.rm = T ) %&gt;% setNames(&quot;area_m2&quot;) %&gt;% dplyr::mutate(area_m2 = dplyr::na_if(area_m2, NaN)) # area_df_temp %&gt;% dplyr::glimpse() # sum volume within each segment to get the total volume vol_df_temp &lt;- terra::zonal( x = vol_rast_temp , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;sum&quot;, na.rm = T ) %&gt;% setNames(&quot;volume_m3&quot;) %&gt;% dplyr::mutate(volume_m3 = dplyr::na_if(volume_m3, NaN)) # vol_df_temp %&gt;% dplyr::glimpse() # max ht within each segment to get the max ht ht_df_temp &lt;- terra::zonal( x = chm_rast , z = sf_data %&gt;% sf::st_transform(terra::crs(chm_rast)) %&gt;% terra::vect() , fun = &quot;max&quot;, na.rm = T ) %&gt;% setNames(&quot;max_height_m&quot;) %&gt;% dplyr::mutate(max_height_m = dplyr::na_if(max_height_m, NaN)) ################################# # attach to sf ################################# if( !identical( nrow(sf_data) , nrow(area_df_temp) , nrow(vol_df_temp) , nrow(ht_df_temp) ) ){ stop(&quot;unable to find data in raster for given vectors&quot;) } ret_dta &lt;- sf_data %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;area_m2&quot; , &quot;volume_m3&quot; , &quot;max_height_m&quot; , &quot;volume_per_area&quot; ))) %&gt;% dplyr::bind_cols( area_df_temp , vol_df_temp , ht_df_temp ) %&gt;% dplyr::mutate( volume_per_area = volume_m3/area_m2 ) # ret_dta &lt;- sf_data %&gt;% # purrr::reduce( # list(sf_data, area_df_temp, vol_df_temp, ht_df_temp) # , dplyr::left_join # , by = sf_id # ) %&gt;% # dplyr::mutate( # volume_per_area = volume_m3/area_m2 # ) return( list( sf_data = ret_dta , area_rast = area_rast_temp , volume_rast = vol_rast_temp ) ) } # get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% # dplyr::glimpse() # get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = arnf_chm_rast) %&gt;% # dplyr::glimpse() 4.5.1 Structural Rasters we can quickly look at the area raster that was used for the volume calculation get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;area_rast&quot;) %&gt;% terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = &quot;area (m2)&quot;) and we can quickly look at the volume raster get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;volume_rast&quot;) %&gt;% terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = &quot;volume (m3)&quot;) # terra::plot( # aoi_slash_piles_polys %&gt;% # sf::st_transform(terra::crs(aoi_chm_rast_slice)) %&gt;% # terra::vect() # , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 # ) the volume raster mirrors the CHM but with volume as the cell value instead of height aoi_chm_rast_slice %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;CHM (m)&quot;) 4.5.2 Demonstration Candidate Segment Metrics we’ll use our get_structural_metrics() with the height-filtered CHM to compute the structural metrics for the candidate piles # watershed_segs_poly watershed_segs_poly &lt;- get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we already have area so we&#39;ll drop the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) # dbscan_segs_poly dbscan_segs_poly &lt;- get_structural_metrics(sf_data = dbscan_segs_poly, chm_rast = aoi_chm_rast_slice) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we already have area so we&#39;ll drop the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) what did we get back? watershed_segs_poly %&gt;% dplyr::glimpse() ## Rows: 24 ## Columns: 10 ## $ pred_id &lt;dbl&gt; 22, 133, 135, 141, 142, 143, 145, 146, 147, 151, 156… ## $ chull_area_m2 &lt;dbl&gt; 9.495, 25.320, 26.820, 5.275, 5.055, 20.255, 6.175, … ## $ convexity_ratio &lt;dbl&gt; 0.7761980, 0.9095577, 0.8941089, 0.9383886, 0.929772… ## $ mbc_area_m2 &lt;dbl&gt; 15.316338, 33.030222, 35.734991, 10.370370, 6.234503… ## $ circularity_ratio &lt;dbl&gt; 0.4811855, 0.6972402, 0.6710510, 0.4773215, 0.753869… ## $ area_m2 &lt;dbl&gt; 7.375899, 23.048435, 23.999195, 4.953962, 4.703762, … ## $ volume_m3 &lt;dbl&gt; 32.331139, 31.446938, 35.541131, 5.187639, 4.081403,… ## $ max_height_m &lt;dbl&gt; 5.965939, 3.566000, 3.181000, 2.578000, 2.559000, 2.… ## $ volume_per_area &lt;dbl&gt; 4.3833487, 1.3643850, 1.4809301, 1.0471696, 0.867689… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499326 4317738, 4..., POLYGON ((49… plot the metrics of pile area, height, and volume # p1_temp &lt;- p_fn_temp &lt;- function(dta,fill_col,col_nm=latex2exp::TeX(&quot;area $\\\\textrm{m}^2$&quot;),pal=&quot;Oranges&quot;){ ggplot2::ggplot(data = dta) + ggplot2::geom_sf( mapping=ggplot2::aes(fill=.data[[fill_col]]) # mapping=ggplot2::aes(fill={{fill_col}}) , color = NA ) + ggplot2::geom_sf_text( # mapping=ggplot2::aes(label=scales::comma({{fill_col}}, accuracy=0.1)) mapping=ggplot2::aes(label=scales::comma(.data[[fill_col]], accuracy=0.1)) , vjust = 1, hjust = -0.9, size = 2.5 ) + ggplot2::scale_fill_distiller(palette = pal, name = col_nm, direction = 1) + ggplot2::labs(subtitle = col_nm) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.title = ggplot2::element_blank() , plot.subtitle = ggplot2::element_text(size = 6, hjust = 0.5) , panel.border = ggplot2::element_rect(color = &quot;black&quot;, fill = NA, size = 1) , legend.text = ggplot2::element_text(size = 7) ) } # lists pal_temp &lt;- c(&quot;Blues&quot;,&quot;Purples&quot;,&quot;Greens&quot;) nm_temp &lt;- c( latex2exp::TeX(&quot;area $\\\\textrm{m}^2$&quot;) , latex2exp::TeX(&quot;volume $\\\\textrm{m}^3$&quot;) , &quot;height m&quot; ) col_temp &lt;- c( &quot;area_m2&quot; , &quot;volume_m3&quot; , &quot;max_height_m&quot; ) # watershed ws_p_temp &lt;- 1:length(col_temp) %&gt;% purrr::map( \\(x) p_fn_temp( watershed_segs_poly , fill_col = col_temp[x] , col_nm = nm_temp[x] , pal = pal_temp[x] ) ) # dbscan db_p_temp &lt;- 1:length(col_temp) %&gt;% purrr::map( \\(x) p_fn_temp( dbscan_segs_poly , fill_col = col_temp[x] , col_nm = nm_temp[x] , pal = pal_temp[x] ) ) p1_temp &lt;- patchwork::wrap_plots( ws_p_temp ) + patchwork::plot_annotation( title = &quot;watershed&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14)) ) p2_temp &lt;- patchwork::wrap_plots( db_p_temp ) + patchwork::plot_annotation( title = &quot;dbscan&quot; , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14)) ) patchwork::wrap_plots( list( patchwork::wrap_elements( p1_temp ) , patchwork::wrap_elements( p2_temp ) ) , nrow = 2 ) after all of that, the results of the two methods are the same for this particular demonstration area 4.6 Final Shape Refinement In the final stage, we generate convex hulls for the segments to smooth the blocky, pixelated edges inherent in raster data (which can look like they were generated in Minecraft). Any segments with overlapping convex hulls are then removed to help filter out false detections which may be groups of small trees or shrubs. This step is intended to reflect real-world conditions where distinct slash piles are constructed with enough spacing to remain spatially independent rather than overlapping. Finally, we’ll apply one more filter for the area and height thresholds. ############################################################################### # make a function to remove overlapping polygons from a sf data frame ############################################################################### st_remove_overlaps &lt;- function(sf_data) { if(!inherits(sf_data, &quot;sf&quot;)){stop(&quot;must pass `sf` data object&quot;)} # if not polygons if( !all(sf::st_is(sf_data, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) ){ stop(paste0( &quot;`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])&quot; )) } if(nrow(sf_data)&lt;=1){return(sf_data)} # combine all touching polygons and keep the ones that overlap multiple from the original polygons comb_temp &lt;- sf_data %&gt;% dplyr::ungroup() %&gt;% sf::st_union(by_feature = F) %&gt;% sf::st_cast(&quot;POLYGON&quot;) %&gt;% sf::st_as_sf() %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% sf::st_set_crs(sf::st_crs(sf_data)) %&gt;% dplyr::mutate(new_id = dplyr::row_number()) %&gt;% dplyr::select(new_id) # identify overlaps overlap_temp &lt;- comb_temp %&gt;% sf::st_intersection(sf_data) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::group_by(new_id) %&gt;% dplyr::summarise(n_orig = dplyr::n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::filter(n_orig&gt;=2) %&gt;% dplyr::pull(new_id) if(length(overlap_temp)==0){return(sf_data)} # just get the overlaps comb_temp &lt;- comb_temp %&gt;% dplyr::filter(new_id %in% overlap_temp) %&gt;% sf::st_union() # remove all input polygons from the original data that have any overlaps return(sf::st_difference(sf_data,comb_temp)) } take the convex hull and apply our st_remove_overlaps() function to the remaining candidate segments. Finally, we filter for area based on the smoothed shape # watershed_segs_poly watershed_segs_poly &lt;- watershed_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %&gt;% # filter for height dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # dbscan_segs_poly dbscan_segs_poly &lt;- dbscan_segs_poly %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %&gt;% # filter for height dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # dbscan_segs_poly %&gt;% dplyr::glimpse() 4.6.1 Watershed Segmentation plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered watershed candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = watershed_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice 4.6.2 DBSCAN Segmentation plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_plt_ortho + ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = &quot;black&quot;, lwd = 0.8) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) + ggplot2::theme(legend.position = &quot;none&quot;) plot the filtered dbscan candidate segments (magenta) and the actual piles (cyan) on the CHM plt_aoi_chm(aoi_chm_rast_slice) + ggplot2::geom_sf( data = aoi_slash_piles_polys , fill = NA, color = &quot;cyan&quot;, lwd = 0.6 ) + ggplot2::geom_sf( data = dbscan_segs_poly , fill = NA, color = &quot;magenta&quot;, lwd = 0.6 ) nice 4.6.3 Quick methods comparison let’s quickly look at the watershed and dbscan segments on the same plot ggplot2::ggplot() + ggplot2::geom_sf( data = watershed_segs_poly, mapping=ggplot2::aes(color=&quot;watershed&quot;) , fill = NA, lwd = 2 ) + ggplot2::geom_sf( data = dbscan_segs_poly, mapping=ggplot2::aes(color=&quot;dbscan&quot;) , fill = NA, lwd = 1 ) + ggplot2::scale_color_manual(values = c(&quot;gray33&quot;, &quot;aquamarine3&quot;),name=&quot;&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;top&quot;) almost exactly the same let’s see how many segments were originally detected using each method and how many we are left with after our filtering for shape irregularity, pile area and height expectations, circularity, and potential overlaps after smoothing? dplyr::tibble( method = c(&quot;watershed&quot;, &quot;DBSCAN&quot;) , old_segments = c( terra::freq(watershed_segs) %&gt;% nrow() , terra::freq(dbscan_segs) %&gt;% nrow() ) , new_segments = c( nrow(watershed_segs_poly) , nrow(dbscan_segs_poly) ) # area , old_area = c( terra::cellSize(watershed_segs) %&gt;% terra::crop(watershed_segs,mask=T) %&gt;% terra::global(fun=&quot;sum&quot;, na.rm=T) %&gt;% as.numeric() , terra::cellSize(dbscan_segs) %&gt;% terra::crop(dbscan_segs,mask=T) %&gt;% terra::global(fun=&quot;sum&quot;, na.rm=T) %&gt;% as.numeric() ) , new_area = c( watershed_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() , dbscan_segs_poly %&gt;% sf::st_union() %&gt;% sf::st_area() %&gt;% as.numeric() ) ) %&gt;% dplyr::mutate( segments_pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;segments&quot;), ~scales::comma(.x,accuracy=1)) , area_pct_removed = scales::percent((new_area-old_area)/old_area, accuracy = 0.1) , dplyr::across(tidyselect::ends_with(&quot;area&quot;), ~scales::comma(.x,accuracy=0.1)) ) %&gt;% dplyr::select( method ,tidyselect::ends_with(&quot;_segments&quot;), segments_pct_removed ,tidyselect::ends_with(&quot;_area&quot;), area_pct_removed ) %&gt;% kableExtra::kbl( caption = &quot;Demonstration area candidate segments by method&lt;br&gt;final candidate segments fully filtered for size and geometric expectations&quot; , col.names = c( &quot;method&quot; , &quot;orig. candidate&lt;br&gt;segments&quot;, &quot;final&lt;br&gt;segments&quot;, &quot;% candidates&lt;br&gt;removed&quot; , &quot;orig. candidate&lt;br&gt;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot;, &quot;final&lt;br&gt;area (m&lt;sup&gt;2&lt;/sup&gt;)&quot;, &quot;% area&lt;br&gt;removed&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 4.6: Demonstration area candidate segments by methodfinal candidate segments fully filtered for size and geometric expectations method orig. candidatesegments finalsegments % candidatesremoved orig. candidatearea (m2) finalarea (m2) % arearemoved watershed 214 24 -88.8% 276.4 242.0 -12.4% DBSCAN 200 25 -87.5% 274.4 245.4 -10.6% wow that is a lot of filtering, but it looks like the result for this demonstration area is decently accurate (we’ll perform full validation of the method later). That is, there are few false positive predictions (commission errors) and few false negative predictions (omission errors)…in the next section we’ll integrate spectral data to further filter the false positive predictions based on how closely their spectral information matches vegetation 4.7 Pile Detection Function The rule-based method for slash pile detection using CHM raster data we reviewed above generally follows this outline: CHM Generation: A Canopy Height Model (CHM) is generated from the point cloud data. The CHM is generated by removing the ground surface effectively representing a Digital Surface Model (DSM) without ground, ensuring all values are heights above bare earth. CHM Height Filtering: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a “slice” of the CHM. Segmentation Method Setup: Applies the dynamic parameter logic used in the Watershed or DBSCAN segmentation method. This logic ensures scale-invariant object detection by maintaining constant proportions between the algorithm search windows and the physical dimensions of the target object. This dynamic approach allows the method parameters to adapt automatically to the input data resolution so that the resulting candidate segments remain spatially consistent with target objects. Candidate Segmentation: Watershed or DBSCAN segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form. Shape Refinement &amp; Area Filtering: To align segmentation results with real-world pile construction, we simplify candidate segments by retaining only their largest contiguous portion to eliminate detached noise and ensure each feature represents a discrete physical object. The results are then filtered based on the area expectations. Shape Irregularity: Convexity Filtering: Candidate pile locations are filtered to remove highly irregular shapes by assessing their overlap with their convex hull. This process removes irregular objects like branched tree crowns or segments with holes while allowing solid, regular shapes (e.g. circles, rectangles, triangles) to pass. Circularity Filtering: A circularity filter is applied to measure a shape’s dispersion by dividing the candidate polygon area by the area of its minimum bounding circle. This second-stage shape irregularity filter targets the round bases typical of manual construction by penalizing elongated or non-circular shapes that do not adequately fill their circumcircle. Final Shape Refinement &amp; Overlap Removal: Lastly, segments are smoothed using their convex hull to remove the “blocky” raster edges (like they were made in Minecraft). Overlapping convex hull shapes are then removed to prevent false positives from clustered small trees or shrubs, ensuring singular pile detections. Let’s package all of the steps we demonstrated when formulating the methodology into a single function which can possibly be integrated into the cloud2trees package. The parameters are defined as follows: min_ht_m : numeric. The minimum height (in meters) a detected pile must reach to be considered valid. max_ht_m : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific “slice” of the data, ignoring anything taller than a typical pile. min_area_m2 : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid. max_area_m2 : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid. min_convexity_ratio : numeric. A value between 0 and 1 that controls how strict the filtering is for regularly shaped piles. A value of 1 means only piles that are perfectly smooth and rounded, with no dents or inward curves are kept (e.g. perfect square, rectangle, circle, triangle). A value of 0 allows for both perfectly regular and very irregular shapes. This filter works alongside min_circularity_ratio to identify slash piles based on expected morphology. min_circularity_ratio : numeric. A value between 0 and 1 that controls how strict the filtering is for circular pile shapes. Setting it to 1 means only piles that are perfectly circular are kept. A value of 0 allows for a wide range of shapes, including very circular and non-circular ones (like long, straight lines). For context, a perfect square has a circularity ratio of \\(\\frac{2}{\\pi}\\approx 0.637\\) while an equilateral triangle has a ratio of \\(\\frac{3\\sqrt{3}}{4\\pi}\\approx 0.414\\). This filter works alongside min_convexity_ratio to identify slash piles based on expected morphology. smooth_segs : logical. Setting this option to TRUE will: 1) smooth out the “blocky” edges of detected piles (which can look like they were made in Minecraft) by using their overall shape; and 2) remove any detected piles that overlap significantly with other smoothed piles to help ensure each detection is a single slash pile, not a cluster of objects like small trees or shrubs. # detect funciton slash_pile_detect &lt;- function( chm_rast , seg_method = &quot;watershed&quot; #### height and area thresholds for the detected piles # these should be based on data from the literature or expectations based on the prescription , min_ht_m # set the min expected pile height , max_ht_m # set the max expected pile height , min_area_m2 # set the min expected pile area , max_area_m2 # set the max expected pile area #### convexity filtering # 1 = perfectly convex (no inward angles); 0 = so many inward angles # values closer to 1 remove more irregular segments; # values closer to 0 keep more irregular segments (and also regular segments) # these will all be further filtered for their circularity if desired , min_convexity_ratio # min required overlap between the predicted pile and the convex hull of the predicted pile #### circularity filtering # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular # min required overlap between the candidate pile segment polygon and the minimum bounding circle of the polygon , min_circularity_ratio #### shape refinement &amp; overlap removal ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules , smooth_segs = T ############## # if defined...will instead write the detected segment polygons to the file given and return the name of the file # ex: &quot;my_wshed_segs.gpkg&quot;; ex: &quot;../data/ur_wshed_segs.gpkg&quot; , ofile = NA ) { # checks if(!inherits(smooth_segs, &quot;logical&quot;) || is.na(smooth_segs)){stop(&quot;define `smooth_segs` as logical&quot;)} ######################## # shape irregularity checks ######################## min_convexity_ratio &lt;- min_convexity_ratio[1] min_circularity_ratio &lt;- min_circularity_ratio[1] if( (is.na(tryCatch(as.numeric(min_convexity_ratio), error = function(e) NA)) || identical(as.numeric(min_convexity_ratio), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_convexity_ratio), error = function(e) NA))) || (is.na(tryCatch(as.numeric(min_circularity_ratio), error = function(e) NA)) || identical(as.numeric(min_circularity_ratio), numeric(0)) || !is.numeric(tryCatch(as.numeric(min_circularity_ratio), error = function(e) NA))) || as.numeric(min_convexity_ratio)&lt;0 || as.numeric(min_convexity_ratio)&gt;1 || as.numeric(min_circularity_ratio)&lt;0 || as.numeric(min_circularity_ratio)&gt;1 ){ # Code to execute if any condition is met (e.g., print an error message) stop(&quot;Error: One or more of `min_convexity_ratio`,`min_circularity_ratio` are not valid numbers between 0 and 1.&quot;) } ######################################################################################## ## 1) Segmentation ######################################################################################## get_segmentation_candidates_ans &lt;- get_segmentation_candidates( chm_rast = chm_rast , method = seg_method , min_ht_m = min_ht_m , max_ht_m = max_ht_m , min_area_m2 = min_area_m2 , max_area_m2 = max_area_m2 ) # get results individual objects segs_rast &lt;- get_segmentation_candidates_ans$segs_rast segs_sf &lt;- get_segmentation_candidates_ans$segs_sf slice_chm_rast &lt;- get_segmentation_candidates_ans$slice_chm_rast # seg_mthd_params &lt;- get_segmentation_candidates_ans$seg_mthd_params if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_ht_m`,`max_ht_m`,`min_area_m2`,`max_area_m2`&quot; )) } ######################################################################################## ## 2) shape refinement and area filtering ######################################################################################## # to better align the segmentation results with real-world pile construction we&#39;ll now # simplify candidate segments composed of multiple separate parts representing a single identified feature (i.e. &quot;multi-polygon&quot; candidate segments. # We&#39;ll simplify these segments by retaining only the largest contiguous portion using `cloud2trees` functionality. # Because slash piles are constructed as distinct, isolated objects to prevent tree mortality during burning, this refinement step isolates the primary # candidate body to eliminate detached noise and ensure each segment represents a discrete physical object before area-based filtering segs_sf &lt;- segs_sf %&gt;% # simplify multipolygons by keeping only the largest portion dplyr::mutate(treeID = pred_id) %&gt;% cloud2trees::simplify_multipolygon_crowns() %&gt;% dplyr::select(-treeID) %&gt;% # area filtering st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_area_m2`,`max_area_m2`&quot; )) } ######################################################################################## ## 3) convexity filtering ######################################################################################## # let&#39;s first filter out segments that have holes in them # or are very irregularly shaped by comparing the area of the polygon and convex hull # min_convexity_ratio = min required overlap between the predicted pile and the convex hull of the predicted pile if(min_convexity_ratio&gt;0){ # apply the convexity filtering on the polygons segs_sf &lt;- st_convexity_filter( sf_data = segs_sf # min required overlap between the polygon and the convex hull of the polygon , min_convexity_ratio = min_convexity_ratio ) } # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and `min_convexity_ratio` expectations&quot; , &quot;\\n try adjusting `min_convexity_ratio` &quot; )) } ######################################################################################## ## 4) circularity filtering ######################################################################################## # let&#39;s apply a minimum bounding circle algorithm to remove non-circular segments from the remaining segments if(min_circularity_ratio&gt;0){ # apply the circularity filtering on the polygons segs_sf &lt;- st_circularity_filter( sf_data = segs_sf # min required overlap between the polygon and the minimum bounding circle of the polygon , min_circularity_ratio = min_circularity_ratio ) } # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and `min_circularity_ratio` expectations&quot; , &quot;\\n try adjusting `min_circularity_ratio` &quot; )) } ######################################################################################## ## 5) calculate CHM-based structural metrics for the candidate piles ######################################################################################## # we&#39;ll use our `get_structural_metrics()` with the height-filtered CHM to compute the structural metrics for the candidate piles segs_sf &lt;- get_structural_metrics( sf_data = segs_sf , chm_rast = slice_chm_rast ) %&gt;% purrr::pluck(&quot;sf_data&quot;) %&gt;% # we may already have area so we&#39;ll use only the value from this function dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;poly_area_m2&quot; ))) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;trouble getting the structural metrics&quot; , &quot;\\n try adjusting .... something &quot; )) } # filter for height segs_sf &lt;- segs_sf %&gt;% dplyr::filter( max_height_m &gt;= min_ht_m &amp; max_height_m &lt;= max_ht_m ) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected using the given CHM and size expectations&quot; , &quot;\\n try adjusting size threshold parameters:&quot; , &quot;\\n `min_ht_m`,`max_ht_m`&quot; )) } ######################################################################################## ## 6) shape refinement &amp; overlap removal ######################################################################################## # use the convex hull shapes of our remaining segments. # This helps to smooth out the often &#39;blocky&#39; edges of raster-based segments # , which can look like they were generated in Minecraft. # Additionally, by removing any segments with overlapping convex hull shapes, # we can likely reduce false detections that are actually groups of small trees or shrubs, # ensuring our results represent singular slash piles. if(smooth_segs){ # take the convex hull and apply our `st_remove_overlaps()` function to the remaining candidate segments. # Finally, we filter for area based on the smoothed shape segs_sf &lt;- segs_sf %&gt;% sf::st_convex_hull() %&gt;% sf::st_simplify() %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% st_remove_overlaps() %&gt;% # now we need to re-do the volume and area calculations dplyr::mutate( area_m2 = sf::st_area(.) %&gt;% as.numeric() , volume_m3 = area_m2*volume_per_area ) %&gt;% st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) # check return if(dplyr::coalesce(nrow(segs_sf),0)==0){ stop(paste0( &quot;no segments detected after removing overlapping final segments&quot; , &quot;\\n try with `smooth_segs = F`&quot; )) } } # calculate diameter segs_sf &lt;- st_calculate_diameter(segs_sf) # check for write if( inherits(ofile,&quot;character&quot;) &amp;&amp; stringr::str_squish(ofile)!=&quot;&quot; &amp;&amp; !identical(stringr::str_squish(ofile),character(0)) ){ sf::st_write(segs_sf, dsn = ofile, quiet = T, append = F) return(ofile) } # return return(list( segs_sf = segs_sf , seg_mthd_params = get_segmentation_candidates_ans$seg_mthd_params , slice_chm_rast = get_segmentation_candidates_ans$slice_chm_rast )) } remove all other parameters and objects that might have the same name as in this function since we used the framework outlined above to define this (fantastic?) beast of a function remove( min_ht_m, max_ht_m , min_area_m2, max_area_m2 , min_convexity_ratio , min_circularity_ratio , get_segmentation_params_ans , dbscan_segs_poly, watershed_segs_poly , dbscan_segs, watershed_segs , dbscan_segs_poly_chull, dbscan_segs_poly_mbc , watershed_segs_poly_chull, watershed_segs_poly_mbc , aoi_chm_rast_slice ) gc() let’s test this real quick on our example area slash_pile_detect_watershed_ans_temp &lt;- slash_pile_detect( chm_rast = aoi_chm_rast , seg_method = &quot;watershed&quot; , min_ht_m = 1 , max_ht_m = 4 , min_area_m2 = 1.5^2 , max_area_m2 = 50 , min_convexity_ratio = 0.7 , min_circularity_ratio = 0.5 ) the slash_pile_detect() function returns: segs_sf: the segments that passed all size and geometric expectations for target slash piles seg_mthd_params: the dynamic parameters used in the Watershed or DBSCAN segmentation method slice_chm_rast: the height-filtered CHM slice used to segment candidate slash piles # what did we get? slash_pile_detect_watershed_ans_temp %&gt;% dplyr::glimpse() ## List of 3 ## $ segs_sf : sf [19 × 9] (S3: sf/tbl_df/tbl/data.frame) ## ..$ pred_id : num [1:19] 54 69 83 84 87 88 89 94 100 101 ... ## ..$ convexity_ratio : num [1:19] 0.91 0.894 0.93 0.881 0.933 ... ## ..$ circularity_ratio: num [1:19] 0.697 0.671 0.754 0.652 0.662 ... ## ..$ area_m2 : num [1:19] 25.32 26.82 5.05 20.26 6.18 ... ## ..$ volume_m3 : num [1:19] 34.55 39.72 4.39 21.23 4.48 ... ## ..$ max_height_m : num [1:19] 3.57 3.18 2.56 2.54 2.36 ... ## ..$ volume_per_area : num [1:19] 1.364 1.481 0.868 1.048 0.725 ... ## ..$ geometry :sfc_POLYGON of length 19; first list element: List of 1 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## ..$ diameter_m : num [1:19] 6.45 6.75 2.82 5.91 3.33 ... ## ..- attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## ..- attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;pred_id&quot; &quot;convexity_ratio&quot; &quot;circularity_ratio&quot; &quot;area_m2&quot; ... ## $ seg_mthd_params:List of 3 ## ..$ data_summary:List of 2 ## .. ..$ pts_per_m2: num 100 ## .. ..$ rast_res_m: num 0.1 ## ..$ watershed :List of 2 ## .. ..$ tol: num 1.5 ## .. ..$ ext: num 2 ## ..$ dbscan :List of 2 ## .. ..$ eps : num 0.15 ## .. ..$ minPts: num 7 ## $ slice_chm_rast :S4 class &#39;SpatRaster&#39; [package &quot;terra&quot;] let’s check out the height-filtered CHM “slice” slash_pile_detect_watershed_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;filtered CHM (m)&quot;) let’s overlay the final candidate segments (magenta) and the actual piles (cyan) on the raw, un-filtered CHM aoi_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), main = &quot;CHM (m) and demonstration piles&quot;) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 2.5 ) how do the form quantification measurements look? p1_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = area_m2)) + ggplot2::scale_fill_distiller(palette = &quot;Blues&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;, fill = &quot;&quot;, subtitle = &quot;area_m2&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank(), plot.subtitle = ggplot2::element_text(size = 7,hjust=0.5)) p2_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = volume_m3)) + ggplot2::scale_fill_distiller(palette = &quot;Purples&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;, fill = &quot;&quot;, subtitle = &quot;volume_m3&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank(), plot.subtitle = ggplot2::element_text(size = 7,hjust=0.5)) p3_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = max_height_m)) + ggplot2::scale_fill_distiller(palette = &quot;Greens&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;, fill = &quot;&quot;, subtitle = &quot;max_height_m&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank(), plot.subtitle = ggplot2::element_text(size = 7,hjust=0.5)) p4_temp &lt;- slash_pile_detect_watershed_ans_temp$segs_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill = diameter_m)) + ggplot2::scale_fill_distiller(palette = &quot;PuRd&quot;, direction = 1) + ggplot2::labs(x=&quot;&quot;,y=&quot;&quot;, fill = &quot;&quot;, subtitle = &quot;diameter_m&quot;) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;top&quot;, axis.text = ggplot2::element_blank(), plot.subtitle = ggplot2::element_text(size = 7,hjust=0.5)) (p1_temp + p2_temp) / (p3_temp + p4_temp) "],["data_fusion.html", "Section 5 Data Fusion 5.1 RGB Indices 5.2 Demonstration Pile Spectral Summary 5.3 Candidate Polygon Spectral Filtering Function 5.4 Data Fusion Method Demonstration", " Section 5 Data Fusion We’ll demonstrate our approach that uses both aerial point cloud-generated CHM data (for structural information) and RGB imagery (for spectral information) which is a data fusion approach. In the prior section, we demonstrated our geometric, rules-based slash pile detection approach. Our data fusion approach identify initial candidate slash piles based on their structural form using this geometric, rules-based method and then integrates the RGB imagery to filter these candidates spectrally. This data fusion methodology leverages the complementary strengths of both data types, using 3D geometry (or “2.5D” as CHM is sometimes referred to) for initial object segmentation and spectral data to refine detections by using thresholds defined to identify green biomass and rock and soil features for exclusion. we’ll continue using the same demonstration area for this walkthrough as introduced in the prior section 5.1 RGB Indices Our data fusion approach uses methods feasible with RGB data since most common UAS systems lack additional multispectral sensors. Despite the absence of multispectral data (e.g. near-infrared), many RGB-based indices correlate strongly with multispectral measurements, particularly those related to leaf area (Santini et al. 2019). We employ six specific spectral threshold tests: the Green Red Vegetation Index (GRVI), Red Green Ratio Index (RGRI), Visible Band-Difference Vegetation Index (VDVI), and Excess Green-minus-Red Index (ExGR), alongside components from the CIELAB and HSV color models. These indices were selected based on their established ability in existing research to effectively distinguish living vegetation from dead material or background features, while the application of thresholds to indices is a common approach for spectral segmentation (Kior et al. 2024). The RGB index thresholds implemented include those found to perform well in distinguishing green vegetation in previous research (Meyer &amp; Neto 2008; Motohka et al. 2010; Wang et al. 2025; Riehle et al. 2020; Johansen et al. 2019; Goodbody et al. 2017). By inverting these established vegetation thresholds, our approach isolates non-photosynthetic slash piles from surrounding green biomass. To enhance segmentation accuracy, the CIELAB and HSV models are used because they offer advantages over the RGB color model which can be sensitive to external variables like lighting (Cheng et al. 2001; Kior et al. 2024). These models provide stability across different lighting conditions, sensors, and flight plans by isolating color from light intensity. The CIELAB (L*a*b*) model provides a perceptually uniform color space based on human vision, using L* for lightness (0-100), a* for green-red (towards red if a* &gt; 0, towards green if a* &lt; 0), and b* for blue-yellow (towards yellow if b* &gt; 0, towards blue if b* &lt; 0). Studies have used the a* component to perform vegetation segmentation and health evaluation (Rigon et al. 2016; Riehle et al. 2020) as well as in the discrimination of wood products (Moya et al. 2012; Amaral Reis et al. 2023). The HSV (Hue, Saturation and Value) model isolates the hue (i.e. color) component to provide a color representation that is invariant to saturation and brightness (i.e. the “value” component). In general, the hue values of green vegetation vary from 50 to 150 degrees using a value range of 0-360 degrees (Yang et al. 2015; Luo et al. 2024). We’ll integrate the spectral indices listed in the table below that rely only on RGB data and have threshold values identified in the literature to distinguish green vegetation from dead/senescent vegetation and background soil or rock. For the thresholds meant to identify green vegetation we’ll use the inverted threshold to retain candidate slash piles. Here are the thresholds represented in the literature: Index Likely Crop Likely Tree Likely Shrub Likely Wood / Diseased Trees Source GRVI x &gt; 0.0 x &gt; 0.0 x &gt; 0.0 Motohka et al. 2010; Goodbody et al. 2017; Johansen et al. 2019 RGRI x &lt; 0.63 x &lt; 0.70 x &lt; 0.52 Wang et al. 2025 VDVI x &gt; 0.06 x &gt; 0.04 x &gt; 0.03 Wang et al. 2025 ExGR x &gt; 0.0 x &gt; 0.0 x &gt; 0.0 Meyer &amp; Neto 2008; Riehle et al. 2020 a* x &lt; -5 – 0 x &gt; 2 – 10 Moya et al. 2012; Rigon et al. 2016; Riehle et al. 2020; Amaral Reis et al. 2023 Hue 50 &lt; x &lt; 150 0 &lt; x &lt; 26 Yang et al. 2015; Luo et al. 2024 For these formulas, \\(R\\), \\(G\\), and \\(B\\) represent the raw pixel values for the Red, Green, and Blue bands, respectively. For indices that use normalized values, \\(r\\), \\(g\\), and \\(b\\) are defined as: \\(r = \\frac{R}{R+G+B}\\) \\(g = \\frac{G}{R+G+B}\\) \\(b = \\frac{B}{R+G+B}\\) Name Acronym Description Recommended Formula / Method Potential Range Green-Red Vegetation Index GRVI Detects vegetation greenness using a normalized difference \\(\\frac{G - R}{G + R}\\) -1 to 1 Red-Green Ratio Index RGRI Compares red to green intensity to estimate plant pigment changes \\(\\frac{R}{G}\\) 0 to \\(\\infty\\) Visible-band Difference Index VDVI Index for extracting vegetation from complex backgrounds \\(\\frac{2G - R - B}{2G + R + B}\\) -1 to 1 Excess Green-minus-Red ExGR Linear index for discriminating plants from soil/background \\(3g - 2.4r - b\\) -3.4 to 3 CIELab a* (Green-Red) a* Perceptually uniform green-to-red axis grDevices::convertColor(..., to=\"Lab\") -128 to 127 HSV Hue Hue The dominant “color type” angle on the color wheel that ensures consistent values regardless of illumination terra::colorize(..., to=\"hsv\") 0 to 1 (or 0–360 degrees) Rather than relying on a single spectral metric, our method employs a “voting” system where all six indices contribute to candidate evaluation. Integrating six distinct index-threshold pairs determined independently by different researchers across diverse sensors and vegetation types is more stable than relying on any single index or study a an ensemble approach minimizes the potential error or limitations inherent in a single identified threshold. This ensemble approach provides a framework that allows users to weight the spectral data by requiring anywhere from 0 to 6 thresholds to be met for a candidate pile to be retained. Setting the requirement to zero relies exclusively on the structural detection, while higher values place progressively more weight on spectral confirmation. A known limitation of our data fusion approach is the spectral similarity between dead wood and geologic features like rocks or boulders. Many common rock-forming minerals are “spectrally featureless” in the visible range with reflectance values remaining relatively constant across the range of visible wavelengths (Harris et al. 2010). These geologic features are difficult to distinguish from dead wood which can appear spectrally similar to background soil and rocks (Zielewska-Büttner et al. 2020). Because our indices are specifically tuned to distinguish vegetation, our framework may struggle in rocky environments where boulders or rock outcroppings are both structurally and spectrally similar to slash piles. It is important to highlight that the spectral data in our data fusion approach functions strictly as a final filter or quality check. It does not generate new piles or alter the shape and location of structurally detected candidates. This leads to a distinct performance trade-off when integrating spectral data. While applying these spectral filters can improve precision by correctly removing false positives (e.g. shrubs, lower branches of trees), it also carries the risk of lowering recall if a true slash pile possesses an unexpected spectral signature. 5.1.1 Spectral Index Functions Although there are dedicated R packages to calculate various spectral indicies (e.g. RStoolbox [Muller et al. 2025]), we’ll make our own to ensure data quality checks and to limit the spectral indices to those highlighted above. # check raster bands and extract rgb layers check_raster_bands &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { # convert to SpatRaster if input is from &#39;raster&#39; package if( inherits(rast, &quot;RasterStack&quot;) || inherits(rast, &quot;RasterBrick&quot;) ){ rast &lt;- terra::rast(rast) }else if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input &#39;rast&#39; must be a SpatRaster from the `terra` package&quot;) } # check if band indices are valid num_bands &lt;- terra::nlyr(rast) # let 999999 be a cheat code cheat_code &lt;- 999999 if( ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &gt; num_bands ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &gt; num_bands ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &gt; num_bands ) || ( red_band_idx!=cheat_code &amp;&amp; red_band_idx &lt; 1 ) || ( green_band_idx!=cheat_code &amp;&amp; green_band_idx &lt; 1 ) || ( blue_band_idx!=cheat_code &amp;&amp; blue_band_idx &lt; 1 ) || length(unique(c(red_band_idx,green_band_idx,blue_band_idx)))!=3 ){ stop(&quot;Invalid band index provided. Band indices must correspond to existing, unique layers in the raster object.&quot;) } # extract bands if(red_band_idx!=cheat_code){ R &lt;- rast[[red_band_idx]] }else{ R &lt;- rast[[1]] } if(green_band_idx!=cheat_code){ G &lt;- rast[[green_band_idx]] }else{ G &lt;- rast[[1]] } if(blue_band_idx!=cheat_code){ B &lt;- rast[[blue_band_idx]] }else{ B &lt;- rast[[1]] } return(list(R = R, G = G, B = B)) } # check_raster_bands(ortho_rast, red_band_idx=1, green_band_idx=3, blue_band_idx = 999999) # convert RGB to HSV color space spectral_rgb_to_hsv &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { # check bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # convert to RGB rgb_rast &lt;- terra::RGB(x = c(R,G,B), value = 1:3) # ?terra::colorize # convert to HSV (returns layers: h, s, v) hsv_rast &lt;- terra::colorize(rgb_rast, to = &quot;hsv&quot;) # names names(hsv_rast) &lt;- c(&quot;hue&quot;, &quot;saturation&quot;, &quot;brightness&quot;) # scale only the hue layer to 360 # hsv_rast$hue &lt;- hsv_rast$hue*360 return(hsv_rast) } # convert RGB to CIELab color space # ?grDevices::convertColor spectral_rgb_to_lab &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx, max_dn = 255) { # check bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B rgb_rast &lt;- c(R,G,B) # values as a matrix (vectorized) normalized to max 255 val vals &lt;- terra::values(rgb_rast) / max_dn # conversion on the matrix lab_vals &lt;- grDevices::convertColor(vals, from = &quot;sRGB&quot;, to = &quot;Lab&quot;) # new SpatRaster using original str and replace values lab_rast &lt;- terra::rast(rgb_rast, nlyrs = 3) terra::values(lab_rast) &lt;- lab_vals names(lab_rast) &lt;- c(&quot;L&quot;, &quot;a&quot;, &quot;b&quot;) return(lab_rast) } # calculate green red vegetation index (GRVI) # (G - R) / (G + R) spectral_index_grvi &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G grvi &lt;- (G - R) / (G + R) names(grvi) &lt;- &quot;grvi&quot; return(grvi) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # red green ratio index (RGRI) # R/G spectral_index_rgri &lt;- function(rast, red_band_idx, green_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx = 999999) # blue_band_idx is dummy here R &lt;- bands$R G &lt;- bands$G rgri &lt;- R/G names(rgri) &lt;- &quot;rgri&quot; return(rgri) } # spectral_index_grvi(ortho_rast,red_band_idx = 1, green_band_idx = 2) %&gt;% terra::plot() # calculate visible band-difference vegetation index (VDVI) # (2G - R - B) / (2G + R + B) spectral_index_vdvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B vdvi &lt;- (2 * G - R - B) / (2 * G + R + B) names(vdvi) &lt;- &quot;vdvi&quot; return(vdvi) } # spectral_index_vdvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate red green blue vegetation index (RGBVI) # (G^2 - (B * R)) / (G^2 + (B * R)) spectral_index_rgbvi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B rgbvi &lt;- (G^2 - (B * R)) / (G^2 + (B * R)) names(rgbvi) &lt;- &quot;rgbvi&quot; return(rgbvi) } # spectral_index_rgbvi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excess green (ExG) # (2G - R - B) / (R + G + B) (using normalized RGB values) # 2G - R - B (using raw values, then normalized by sum of R+G+B) spectral_index_exg &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exg &lt;- (2 * g_norm - r_norm - b_norm) names(exg) &lt;- &quot;exg&quot; return(exg) } # spectral_index_exg(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate brightness index (BI) # sqrt((R^2 + G^2 + B^2) / 3) spectral_index_bi &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B bi &lt;- sqrt((R^2 + G^2 + B^2) / 3) # normalize to 0-1 range max_brightness = max( terra::minmax(R)[2] , terra::minmax(G)[2] , terra::minmax(B)[2] , na.rm = T ) bi &lt;- bi/max_brightness names(bi) &lt;- &quot;bi&quot; return(bi) } # spectral_index_bi(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate excessive red (ExR) # 1.4r - g, where r and g are normalized RGB values. spectral_index_exr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx){ bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb exr &lt;- (1.4 * r_norm - g_norm) names(exr) &lt;- &quot;exr&quot; return(exr) } #&#39; calculate excess green-excess red (ExGR) #&#39; 3g - 2.4r - b, where r, g, b are normalized RGB values. #&#39; equivalent to ExG - ExR. spectral_index_exgr &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B # Calculate normalized RGB values sum_rgb &lt;- R + G + B r_norm &lt;- R / sum_rgb g_norm &lt;- G / sum_rgb b_norm &lt;- B / sum_rgb exgr &lt;- (3 * g_norm - 2.4 * r_norm - b_norm) names(exgr) &lt;- &quot;exgr&quot; return(exgr) } # calculate saturation (SAT) # (max(R,G,B) - min(R,G,B)) / max(R,G,B) spectral_index_saturation &lt;- function(rast, red_band_idx, green_band_idx, blue_band_idx) { bands &lt;- check_raster_bands(rast, red_band_idx, green_band_idx, blue_band_idx) R &lt;- bands$R G &lt;- bands$G B &lt;- bands$B max_rgb &lt;- max(R, G, B, na.rm = T) min_rgb &lt;- min(R, G, B, na.rm = T) sat &lt;- (max_rgb - min_rgb) / max_rgb names(sat) &lt;- &quot;sat&quot; return(sat) } # spectral_index_saturation(ortho_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) %&gt;% terra::plot() # calculate all indices calculate_all_rgb_indices &lt;- function(raster_obj, red_band_idx, green_band_idx, blue_band_idx) { # call individual index functions grvi_layer &lt;- spectral_index_grvi(raster_obj, red_band_idx, green_band_idx) rgri_layer &lt;- spectral_index_rgri(raster_obj, red_band_idx, green_band_idx) vdvi_layer &lt;- spectral_index_vdvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) rgbvi_layer &lt;- spectral_index_rgbvi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exg_layer &lt;- spectral_index_exg(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exr_layer &lt;- spectral_index_exr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) exgr_layer &lt;- spectral_index_exgr(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # bi_layer &lt;- spectral_index_bi(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # sat_layer &lt;- spectral_index_saturation(raster_obj, red_band_idx, green_band_idx, blue_band_idx) # color spaces: HSV hsv_rast &lt;- spectral_rgb_to_hsv(raster_obj, red_band_idx, green_band_idx, blue_band_idx) names(hsv_rast) &lt;- paste0(&quot;hsv_&quot;, names(hsv_rast), recycle0 = T) hsv_hue &lt;- hsv_rast$hsv_hue hsv_saturation &lt;- hsv_rast$hsv_saturation hsv_brightness &lt;- hsv_rast$hsv_brightness # color spaces: CEILab Lab_rast &lt;- spectral_rgb_to_lab(raster_obj, red_band_idx, green_band_idx, blue_band_idx) names(Lab_rast) &lt;- paste0(&quot;Lab_&quot;, names(Lab_rast), recycle0 = T) Lab_L &lt;- Lab_rast$Lab_L Lab_a &lt;- Lab_rast$Lab_a Lab_b &lt;- Lab_rast$Lab_b # stack all calculated indices into a single spatraster all_indices &lt;- c( grvi_layer , rgri_layer , vdvi_layer , rgbvi_layer , exg_layer , exr_layer , exgr_layer # , bi_layer # , sat_layer , hsv_hue , hsv_saturation , hsv_brightness , Lab_L , Lab_a , Lab_b ) return(all_indices) } let’s test this calculate_all_rgb_indices() function with our orthomosaic # calculate_all_rgb_indices all_rgb_indices_rast &lt;- calculate_all_rgb_indices(aoi_rgb_rast,red_band_idx = 1, green_band_idx = 2, blue_band_idx = 3) what did we get? # huh? all_rgb_indices_rast %&gt;% names() ## [1] &quot;grvi&quot; &quot;rgri&quot; &quot;vdvi&quot; &quot;rgbvi&quot; ## [5] &quot;exg&quot; &quot;exr&quot; &quot;exgr&quot; &quot;hsv_hue&quot; ## [9] &quot;hsv_saturation&quot; &quot;hsv_brightness&quot; &quot;Lab_L&quot; &quot;Lab_a&quot; ## [13] &quot;Lab_b&quot; we’ll limit to the indices we have thresholds for all_rgb_indices_rast &lt;- all_rgb_indices_rast %&gt;% terra::subset( c( &quot;grvi&quot; , &quot;rgri&quot; , &quot;vdvi&quot; , &quot;exgr&quot; , &quot;Lab_a&quot; , &quot;hsv_hue&quot; ) ) let’s plot all of those indices for the entire extent of our orthomoasic # plot terra::plot( all_rgb_indices_rast , nc = 3 # , nr = 3 , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F # , col = grDevices::gray.colors(n=111) ) we can also look at the correlation between the different indices # investigate correlation among covariates all_rgb_indices_rast %&gt;% terra::pairs( maxcells = min(11111, terra::ncell(all_rgb_indices_rast)*.01) ) many of these spectral indices are highly (even perfectly) correlated, meaning they provide redundant information. however, the index thresholds were determined independently for the most highly correlated values so we retain them for our voting system filtering methodology since the combination of the index with the unique index provides unique identification functionality. summary stats of these indices over our example area all_rgb_indices_rast %&gt;% terra::summary(size = min(11111, terra::ncell(all_rgb_indices_rast)*.01)) ## grvi rgri vdvi exgr ## Min. :-0.231626 Min. :0.656 Min. :-0.168247 Min. :-0.53902 ## 1st Qu.:-0.041936 1st Qu.:0.955 1st Qu.:-0.014794 1st Qu.:-0.18671 ## Median :-0.018483 Median :1.038 Median :-0.001864 Median :-0.15156 ## Mean :-0.007681 Mean :1.021 Mean : 0.015520 Mean :-0.12184 ## 3rd Qu.: 0.023030 3rd Qu.:1.088 3rd Qu.: 0.029838 3rd Qu.:-0.08337 ## Max. : 0.207713 Max. :1.603 Max. : 0.286542 Max. : 0.45691 ## NA&#39;s :5 NA&#39;s :5 NA&#39;s :5 NA&#39;s :5 ## Lab_a hsv_hue ## Min. :-31.0507 Min. :0.0000 ## 1st Qu.: -2.0458 1st Qu.:0.0639 ## Median : 0.7873 Median :0.1293 ## Mean : -0.3041 Mean :0.2407 ## 3rd Qu.: 3.1358 3rd Qu.:0.2675 ## Max. : 16.2004 Max. :0.9999 ## NA&#39;s :4 NA&#39;s :4 the terra::colorize() function produces Hue values normalized to the [0, 1] range; we can convert these normalized values to the [0, 360] range: (all_rgb_indices_rast$hsv_hue*360) %&gt;% terra::plot(main=&quot;Hue [0,360] range&quot;, axes = F, mar = c(0,0,2,0)) here is a plot of the different spectral indices (high values are brighter, low values are darker) on our example area we were working with in the last section with the demonstration piles in blue all_rgb_indices_rast %&gt;% terra::plot( nc = 3 , col = grDevices::gray.colors(111, start = 0, end = 1) , mar = c(0.5,0.5,2,0.5) , axes = FALSE , legend = F , fun = function(){ lines(terra::vect(aoi_boundary), col=&quot;black&quot;, lwd=2) # add a second vector outline (cyan) lines( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , col = &quot;cyan&quot;, lwd = 1.3) } ) for a refresher, here is the demonstration RGB image with the image annotated piles (cyan) terra::plotRGB(aoi_rgb_rast) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.3 ) 5.1.2 Spectral Index of Polygons we now need a function to crop the raster with all spectral indices given a polygon input data and return the spectral index values as columns attached to the polygon extract_rast_values &lt;- function(sf_data, rast, fun_agg = mean) { # checks if(!inherits(rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } if(!is.function(fun_agg)) { stop(&quot;Argument `fun_agg` must be a function (e.g., mean, median, sum).&quot;) } # crs sf_data &lt;- sf_data %&gt;% sf::st_transform(terra::crs(rast)) # extract values for each layer within each polygon extracted_values &lt;- terra::extract( x = rast , y = sf_data , fun = fun_agg , na.rm = TRUE ) # clean data fun_name &lt;- deparse(substitute(fun_agg)) extracted_values &lt;- extracted_values %&gt;% dplyr::select(-ID) %&gt;% dplyr::rename_with( ~ paste0( &quot;rast_&quot; # , fun_name ### if we want to have custom output depending on the fun_agg , &quot;agg&quot; , &quot;_&quot; , .x , recycle0 = TRUE ) ) # Merge the extracted values back to the original sf data frame # The row order is preserved by terra::extract, so a direct cbind is safe # if no rows were dropped due to spatial mismatch. # For robustness, we can explicitly join by row ID if needed, but for simple cases, cbind works. # Assuming sf_data has a unique ID column or row order is stable: sf_data_with_indices &lt;- sf_data %&gt;% dplyr::bind_cols(extracted_values) return(sf_data_with_indices) } 5.2 Demonstration Pile Spectral Summary let’s calculate the various spectral indices on our demonstration slash pile polygons by getting the median value within the bounds of the pile # extract_rast_values rgb_indices_df &lt;- extract_rast_values(aoi_slash_piles_polys, rast = all_rgb_indices_rast, fun_agg = median) %&gt;% # convert hue to 0-360 dplyr::rename(rast_agg_hsv_hue_01=rast_agg_hsv_hue) %&gt;% dplyr::mutate(rast_agg_hsv_hue = rast_agg_hsv_hue_01*360) rgb_indices_df %&gt;% dplyr::glimpse() ## Rows: 18 ## Columns: 27 ## $ pile_id &lt;dbl&gt; 3, 4, 5, 6, 11, 13, 17, 19, 20, 21, 22, 23, 24, 29… ## $ site &lt;chr&gt; &quot;PSINF Mixed Conifer Site&quot;, &quot;PSINF Mixed Conifer S… ## $ is_in_stand &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F… ## $ comment &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ height_ft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ diameter_ft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ xcoord &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ ycoord &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ refcorner &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ row_number &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499341.7 4317759,..., POLYGON ((… ## $ image_gt_diameter_m &lt;dbl&gt; 6.469934, 6.867876, 6.387723, 6.589466, 5.482888, … ## $ field_height_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_diameter_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_area_m2 &lt;dbl&gt; 25.166539, 32.028082, 22.928349, 26.261937, 20.184… ## $ field_gt_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ image_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ field_gt_volume_m3 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ rast_agg_grvi &lt;dbl&gt; -0.032987678, -0.028157783, -0.052449043, -0.04792… ## $ rast_agg_rgri &lt;dbl&gt; 1.0682260, 1.0579472, 1.1107044, 1.1006650, 1.0577… ## $ rast_agg_vdvi &lt;dbl&gt; -0.01968966, -0.02055517, -0.02802948, -0.02471958… ## $ rast_agg_exgr &lt;dbl&gt; -0.1870950, -0.1833425, -0.2159304, -0.2083939, -0… ## $ rast_agg_Lab_a &lt;dbl&gt; 3.3752460, 3.2705802, 4.2660341, 3.9977866, 3.0468… ## $ rast_agg_hsv_hue_01 &lt;dbl&gt; 0.8790719, 0.8408440, 0.6562789, 0.7464154, 0.5725… ## $ rast_agg_hsv_hue &lt;dbl&gt; 316.4659, 302.7038, 236.2604, 268.7095, 206.1230, … # quick summary rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% summary() ## rast_agg_grvi rast_agg_rgri rast_agg_vdvi rast_agg_exgr ## Min. :-0.05245 Min. :0.8951 Min. :-0.03479 Min. :-0.2159 ## 1st Qu.:-0.03178 1st Qu.:0.9909 1st Qu.:-0.02720 1st Qu.:-0.1862 ## Median :-0.02010 Median :1.0410 Median :-0.02195 Median :-0.1712 ## Mean :-0.01128 Mean :1.0249 Mean :-0.02268 Mean :-0.1707 ## 3rd Qu.: 0.00461 3rd Qu.:1.0657 3rd Qu.:-0.01708 3rd Qu.:-0.1550 ## Max. : 0.05536 Max. :1.1107 Max. :-0.01175 Max. :-0.1203 ## rast_agg_Lab_a rast_agg_hsv_hue_01 rast_agg_hsv_hue ## Min. :0.3492 Min. :0.5726 Min. :206.1 ## 1st Qu.:0.9728 1st Qu.:0.6233 1st Qu.:224.4 ## Median :2.3915 Median :0.7249 Median :261.0 ## Mean :2.3050 Mean :0.7221 Mean :259.9 ## 3rd Qu.:3.3491 3rd Qu.:0.8117 3rd Qu.:292.2 ## Max. :4.2660 Max. :0.9127 Max. :328.6 let’s plot it # pivot agg_df_temp &lt;- rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::select(-rast_agg_hsv_hue_01) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;rast_agg_&quot;) %&gt;% stringr::str_to_upper()) # plot ggplot2::ggplot() + ggplot2::geom_density( data = agg_df_temp , mapping = ggplot2::aes(x = value, fill = name) , color = NA, alpha = 0.8 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=median(value,na.rm=T)) , mapping = ggplot2::aes(xintercept = value, color = &quot;median&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=0.025)) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::geom_vline( data = agg_df_temp %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(value=quantile(value,na.rm=T,probs=(1-0.025))) , mapping = ggplot2::aes(xintercept = value, color = &quot;p2.5–p97.5&quot;) , linetype = &quot;solid&quot;, lwd = 1 ) + ggplot2::scale_fill_viridis_d(option = &quot;turbo&quot;, begin = 0.1, end = 0.9, alpha = 0.7) + # ggplot2::scale_fill_brewer(palette = &quot;Set2&quot;) + ggplot2::scale_color_manual(values = c(&quot;gray22&quot;,&quot;gray&quot;,&quot;gray&quot;)) + ggplot2::scale_x_continuous(breaks = scales::breaks_extended(8)) + ggplot2::scale_y_continuous(NULL, breaks = NULL) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 3 , scales = &quot;free&quot; ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 7) , axis.text.y = ggplot2::element_blank() ) + ggplot2::guides(fill = &quot;none&quot;) that’s interesting. compare those values with the thresholds identified in the research listed in the table above here is a plot of the median value of the different spectral indices (high values are brighter, low values are darker) within the bounds of the pile on our example area we were working with in the last section polys_temp &lt;- rgb_indices_df %&gt;% sf::st_transform(sf::st_crs(aoi_boundary)) %&gt;% dplyr::select(pile_id, tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;rast_agg_hsv_hue_01&quot; ))) %&gt;% tidyr::pivot_longer(cols = tidyselect::starts_with(&quot;rast_agg_&quot;)) %&gt;% dplyr::mutate(name = stringr::str_remove(name,&quot;rast_agg_&quot;)) # # dplyr::filter(name==&quot;grvi&quot;) %&gt;% # ggplot2::ggplot() + # ggplot2::geom_sf(mapping=ggplot2::aes(fill=value)) + # ggplot2::facet_wrap(facets=dplyr::vars(name)) + # ggplot2::theme_void() + # ggplot2::theme(legend.position = &quot;top&quot;) # rast clip rast_temp &lt;- all_rgb_indices_rast %&gt;% terra::crop(aoi_boundary %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) %&gt;% terra::mask(aoi_boundary %&gt;% sf::st_buffer(7.3) %&gt;% terra::vect()) # plot list plt_list_temp &lt;- # names(all_rgb_indices_rast) %&gt;% &quot;hsv_hue&quot; %&gt;% # sample(6) %&gt;% purrr::map( \\(x) ggplot2::ggplot() + ggplot2::geom_tile( data = rast_temp[[x]] %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x = x, y = y, fill = f) , alpha = 0.9 ) + ggplot2::geom_sf( data = aoi_boundary , color = &quot;black&quot;, fill = NA, lwd = 0.8 ) + ggplot2::geom_sf( data = polys_temp %&gt;% dplyr::filter(name == x) # , mapping = ggplot2::aes(fill=value) , color = &quot;cyan&quot;, lwd = 0.6 ) + ggrepel::geom_text_repel( data = polys_temp %&gt;% dplyr::filter(name == x) %&gt;% sf::st_point_on_surface() %&gt;% dplyr::mutate( x_coord = sf::st_coordinates(.)[, 1] , y_coord = sf::st_coordinates(.)[, 2] ) , mapping = ggplot2::aes( x = x_coord , y = y_coord , label = dplyr::case_when( name == &quot;hsv_hue&quot; ~ scales::comma(value, accuracy=1) , T ~ scales::comma(value, accuracy=0.01) ) , fontface = &quot;bold&quot; ) , nudge_x = 0.5 # initial horizontal nudge , nudge_y = -0.2 # initial vertical nudge , size = 2.2, color = &quot;cyan&quot; , force = 1 , box.padding = 0.3 # Increase padding to push labels further away # , point.padding = 0.7 # Ensure distance from the original point , min.segment.length = 0.5 # Minimum length of the connecting line segment , segment.color = NA ) + ggplot2::scale_fill_distiller(palette = &quot;Greys&quot;) + # ggplot2::scale_fill_gradientn(colors = grDevices::gray.colors(111, start = 0, end = 1)) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( fill = x , subtitle = x ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; , plot.subtitle = ggplot2::element_text(size = 11, face = &quot;bold&quot;, hjust = 0.5) ) ) # plt_list_temp # patchwork patchwork::wrap_plots( plt_list_temp , ncol = 3 ) 5.2.1 Voting System let’s consider a voting system approach for filtering candidate slash piles using the multiple spectral indices. a voting system could allow for a more robust and nuanced decision than relying on a single index. let’s make a highly specialized function using the data returned by out extract_rast_values() function ########################################################## #### function to validate threshold vector or list pair ########################################################## validate_thresholds_fn &lt;- function(th_list) { # input is a list or a numeric vector if (!is.list(th_list) &amp;&amp; !is.numeric(th_list)) { stop(&quot;Validation Error: Input must be a list of pairs or a single numeric vector pair.&quot;) } # to a list to standardize the purrr::map iteration items_to_check &lt;- if(is.list(th_list)){ th_list }else{ list(th_list) } # validate logic on each pair purrr::map(items_to_check, function(x) { # numeric type if (!is.numeric(x)) { stop(&quot;Validation Error: Threshold elements must be numeric.&quot;) } # length is exactly 2 if (length(x) != 2) { stop(paste(&quot;Validation Error: Pair must have exactly 2 values. Found length:&quot;, length(x))) } # order (lower &lt; upper) if (x[1] &gt;= x[2]) { stop(paste0(&quot;Validation Error: Lower limit must be smaller than upper limit. Found: [&quot;, x[1], &quot;, &quot;, x[2], &quot;]&quot;)) } }) # 4. If all checks passed (no stop triggered), return the original input return(th_list) } ########################################################## # function to filter a data frame by a list pair and column ########################################################## filter_by_thresholds_fn &lt;- function(df, target_col, th_list) { # col exists? if (!(target_col %in% names(df))) { stop(paste0(&quot;Column &#39;&quot;, target_col, &quot;&#39; not found in the data frame&quot;)) } # validate the thresholds using previous function valid_th &lt;- validate_thresholds_fn(th_list) # thresholds to a list if a single vector was provided th_pairs &lt;- if(is.list(valid_th)){ valid_th }else{ list(valid_th) } # use purrr::map to create a list of logical vectors (one for each pair) # then reduce them with &#39;|&#39; so any row hitting any range is kept df %&gt;% dplyr::mutate( is_inrange = purrr::map(th_pairs, function(x) { dplyr::between(.data[[target_col]], x[1], x[2]) }) %&gt;% purrr::reduce(`|`) %&gt;% as.integer() ) # dplyr::filter( # purrr::map( # th_pairs # , function(x) { # dplyr::between(.data[[target_col]], x[1], x[2]) # } # ) %&gt;% # purrr::reduce(`|`) # ) } # filter_by_thresholds_fn( # rgb_indices_df # , target_col = &quot;rast_agg_hsv_hue&quot; # # , th_list = c(275,Inf) # , th_list = list(c(0,210), c(275,Inf)) # # , th_list = c(275,207) # ) %&gt;% # ggplot2::ggplot(aes(x=rast_agg_hsv_hue,y=0,color=as.factor(is_inrange))) + ggplot2::geom_jitter() # # filter_by_thresholds_fn( # rgb_indices_df # , target_col = &quot;rast_agg_hsv_hue&quot; # # , th_list = c(275,Inf) # , th_list = list(c(0,210), c(275,Inf)) # # , th_list = c(275,207) # ) %&gt;% # dplyr::glimpse() # voting system rgb_indices_threshold_voting &lt;- function( rgb_indices_df # define ranges to *keep* piles , th_grvi = c(-Inf,0) , th_rgri = c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_vdvi = c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper , th_exgr = c(-Inf,0) , th_a = c(-5+0.001,Inf) , th_hue = list(c(0,50-0.001), c(150+0.001,Inf)) ){ # checks if(!inherits(rgb_indices_df, &quot;data.frame&quot;)){ stop(&quot;Input `rgb_indices_df` must be an data.frame.&quot;) } # names agg_cols &lt;- c(&quot;rast_agg_grvi&quot;,&quot;rast_agg_exgr&quot;,&quot;rast_agg_rgri&quot;,&quot;rast_agg_vdvi&quot;,&quot;rast_agg_Lab_a&quot;,&quot;rast_agg_hsv_hue&quot;) # &quot;rast_agg_rgbvi&quot;, nm_diff &lt;- base::setdiff( agg_cols , names(rgb_indices_df) ) if(length(nm_diff)&gt;0){ stop(paste0(&quot;required variables missing:\\n&quot;, &quot;... &quot;, paste(nm_diff, collapse = &quot;, &quot;) )) } # thresholds safe_validate_thresholds_fn &lt;- purrr::safely(validate_thresholds_fn) # th_grvi chk_grvi &lt;- safe_validate_thresholds_fn(th_grvi) if(is.null(chk_grvi$result)){ stop(paste0(&quot;Input `th_grvi`: &quot;, chk_grvi$error)) } # th_rgri chk_rgri &lt;- safe_validate_thresholds_fn(th_rgri) if(is.null(chk_rgri$result)){ stop(paste0(&quot;Input `th_rgri`: &quot;, chk_rgri$error)) } # th_vdvi chk_vdvi &lt;- safe_validate_thresholds_fn(th_vdvi) if(is.null(chk_vdvi$result)){ stop(paste0(&quot;Input `th_vdvi`: &quot;, chk_vdvi$error)) } # th_exgr chk_exgr &lt;- safe_validate_thresholds_fn(th_exgr) if(is.null(chk_exgr$result)){ stop(paste0(&quot;Input `th_exgr`: &quot;, chk_exgr$error)) } # th_a chk_a &lt;- safe_validate_thresholds_fn(th_a) if(is.null(chk_a$result)){ stop(paste0(&quot;Input `th_a`: &quot;, chk_a$error)) } # th_hue chk_hue &lt;- safe_validate_thresholds_fn(th_hue) if(is.null(chk_hue$result)){ stop(paste0(&quot;Input `th_hue`: &quot;, chk_hue$error)) } # get rid of columns we&#39;ll create rgb_indices_df &lt;- rgb_indices_df %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , &quot;is_inrange&quot; , &quot;inrange_th_grvi&quot; , &quot;inrange_th_rgri&quot; , &quot;inrange_th_vdvi&quot; , &quot;inrange_th_exgr&quot; , &quot;inrange_th_Lab_a&quot; , &quot;inrange_th_hsv_hue&quot; ))) # check threshold ret_df &lt;- rgb_indices_df %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_grvi&quot;, th_list = th_grvi) %&gt;% dplyr::rename(inrange_th_grvi=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_rgri&quot;, th_list = th_rgri) %&gt;% dplyr::rename(inrange_th_rgri=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_vdvi&quot;, th_list = th_vdvi) %&gt;% dplyr::rename(inrange_th_vdvi=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_exgr&quot;, th_list = th_exgr) %&gt;% dplyr::rename(inrange_th_exgr=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_Lab_a&quot;, th_list = th_a) %&gt;% dplyr::rename(inrange_th_Lab_a=is_inrange) %&gt;% filter_by_thresholds_fn(target_col = &quot;rast_agg_hsv_hue&quot;, th_list = th_hue) %&gt;% dplyr::rename(inrange_th_hsv_hue=is_inrange) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( inrange_th_votes = sum( dplyr::c_across(tidyselect::starts_with(&quot;inrange_th_&quot;)) , na.rm = T ) %&gt;% dplyr::coalesce(0) ) %&gt;% ungroup() #return return(ret_df) } let’s look at the columns we get from our rgb_indices_threshold_voting() function rgb_indices_df &lt;- rgb_indices_threshold_voting(rgb_indices_df=rgb_indices_df) # huh? rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% summary() ## inrange_th_grvi inrange_th_rgri inrange_th_vdvi inrange_th_exgr ## Min. :0.0000 Min. :1 Min. :1 Min. :1 ## 1st Qu.:0.2500 1st Qu.:1 1st Qu.:1 1st Qu.:1 ## Median :1.0000 Median :1 Median :1 Median :1 ## Mean :0.7222 Mean :1 Mean :1 Mean :1 ## 3rd Qu.:1.0000 3rd Qu.:1 3rd Qu.:1 3rd Qu.:1 ## Max. :1.0000 Max. :1 Max. :1 Max. :1 ## inrange_th_Lab_a inrange_th_hsv_hue inrange_th_votes ## Min. :1 Min. :1 Min. :5.000 ## 1st Qu.:1 1st Qu.:1 1st Qu.:5.250 ## Median :1 Median :1 Median :6.000 ## Mean :1 Mean :1 Mean :5.722 ## 3rd Qu.:1 3rd Qu.:1 3rd Qu.:6.000 ## Max. :1 Max. :1 Max. :6.000 notice the “Mean” value in the summary above is the proportion of demonstration piles that successfully met the spectral index threshold criteria (i.e. piles to be “kept”). it looks like the GRVI threshold was most unaligned with these demonstration piles, something we anticipated by looking at the distributions above compared with the threshold value recommended in the literature for detecting green vegetation. let’s look at the proportional distribution of demonstration piles meeting the threshold by individual spectral index rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::filter(name!=&quot;VOTES&quot;) %&gt;% dplyr::count(name,value) %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate( pct = n/sum(n) , value = factor(value, levels = 0:1, labels = c(&quot;outside threshold&quot;,&quot;within threshold&quot;), ordered = T) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 3, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;magma&quot;, begin = 0.3, end = 0.7) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::facet_wrap( facets = dplyr::vars(name) , ncol = 2 ) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, fill = &quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) and let’s look at the distribution of demonstration piles based on the number of individual spectral index thresholds met. we’ll use this count as our voting system. dplyr::tibble(value=0:6) %&gt;% dplyr::left_join( rgb_indices_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::starts_with(&quot;inrange_th_votes&quot;)) %&gt;% tidyr::pivot_longer(cols = dplyr::everything()) %&gt;% dplyr::mutate(name = stringr::str_remove_all(name,&quot;inrange_th_&quot;) %&gt;% stringr::str_to_upper()) %&gt;% dplyr::count(name,value) , by = dplyr::join_by(value) ) %&gt;% dplyr::mutate( n = dplyr::coalesce(n,0) , pct = n/sum(n) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) , value = factor(value) , cum_pct = cumsum(pct) , cum_pct_lab = scales::percent(cum_pct,accuracy=0.1) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = value, y = pct, label = lab, fill = value) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.8 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 4, vjust = -0.2) + ggplot2::scale_fill_viridis_d(option = &quot;mako&quot;, direction=-1) + ggplot2::scale_y_continuous( labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.15)) ) + ggplot2::labs( y = &quot;&quot;, x = &quot;spectral index threshold votes&quot;, fill = &quot;&quot; , subtitle = &quot;distribution of demonstration piles meeting spectral index thresholds&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 12) , axis.text.y = ggplot2::element_blank() ) we can use this spectral index voting system to filter candidate slash piles with a user-defined parameter which defines the sensitivity of filtering based on the spectral information. For example, a value of “6” would heavily weight the spectral information in determining which piles to keep while a value of “1” would put less weight on the spectral data. 5.3 Candidate Polygon Spectral Filtering Function let’s put all of this together to define a function that takes as input: 1) a spatial data frame of candidate polygons; 2) a raster with RGB spectral data; 3) user-defined spectral weighting (voting system) polygon_spectral_filtering &lt;- function( sf_data , rgb_rast # define the band index , red_band_idx , green_band_idx , blue_band_idx # spectral weighting , spectral_weight = 3 # return unfiltered or filtered , filter_return = T ) { if(!inherits(filter_return,&quot;logical&quot;)){ stop(&quot;Input `filter_return` should be logical: T to filter return based on the `spectral_weight` or F to return the full `sf_data`&quot;) } # ### could make these parameters # th_grvi &lt;- c(-Inf,0) # th_rgri &lt;- c((0.7+0.001),Inf) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper # th_vdvi &lt;- c(-Inf,(0.03+0.001)) # increase each by 0.001 since we&#39;ll be checking lower&lt;=x&lt;=upper # th_exgr &lt;- c(-Inf,0) # th_a &lt;- c(-5+0.001,Inf) # th_hue &lt;- list(c(0,50-0.001), c(150+0.001,Inf)) # checks if(!inherits(rgb_rast, &quot;SpatRaster&quot;)){ stop(&quot;Input `rast` must be a SpatRaster object.&quot;) } if(!inherits(sf_data, &quot;sf&quot;)){ stop(&quot;Input `sf_data` must be an sf data frame.&quot;) } if(!all(sf::st_geometry_type(sf_data) %in% c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) { stop(&quot;Input `sf_data` must contain polygon geometries.&quot;) } spectral_weight &lt;- as.numeric(spectral_weight) if( filter_return &amp;&amp; ( is.na(spectral_weight) || is.null(spectral_weight) || is.nan(spectral_weight) || !(spectral_weight %in% c(0:6)) ) ){ stop(&quot;Input `spectral_weight` must be a number between 0 (no filtering based on spectral) and 6 (highest weighting of spectral data)&quot;) } # if you don&#39;t want to do it, then why do it? if( filter_return &amp;&amp; dplyr::coalesce(spectral_weight,0)==0 ){ return(sf_data) } ################################################## # calculate_all_rgb_indices ################################################## all_rgb_indices_rast &lt;- calculate_all_rgb_indices( raster_obj = rgb_rast , red_band_idx = red_band_idx , green_band_idx = green_band_idx , blue_band_idx = blue_band_idx ) ################################################## # limit to the indices we have thresholds for ################################################## some_rgb_indices_rast &lt;- all_rgb_indices_rast %&gt;% terra::subset( c( &quot;grvi&quot; , &quot;rgri&quot; , &quot;vdvi&quot; , &quot;exgr&quot; , &quot;Lab_a&quot; , &quot;hsv_hue&quot; ) ) # !!!!!!!!!!!!! convert hsv_hue to 0-360 range !!!!!!!!!!!!! some_rgb_indices_rast$hsv_hue &lt;- some_rgb_indices_rast$hsv_hue*360 ################################################## # extract_rast_values ################################################## rgb_indices_df &lt;- extract_rast_values( sf_data = sf_data %&gt;% dplyr::ungroup() , rast = some_rgb_indices_rast , fun_agg = median ) ################################################## # rgb_indices_threshold_voting ################################################## rgb_indices_df &lt;- rgb_indices_threshold_voting( rgb_indices_df=rgb_indices_df # , th_grvi = th_grvi # , th_rgri = th_rgri # , th_vdvi = th_vdvi # , th_exgr = th_exgr # , th_a = th_a # , th_hue = th_hue ) ################################################## # filtering ################################################## if(filter_return){ rgb_indices_df &lt;- rgb_indices_df %&gt;% dplyr::filter(inrange_th_votes&gt;=spectral_weight) } # return return(list( segs_sf = rgb_indices_df , rgb_indices_rast = all_rgb_indices_rast )) } # polygon_spectral_filtering( # sf_data = slash_piles_polys # , rgb_rast = ortho_rast # , red_band_idx = 1 # , green_band_idx = 2 # , blue_band_idx = 3 # , spectral_weight = 4 # ) %&gt;% # nrow() # # dplyr::glimpse() # nrow(slash_piles_polys) 5.4 Data Fusion Method Demonstration we previously worked through an example where we identified candidate slash piles based on their structural form using our raster-based segmentation approach. we’re going to use that demonstration area, apply the slash_pile_detect() function to detect candidate slash piles from the CHM data based on expected size and geometric properties, and then integrate the spectral filtering method we defined above. for this demonstration, we’ll use the DBSCAN segmentation method with the same size and geometric thresholds that we used in the previous section so that we can demonstrate how the spectral filtering helps remove false positives that are likely vegetation # structurally predicted from chm slash_pile_detect_dbscan_ans_temp &lt;- slash_pile_detect( chm_rast = aoi_chm_rast , seg_method = &quot;dbscan&quot; , min_ht_m = 0.5 , max_ht_m = 6 , min_area_m2 = 1.5 , max_area_m2 = 50 , min_convexity_ratio = 0.5 , min_circularity_ratio = 0.45 ) let’s overlay the structural candidate segments (magenta) and the actual piles (cyan) on the raw, un-filtered CHM aoi_chm_rast %&gt;% # slash_pile_detect_dbscan_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), mar = c(0,0,0,0)) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_dbscan_ans_temp$segs_sf %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 2.5 ) now overlay the structural candidate segments (magenta) and the actual piles (cyan) on the RGB aoi_rgb_rast %&gt;% terra::plotRGB(axes = F, mar = c(0,0,0,0), stretch = &quot;lin&quot;) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_dbscan_ans_temp$segs_sf %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 2.5 ) notice there are lower portions of trees or small trees that are proposed as candidate segments given our less strict size and geometric filters Remember, our data fusion method uses the spectral data strictly as a final filter or quality check on the structurally-detected candidate piles, meaning it neither adds new piles nor alters the shape or location of the candidates. As a result, if the structural detection step missed a pile (false negative or omission), the spectral data won’t go back and fix it. The only changes we can expect by including spectral data in our data fusion approach is a trade-off: we can either improve our precision by successfully removing detections that aren’t actually piles (commissions or false positives), or we run the risk of mistakenly filtering out real piles (true positives) if their spectral signature happens to look unusual, which would unfortunately lower our recall. let’s apply our spectral filtering method to the set of structurally-detected piles but we’ll leave the return unfiltered (filter_return=F) so that we can see which candidate piles would have been filtered and why depending on the spectral_weight setting which defines how many of the six spectral thresholds must be met for a candidate pile to be retained given filter_return=T # names(aoi_rgb_rast) slash_pile_detect_spec_filt_temp &lt;- polygon_spectral_filtering( sf_data = slash_pile_detect_dbscan_ans_temp$segs_sf , rgb_rast = aoi_rgb_rast # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 # leave return unfiltered , filter_return = F ) what did we get? # huh? slash_pile_detect_spec_filt_temp %&gt;% dplyr::glimpse() ## List of 2 ## $ segs_sf : sf [25 × 22] (S3: sf/tbl_df/tbl/data.frame) ## ..$ pred_id : num [1:25] 3 4 22 35 38 39 40 43 56 67 ... ## ..$ convexity_ratio : num [1:25] 0.931 0.929 0.938 0.9 0.928 ... ## ..$ circularity_ratio : num [1:25] 0.671 0.73 0.477 0.641 0.733 ... ## ..$ area_m2 : num [1:25] 8.33 6.18 5.27 5.51 8.06 ... ## ..$ volume_m3 : num [1:25] 6.66 3.13 5.52 3.25 4.45 ... ## ..$ max_height_m : num [1:25] 1.73 1.15 2.58 1.5 1.53 ... ## ..$ volume_per_area : num [1:25] 0.799 0.506 1.047 0.589 0.553 ... ## ..$ geometry :sfc_POLYGON of length 25; first list element: List of 1 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## ..$ diameter_m : num [1:25] 3.83 3.14 3.63 3.14 3.54 ... ## ..$ rast_agg_grvi : num [1:25] -0.0116 -0.0413 0.0245 0.0271 0.0548 ... ## ..$ rast_agg_rgri : num [1:25] 1.023 1.086 0.952 0.947 0.896 ... ## ..$ rast_agg_vdvi : num [1:25] -0.019 -0.0235 0.0115 -0.0343 -0.0289 ... ## ..$ rast_agg_exgr : num [1:25] -0.166 -0.2007 -0.0939 -0.1466 -0.1192 ... ## ..$ rast_agg_Lab_a : num [1:25] 1.844 3.729 -0.727 0.79 0.345 ... ## ..$ rast_agg_hsv_hue : num [1:25] 257 328 141 227 221 ... ## ..$ inrange_th_grvi : int [1:25] 1 1 0 0 0 0 0 1 0 1 ... ## ..$ inrange_th_rgri : int [1:25] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_vdvi : int [1:25] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_exgr : int [1:25] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_Lab_a : int [1:25] 1 1 1 1 1 1 1 1 1 1 ... ## ..$ inrange_th_hsv_hue: int [1:25] 1 1 0 1 1 1 1 1 1 1 ... ## ..$ inrange_th_votes : num [1:25] 6 6 4 5 5 5 5 6 5 6 ... ## ..- attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## ..- attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA NA ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:21] &quot;pred_id&quot; &quot;convexity_ratio&quot; &quot;circularity_ratio&quot; &quot;area_m2&quot; ... ## $ rgb_indices_rast:S4 class &#39;SpatRaster&#39; [package &quot;terra&quot;] # slash_pile_detect_spec_filt_temp$segs_sf$rast_agg_hsv_hue %&gt;% summary() how many piles would be removed if we set a spectral_weight of “5” which requires five of the six spectral thresholds to be met for a candidate pile to be retained # how many piles were removed? nrow(slash_pile_detect_spec_filt_temp$segs_sf)- nrow(slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5)) ## [1] 5 # what proportion were removed? scales::percent( ( nrow(slash_pile_detect_spec_filt_temp$segs_sf)- nrow(slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5)) )/nrow(slash_pile_detect_spec_filt_temp$segs_sf) , accuracy=0.1 ) ## [1] &quot;20.0%&quot; let’s highlight the spectrally filtered segments (orange) with the candidate segments that were retained by the spectral filtering (magenta) and the actual piles (cyan) on the raw, un-filtered CHM aoi_chm_rast %&gt;% # slash_pile_detect_dbscan_ans_temp$slice_chm_rast %&gt;% terra::plot(axes = F, col = viridis::plasma(100), mar = c(0,0,0,0)) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_chm_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5) %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 2.5 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&lt;5) %&gt;% terra::vect() , add = T, border = &quot;orangered&quot;, col = NA, lwd = 2.5 ) now let’s highlight the spectrally filtered segments (orange) with the candidate segments that were retained by the spectral filtering (magenta) and the actual piles (cyan) on the RGB aoi_rgb_rast %&gt;% terra::plotRGB(axes = F, mar = c(0,0,0,0), stretch = &quot;lin&quot;) terra::plot( aoi_boundary %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot( aoi_slash_piles_polys %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 2 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&gt;=5) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 2.5 ) terra::plot( slash_pile_detect_spec_filt_temp$segs_sf %&gt;% dplyr::filter(inrange_th_votes&lt;5) %&gt;% sf::st_transform(terra::crs(aoi_rgb_rast)) %&gt;% terra::vect() , add = T, border = &quot;orangered&quot;, col = NA, lwd = 2.5 ) in this demonsration area, the spectral filtering of our data fusion approach successfully filtered the structurally detected candidate piles that were clearly lower parts of trees (clearly green in the RGB). however, the spectral filtering failed to remove some false positive predictions that were shadowed in the RGB imagery. a positive result, though, was that the spectral filtering stage did not remove any true positive predictions. let’s see the spectral index values of the candidates which were identified for removal slash_pile_detect_spec_filt_temp$segs_sf %&gt;% sf::st_drop_geometry() %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(rand = runif(n=nrow(slash_pile_detect_spec_filt_temp$segs_sf))) %&gt;% dplyr::arrange(rand) %&gt;% dplyr::mutate( is_removed = inrange_th_votes&lt;5 , sorter = dplyr::row_number() ) %&gt;% dplyr::select( pred_id, is_removed, sorter , tidyselect::starts_with(&quot;rast_agg_&quot;) , tidyselect::starts_with(&quot;inrange_th_&quot;) ) %&gt;% dplyr::select(-tidyselect::ends_with(&quot;_votes&quot;)) %&gt;% tidyr::pivot_longer( cols = c( tidyselect::starts_with(&quot;rast_agg_&quot;) , tidyselect::starts_with(&quot;inrange_th_&quot;) ) ) %&gt;% dplyr::mutate( i = name %&gt;% stringr::str_remove(&quot;^rast_agg_&quot;) %&gt;% stringr::str_remove(&quot;^inrange_th_&quot;) , v = stringr::str_extract(name, &quot;^(rast_agg_|inrange_th_)&quot;) ) %&gt;% dplyr::select(-name) %&gt;% tidyr::pivot_wider(names_from = v, values_from = value) %&gt;% dplyr::mutate(inrange_th_ = as.logical(inrange_th_)) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = rast_agg_, y = sorter , shape = is_removed , color = inrange_th_ ) ) + ggplot2::geom_point(size = 4) + ggplot2::facet_wrap(facets = dplyr::vars(i), scales = &quot;free_x&quot;) + ggplot2::scale_color_viridis_d(option = &quot;turbo&quot;, begin = 0.2, direction = -1) + ggplot2::scale_shape_manual(values = c(19,17)) + ggplot2::scale_y_continuous(NULL,breaks=1:nrow(slash_pile_detect_spec_filt_temp$segs_sf)) + ggplot2::labs( x = &quot;&quot; , shape = &quot;ultimately\\nspectrally filtered?&quot; , color = &quot;meets\\nindex threshold?&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , axis.ticks.y = ggplot2::element_blank() , axis.text.y = ggplot2::element_blank() , panel.grid.major.y = ggplot2::element_line(color = &quot;gray97&quot;, linewidth = 0.05) , panel.grid.minor.y = ggplot2::element_line(color = &quot;gray97&quot;, linewidth = 0.05) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(size = 5)), shape = ggplot2::guide_legend(override.aes = list(size = 5)) ) the strength of our ensemble spectral index filtering approach is clear with this demonstration data as only one index perfectly aligned with the overall vote for removing candidate piles "],["meth_eval.html", "Section 6 Method Evaluation 6.1 Instance Matching 6.2 Detection Accuracy Metrics 6.3 Quantification Accuracy Metrics", " Section 6 Method Evaluation This section is entirely devoted to detailing the methods and defining analysis functions for instance matching and the calculation of overall prediction performance assessment metrics. Image-annotated slash pile footprints, which are available across all study sites, will be used as the ground truth data to perform a confusion matrix-based validation accuracy assessment of the methods. Instance matching compares predicted pile segments to the ground truth data to establish True Positives (TP), False Positives (FP, commissions), and False Negatives (FN, omissions). Aggregation of the instance matching results allows us to calculate performance assessment metrics to determine overall detection accuracy and form quantification accuracy. detection accuracy metrics: including Recall, Precision, and F-score, are calculated directly by aggregating these raw TP, FP, and FN counts and quantifies the method’s ability to find the piles quantification accuracy metrics: such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified 6.1 Instance Matching Puliti et al. (2023, p. 14) provide guidance on performing “instance segmentation evaluation” to assess the ability of a method to correctly identify and delineate individual tree crown instances compared ground truth data. We’ll use this same methodology to test our slash pile identification approach. The first step in performing any instance segmentation evaluation is to match the point cloud reference and predicted instance IDs. To do this, it is necessary to define whether a prediction is correct. Here we adopt a method Wielgosz et al. (2023) proposed for matching tree instance IDs from two point clouds with reference and predicted instance IDs, respectively. Given a reference and a predicted point cloud with two separate sets of instances, the tree instances are iteratively matched in descending order from the tallest to the shortest trees by using the following algorithm: Find the tallest tree in the reference data; Find the tree in the predicted instances that have the largest intersection over union (IoU) with the tree selected in the previous step; if the IoU is &lt;0.5: the predicted tree is considered an error, and thus no reference instance ID is available; if the IoU is ≥0.5: the tree is considered a correct match, and assign reference instance ID label to the predicted tree; Add to collection (dictionary) of predicted tree instances with IDs matching the reference instance IDs. Following the initial matching of reference and predicted instance IDs, the evaluation can be done on the tree level to evaluate detection, omission, and commission rates (which can be used to calculate precision, recall, and the F-score metric) # check the data check_gt_str &lt;- function( gt_inst , gt_id = &quot;pile_id&quot; , predictions , pred_id = &quot;pred_pile_id&quot; ) { if( !inherits(gt_inst,&quot;sf&quot;)){stop(&quot;ground truth must be spatial `sf` data with a single record&quot;)} if( !inherits(predictions,&quot;sf&quot;) ){stop(&quot;predictions must be spatial `sf` data&quot;)} if( !identical(sf::st_crs(gt_inst),sf::st_crs(predictions)) ){stop(&quot;`sf` data should have same crs projection&quot;)} if( is.null(gt_id) || is.na(gt_id) || !inherits(gt_id, &quot;character&quot;) || stringr::str_trim(gt_id) == &quot;&quot; ){ stop(&quot;ground truth data must contain `gt_id` column&quot;) } if( is.null(pred_id) || is.na(pred_id) || !inherits(pred_id, &quot;character&quot;) || stringr::str_trim(pred_id) == &quot;&quot; ){ stop(&quot;ground truth data must contain `pred_id` column&quot;) } if( !(names(gt_inst) %&gt;% stringr::str_equal(gt_id) %&gt;% any()) ){stop(&quot;ground truth data must contain `gt_id` column&quot;)} # get rid of gt_id if it exists in the predictions and is not the key if( (names(predictions) %&gt;% stringr::str_equal(gt_id) %&gt;% any() ) &amp;&amp; (gt_id!=pred_id) ){ predictions &lt;- predictions %&gt;% # throw in hey_xxxxxxxxxx to test it works if we include non-existant columns dplyr::select( -dplyr::any_of(c( &quot;hey_xxxxxxxxxx&quot; , gt_id ))) } # rename it if gt_id==pred_id if( (names(predictions) %&gt;% stringr::str_equal(gt_id) %&gt;% any() ) &amp;&amp; (gt_id==pred_id) ){ predictions &lt;- predictions %&gt;% dplyr::rename_with( .cols = dplyr::all_of(gt_id) , .fn = function(x){&quot;prediction_idxxx&quot;} ) pred_id &lt;- &quot;prediction_idxxx&quot; }else if( !(names(predictions) %&gt;% stringr::str_equal(pred_id) %&gt;% any()) ){ stop(&quot;predictions data must contain `pred_id` column&quot;) } return(list( predictions = predictions , pred_id = pred_id )) } # match the instance ground_truth_single_match &lt;- function( gt_inst , gt_id = &quot;pile_id&quot; , predictions , pred_id = &quot;pred_pile_id&quot; , min_iou_pct = 0.5 ) { # check it check_ans &lt;- check_gt_str( gt_inst = gt_inst , gt_id = gt_id , predictions = predictions , pred_id = pred_id ) if(nrow(gt_inst)!=1 ){stop(&quot;ground truth must be spatial `sf` data with a single record&quot;)} predictions &lt;- check_ans$predictions pred_id &lt;- check_ans$pred_id # intersection i_temp &lt;- sf::st_intersection(predictions,gt_inst) %&gt;% dplyr::mutate(i_area = sf::st_area(.) %&gt;% as.numeric()) if(nrow(i_temp)==0){return(NULL)} # union u_temp &lt;- i_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::inner_join(predictions %&gt;% sf::st_set_geometry(&quot;geom1&quot;), by = pred_id) %&gt;% dplyr::inner_join(gt_inst %&gt;% sf::st_set_geometry(&quot;geom2&quot;) %&gt;% dplyr::select(dplyr::all_of(gt_id)), by = gt_id) %&gt;% dplyr::rowwise() %&gt;% dplyr::mutate( u_area = sf::st_union(geom1, geom2) %&gt;% sf::st_area() %&gt;% as.numeric() ) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(geom1,geom2)) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( iou = dplyr::case_when( is.na(u_area) | is.nan(u_area) ~ NA , T ~ dplyr::coalesce(i_area,0)/u_area ) ) %&gt;% dplyr::filter(!is.na(iou) &amp; iou&gt;=min_iou_pct) if(nrow(u_temp)==0){return(NULL)} # return return( u_temp %&gt;% # pick the highest iou dplyr::arrange(desc(iou)) %&gt;% dplyr::slice(1) %&gt;% # column clean dplyr::select(dplyr::all_of( c( gt_id, &quot;i_area&quot;, &quot;u_area&quot;, &quot;iou&quot; , base::setdiff( names(predictions) , c(&quot;geometry&quot;, &quot;geom&quot;, gt_id, &quot;i_area&quot;, &quot;u_area&quot;, &quot;iou&quot;) ) ) )) ) } we’ll continue using the same demonstration area which is outside of the study area at PSINF for this walkthrough we’ll generate some fake predictions over the demonstration area so that we purposefully get a good mix of FP, TP, and FN “predictions” predictions_temp &lt;- aoi_slash_piles_polys %&gt;% dplyr::slice_sample(prop = 0.7) %&gt;% sf::st_centroid() %&gt;% dplyr::mutate(rand=as.integer(runif(n=dplyr::n(), min = 1, max = 3))) %&gt;% dplyr::select(rand,pile_id) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( geometry = sf::st_buffer(geometry, rand) ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::bind_rows( sf::st_sample( sf::st_difference( aoi_boundary , sf::st_union(aoi_slash_piles_polys) ) , size = 33 , type = &quot;random&quot; ) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(rand=as.integer(runif(n=dplyr::n(), min = 1, max = 3))) %&gt;% dplyr::select(rand) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( geometry = sf::st_buffer(geometry, rand) ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) ) %&gt;% dplyr::mutate(pred_id = dplyr::row_number() %&gt;% as.character()) %&gt;% dplyr::select(pred_id,pile_id) # storing the pile_id so we know which ones might be matches check out the fake predictions compared to the ground truth pile footprints ggplot2::ggplot() + ggplot2::geom_sf(data = aoi_boundary, color = &quot;black&quot;, fill = NA) + ggplot2::geom_sf(data = aoi_slash_piles_polys, mapping = ggplot2::aes(color = &quot;ground truth&quot;), fill = NA) + ggplot2::geom_sf(data = predictions_temp, mapping = ggplot2::aes(color = &quot;fake predictions&quot;), fill = NA) + ggplot2::scale_color_manual(values=c(&quot;magenta&quot;,&quot;cyan&quot;)) + ggplot2::labs(color=&quot;&quot;) + ggplot2::theme_void() test for a single ground truth instance ground_truth_single_match( gt_inst = aoi_slash_piles_polys %&gt;% dplyr::filter(pile_id==purrr::discard(predictions_temp$pile_id, is.na)[1]) , gt_id = &quot;pile_id&quot; , predictions = predictions_temp , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.01 ) ## # A tibble: 1 × 5 ## pile_id i_area u_area iou pred_id ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 11 3.14 20.2 0.156 1 now we need to make a function that matches the instances iteratively allowing for only a single match from the predictions (i.e. one prediction can only go to one ground truth instance), and returns all instances labeled as true positive (correctly matched with a prediction), commission (predictions which do not match a ground truth instance; false positive), or omission (ground truth instances for which no predictions match; false negative) ground_truth_prediction_match &lt;- function( # ground_truth should be sorted already ground_truth , gt_id = &quot;pile_id&quot; # predictions just needs treeID , predictions , pred_id = &quot;pred_pile_id&quot; , min_iou_pct = 0.5 ) { # check it check_ans &lt;- check_gt_str( gt_inst = ground_truth , gt_id = gt_id , predictions = predictions , pred_id = pred_id ) predictions &lt;- check_ans$predictions pred_id &lt;- check_ans$pred_id # set up a blank data frame return_df &lt;- dplyr::tibble( i_area = as.numeric(NA) , u_area = as.numeric(NA) , iou = as.numeric(NA) ) %&gt;% dplyr::bind_cols( ground_truth %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(gt_id)) %&gt;% dplyr::slice(0) ) %&gt;% dplyr::bind_cols( predictions %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::slice(0) ) %&gt;% dplyr::relocate(tidyselect::starts_with(gt_id)) # save names to select nms_temp &lt;- names(return_df) # start with tallest tree and match to get true positives for (i in 1:nrow(ground_truth)) { match_temp &lt;- ground_truth_single_match( gt_inst = ground_truth %&gt;% dplyr::slice(i) , gt_id = gt_id , predictions = predictions %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::anti_join(return_df,by=pred_id) , pred_id = pred_id , min_iou_pct = min_iou_pct ) # add to return if(!is.null(match_temp)){ return_df &lt;- return_df %&gt;% dplyr::bind_rows(match_temp %&gt;% dplyr::select(nms_temp)) } match_temp &lt;- NULL } # label tps return_df &lt;- return_df %&gt;% dplyr::mutate(match_grp = &quot;true positive&quot;) # add omissions return_df &lt;- return_df %&gt;% dplyr::bind_rows( ground_truth %&gt;% sf::st_drop_geometry() %&gt;% dplyr::anti_join(return_df,by=gt_id) %&gt;% dplyr::select(dplyr::all_of(gt_id)) %&gt;% dplyr::mutate(match_grp = &quot;omission&quot;) ) # add commissions return_df &lt;- return_df %&gt;% dplyr::bind_rows( predictions %&gt;% sf::st_drop_geometry() %&gt;% dplyr::anti_join(return_df,by=pred_id) %&gt;% dplyr::select(dplyr::all_of(pred_id)) %&gt;% dplyr::mutate(match_grp = &quot;commission&quot;) ) # make match_grp factor return_df &lt;- return_df %&gt;% dplyr::mutate( match_grp = factor( match_grp , ordered = T , levels = c( &quot;true positive&quot; , &quot;commission&quot; , &quot;omission&quot; ) ) %&gt;% forcats::fct_rev() ) # return if(nrow(return_df)==0){ warning(&quot;no records found for ground truth to predition matching&quot;) return(NULL) }else{ return(return_df) } } let’s see how we did given the full list of fake predictions and ground truth data using an IoU proportion of 30% ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match( ground_truth = aoi_slash_piles_polys %&gt;% dplyr::arrange(desc(field_diameter_m)) # this is so the algorithm starts with the largest , gt_id = &quot;pile_id&quot; , predictions = predictions_temp , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.3 ) # huh? ground_truth_prediction_match_ans %&gt;% dplyr::glimpse() ## Rows: 53 ## Columns: 6 ## $ pile_id &lt;dbl&gt; 5, 13, 17, 19, 21, 22, 23, 24, 29, 53, 3, 4, 6, 11, 20, 56, … ## $ i_area &lt;dbl&gt; 12.560629, 3.140157, 6.149464, 3.140157, 3.140157, 5.215906,… ## $ u_area &lt;dbl&gt; 22.928349, 5.968836, 12.560629, 5.942413, 6.758426, 12.56062… ## $ iou &lt;dbl&gt; 0.5478209, 0.5260920, 0.4895825, 0.5284313, 0.4646285, 0.415… ## $ pred_id &lt;chr&gt; &quot;5&quot;, &quot;2&quot;, &quot;4&quot;, &quot;11&quot;, &quot;12&quot;, &quot;6&quot;, &quot;8&quot;, &quot;10&quot;, &quot;9&quot;, &quot;3&quot;, NA, NA,… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive, true positive, … how did our predictions do for this test example? # what did we get? ground_truth_prediction_match_ans %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate(pct = (n/sum(n)) %&gt;% scales::percent(accuracy=0.1)) ## # A tibble: 3 × 3 ## match_grp n pct ## &lt;ord&gt; &lt;int&gt; &lt;chr&gt; ## 1 omission 8 15.1% ## 2 commission 35 66.0% ## 3 true positive 10 18.9% let’s quickly look at the IoU values on the true positives ground_truth_prediction_match_ans %&gt;% dplyr::select(iou) %&gt;% summary() ## iou ## Min. :0.4153 ## 1st Qu.:0.4588 ## Median :0.4936 ## Mean :0.5021 ## 3rd Qu.:0.5279 ## Max. :0.6619 ## NA&#39;s :43 here is the distribution of IoU for the TP matches # palette pal_match_grp = c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # plot ground_truth_prediction_match_ans %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = iou, color = match_grp, fill = match_grp)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.8) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::scale_x_continuous(labels=scales::percent) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;IoU of correct precitions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 9, face = &quot;bold&quot;, color = &quot;black&quot;) ) let’s look at the results spatially noting that just because a prediction overlaps with a ground truth pile does not mean that it meets the IoU threshold for determining a positive match. in these cases where the IoU was insufficient, a commission (FP) will overlap with an omission (FN). # plot it ggplot2::ggplot() + ggplot2::geom_sf(data = aoi_boundary, color = &quot;black&quot;, fill = NA) + ggplot2::geom_sf( data = aoi_slash_piles_polys %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.7 ) + ggplot2::geom_sf( data = predictions_temp %&gt;% dplyr::left_join( ground_truth_prediction_match_ans %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 1.1 ) + ggplot2::scale_fill_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, name = &quot;&quot;) + ggplot2::theme_void() + ggplot2::guides( fill = ggplot2::guide_legend(override.aes = list(color = c(NA,NA,pal_match_grp[&quot;commission&quot;]))) , color = &quot;none&quot; ) 6.2 Detection Accuracy Metrics Detection accuracy metrics are calculated by aggregating raw TP, FP, and FN counts to quantify the method’s ability to find the piles. Aggregation of the instance matching allows us to evaluate omission rate (false negative rate or miss rate), commission rate (false positive rate), precision, recall (detection rate), and the F-score metric. As a reminder, true positive (TP) instances correctly match ground truth instances with a prediction, commission predictions do not match a ground truth instance (false positive; FP), and omissions are ground truth instances for which no predictions match (false negative; FN) \\[\\textrm{omission rate} = \\frac{FN}{TP+FN}\\] \\[\\textrm{commission rate} = \\frac{FP}{TP+FP}\\] \\[\\textrm{precision} = \\frac{TP}{TP+FP}\\] \\[\\textrm{recall} = \\frac{TP}{TP+FN}\\] \\[ \\textrm{F-score} = 2 \\times \\frac{\\bigl(precision \\times recall \\bigr)}{\\bigl(precision + recall \\bigr)} \\] let’s make a function to calculate these detection accuracy metrics based on aggregated TP, FP, and FN counts # first function takes df with cols tp_n, fp_n, and fn_n to calculate rates confusion_matrix_scores_fn &lt;- function(df) { df %&gt;% dplyr::mutate( omission_rate = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) == 0 ~ 0 # if there are no actual piles, there is nothing to miss , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 1 # every single actual pile was missed , dplyr::coalesce(fn_n,0) == 0 &amp; dplyr::coalesce(tp_n,0) &gt; 0 ~ 0 , T ~ fn_n/(tp_n+fn_n) ) # False Negative Rate or Miss Rate , commission_rate = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 0 # if no predictions are made, the model could not have made any commission errors , dplyr::coalesce(fp_n,0) == 0 &amp; dplyr::coalesce(tp_n,0) &gt; 0 ~ 0 , T ~ fp_n/(tp_n+fp_n) ) # False Positive Rate , precision = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) == 0 ~ 1 # if no predictions are made, the model made zero incorrect positive claims , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fp_n,0) &gt; 0 ~ 0 , T ~ tp_n/(tp_n+fp_n) ) , recall = dplyr::case_when( dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) == 0 ~ 1 # if there are no actual piles, there is nothing to miss , dplyr::coalesce(tp_n,0) == 0 &amp; dplyr::coalesce(fn_n,0) &gt; 0 ~ 0 # every single actual pile was missed , T ~ tp_n/(tp_n+fn_n) ) , f_score = dplyr::case_when( dplyr::coalesce(precision,0) == 0 | dplyr::coalesce(recall,0) == 0 ~ 0 , T ~ 2 * ( (precision*recall)/(precision+recall) ) ) ) } test it using our fake predictions ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate( match_grp = dplyr::case_match( match_grp , &quot;true positive&quot;~&quot;tp&quot; , &quot;commission&quot;~&quot;fp&quot; , &quot;omission&quot;~&quot;fn&quot; ) ) %&gt;% tidyr::pivot_wider( names_from = match_grp , values_from = c(n) , names_glue = &quot;{match_grp}_{.value}&quot; ) %&gt;% confusion_matrix_scores_fn() ## # A tibble: 1 × 8 ## fn_n fp_n tp_n omission_rate commission_rate precision recall f_score ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8 35 10 0.444 0.778 0.222 0.556 0.317 6.3 Quantification Accuracy Metrics Quantification accuracy metrics such as RMSE, MAPE, and Mean Error of pile form measurements (e.g. height, diameter) are calculated by aggregating the differences between the estimated pile attributes and the ground truth values for instances classified as True Positives. These metrics tell us about the method’s ability to accurately quantify the form of the piles it successfully identified. We only have field-collected slash pile height and diameter measurements from a single study site, the PSINF Mixed Conifer Site. Data from this one study site will be used to test the slash pile quantification accuracies acheived by the proposed methodology, while data from all study sites will be used to validate the slash pile detection methodology. to prepare our results for analysis, we will develop a function that aggregates the pile-level data into a single record for each metric-error measurement combination. this function will calculate detection performance metrics such as F-score, precision, and recall (using the confusion_matrix_scores_fn() we defined above), as well as quantification accuracy metrics including Root Mean Squared Error (RMSE), Mean Error (ME), and Mean Absolute Percentage Error (MAPE) to assess the accuracy of our pile form measurements. this could be a valuable function for any future analysis comparing predictions to ground truth data. here are the quantification accuracy metric formulas: \\[ \\textrm{RMSE} = \\sqrt{ \\frac{ \\sum_{i=1}^{N} (y_{i} - \\hat{y_{i}})^{2}}{N}} \\] \\[ \\textrm{ME} = \\frac{ \\sum_{i=1}^{N} (\\hat{y_{i}} - y_{i})}{N} \\] \\[ \\textrm{MAPE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left| \\frac{y_{i} - \\hat{y_{i}}}{y_{i}} \\right| \\] Where \\(N\\) is equal to the total number of correctly matched piles, \\(y_i\\) is the ground truth measured value and \\(\\hat{y_i}\\) is the predicted value of \\(i\\) we could also calculate Relative RMSE (RRMSE) \\[ \\textrm{RRMSE} = \\frac{\\text{RMSE}}{\\bar{y}} \\times 100\\% \\] where, \\(\\bar{y}\\) represents the mean of the ground truth values. the interpretations of RMSE and RRMSE are: RMSE: Measures the average magnitude of the differences between predicted and the actual observed values, expressed in the same units as the metric. RRMSE: Expresses RMSE as a percentage of the mean of the observed values, providing a scale-independent measure to compare model accuracy across different datasets or models. for this analysis, we’ll show how to calculate RRMSE but we’ll only investigate MAPE Use MAPE when: You need an easily understandable metric for comparing prediction accuracy across different series or models with varying scales, particularly when zeros or near-zero actual values are not present in your data. Use RRMSE when: You need a metric that is more robust to small or zero actual values and you want to penalize larger errors more heavily due to the squaring of errors in its calculation. # aggregate results from ground_truth_prediction_match() agg_ground_truth_match &lt;- function(ground_truth_prediction_match_ans) { if(nrow(ground_truth_prediction_match_ans)==0){return(NULL)} if( !(names(ground_truth_prediction_match_ans) %&gt;% stringr::str_equal(&quot;match_grp&quot;) %&gt;% any()) ){stop(&quot;ground_truth_prediction_match_ans must contain `match_grp` column&quot;)} # check for difference columns (contains &quot;_diff&quot;) and calc rmse for only those to return a single line df with colums for each diff_rmse if( (ground_truth_prediction_match_ans %&gt;% dplyr::select(tidyselect::starts_with(&quot;diff_&quot;) | tidyselect::starts_with(&quot;pct_diff_&quot;)) %&gt;% ncol() )&gt;0 ){ # get rmse and mean difference/error for all columns with &quot;_diff&quot; but not &quot;pct_diff&quot; # get mape for all columns with &quot;pct_diff&quot; but not &quot;diff_&quot; rmse_df &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::select( tidyselect::starts_with(&quot;diff_&quot;) | tidyselect::starts_with(&quot;pct_diff_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything(), values_drop_na = T) %&gt;% dplyr::group_by(name) %&gt;% dplyr::summarise( sq = sum(value^2, na.rm = T) , mean = mean(value, na.rm = T) , sumabs = sum(abs(value), na.rm = T) , nomiss = sum(!is.na(value)) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( rmse = dplyr::case_when( dplyr::coalesce(nomiss,0)==0 ~ as.numeric(NA) , T ~ sqrt(sq/nomiss) ) , mape = dplyr::case_when( dplyr::coalesce(nomiss,0)==0 ~ as.numeric(NA) , T ~ sumabs/nomiss ) ) %&gt;% # NA nonsense values dplyr::mutate( mape = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ mape , T ~ as.numeric(NA) ) , rmse = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ as.numeric(NA) , T ~ rmse ) , mean = dplyr::case_when( stringr::str_starts(name, &quot;pct_diff_&quot;) ~ as.numeric(NA) , T ~ mean ) ) %&gt;% dplyr::select(name,rmse,mean,mape) %&gt;% tidyr::pivot_wider( names_from = name , values_from = c(rmse,mean,mape) , names_glue = &quot;{name}_{.value}&quot; ) %&gt;% # remove columns with NA in all rows dplyr::select( dplyr::where( ~!all(is.na(.x)) ) ) if( dplyr::coalesce(nrow(rmse_df),0)==0 || dplyr::coalesce(ncol(rmse_df),0)==0 ){ # empty df rmse_df &lt;- dplyr::tibble() } }else{ # empty df rmse_df &lt;- dplyr::tibble() } # count by match group agg &lt;- ground_truth_prediction_match_ans %&gt;% dplyr::ungroup() %&gt;% dplyr::count(match_grp) %&gt;% dplyr::mutate( match_grp = dplyr::case_match( match_grp , &quot;true positive&quot;~&quot;tp&quot; , &quot;commission&quot;~&quot;fp&quot; , &quot;omission&quot;~&quot;fn&quot; ) ) # true positive, false positive, false negative rates return_df &lt;- dplyr::tibble(match_grp = c(&quot;tp&quot;,&quot;fp&quot;,&quot;fn&quot;)) %&gt;% dplyr::left_join(agg, by = &quot;match_grp&quot;) %&gt;% dplyr::mutate(dplyr::across(.cols = c(n), .fn = ~dplyr::coalesce(.x,0))) %&gt;% tidyr::pivot_wider( names_from = match_grp , values_from = c(n) , names_glue = &quot;{match_grp}_{.value}&quot; ) # rates, precision, recall, f-score return_df &lt;- confusion_matrix_scores_fn(return_df) # add rmse if(nrow(rmse_df)&gt;0){ return_df &lt;- return_df %&gt;% dplyr::bind_cols(rmse_df) } # return return(return_df) } There is a lot going on in our agg_ground_truth_match() function but it’s application is straightforward enough: The minimum required input is a data frame of the raw instance matches with a column named match_grp which is string/factor with the levels “true positive”, “commission”, and “omission” as returned by the ground_truth_prediction_match() function Optionally, if the data contain columns with the prefix “diff_” the mean error (ME) is calculated for those columns with the return having the suffix “_mean” and the RMSE is calculated for those columns with the return having the suffix “_rmse” interpretation of the ME is enhanced if these “diff_” columns are calculated as the predicted value minus the actual value (e.g. pred_diameter_m - gt_diameter_m) Optionally, if the data contain columns with the prefix “pct_diff_” the mean absolute percent error (MAPE) is calculated for those columns with the return having the suffix “_mape” these “pct_diff_” columns are calculated as the actual value minus the predicted value divided by the actual value (e.g. (gt_diameter_m - pred_diameter_m)/gt_diameter_m) first, let’s look at the agg_ground_truth_match() return using an example minimum required input data frame of the raw instance matches with a column named match_grp which is string/factor with the levels “true positive”, “commission”, and “omission” dplyr::tibble( match_grp = c( rep(&quot;true positive&quot;, times = 9) , rep(&quot;commission&quot;, times = 2) , rep(&quot;omission&quot;, times = 4) ) ) %&gt;% agg_ground_truth_match() %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 8 ## $ tp_n &lt;dbl&gt; 9 ## $ fp_n &lt;dbl&gt; 2 ## $ fn_n &lt;dbl&gt; 4 ## $ omission_rate &lt;dbl&gt; 0.3076923 ## $ commission_rate &lt;dbl&gt; 0.1818182 ## $ precision &lt;dbl&gt; 0.8181818 ## $ recall &lt;dbl&gt; 0.6923077 ## $ f_score &lt;dbl&gt; 0.75 now, let’s look at the agg_ground_truth_match() output using our fake pile prediction instance match example made by our ground_truth_prediction_match() function as input. Before agg_ground_truth_match(), we’ll add area of the fake predicted piles and area of the ground truth piles (based on image-annotated boundaries) to ensure we get RMSE, MAPE, and ME quantification accuracy metrics in the result # first, we&#39;ll add pile area from the respective spatial data ground_truth_prediction_match_ans &lt;- ground_truth_prediction_match_ans %&gt;% # join on gt area data dplyr::left_join( aoi_slash_piles_polys %&gt;% dplyr::select(pile_id) %&gt;% dplyr::mutate(gt_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( predictions_temp %&gt;% dplyr::select(pred_id) %&gt;% dplyr::mutate(pred_area_m2 = sf::st_area(.) %&gt;% as.numeric()) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 ) # agg_ground_truth_match() agg_ground_truth_match(ground_truth_prediction_match_ans) %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 11 ## $ tp_n &lt;dbl&gt; 10 ## $ fp_n &lt;dbl&gt; 35 ## $ fn_n &lt;dbl&gt; 8 ## $ omission_rate &lt;dbl&gt; 0.4444444 ## $ commission_rate &lt;dbl&gt; 0.7777778 ## $ precision &lt;dbl&gt; 0.2222222 ## $ recall &lt;dbl&gt; 0.5555556 ## $ f_score &lt;dbl&gt; 0.3174603 ## $ diff_area_m2_rmse &lt;dbl&gt; 5.389461 ## $ diff_area_m2_mean &lt;dbl&gt; -1.263415 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.6507452 the agg_ground_truth_match() allows for multiple “diff_” and “pct_diff_” columns to aggregate quantification accuracy metrics for different measurements ground_truth_prediction_match_ans %&gt;% dplyr::mutate( # fake one pred_other_measurement = runif(n=dplyr::n(),min = 1, max = 11) , pred_other_measurement = ifelse(is.na(pred_id),NA,pred_other_measurement) # fake one , gt_other_measurement = runif(n=dplyr::n(),min = 3, max = 13) , gt_other_measurement = ifelse(is.na(pile_id),NA,gt_other_measurement) ) %&gt;% # calculate difference columns dplyr::mutate( diff_other_measurement = pred_other_measurement-gt_other_measurement , pct_diff_other_measurement = (gt_other_measurement-pred_other_measurement)/gt_other_measurement ) %&gt;% agg_ground_truth_match() %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 14 ## $ tp_n &lt;dbl&gt; 10 ## $ fp_n &lt;dbl&gt; 35 ## $ fn_n &lt;dbl&gt; 8 ## $ omission_rate &lt;dbl&gt; 0.4444444 ## $ commission_rate &lt;dbl&gt; 0.7777778 ## $ precision &lt;dbl&gt; 0.2222222 ## $ recall &lt;dbl&gt; 0.5555556 ## $ f_score &lt;dbl&gt; 0.3174603 ## $ diff_area_m2_rmse &lt;dbl&gt; 5.389461 ## $ diff_other_measurement_rmse &lt;dbl&gt; 2.842555 ## $ diff_area_m2_mean &lt;dbl&gt; -1.263415 ## $ diff_other_measurement_mean &lt;dbl&gt; -0.3700619 ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.6507452 ## $ pct_diff_other_measurement_mape &lt;dbl&gt; 0.3802022 "],["meth_preds.html", "Section 7 Method Predictions 7.1 Size and Geometric Parameter Settings 7.2 CHM-based Slash Pile Candidates 7.3 Spectral Filter Slash Pile Candidates", " Section 7 Method Predictions We are finally ready to make predictions using our proposed training-free, rules-based methodology for identifying slash piles from UAS data with a structural and spectral data fusion approach. To this point we have: Provided a data overview: here and here Processed the UAS point cloud Demonstrated our geometry-based slash pile detection methodology Demonstrated our spectral refinement (i.e. data fusion) methodology and Reviewed how we will evaluate our method In this section, we’ll implement the proposed geometric, rules-based slash piled detection methodology on our experimental sites using our data fusion approach which utilizes both structural data (i.e. CHM) and spectral RGB data across the four study sites. The integration of spectral data in our data fusion approach allows for less restrictive structural settings, while the absence of spectral filtering would necessitate stricter size and geometric thresholds to minimize false positive predictions. We only test the data fusion method here because the spectral data from imagery is foundational to UAS-DAP point cloud data. That is, aerial imagery is the raw input data used to generate the aerial point cloud data which represents structure in 3D space in UAS-DAP workflows. 7.1 Size and Geometric Parameter Settings Our geometric, rules-based methodology uses input CHM data and user-defined thresholds for size (height and area) and 2D pile footprint shape regularity (convexity and circularity). The expected height and area search range for slash piles should be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion whether these are a sample of empirical measurements or rough estimates based on visual observation of pile construction outcomes post-treatment. These thresholds define the search space using the CHM data and refine candidate segments to yield final pile predictions. Here, we review the pile construction prescription (if available) and supplemental visual observational information for each study site and set the size and geometric thresholds for our structural pile detection methodology. The study site prescriptions can be reviewed here 7.1.1 PSINF Mixed Conifer Site While the silvicultural prescription provides no specific details regarding pile construction, the management objective to create a wildfire-resilient post-treatment structure suggests that piles were likely located in open spaces away from residual trees. This spacing might enhance the ability of our detection methodology by reducing structural interference from the canopy, regardless of the variations in pile size. Anecdotal feedback from post-treatment site walkthroughs further informs our structural parameters, indicating that hand-piles were generally well-constructed to facilitate efficient prescribed burning and approximately 1.5 m by 1.5 m (5 ft by 5 ft) in size. Mechanical piles at the landings maintained a roughly circular form but were significantly larger, with widths comparable to two or three work vehicles and a taller height than the vehicle. 7.1.2 TRFO-BLM Pinyon-Juniper Site The silvicultural prescription for the TRFO-BLM site includes exact pile construction minimum dimensions of 1.5 m (5 ft) in length, width, and height, which establishes an expected minimum pile area of approximately 2.3 square meters. While these guidelines focus on compact construction to facilitate consumption during burning, the lack of an explicit maximum size requires the use of anecdotal feedback to determine upper thresholds for our detection methodology. Site managers reported that piles were often larger than expected and “messy” (indicating more irregular footprints than expected). Despite the prescribed residual forest structure being characterized by open interspaces with uniform gaps between trees, the anecdotal observation that piles were frequently constructed too close to residual trees introduces a potential challenge for automated detection. This proximity may cause the structural and spectral signatures of the piles to merge with the surrounding canopy. 7.1.3 BHEF Ponderosa Pine Site While the silvicultural prescription for the BHEF site defines no specific pile construction parameters, the treatment resulted exclusively in mechanical piles located at landings without additional hand piles. Onsite observations indicated that these piles are gernerally very large and lack a standardized shape or form. For example, some piles were circular and piled high vertically while others were shorter (around DBH) with elongated oval footprints. We established detection thresholds by using familiar anchors to contextualize scale, such as the dimensions of our work truck. Ground-based cell phone images and an aerial UAS photo capturing the truck parked next to one of the largest piles confirmed that some piles reached the scale of a small-sized, one story American single-family home. We used these onsite observations and truck- and house-sized estimates to set high minimum area and height thresholds to isolate the piles from other features. Because these large dimensions may structurally resemble the residual tree groups, spectral information may be key to ensuring the detection accuracy of our method by filtering out false positive predictions from the structural detection. 7.1.4 ARNF Ponderosa Pine Site While the silvicultural prescription for the ARNF site defines no specific pile construction parameters, it specifies that all residual waste was mechanically piled at landings for future prescribed burning. Onsite observations indicated that these mechanical piles are uniformly massive and generally circular. The piles were also compact and vertical in structure with limited horizontal sprawl, a construction form that will likely increase consumption efficiency during prescribed burning. Some landings contained clusters of two to five individual piles. To calibrate our detection methodology for these large-scale features, we used cell phone photos taken from the ground during site walkthroughs to compare the piles against a lifted Dodge Ram 2500 Mega Cab turbo diesel. By using this vehicle as a known physical anchor, we estimated that the piles were often at least 2-3 the truck’s height of approximately 2.4 m (8 ft), with footprints significantly exceeding the 16.7 to 26.7 square meters of a standard parking space. These dimensional estimates allow us to set relatively large minimum area and height thresholds for our detection methodology to ensure the exclusion of smaller detected objects like trees or boulders since no small hand piles were expected. 7.1.5 Study Paremeter Settings First, we’re going to make the resolution on the CHM raster for the machine site a bit more coarse since the target object size is larger and we shouldn’t need such fine-grain detail. Also, aggregating the raster to a coarser resolution should help to smooth out some of the noise in fine-grain CHM data which may be necessary for detecting small elevational changes necessary to detect much smaller hand piles. agg_chm_res_m &lt;- 0.15 # bhef_chm_rast fnm_temp &lt;- file.path(&quot;../data/BHEF_202306/&quot;, paste0(&quot;bhef_chm_rast_&quot;,agg_chm_res_m,&quot;m.tif&quot;)) if(!file.exists(fnm_temp)){ rast_temp &lt;- bhef_chm_rast remove(bhef_chm_rast) gc() bhef_chm_rast &lt;- cloud2trees:::adjust_raster_resolution( raster_object = rast_temp , target_resolution = agg_chm_res_m , fun = max # max for CHM , resample_method = &quot;bilinear&quot; , ofile = fnm_temp ) remove(fnm_temp,rast_temp) gc() }else{ bhef_chm_rast &lt;- terra::rast(fnm_temp) } # arnf_chm_rast fnm_temp &lt;- file.path(&quot;../data/ARNF_DiamondView_202510/&quot;, paste0(&quot;arnf_chm_rast_&quot;,agg_chm_res_m,&quot;m.tif&quot;)) if(!file.exists(fnm_temp)){ rast_temp &lt;- arnf_chm_rast remove(arnf_chm_rast) gc() arnf_chm_rast &lt;- cloud2trees:::adjust_raster_resolution( raster_object = rast_temp , target_resolution = agg_chm_res_m , fun = max # max for CHM , resample_method = &quot;bilinear&quot; , ofile = fnm_temp ) remove(fnm_temp,rast_temp) gc() }else{ arnf_chm_rast &lt;- terra::rast(fnm_temp) } Set the structural detection parameters based on pile construction prescription and anecdotal feedback from onsite observation Parameter PSINF Mixed Conifer Site TRFO-BLM Pinyon-Juniper Site BHEF Ponderosa Pine Site ARNF Ponderosa Pine Site min_ht_m 1.0 (66% of min. hand pile) 0.75 (50% of min. hand pile) 1.25 (slightly &lt; DBH) 2.4 (truck height) max_ht_m 5.0 (2x truck height) 3.0 (2x hand pile height) 6.0 (2.5x truck height) 9.6 (4x truck height) min_area_m2 2.0 (90% of min. hand pile) 2.0 (90% of min. hand pile) 54.0 (2x parking space) 54.0 (2x parking space) max_area_m2 54.0 (2x parking space) 22.5 (10x min. hand pile) 486.0 (18x parking space) 621.0 (23x parking space) min_convexity_ratio 0.65 (strict) 0.55 (strict) 0.55 (strict) 0.55 (strict) min_circularity_ratio 0.5 (strict) 0.35 (moderate) 0.0 (no circularity constraint) 0.3 (moderate) for the spectral_weight parameter we can be fairly strict with our spectral filtering across all of these study sites because the piles were generally constructed away from residual trees. As a reminder, the spectral_weight parameter defines the minimum number of the six independent spectral indices that must positively identify a candidate object as non-vegetated to retain it, where increasing the value towards six (6) enforces a stricter consensus to filter out live green vegetation and decreasing it allows for more permissive detection in areas where shadows or canopy overlap may obscure the spectral signature. Site spectral_weight Justification ARNF 5 Located in open landings, these piles have minimal overlap with live canopy; a strict weight ensures that any edge-case vegetation or weeds growing near the piles are effectively excluded. BHEF 5 A high consensus threshold is critical here to distinguish massive piles from residual tree groups, as high spectral weight ensures that objects with live green foliage are filtered out of the structural results. TRFO-BLM 5 The “heavy intensity uniform thinning treatment” in this pinyon-juniper site which opened up significant space between residual trees likely allows for a strict threshold to reliably remove any candidates which may be green shrubs or low-hanging branches. PSINF 4 Because hand piles are often positioned near the residual trees such that many are shadowed by the canopy in the aerial imagery, a slightly lower weight prevents the accidental removal of piles that may be shadowed or have spectral “bleeding” from live tree crowns. let’s table that so we have the information all_stand_boundary &lt;- all_stand_boundary %&gt;% dplyr::left_join( dplyr::tibble( site = c(&quot;PSINF Mixed Conifer Site&quot;, &quot;TRFO-BLM Pinyon-Juniper Site&quot;, &quot;BHEF Ponderosa Pine Site&quot;, &quot;ARNF Ponderosa Pine Site&quot;) , min_ht_m = c(1, 0.75, 1.25, 2.4) , max_ht_m = c(5.0, 3.0, 6.0, 9.6) , min_area_m2 = c(2.0, 2.0, 54.0, 54.0) , max_area_m2 = c(54.0, 22.5, 486.0, 621.0) , min_convexity_ratio = c(0.65, 0.55, 0.55, 0.55) , min_circularity_ratio = c(0.5, 0.35, 0.0, 0.3) , spectral_weight = c(4, 5, 5, 5) , chm_res_m = c( terra::res(psinf_chm_rast)[1] , terra::res(pj_chm_rast)[1] , terra::res(bhef_chm_rast)[1] , terra::res(arnf_chm_rast)[1] ) ) , by = &quot;site&quot; ) all_stand_boundary %&gt;% dplyr::glimpse() ## Rows: 4 ## Columns: 13 ## $ site &lt;chr&gt; &quot;ARNF Ponderosa Pine Site&quot;, &quot;BHEF Ponderosa Pine… ## $ geometry &lt;GEOMETRY [m]&gt; MULTIPOLYGON (((-794262.3 2..., MULTIPO… ## $ site_area_m2 &lt;dbl&gt; 736062.04, 1031024.64, 174975.91, 51736.28 ## $ site_area_ha &lt;dbl&gt; 73.606204, 103.102464, 17.497591, 5.173628 ## $ site_data_lab &lt;chr&gt; &quot;arnf&quot;, &quot;bhef&quot;, &quot;psinf&quot;, &quot;pj&quot; ## $ min_ht_m &lt;dbl&gt; 2.40, 1.25, 1.00, 0.75 ## $ max_ht_m &lt;dbl&gt; 9.6, 6.0, 5.0, 3.0 ## $ min_area_m2 &lt;dbl&gt; 54, 54, 2, 2 ## $ max_area_m2 &lt;dbl&gt; 621.0, 486.0, 54.0, 22.5 ## $ min_convexity_ratio &lt;dbl&gt; 0.55, 0.55, 0.65, 0.55 ## $ min_circularity_ratio &lt;dbl&gt; 0.30, 0.00, 0.50, 0.35 ## $ spectral_weight &lt;dbl&gt; 5, 5, 4, 5 ## $ chm_res_m &lt;dbl&gt; 0.15, 0.15, 0.10, 0.10 generate a kableExtra table all_stand_boundary %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c( tidyselect::starts_with(&quot;site_area&quot;) , site_data_lab )) %&gt;% tidyr::pivot_longer(cols=-site) %&gt;% dplyr::mutate( value = dplyr::case_when( name == &quot;spectral_weight&quot; ~ scales::comma(value,accuracy=1) , name %in% c(&quot;min_ht_m&quot;, &quot;chm_res_m&quot;, &quot;min_convexity_ratio&quot;, &quot;min_circularity_ratio&quot;) ~ scales::comma(value,accuracy=0.01) , T ~ scales::comma(value,accuracy=0.1) ) ) %&gt;% tidyr::pivot_wider(names_from = site, values_from = value) %&gt;% dplyr::rename(parameter = name) %&gt;% # kable kableExtra::kbl( caption = &quot;user-defined thresholds for size and expected pile shape regularity&quot; , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling() Table 7.1: user-defined thresholds for size and expected pile shape regularity parameter ARNF Ponderosa Pine Site BHEF Ponderosa Pine Site PSINF Mixed Conifer Site TRFO-BLM Pinyon-Juniper Site min_ht_m 2.40 1.25 1.00 0.75 max_ht_m 9.6 6.0 5.0 3.0 min_area_m2 54.0 54.0 2.0 2.0 max_area_m2 621.0 486.0 54.0 22.5 min_convexity_ratio 0.55 0.55 0.65 0.55 min_circularity_ratio 0.30 0.00 0.50 0.35 spectral_weight 5 5 4 5 chm_res_m 0.15 0.15 0.10 0.10 let’s organize our site boundary, ground truth, CHM, and RGB data into lists so we can programmatically iterate through all sites more efficiently ########################################## # stand_boundary ########################################## # suffix suffix_temp &lt;- &quot;_stand_boundary&quot; # convert to list of objects and remove the suffix from the name in the list stand_boundary &lt;- all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% base::mget(inherits = T) %&gt;% purrr::set_names(~ str_remove(.x, suffix_temp)) # names(stand_boundary) # dplyr::glimpse(stand_boundary) # remove all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% purrr::map(\\(x) remove(list = x,inherits = T)) ########################################## # slash_piles_polys ########################################## # suffix suffix_temp &lt;- &quot;_slash_piles_polys&quot; # convert to list of objects and remove the suffix from the name in the list slash_piles_polys &lt;- all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% base::mget(inherits = T) %&gt;% purrr::set_names(~ str_remove(.x, suffix_temp)) # names(slash_piles_polys) # dplyr::glimpse(slash_piles_polys) # remove all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% purrr::map(\\(x) remove(list = x,inherits = T)) ########################################## # chm_rast ########################################## # suffix suffix_temp &lt;- &quot;_chm_rast&quot; # convert to list of objects and remove the suffix from the name in the list chm_rast &lt;- all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% base::mget(inherits = T) %&gt;% purrr::set_names(~ str_remove(.x, suffix_temp)) # names(chm_rast) # dplyr::glimpse(chm_rast) # remove all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% purrr::map(\\(x) remove(list = x,inherits = T)) ########################################## # rgb_rast ########################################## # suffix suffix_temp &lt;- &quot;_rgb_rast&quot; # convert to list of objects and remove the suffix from the name in the list rgb_rast &lt;- all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% base::mget(inherits = T) %&gt;% purrr::set_names(~ str_remove(.x, suffix_temp)) # names(rgb_rast) # dplyr::glimpse(rgb_rast) # remove all_stand_boundary$site_data_lab %&gt;% paste0(suffix_temp) %&gt;% purrr::map(\\(x) remove(list = x,inherits = T)) 7.2 CHM-based Slash Pile Candidates Our geometric, rules-based methodology uses input CHM data and user-defined thresholds for size (height and area) and 2D pile footprint shape regularity (convexity and circularity). We defined a function to make the detection from the CHM easy given the parameters we reviewed above: slash_pile_detect() check the segmentation parameters to be used in each of the DBSCAN and Watershed segmentation methods segmentation_params_used &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) get_segmentation_params( min_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_ht_m) , max_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_ht_m) , min_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_area_m2) , max_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_area_m2) , rast_res_m = terra::res(chm_rast[[x]])[1] ) ) # segmentation_params_used We’ll get the predictions using both the DBSCAN and Watershed segmentation approaches. Review this section for a refresher on how we use these methods ################################################## # map over slash_pile_detect for dbscan ################################################## # file.names to only run if not already done since it takes a while for all sites dir_temp &lt;- &quot;../data&quot; if(!dir.exists(dir_temp)){dir.create(dir_temp,showWarnings = F)} nmsfx_temp &lt;- &quot;_dbscan_structural_preds.gpkg&quot; if( !all(file.exists( file.path(dir_temp, paste0(all_stand_boundary$site_data_lab,nmsfx_temp)) )) ){ # map over slash_pile_detect for dbscan dbscan_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) slash_pile_detect( chm_rast = chm_rast[[x]] , seg_method = &quot;dbscan&quot; , min_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_ht_m) , max_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_ht_m) , min_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_area_m2) , max_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_area_m2) , min_convexity_ratio = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_convexity_ratio) , min_circularity_ratio = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_circularity_ratio) , ofile = file.path(dir_temp, paste0(x,nmsfx_temp)) ) # purrr::pluck(&quot;segs_sf&quot;) , .progress = T ) # # write # dbscan_structural_preds %&gt;% # purrr::imap( # \\(x,nm) # sf::st_write( # obj = x # , dsn = file.path(dir_temp, paste0(nm,nmsfx_temp)) # , append = F # , quiet = T # ) # ) # read files dbscan_structural_preds &lt;- dbscan_structural_preds %&gt;% purrr::map( \\(x) sf::st_read(dsn = x, quiet = T) ) }else{ # read already done dbscan_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) sf::st_read( dsn = file.path(dir_temp, paste0(x,nmsfx_temp)) , quiet = T ) ) } # filter all candidate piles for only those that intersect with the study boundary dbscan_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) dplyr::inner_join( dbscan_structural_preds[[x]] , dbscan_structural_preds[[x]] %&gt;% sf::st_intersection( stand_boundary[[x]] %&gt;% sf::st_transform(sf::st_crs(dbscan_structural_preds[[x]])) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pred_id&quot; ) ) ################################################## # map over slash_pile_detect for watershed ################################################## # file.names to only run if not already done since it takes a while for all sites dir_temp &lt;- &quot;../data&quot; if(!dir.exists(dir_temp)){dir.create(dir_temp,showWarnings = F)} nmsfx_temp &lt;- &quot;_watershed_structural_preds.gpkg&quot; if( !all(file.exists( file.path(dir_temp, paste0(all_stand_boundary$site_data_lab,nmsfx_temp)) )) ){ # map over slash_pile_detect for watershed watershed_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% # .[2:4] %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) slash_pile_detect( chm_rast = chm_rast[[x]] , seg_method = &quot;watershed&quot; , min_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_ht_m) , max_ht_m = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_ht_m) , min_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_area_m2) , max_area_m2 = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(max_area_m2) , min_convexity_ratio = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_convexity_ratio) , min_circularity_ratio = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(min_circularity_ratio) , ofile = file.path(dir_temp, paste0(x,nmsfx_temp)) ) # purrr::pluck(&quot;segs_sf&quot;) , .progress = T ) # read files watershed_structural_preds &lt;- watershed_structural_preds %&gt;% purrr::map( \\(x) sf::st_read(dsn = x, quiet = T) ) }else{ # read already done watershed_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) sf::st_read( dsn = file.path(dir_temp, paste0(x,nmsfx_temp)) , quiet = T ) ) } # filter all candidate piles for only those that intersect with the study boundary watershed_structural_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) dplyr::inner_join( watershed_structural_preds[[x]] , watershed_structural_preds[[x]] %&gt;% sf::st_intersection( stand_boundary[[x]] %&gt;% sf::st_transform(sf::st_crs(watershed_structural_preds[[x]])) ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pred_id) %&gt;% dplyr::mutate(is_in_stand = T) , by = &quot;pred_id&quot; ) ) let’s summarize the number of structural candidate segments and the area they cover by site dplyr::bind_rows( # watershed watershed_structural_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% sf::st_drop_geometry() %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(area_m2, volume_m3, max_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , sum = ~sum(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) ) ) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate(method = &quot;watershed&quot;) , # dbscan dbscan_structural_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% sf::st_drop_geometry() %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(area_m2, volume_m3, max_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , sum = ~sum(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) ) ) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) ) %&gt;% dplyr::mutate( dplyr::across( c(tidyselect::ends_with(&quot;_sum&quot;),n) # dplyr::where(is.numeric) , ~scales::comma(.x,accuracy = 1) ) , dplyr::across( dplyr::where(is.numeric) , ~scales::comma(.x,accuracy = .1) ) , area_m2_mean = paste0(area_m2_mean, &quot;&lt;br&gt;(&quot;,area_m2_sd,&quot;)&quot;) , volume_m3_mean = paste0(volume_m3_mean, &quot;&lt;br&gt;(&quot;,volume_m3_sd,&quot;)&quot;) , max_height_m_mean = paste0(max_height_m_mean, &quot;&lt;br&gt;(&quot;,max_height_m_sd,&quot;)&quot;) ) %&gt;% dplyr::select( -tidyselect::ends_with(&quot;_sd&quot;) , -max_height_m_sum ) %&gt;% dplyr::relocate(site,method,n) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Structurally detected candidate segments by method and study site&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , &quot;# candidates&quot; , &quot;area m&lt;sup&gt;2&lt;/sup&gt;&lt;br&gt;mean (sd)&quot; , &quot;area m&lt;sup&gt;2&lt;/sup&gt;&lt;br&gt;total&quot; , &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&lt;br&gt;mean (sd)&quot; , &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&lt;br&gt;total&quot; , &quot;height m&lt;br&gt;mean (sd)&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 7.2: Structurally detected candidate segments by method and study site site method # candidates area m2mean (sd) area m2total volume m3mean (sd) volume m3total height mmean (sd) ARNF Ponderosa Pine Site dbscan 76 217.5(147.6) 16,533 843.8(500.6) 64,131 8.9(1.2) watershed 92 183.7(131.1) 16,896 757.4(528.3) 69,677 8.9(1.2) BHEF Ponderosa Pine Site dbscan 270 165.9(90.3) 44,802 399.6(258.6) 107,884 5.5(1.1) watershed 319 150.3(72.0) 47,933 410.7(272.3) 131,019 5.5(1.0) PSINF Mixed Conifer Site dbscan 188 7.6(7.3) 1,422 10.2(11.3) 1,919 3.0(1.3) watershed 193 7.5(7.2) 1,450 10.3(11.4) 1,979 3.0(1.3) TRFO-BLM Pinyon-Juniper Site dbscan 378 8.7(4.0) 3,273 6.6(5.6) 2,477 1.6(0.8) watershed 377 8.6(4.0) 3,235 6.4(5.5) 2,429 1.6(0.8) 7.2.1 DBSCAN Candidates We’ll quickly plot the structurally-detected candidate segments using the DBSCAN method for each study site # function to plot ortho terra_plt_ortho &lt;- function( ortho , gt_piles , pred_piles , boundary , title ) { terra::plotRGB(ortho, stretch = &quot;lin&quot;) terra::plot( boundary %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA , main = title ) terra::plot( gt_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) terra::plot( pred_piles %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 1.2 ) } # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) , pred_piles = dbscan_structural_preds[[x]] %&gt;% dplyr::filter(is_in_stand) , boundary = stand_boundary[[x]] , title = paste0( &quot;DBSCAN: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) ) 7.2.2 Watershed Candidates We’ll quickly plot the structurally-detected candidate segments using the Watershed method for each study site # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) , pred_piles = watershed_structural_preds[[x]] %&gt;% dplyr::filter(is_in_stand) , boundary = stand_boundary[[x]] , title = paste0( &quot;Watershed: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) ) 7.3 Spectral Filter Slash Pile Candidates Now, we’ll apply spectral filtering of the structurally-detected candidate piles using our data fusion approach. As a quick reminder, the spectral filtering functions to distinguish woody debris from live vegetation. We use a spectral voting system using six independent spectral indices derived from RGB data alone. The spectral_weight parameter defines the consensus threshold, requiring a specific number of index thresholds (0-6) required to retain structural candidate piles to generate the final method prediction. see our parameter setting table above above for the spectral_weight setting which defines how many of the six spectral thresholds must be met for a candidate pile to be retained for final selection as a predicted slash pile. ################################################## # map over polygon_spectral_filtering for dbscan ################################################## # file.names to only run if not already done since it takes a while for all sites dir_temp &lt;- &quot;../data&quot; if(!dir.exists(dir_temp)){dir.create(dir_temp,showWarnings = F)} nmsfx_temp &lt;- &quot;_dbscan_spectral_preds.gpkg&quot; if( !all(file.exists( file.path(dir_temp, paste0(all_stand_boundary$site_data_lab,nmsfx_temp)) )) ){ # map over polygon_spectral_filtering for dbscan dbscan_spectral_preds &lt;- all_stand_boundary$site_data_lab %&gt;% # .[1:2] %&gt;% purrr::set_names() %&gt;% # map_chr returns character bc we&#39;ll return file path purrr::map_chr( function(x) { # polygon_spectral_filtering safe_polygon_spectral_filtering &lt;- purrr::safely(polygon_spectral_filtering) segs_sf &lt;- safe_polygon_spectral_filtering( sf_data = dbscan_structural_preds[[x]] , rgb_rast = rgb_rast[[x]] # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 , spectral_weight = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(spectral_weight) , filter_return = F ) if(is.null(segs_sf$result)){ return(NULL) }else{ segs_sf &lt;- segs_sf$result$segs_sf %&gt;% dplyr::mutate( spectral_weight = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(spectral_weight) ) } # write fpth &lt;- file.path(dir_temp, paste0(x,nmsfx_temp)) sf::st_write( obj = segs_sf , dsn = fpth , append = F , quiet = T ) # return return(fpth) } ) # read files dbscan_spectral_preds &lt;- dbscan_spectral_preds %&gt;% purrr::map( \\(x) sf::st_read(dsn = x, quiet = T) ) }else{ # read already done dbscan_spectral_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) sf::st_read( dsn = file.path(dir_temp, paste0(x,nmsfx_temp)) , quiet = T ) ) } ################################################## # map over polygon_spectral_filtering for watershed ################################################## # file.names to only run if not already done since it takes a while for all sites dir_temp &lt;- &quot;../data&quot; if(!dir.exists(dir_temp)){dir.create(dir_temp,showWarnings = F)} nmsfx_temp &lt;- &quot;_watershed_spectral_preds.gpkg&quot; if( !all(file.exists( file.path(dir_temp, paste0(all_stand_boundary$site_data_lab,nmsfx_temp)) )) ){ # map over polygon_spectral_filtering for watershed watershed_spectral_preds &lt;- all_stand_boundary$site_data_lab %&gt;% # .[3:4] %&gt;% purrr::set_names() %&gt;% # map_chr returns character bc we&#39;ll return file path purrr::map_chr( function(x) { # polygon_spectral_filtering safe_polygon_spectral_filtering &lt;- purrr::safely(polygon_spectral_filtering) segs_sf &lt;- safe_polygon_spectral_filtering( sf_data = watershed_structural_preds[[x]] , rgb_rast = rgb_rast[[x]] # define the band index , red_band_idx = 1 , green_band_idx = 2 , blue_band_idx = 3 , spectral_weight = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(spectral_weight) , filter_return = F ) if(is.null(segs_sf$result)){ return(NULL) }else{ segs_sf &lt;- segs_sf$result$segs_sf %&gt;% dplyr::mutate( spectral_weight = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(spectral_weight) ) } # write fpth &lt;- file.path(dir_temp, paste0(x,nmsfx_temp)) sf::st_write( obj = segs_sf , dsn = fpth , append = F , quiet = T ) # return return(fpth) } ) # read files watershed_spectral_preds &lt;- watershed_spectral_preds %&gt;% purrr::map( \\(x) sf::st_read(dsn = x, quiet = T) ) }else{ # read already done watershed_spectral_preds &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) sf::st_read( dsn = file.path(dir_temp, paste0(x,nmsfx_temp)) , quiet = T ) ) } let’s check out the proportion that were filtered out for each site dplyr::bind_rows( watershed_spectral_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( retained = ifelse(inrange_th_votes&gt;=spectral_weight,&quot;retained&quot;,&quot;removed&quot;) ) %&gt;% dplyr::count(retained) %&gt;% dplyr::mutate( pct = (n/sum(n)) %&gt;% scales::percent(accuracy = 0.1) , n = scales::comma(n,accuracy=1) ) %&gt;% tidyr::pivot_wider(names_from = retained, values_from = -retained) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;watershed&quot; ) ) %&gt;% dplyr::bind_rows() , dbscan_spectral_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( retained = ifelse(inrange_th_votes&gt;=spectral_weight,&quot;retained&quot;,&quot;removed&quot;) ) %&gt;% dplyr::count(retained) %&gt;% dplyr::mutate( pct = (n/sum(n)) %&gt;% scales::percent(accuracy = 0.1) , n = scales::comma(n,accuracy=1) ) %&gt;% tidyr::pivot_wider(names_from = retained, values_from = -retained) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;dbscan&quot; ) ) %&gt;% dplyr::bind_rows() ) %&gt;% dplyr::relocate(site,method) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Spectrally filtered candidate segments by method and study site&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , &quot;# removed&quot;, &quot;# retained&quot; , &quot;% removed&quot;, &quot;% retained&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 7.3: Spectrally filtered candidate segments by method and study site site method # removed # retained % removed % retained ARNF Ponderosa Pine Site dbscan 53 23 69.7% 30.3% watershed 66 26 71.7% 28.3% BHEF Ponderosa Pine Site dbscan 246 24 91.1% 8.9% watershed 294 25 92.2% 7.8% PSINF Mixed Conifer Site dbscan 68 120 36.2% 63.8% watershed 70 123 36.3% 63.7% TRFO-BLM Pinyon-Juniper Site dbscan 48 330 12.7% 87.3% watershed 48 329 12.7% 87.3% we can look at a distribution of the number of spectral thresholds met by the structural candidates for each site and segmentation method dplyr::bind_rows( dbscan_spectral_preds %&gt;% purrr::imap( \\(x,nm) dplyr::tibble(inrange_th_votes = 0:6) %&gt;% dplyr::left_join( x %&gt;% dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(inrange_th_votes) , by = &quot;inrange_th_votes&quot; ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;dbscan&quot; , n = dplyr::coalesce(n,0) ) ) %&gt;% dplyr::bind_rows() , watershed_spectral_preds %&gt;% purrr::imap( \\(x,nm) dplyr::tibble(inrange_th_votes = 0:6) %&gt;% dplyr::left_join( x %&gt;% dplyr::ungroup() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(inrange_th_votes) , by = &quot;inrange_th_votes&quot; ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;watershed&quot; , n = dplyr::coalesce(n,0) ) ) %&gt;% dplyr::bind_rows() ) %&gt;% dplyr::group_by(site,method) %&gt;% dplyr::mutate( pct = n/sum(n) , inrange_th_votes = ordered(inrange_th_votes) , lab = paste0(scales::percent(pct,accuracy=0.1), &quot;\\n(n=&quot;, scales::comma(n,accuracy=1), &quot;)&quot;) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(site = stringr::word(site)) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = inrange_th_votes, y = pct, label = lab, fill = inrange_th_votes) ) + ggplot2::geom_col( width = 0.6 , color = NA, alpha = 0.95 ) + ggplot2::geom_text(color = &quot;black&quot;, size = 3, vjust = -0.2) + # ggplot2::scale_fill_viridis_d(option = &quot;mako&quot;, direction = -1) + ggplot2::scale_fill_brewer(palette = &quot;Purples&quot;, direction = 1) + ggplot2::scale_y_continuous( breaks = seq(0,1,by=0.2) , labels = scales::percent , expand = ggplot2::expansion(mult = c(0,0.2)) ) + ggplot2::facet_grid( rows = dplyr::vars(site) , cols = dplyr::vars(method) , switch = &quot;y&quot; , axes = &quot;all_x&quot; ) + ggplot2::labs( x = &quot;spectral thresholds met&quot;, y = &quot;&quot;, fill = &quot;&quot; , subtitle = &quot;number of spectral thresholds met by the structural candidates&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 9) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() ) now that we know the breakdown, we can remove the candidates which did not meet the spectral_weight setting # filter all candidate piles for only those that meet the spectral_weight setting dbscan_spectral_preds &lt;- dbscan_spectral_preds %&gt;% purrr::map( \\(x) x %&gt;% dplyr::filter(inrange_th_votes&gt;=spectral_weight) ) watershed_spectral_preds &lt;- watershed_spectral_preds %&gt;% purrr::map( \\(x) x %&gt;% dplyr::filter(inrange_th_votes&gt;=spectral_weight) ) let’s summarize the number of final candidate segments that passed the spectral filtering and the area they cover by site dplyr::bind_rows( # watershed watershed_spectral_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% sf::st_drop_geometry() %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(area_m2, volume_m3, max_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , sum = ~sum(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) ) ) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate(method = &quot;watershed&quot;) , # dbscan dbscan_spectral_preds %&gt;% purrr::imap( \\(x,nm) x %&gt;% sf::st_drop_geometry() %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( dplyr::across( c(area_m2, volume_m3, max_height_m) , .fns = list( mean = ~mean(.x,na.rm=T) , sd = ~sd(.x,na.rm=T) , sum = ~sum(.x,na.rm=T) ) ) , n = dplyr::n() ) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) ) ) %&gt;% dplyr::bind_rows() %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) ) %&gt;% dplyr::mutate( dplyr::across( c(tidyselect::ends_with(&quot;_sum&quot;),n) # dplyr::where(is.numeric) , ~scales::comma(.x,accuracy = 1) ) , dplyr::across( dplyr::where(is.numeric) , ~scales::comma(.x,accuracy = .1) ) , area_m2_mean = paste0(area_m2_mean, &quot;&lt;br&gt;(&quot;,area_m2_sd,&quot;)&quot;) , volume_m3_mean = paste0(volume_m3_mean, &quot;&lt;br&gt;(&quot;,volume_m3_sd,&quot;)&quot;) , max_height_m_mean = paste0(max_height_m_mean, &quot;&lt;br&gt;(&quot;,max_height_m_sd,&quot;)&quot;) ) %&gt;% dplyr::select( -tidyselect::ends_with(&quot;_sd&quot;) , -max_height_m_sum ) %&gt;% dplyr::relocate(site,method,n) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Final, spectrally filtered candidate segments by method and study site&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , &quot;# candidates&quot; , &quot;area m&lt;sup&gt;2&lt;/sup&gt;&lt;br&gt;mean (sd)&quot; , &quot;area m&lt;sup&gt;2&lt;/sup&gt;&lt;br&gt;total&quot; , &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&lt;br&gt;mean (sd)&quot; , &quot;volume m&lt;sup&gt;3&lt;/sup&gt;&lt;br&gt;total&quot; , &quot;height m&lt;br&gt;mean (sd)&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 7.4: Final, spectrally filtered candidate segments by method and study site site method # candidates area m2mean (sd) area m2total volume m3mean (sd) volume m3total height mmean (sd) ARNF Ponderosa Pine Site dbscan 23 371.9(133.4) 8,553 1,155.3(608.2) 26,573 7.7(1.4) watershed 26 326.5(152.7) 8,488 1,001.2(640.6) 26,032 7.7(1.3) BHEF Ponderosa Pine Site dbscan 24 180.8(82.6) 4,339 174.9(126.2) 4,198 2.3(0.6) watershed 25 177.4(82.7) 4,434 178.2(124.8) 4,455 2.5(0.9) PSINF Mixed Conifer Site dbscan 120 8.9(8.3) 1,072 8.8(12.6) 1,054 2.2(0.7) watershed 123 9.0(8.5) 1,113 9.0(13.0) 1,111 2.2(0.7) TRFO-BLM Pinyon-Juniper Site dbscan 330 8.9(3.9) 2,935 5.5(3.5) 1,816 1.4(0.7) watershed 329 8.8(3.8) 2,905 5.4(3.3) 1,785 1.4(0.7) 7.3.1 DBSCAN Predictions We’ll quickly plot the structurally-detected and spectrally filtered candidate segments using the DBSCAN method for each study site # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) , pred_piles = dbscan_spectral_preds[[x]] %&gt;% dplyr::filter(is_in_stand) , boundary = stand_boundary[[x]] , title = paste0( &quot;Final DBSCAN: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) ) 7.3.2 Watershed Predictions We’ll quickly plot the structurally-detected and spectrally filtered candidate segments using the Watershed method for each study site # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) , pred_piles = watershed_spectral_preds[[x]] %&gt;% dplyr::filter(is_in_stand) , boundary = stand_boundary[[x]] , title = paste0( &quot;Final Watershed: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) ) "],["preds_detect.html", "Section 8 Detection Accuracy 8.1 Instance Matching 8.2 Detection Accuracy Metrics 8.3 Segmentation Method Accuracy Comparison 8.4 Individual Pile Evaluation", " Section 8 Detection Accuracy To this point we have: Provided a data overview: here and here Processed the UAS point cloud Demonstrated our geometry-based slash pile detection methodology Demonstrated our spectral refinement (i.e. data fusion) methodology Reviewed how we will evaluate our method and Made predictions using our method on four experimental sites In this section, we’ll evaluate the effectiveness of the proposed geometric, rules-based slash pile detection methodology by assessing its detection accuracy performance. We fully reviewed the detection accuracy assessment workflow here, but here is a quick overview: Detection accuracy metrics are calculated by aggregating raw TP (true positive), FP (false positive; commission), and FN (false negative; omission) counts to quantify the method’s ability to find the piles. Aggregation of the instance matching allows us to evaluate omission rate (false negative rate or miss rate), commission rate (false positive rate), precision, recall (detection rate), and the F-score metric. As a reminder, true positive (TP) instances correctly match ground truth instances with a prediction, commission predictions do not match a ground truth instance (false positive; FP), and omissions are ground truth instances for which no predictions match (FN) 8.1 Instance Matching The first step in evaluating the performance of our slash pile detection methodology is to perform instance matching. Instance matching is the process of checking our predictions of slash pile presence (or absence) against the actual pile locations in real life (we use image-annotated pile outlines as ground truth) to determine if the method correctly identifies presence and absence. We use the framework established by Puliti et al. (2023, p. 14) to validate detections based on an Intersection over Union (IoU) threshold. We set this threshold at 45% which is slightly more permissive than the 50% used by Puliti et al. (2023) for tree crowns to accommodate the fact that our target objects are located on the forest floor rather than in the canopy and are therefore subject to higher levels of occlusion from aerial data. we reviewed this process and defined the function ground_truth_prediction_match() here # map over ground_truth_prediction_match for dbscan dbscan_gt_pred_match &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) ground_truth_prediction_match( ground_truth = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% sf::st_transform( sf::st_crs(dbscan_spectral_preds[[x]]) ) %&gt;% dplyr::arrange(desc(image_gt_area_m2)) # this is so the algorithm starts with the largest , gt_id = &quot;pile_id&quot; , predictions = dbscan_spectral_preds[[x]] , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.45 ) , .progress = T ) # map over ground_truth_prediction_match for watershed watershed_gt_pred_match &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(x) ground_truth_prediction_match( ground_truth = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% sf::st_transform( sf::st_crs(watershed_spectral_preds[[x]]) ) %&gt;% dplyr::arrange(desc(image_gt_area_m2)) # this is so the algorithm starts with the largest , gt_id = &quot;pile_id&quot; , predictions = watershed_spectral_preds[[x]] , pred_id = &quot;pred_id&quot; , min_iou_pct = 0.45 ) , .progress = T ) let’s see what the instance matching data looks like # what did we get? dbscan_gt_pred_match[[1]] %&gt;% dplyr::glimpse() ## Rows: 24 ## Columns: 6 ## $ pile_id &lt;int&gt; 7, 8, 4, 6, 15, 13, 17, 11, 10, 9, 19, 18, 2, 5, 12, 1, 14, … ## $ i_area &lt;dbl&gt; 536.5570, 539.9044, 492.3933, 449.3572, 422.1786, 425.3035, … ## $ u_area &lt;dbl&gt; 593.2048, 579.0174, 519.5787, 483.3788, 459.7354, 454.9364, … ## $ iou &lt;dbl&gt; 0.9045055, 0.9324494, 0.9476780, 0.9296171, 0.9183078, 0.934… ## $ pred_id &lt;dbl&gt; 24249, 23782, 12862, 23411, 15434, 14529, 7687, 16382, 22005… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive, true positive, … let’s quickly look at the distribution of IoU for the TP matches # palette pal_match_grp = c( &quot;omission&quot;=viridis::cividis(3)[1] , &quot;commission&quot;= viridis::cividis(3)[2] , &quot;true positive&quot;=viridis::cividis(3)[3] ) # plot iou_dta_temp &lt;- dplyr::bind_rows( dbscan_gt_pred_match %&gt;% purrr::imap( \\(x,nm) x %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;dbscan&quot; ) ) %&gt;% dplyr::bind_rows() , watershed_gt_pred_match %&gt;% purrr::imap( \\(x,nm) x %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate( site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==nm) %&gt;% dplyr::pull(site) , method = &quot;watershed&quot; ) ) %&gt;% dplyr::bind_rows() ) # plot it iou_dta_temp %&gt;% dplyr::mutate( site = stringr::word(site) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% # dplyr::glimpse() ggplot2::ggplot(mapping = ggplot2::aes(x = iou)) + ggplot2::geom_vline(xintercept = 0.45, color = &quot;gray&quot;, linetype = &quot;dashed&quot;, lwd = 1.5) + ggplot2::geom_violin( mapping = ggplot2::aes(y = 0, color = match_grp, fill = match_grp) , alpha = 0.8 ) + ggplot2::geom_boxplot(width = 0.1, fill = NA, outliers = F) + ggplot2::scale_color_manual(values=pal_match_grp) + ggplot2::scale_fill_manual(values=pal_match_grp) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::scale_x_continuous(limits = c(0,1), labels=scales::percent, breaks = scales::breaks_extended(n=6)) + ggplot2::facet_grid( rows = dplyr::vars(site) , cols = dplyr::vars(method) # , scales = &quot;free_y&quot; , switch = &quot;y&quot; , axes = &quot;all_x&quot; ) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;IoU of correct precitions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 9) , axis.text.y = ggplot2::element_blank() , axis.ticks.y = ggplot2::element_blank() ) the majority of correct predictions had high overlap with the actual, ground truth piles with only a few piles at one site approaching the 45% minimum threshold to determine a match. let’s check out the summary stats iou_dta_temp %&gt;% dplyr::group_by(site,method) %&gt;% dplyr::summarise( dplyr::across( c(iou) , .fns = list( mean = ~mean(.x,na.rm=T) , q50 = ~quantile(.x,na.rm=T,probs=0.5) , sd = ~sd(.x,na.rm=T) # , q10 = ~quantile(.x,na.rm=T,probs=0.1) # , q90 = ~quantile(.x,na.rm=T,probs=0.9) # , min = ~min(.x,na.rm=T) # , max = ~max(.x,na.rm=T) , range = ~paste0( scales::percent(min(.x,na.rm=T), accuracy = 0.1) ,&quot;-&quot; , scales::percent(max(.x,na.rm=T), accuracy = 0.1) ) ) ) , n = dplyr::n() %&gt;% scales::comma(accuracy = 1) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( dplyr::across( dplyr::where(is.numeric) , ~scales::percent(.x,accuracy=0.1) ) ) %&gt;% dplyr::relocate(site,method,n) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;IoU of correct predictions (TP)&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , &quot;TP predictions&quot; , &quot;IoU mean&quot; , &quot;IoU median&quot; , &quot;IoU sd&quot; , &quot;IoU range&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 8.1: IoU of correct predictions (TP) site method TP predictions IoU mean IoU median IoU sd IoU range ARNF Ponderosa Pine Site dbscan 18 92.8% 93.2% 1.8% 88.4%-95.1% watershed 18 92.8% 93.2% 1.8% 88.4%-95.1% BHEF Ponderosa Pine Site dbscan 24 79.1% 83.3% 12.3% 50.5%-93.7% watershed 24 79.1% 83.3% 12.2% 50.5%-93.5% PSINF Mixed Conifer Site dbscan 115 82.8% 84.7% 6.8% 57.1%-92.5% watershed 115 82.8% 84.6% 6.8% 57.1%-92.5% TRFO-BLM Pinyon-Juniper Site dbscan 245 81.1% 82.9% 8.4% 49.2%-93.4% watershed 245 81.1% 82.9% 8.4% 49.2%-93.4% let’s look at the results spatially noting that just because a prediction overlaps with a ground truth pile does not mean that it meets the IoU threshold for determining a positive match. in these cases where the IoU was insufficient, a commission (FP) will overlap with an omission (FN). plt_fn_temp &lt;- function(x, method) { if(tolower(method) == &quot;dbscan&quot;){ preds &lt;- dbscan_spectral_preds gt_pred_match &lt;- dbscan_gt_pred_match }else if(tolower(method) == &quot;watershed&quot;){ preds &lt;- watershed_spectral_preds gt_pred_match &lt;- watershed_gt_pred_match }else{return(NULL)} # plot it ggplot2::ggplot() + ggplot2::geom_sf( data = stand_boundary[[x]] %&gt;% sf::st_transform(sf::st_crs(preds[[x]])) , color = &quot;black&quot;, fill = NA ) + ggplot2::geom_sf( data = slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( gt_pred_match[[x]] %&gt;% dplyr::select(pile_id,match_grp) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(sf::st_crs(preds[[x]])) , mapping = ggplot2::aes(fill = match_grp) , color = NA ,alpha=0.7 , show.legend = T ) + ggplot2::geom_sf( data = preds[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::left_join( gt_pred_match[[x]] %&gt;% dplyr::select(pred_id,match_grp) , by = &quot;pred_id&quot; ) , mapping = ggplot2::aes(fill = match_grp, color = match_grp) , alpha = 0 , lwd = 0.5 , show.legend = T ) + ggplot2::scale_fill_manual(values = pal_match_grp, drop = F, name = &quot;&quot;) + ggplot2::scale_color_manual(values = pal_match_grp, drop = F, name = &quot;&quot;) + ggplot2::labs( subtitle = paste0( method , &quot; predictions: &quot; , slash_piles_polys[[x]] %&gt;% dplyr::slice(1) %&gt;% dplyr::pull(site) ) ) + ggplot2::theme_void() + ggplot2::theme( plot.subtitle = ggplot2::element_text( size = 7, hjust = 0.5 , vjust = 1 , margin = margin(t = 0, r = 0, b = -2, l = 0, unit = &quot;pt&quot;) ) ) + ggplot2::guides( fill = ggplot2::guide_legend( override.aes = list( color = c(NA,pal_match_grp[&quot;commission&quot;],NA) , fill = c(pal_match_grp[&quot;omission&quot;],NA,pal_match_grp[&quot;true positive&quot;]) ) ) , color = &quot;none&quot; ) } # do it dbscan_plt_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(xx) plt_fn_temp(xx,method = &quot;DBSCAN&quot;) ) # dbscan_plt_temp[[1]] watershed_plt_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( \\(xx) plt_fn_temp(xx,method = &quot;Watershed&quot;) ) # watershed_plt_temp[[1]] combine plots with patchwork # c(dbscan_plt_temp, watershed_plt_temp) %&gt;% # (\\(x) x[order(names(x))])() %&gt;% # names() patchwork::wrap_plots( c(dbscan_plt_temp, watershed_plt_temp) %&gt;% (\\(x) x[order(names(x))])() , ncol = 2, guides = &quot;collect&quot; , byrow = T ) &amp; ggplot2::theme(legend.position = &quot;bottom&quot;) note the color legend…we like to see a lot of yellow :D 8.2 Detection Accuracy Metrics now we aggregate the pile-level data (TP, FP, FN) into a single record for each study site and segmentation method combination. Detection performance metrics include F-score, precision, and recall. 8.2.1 Aggregate Instance Match Results because our agg_ground_truth_match() function that we defined earlier includes capabilities to compute quantification metrics as well (e.g. height MAPE, RMSE, etc.), we’ll add the pile sizing metrics to our instance match data so that agg_ground_truth_match() recognizes them. “diff_” columns are calculated as the predicted value minus the actual value (e.g. pred_diameter_m - gt_diameter_m) “pct_diff_” columns are calculated as the actual value minus the predicted value divided by the actual value (e.g. (gt_diameter_m - pred_diameter_m)/gt_diameter_m) # add prediction and validation measurements for dbscan dbscan_gt_pred_match &lt;- dbscan_gt_pred_match %&gt;% purrr::imap( \\(x,nm) # because psinf has field data but no others do if(nm==&quot;psinf&quot;){ x %&gt;% # join on gt data dplyr::left_join( slash_piles_polys[[nm]] %&gt;% dplyr::rename(field_volume_m3=field_gt_volume_m3) %&gt;% dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2, field_height_m, field_diameter_m, field_volume_m3) %&gt;% dplyr::rename_with(~ stringr::str_remove(.x, &quot;^image_&quot;)) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( dbscan_spectral_preds[[nm]] %&gt;% dplyr::select( pred_id , diameter_m , area_m2 , volume_m3 , max_height_m ) %&gt;% dplyr::rename(height_m=max_height_m) %&gt;% dplyr::rename_with( ~ paste0(&quot;pred_&quot;, .x, recycle0 = TRUE) , .cols = -c(pred_id) ) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( # area_m2 diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # field diameter_m , diff_field_diameter_m = pred_diameter_m-field_diameter_m , pct_diff_field_diameter_m = (field_diameter_m-pred_diameter_m)/field_diameter_m # field height_m , diff_field_height_m = pred_height_m-field_height_m , pct_diff_field_height_m = (field_height_m-pred_height_m)/field_height_m # # field volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_volume_m3 # , pct_diff_field_volume_m3 = (field_volume_m3-pred_volume_m3)/field_volume_m3 ) }else{ x %&gt;% # join on gt data dplyr::left_join( slash_piles_polys[[nm]] %&gt;% dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2) %&gt;% dplyr::rename_with(~ stringr::str_remove(.x, &quot;^image_&quot;)) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( dbscan_spectral_preds[[nm]] %&gt;% dplyr::select( pred_id , diameter_m , area_m2 , volume_m3 , max_height_m ) %&gt;% dplyr::rename(height_m=max_height_m) %&gt;% dplyr::rename_with( ~ paste0(&quot;pred_&quot;, .x, recycle0 = TRUE) , .cols = -c(pred_id) ) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( # area_m2 diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m ) } ) # dbscan_gt_pred_match %&gt;% dplyr::glimpse() # add prediction and validation measurements for watershed watershed_gt_pred_match &lt;- watershed_gt_pred_match %&gt;% purrr::imap( \\(x,nm) # because psinf has field data but no others do if(nm==&quot;psinf&quot;){ x %&gt;% # join on gt data dplyr::left_join( slash_piles_polys[[nm]] %&gt;% dplyr::rename(field_volume_m3=field_gt_volume_m3) %&gt;% dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2, field_height_m, field_diameter_m, field_volume_m3) %&gt;% dplyr::rename_with(~ stringr::str_remove(.x, &quot;^image_&quot;)) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( watershed_spectral_preds[[nm]] %&gt;% dplyr::select( pred_id , diameter_m , area_m2 , volume_m3 , max_height_m ) %&gt;% dplyr::rename(height_m=max_height_m) %&gt;% dplyr::rename_with( ~ paste0(&quot;pred_&quot;, .x, recycle0 = TRUE) , .cols = -c(pred_id) ) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( # area_m2 diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m # field diameter_m , diff_field_diameter_m = pred_diameter_m-field_diameter_m , pct_diff_field_diameter_m = (field_diameter_m-pred_diameter_m)/field_diameter_m # field height_m , diff_field_height_m = pred_height_m-field_height_m , pct_diff_field_height_m = (field_height_m-pred_height_m)/field_height_m # # field volume_m3 # , diff_field_volume_m3 = pred_volume_m3-field_volume_m3 # , pct_diff_field_volume_m3 = (field_volume_m3-pred_volume_m3)/field_volume_m3 ) }else{ x %&gt;% # join on gt data dplyr::left_join( slash_piles_polys[[nm]] %&gt;% dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2) %&gt;% dplyr::rename_with(~ stringr::str_remove(.x, &quot;^image_&quot;)) %&gt;% sf::st_drop_geometry() , by = &quot;pile_id&quot; ) %&gt;% # join on pred area data dplyr::left_join( watershed_spectral_preds[[nm]] %&gt;% dplyr::select( pred_id , diameter_m , area_m2 , volume_m3 , max_height_m ) %&gt;% dplyr::rename(height_m=max_height_m) %&gt;% dplyr::rename_with( ~ paste0(&quot;pred_&quot;, .x, recycle0 = TRUE) , .cols = -c(pred_id) ) %&gt;% sf::st_drop_geometry() , by = &quot;pred_id&quot; ) %&gt;% # calculate difference columns dplyr::mutate( # area_m2 diff_area_m2 = pred_area_m2-gt_area_m2 , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2 # diameter_m , diff_diameter_m = pred_diameter_m-gt_diameter_m , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m ) } ) # watershed_gt_pred_match %&gt;% dplyr::glimpse() # agg_ground_truth_match(watershed_gt_pred_match[[1]]) %&gt;% dplyr::glimpse() apply our agg_ground_truth_match() function agg_ground_truth_match_ans &lt;- dplyr::bind_rows( dbscan_gt_pred_match %&gt;% purrr::map_dfr(agg_ground_truth_match, .id = &quot;site_data_lab&quot;) %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) %&gt;% dplyr::bind_rows() , watershed_gt_pred_match %&gt;% purrr::map_dfr(agg_ground_truth_match, .id = &quot;site_data_lab&quot;) %&gt;% dplyr::mutate(method = &quot;watershed&quot;) %&gt;% dplyr::bind_rows() ) %&gt;% dplyr::inner_join( all_stand_boundary %&gt;% dplyr::select(site_data_lab, site) %&gt;% sf::st_drop_geometry() , by = &quot;site_data_lab&quot; ) %&gt;% # make factor dplyr::mutate( site = ordered(site) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) what did we get? agg_ground_truth_match_ans %&gt;% dplyr::glimpse() ## Rows: 8 ## Columns: 23 ## $ site_data_lab &lt;chr&gt; &quot;arnf&quot;, &quot;bhef&quot;, &quot;psinf&quot;, &quot;pj&quot;, &quot;arnf&quot;, … ## $ tp_n &lt;dbl&gt; 18, 24, 115, 246, 18, 24, 115, 246 ## $ fp_n &lt;dbl&gt; 5, 0, 5, 85, 8, 1, 8, 84 ## $ fn_n &lt;dbl&gt; 1, 2, 6, 31, 1, 2, 6, 31 ## $ omission_rate &lt;dbl&gt; 0.05263158, 0.07692308, 0.04958678, 0.1… ## $ commission_rate &lt;dbl&gt; 0.21739130, 0.00000000, 0.04166667, 0.2… ## $ precision &lt;dbl&gt; 0.7826087, 1.0000000, 0.9583333, 0.7432… ## $ recall &lt;dbl&gt; 0.9473684, 0.9230769, 0.9504132, 0.8880… ## $ f_score &lt;dbl&gt; 0.8571429, 0.9600000, 0.9543568, 0.8092… ## $ diff_area_m2_rmse &lt;dbl&gt; 16.594443, 48.389761, 2.050426, 1.74561… ## $ diff_diameter_m_rmse &lt;dbl&gt; 0.6451003, 2.4203931, 0.3832957, 0.3879… ## $ diff_area_m2_mean &lt;dbl&gt; 12.7587200, -24.8476306, -0.7831500, -0… ## $ diff_diameter_m_mean &lt;dbl&gt; -0.4015052, -1.3737463, -0.2049347, -0.… ## $ pct_diff_area_m2_mape &lt;dbl&gt; 0.03548836, 0.14870735, 0.10290712, 0.1… ## $ pct_diff_diameter_m_mape &lt;dbl&gt; 0.01779425, 0.08146903, 0.06780040, 0.0… ## $ diff_field_diameter_m_rmse &lt;dbl&gt; NA, NA, 0.4664407, NA, NA, NA, 0.471317… ## $ diff_field_height_m_rmse &lt;dbl&gt; NA, NA, 0.6679947, NA, NA, NA, 0.667994… ## $ diff_field_diameter_m_mean &lt;dbl&gt; NA, NA, 0.1892385, NA, NA, NA, 0.192082… ## $ diff_field_height_m_mean &lt;dbl&gt; NA, NA, -0.06963052, NA, NA, NA, -0.069… ## $ pct_diff_field_diameter_m_mape &lt;dbl&gt; NA, NA, 0.1000518, NA, NA, NA, 0.101088… ## $ pct_diff_field_height_m_mape &lt;dbl&gt; NA, NA, 0.1916669, NA, NA, NA, 0.191666… ## $ method &lt;ord&gt; DBSCAN, DBSCAN, DBSCAN, DBSCAN, Watersh… ## $ site &lt;ord&gt; ARNF Ponderosa Pine Site, BHEF Ponderos… 8.2.2 Detection Accuracy Results let’s make a nice table of the detection accuracy metrics by study site and segmentation method agg_ground_truth_match_ans %&gt;% dplyr::select( site, method , tidyselect::ends_with(&quot;_n&quot;) , precision, recall, f_score ) %&gt;% dplyr::mutate( dplyr::across( tidyselect::ends_with(&quot;_n&quot;) , ~scales::comma(.x,accuracy=1) ) , dplyr::across( dplyr::where(is.numeric) , ~scales::percent(.x,accuracy=0.1) ) ) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Detection Accuracy&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , &quot;TP predictions&quot;, &quot;FP predictions&quot;, &quot;FN predictions&quot; , &quot;Precision&quot;, &quot;Recall&quot;, &quot;F-score&quot; ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 8.2: Detection Accuracy site method TP predictions FP predictions FN predictions Precision Recall F-score ARNF Ponderosa Pine Site DBSCAN 18 5 1 78.3% 94.7% 85.7% Watershed 18 8 1 69.2% 94.7% 80.0% BHEF Ponderosa Pine Site DBSCAN 24 0 2 100.0% 92.3% 96.0% Watershed 24 1 2 96.0% 92.3% 94.1% PSINF Mixed Conifer Site DBSCAN 115 5 6 95.8% 95.0% 95.4% Watershed 115 8 6 93.5% 95.0% 94.3% TRFO-BLM Pinyon-Juniper Site DBSCAN 246 85 31 74.3% 88.8% 80.9% Watershed 246 84 31 74.5% 88.8% 81.1% 8.3 Segmentation Method Accuracy Comparison Our slash pile detection methodology implements and tests two different segmentation approaches to identify candidate slash piles from the CHM. We fully reviewed these two approaches here but we’ll present a quick review. First, the watershed segmentation method is a raster-based technique that treats the inverted height surface as a topographic landscape where local maxima serve as initial seeds to define the boundaries of individual basins. Second, DBSCAN segmentation is traditionally a point-based clustering method that we adapted for raster data by treating the cell centroids as points. To maintain consistency across varying datasets and limit the amount of effort required by users, we developed a dynamic parameterization logic that automatically calibrates both algorithms by translating user-defined physical dimensions into data-specific values. This dynamic parameterization uses the target pile size and input data resolution to calculate geometry-based search windows and density thresholds to ensure that the algorithm settings are proportional to the target object regardless of changes in input data resolution. let’s make some plots to visualize this information agg_ground_truth_match_ans %&gt;% dplyr::select( site, method , precision, recall, f_score ) %&gt;% tidyr::pivot_longer( cols = c(precision,recall,f_score) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( metric = metric %&gt;% forcats::fct_relevel(&quot;f_score&quot;, &quot;recall&quot;, &quot;precision&quot;) %&gt;% forcats::fct_recode(&quot;F-score&quot; = &quot;f_score&quot;, &quot;Recall&quot; = &quot;recall&quot;, &quot;Precision&quot; = &quot;precision&quot;) ) %&gt;% dplyr::mutate( dplyr::across( dplyr::where(is.numeric) , list(lab = ~scales::percent(.x,accuracy=0.1)) ) ) %&gt;% dplyr::mutate(site = stringr::word(site)) %&gt;% # dplyr::pull(metric) %&gt;% levels() ggplot2::ggplot( mapping = ggplot2::aes( y = value, x = method , color = metric, group = metric ) ) + ggplot2::geom_line(alpha = 0.8, lwd = 2) + # lhs labs ggrepel::geom_text_repel( data = function(x){dplyr::filter(x,method == &quot;DBSCAN&quot;)} , mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) # , color = &quot;black&quot; , size = 3 # , min.segment.length = 0 , nudge_x = -0.1 , direction = &quot;y&quot; , hjust = 1 ) + # rhs labs ggrepel::geom_text_repel( data = function(x){dplyr::filter(x,method == &quot;Watershed&quot;)} , mapping = ggplot2::aes(label = value_lab, fontface = &quot;bold&quot;) # , color = &quot;black&quot; , size = 3 # , min.segment.length = 0 , nudge_x = 0.1 , direction = &quot;y&quot; , hjust = 0 ) + ggplot2::geom_point(size = 3) + ggplot2::scale_color_manual(values=pal_eval_metric2) + ggplot2::scale_y_continuous( limits = c(0,1) , labels=scales::percent , breaks = scales::breaks_extended(n=6) , expand = ggplot2::expansion(mult = c(0,0.03)) ) + ggplot2::facet_grid( cols = dplyr::vars(site) , axes = &quot;all&quot; ) + ggplot2::labs( color=&quot;&quot;,x=&quot;Segmentation Method&quot;,y=&quot;&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = ggplot2::element_text(size = 10) ) + ggplot2::guides( color = ggplot2::guide_legend(override.aes = list(shape = 15, linetype = 0, size = 6, alpha = 1)) ) recall never changes, the changes in F-score are entirely due to changes in precision 8.3.1 Paired T-Test To compare the detection performance of the two algorithms across our set of four study sites, we can quickly use a paired t-test to check if the average of the differences in F-score between the two methods is significantly different from zero. If the p-value is less than 0.05, you can say the difference is statistically significant. However, with only four sites this test may not be robust enough to detect differences in detection accuracy across the methods unless one method is a lot better… # get scores for each method since t.test needs the sites to be ORDERED the same for proper &quot;paired&quot; comparison dbscan_temp &lt;- agg_ground_truth_match_ans %&gt;% dplyr::arrange(site) %&gt;% dplyr::filter(tolower(method) == &quot;dbscan&quot;) %&gt;% dplyr::pull(f_score) watershed_temp &lt;- agg_ground_truth_match_ans %&gt;% dplyr::arrange(site) %&gt;% dplyr::filter(tolower(method) == &quot;watershed&quot;) %&gt;% dplyr::pull(f_score) # t.test ttest_temp &lt;- t.test(dbscan_temp, watershed_temp, paired = T) let’s see what we got ttest_temp ## ## Paired t-test ## ## data: dbscan_temp and watershed_temp ## t = 1.7185, df = 3, p-value = 0.1842 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -0.01839271 0.06157628 ## sample estimates: ## mean difference ## 0.02159179 the t.test() computed the mean difference (MD) between the DBSCAN and Watershed F-score to determine if the difference is statistically significant (i.e. significantly different from zero). the mean difference (MD) is 2.16% (DBSCAN F-Score minus Watershed F-Score). the p-value of 0.1842 is greater than 0.05, meaning we fail to reject the null hypothesis that the true mean difference is zero. this implies that neither the DBSCAN nor the Watershed method was statistically significantly better (or worse) than the other segmentation method at correctly identifying the location of actual slash piles while minimizing incorrect predictions at locations where no actual pile was present. 8.3.2 Bayesian Approach The paired t-test above failed to detect a difference in detection accuracy (F-score) by segmentation method (DBSCAN vs Watershed). With only four sites the paired t-test may not be robust enough to detect differences in detection accuracy across the methods. An alternative is a quick Bayesian model which may provide a more robust alternative to the paired t-test by estimating the full probability distribution of the difference between methods rather than relying on a single p-value. While a paired t-test simply evaluates the average difference within sites, a Bayesian model can account for the nested structure of the data by allowing the intercept to vary by study site ((1|site) in the model) while keeping the slope constant across locations (f_score ~ method in the model). The slope of the model represents the effect of the segmentation method. This approach allows the model to adjust for the unique baseline difficulty of pile detection at each study site and isolates the detection accuracy change caused by using a different segmentation method. Since F-score is bound between zero and one, we use a Beta regression family to ensure predictions are not made outside of these bounds. # brms::brm fscore_mod_method_temp &lt;- brms::brm( f_score ~ method + (1|site) , data = agg_ground_truth_match_ans # family , family = brms::Beta(link = &quot;logit&quot;) # mcmc , iter = 6000, warmup = 3000 , chains = 4 , cores = lasR::half_cores() , file = paste0(&quot;../data/&quot;, &quot;fscore_mod_method&quot;) ) # look at results # plot(fscore_mod_method_temp) quickly look at the model estimates of the effect of segmentation method brms::fixef(fscore_mod_method_temp) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.0595705 0.5967389 0.7668670 3.1651931 ## method.L -0.1489126 0.2003737 -0.5544614 0.2675816 # stats::coef(fscore_mod_method_temp) plot the posterior predictive distributions of the conditional mean F-score by segmentation method with the 95% highest posterior density interval (HDI) # get posterior draws draws_temp &lt;- agg_ground_truth_match_ans %&gt;% dplyr::distinct(method) %&gt;% # re_formula = NA gives population average (average across site) tidybayes::add_epred_draws(fscore_mod_method_temp, re_formula = NA) %&gt;% dplyr::mutate(value = .epred) %&gt;% dplyr::ungroup() # plot draws_temp %&gt;% ggplot( mapping = aes( x = value , y = method , fill = method ) ) + tidybayes::stat_halfeye( point_interval = tidybayes::median_hdci, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + harrypotter::scale_fill_hp_d(option = &quot;dracomalfoy&quot;, drop = F) + ggplot2::scale_x_continuous(limits = c(0,1), labels=scales::percent, breaks = scales::breaks_extended(n=6)) + ggplot2::labs( subtitle = &quot;posterior distribution of F-score by segmentation method\\nand the 95% highest posterior density interval (HDI)&quot; , x = &quot;F-score&quot;, y = &quot;&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) summary table of the posterior distribution and 95% HDI using tidybayes::median_hdci() to avoid potential for returning multiple rows by group if our data is grouped. See the documentation for the ggdist package which notes that “If the distribution is multimodal, hdi may return multiple intervals for each probability level (these will be spread over rows).” draws_temp %&gt;% dplyr::group_by(method) %&gt;% tidybayes::median_hdci(value) %&gt;% dplyr::select(-c(.point,.interval, .width)) %&gt;% dplyr::mutate( dplyr::across( dplyr::where(is.numeric) , ~scales::percent(.x,accuracy=0.1) ) ) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;F-score&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;method&quot; , &quot;F-score&lt;br&gt;median&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 8.3: F-score95% HDI of the posterior predictive distribution method F-scoremedian HDI low HDI high DBSCAN 90.0% 74.1% 97.4% Watershed 87.9% 70.4% 97.8% we can also make pairwise comparisons using the posterior draws with tidybayes::compare_levels() to determine the difference in F-score between the two methods, but now, instead of one mean difference value as in the paired t-test, we get a distribution of the difference which provides much more detailed insight to the difference in detection accuracy between the two segmentation methods comp_temp &lt;- draws_temp %&gt;% tidybayes::compare_levels( value , by = method # make the comparison the same as t.test: dbscan-watershed , comparison = list(c(&quot;DBSCAN&quot;,&quot;Watershed&quot;)) ) # dplyr::glimpse(comp_temp) med_comp_temp &lt;- tidybayes::median_hdci(comp_temp$value) mean_comp_temp &lt;- tidybayes::mean_hdci(comp_temp$value) # plot comp_temp %&gt;% ggplot2::ggplot(aes(x = value, y = 0)) + ggplot2::geom_vline( xintercept = 0 # , linetype = &quot;dashed&quot; , color = &quot;black&quot; , lwd = 1.5 ) + tidybayes::stat_halfeye( point_interval = tidybayes::median_hdci, .width = .95 , fill = &quot;navy&quot;, alpha = 0.8 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + ggplot2::annotate( &quot;text&quot; , x = (med_comp_temp %&gt;% dplyr::select(y,ymin,ymax) %&gt;% base::unlist(use.names = F)) , y = -0.01 , label = ( med_comp_temp %&gt;% dplyr::select(y,ymin,ymax) %&gt;% base::unlist(use.names = F) %&gt;% scales::percent(accuracy = 0.1) ) ) + ggplot2::scale_y_continuous(breaks=NULL) + ggplot2::scale_x_continuous(labels=scales::percent, breaks = scales::breaks_extended(n=8), expand = ggplot2::expansion(mult = 0.05)) + ggplot2::labs( subtitle = &quot;difference in F-score between segmentation methods&quot; , x = &quot;difference in F-score&quot; , y = &quot;difference (DBSCAN - Watershed)&quot; ) + ggplot2::theme_light() + ggplot2::theme( axis.title.y = ggplot2::element_text(angle = 0, vjust = 0.5) ) # scales::percent(mean_comp_temp$y,accuracy=0.1) # scales::percent(ttest_temp$estimate, accuracy = 0.1) the 95% HDI shown as the gray line below the posterior distribution summarizes the posterior draws to represent a density interval with a value of central tendency. We plot the median (scales::percent(med_comp_temp$y,accuracy=0.1)) as the value of central tendency of the difference in F-score between the two methods but we could also determine the mean difference which we calculated above using tidybayes::mean_hdci(). Our Bayesian approach estimates the mean difference in F-score between the two methods as scales::percent(mean_comp_temp$y,accuracy=0.1) which we can directly compare to the mean difference tested using the paired t-test above of scales::percent(ttest_temp$estimate, accuracy = 0.1). table the 95% HDI of the difference in F-score between the two methods med_comp_temp %&gt;% dplyr::mutate( dplyr::across( dplyr::where(is.numeric) , ~scales::percent(.x,accuracy=0.1) ) ) %&gt;% dplyr::select(tidyselect::starts_with(&quot;y&quot;)) %&gt;% dplyr::mutate(d = &quot;difference (DBSCAN - Watershed)&quot;) %&gt;% dplyr::relocate(d) %&gt;% kableExtra::kbl( caption = &quot;difference in F-score between the two methods&lt;br&gt;95% HDI of the posterior predictive distribution&quot; , col.names = c( &quot;&quot; , &quot;difference F-score&lt;br&gt;median&quot; , &quot;HDI low&quot;, &quot;HDI high&quot; ) , escape = F ) %&gt;% kableExtra::kable_styling() Table 8.4: difference in F-score between the two methods95% HDI of the posterior predictive distribution difference F-scoremedian HDI low HDI high difference (DBSCAN - Watershed) 1.9% -4.0% 9.8% finally, we can use the posterior draws of the difference in F-score (calculated with tidybayes::compare_levels()) to determine the probability that one method is better than the other comp_temp &lt;- comp_temp %&gt;% dplyr::mutate( diff_gt_0 = as.numeric(value&gt;0) ) # simply calculate the proportion of posterior draws where the difference is greater than zero mean(comp_temp$diff_gt_0) %&gt;% scales::percent(accuracy = 0.1) ## [1] &quot;80.7%&quot; There is a scales::percent(mean(comp_temp$diff_gt_0),accuracy = 0.1) probability that the DBSCAN method results in better slash pile detection accuracy (i.e. higher F-score) than the Watershed method 8.4 Individual Pile Evaluation let’s visually inspect the TP, FP, and FN predictions to see if we can get some insight into why actual piles were missed (omissions) or correctly predicted (TP) and why the method may have made incorrect predictions (commissions) p_fn_temp &lt;- function(row_n = 1, site, method = &quot;dbscan&quot;, mtchgrp = &quot;true positive&quot;) { if(tolower(method) == &quot;dbscan&quot;){ w_dta &lt;- dbscan_gt_pred_match[[site]] %&gt;% dplyr::filter(match_grp == mtchgrp) p_dta &lt;- dbscan_spectral_preds[[site]] }else{ w_dta &lt;- watershed_gt_pred_match[[site]] %&gt;% dplyr::filter(match_grp == mtchgrp) p_dta &lt;- watershed_spectral_preds[[site]] } # get area of largest with buffer so all plots are same size if(site %in% c(&quot;bhef&quot;)){ b &lt;- 8.5 }else if(site %in% c(&quot;arnf&quot;)){ b &lt;- 6 }else{ b &lt;- 4 } if( mtchgrp %in% c(&quot;true positive&quot;, &quot;omission&quot;) ){ area_temp &lt;- slash_piles_polys[[site]] %&gt;% dplyr::inner_join( w_dta %&gt;% dplyr::slice_max(order_by = gt_area_m2, n = 1) , by = &quot;pile_id&quot; ) %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) %&gt;% sf::st_buffer(b) %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% ceiling() }else{ area_temp &lt;- p_dta %&gt;% dplyr::inner_join( w_dta %&gt;% dplyr::slice_max(order_by = pred_area_m2, n = 1) , by = &quot;pred_id&quot; ) %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) %&gt;% sf::st_buffer(b) %&gt;% sf::st_area() %&gt;% as.numeric() %&gt;% ceiling() } # tp tp &lt;- w_dta %&gt;% dplyr::slice(row_n) # ortho area if(mtchgrp %in% c(&quot;true positive&quot;)){ # gt pile gt_pile &lt;- slash_piles_polys[[site]] %&gt;% dplyr::filter(pile_id == tp$pile_id) # pred pile pred_pile &lt;- p_dta %&gt;% dplyr::filter(pred_id == tp$pred_id) ortho_st &lt;- sf::st_union( gt_pile %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) , pred_pile %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) ) %&gt;% sf::st_centroid() %&gt;% sf::st_buffer( sqrt(area_temp/4) ## numerator = desired plot size in m2 , endCapStyle = &quot;SQUARE&quot; ) %&gt;% dplyr::mutate(dummy=1) }else if( mtchgrp %in% c(&quot;omission&quot;) ){ # gt pile gt_pile &lt;- slash_piles_polys[[site]] %&gt;% dplyr::filter(pile_id == tp$pile_id) ortho_st &lt;- gt_pile %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) %&gt;% sf::st_centroid() %&gt;% sf::st_buffer( sqrt(area_temp/4) ## numerator = desired plot size in m2 , endCapStyle = &quot;SQUARE&quot; ) %&gt;% dplyr::mutate(dummy=1) }else if( mtchgrp %in% c(&quot;commission&quot;) ){ # pred pile pred_pile &lt;- p_dta %&gt;% dplyr::filter(pred_id == tp$pred_id) ortho_st &lt;- pred_pile %&gt;% sf::st_transform(crs=terra::crs(rgb_rast[[site]])) %&gt;% sf::st_centroid() %&gt;% sf::st_buffer( sqrt(area_temp/4) ## numerator = desired plot size in m2 , endCapStyle = &quot;SQUARE&quot; ) %&gt;% dplyr::mutate(dummy=1) } # get plt rp &lt;- ortho_plt_fn( rgb_rast = rgb_rast[[site]] , stand = ortho_st , add_stand = F , buffer = 0 ) # #### add chm? # if(addchm){ # # get max ht # maxh &lt;- all_stand_boundary %&gt;% # dplyr::filter(site_data_lab == site) %&gt;% # dplyr::slice(1) %&gt;% # dplyr::pull(max_ht_m) # # ff &lt;- tempfile(fileext = &quot;.tif&quot;) # # crop, slice rast # ##### ???????????????????????? this kills your computer every time :\\ # crp_chm_rast_temp &lt;- chm_rast[[site]] %&gt;% # terra::crop( # ortho_st %&gt;% # dplyr::ungroup() %&gt;% # sf::st_union() %&gt;% # sf::st_bbox() %&gt;% # sf::st_as_sfc() %&gt;% # sf::st_transform(terra::crs(chm_rast[[site]])) %&gt;% # terra::vect() # , mask = T # # , filename = ff # ) # crp_chm_rast_temp &lt;- # # slice # terra::clamp( # crp_chm_rast_temp # , upper = maxh # , lower = 0 # , values = F # ) # rp &lt;- rp + # ggnewscale::new_scale_fill() + # ggplot2::geom_tile( # data = crp_chm_rast_temp %&gt;% # terra::as.data.frame(xy=T) %&gt;% # dplyr::rename(f=3) # , mapping = ggplot2::aes(x=x,y=y,fill=f) # , alpha = 0.5 # , inherit.aes = F # ) + # ggplot2::scale_fill_viridis_c( # option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot; # , limits = c(0,ceiling(maxh)) # ) # } #### add piles if(mtchgrp %in% c(&quot;true positive&quot;, &quot;omission&quot;)){ rp &lt;- rp + ggplot2::geom_sf(data = gt_pile, fill = NA, color = &quot;cyan&quot;, lwd = 0.6) } if(mtchgrp %in% c(&quot;true positive&quot;, &quot;commission&quot;)){ rp &lt;- rp + ggplot2::geom_sf(data = pred_pile, fill = NA, color = &quot;magenta&quot;, lwd = 0.5) } return( rp # list(rp,ortho_st) ) } 8.4.1 True Positives Check out the plots for the TP matches # max piles per site nplts_temp &lt;- 12 # dbscan dbscan_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;dbscan&quot;, mtchgrp = &quot;true positive&quot;) ) return(pl) } ) # watershed watershed_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- watershed_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;watershed&quot;, mtchgrp = &quot;true positive&quot;) ) return(pl) } ) 8.4.1.1 DBSCAN plot example true positive matches on the RGB with the actual pile (cyan) and predicted (magenta) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(dbscan_tp_plts_temp[[x]]))){return(NULL)} l &lt;- dbscan_tp_plts_temp[[x]] %&gt;% length() dbscan_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.1.2 Watershed plot example true positive matches on the RGB with the actual pile (cyan) and predicted (magenta) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(watershed_tp_plts_temp[[x]]))){return(NULL)} l &lt;- watershed_tp_plts_temp[[x]] %&gt;% length() watershed_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.2 Omissions (False Negatives) Check out the plots for the omissions (FN) # dbscan dbscan_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;omission&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;dbscan&quot;, mtchgrp = &quot;omission&quot;) ) return(pl) } ) # watershed watershed_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- watershed_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;omission&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;watershed&quot;, mtchgrp = &quot;omission&quot;) ) return(pl) } ) 8.4.2.1 DBSCAN plot example omissions on the RGB with the actual pile (cyan) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(dbscan_tp_plts_temp[[x]]))){return(NULL)} l &lt;- dbscan_tp_plts_temp[[x]] %&gt;% length() dbscan_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.2.2 Watershed plot example omissions on the RGB with the actual pile (cyan) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(watershed_tp_plts_temp[[x]]))){return(NULL)} l &lt;- watershed_tp_plts_temp[[x]] %&gt;% length() watershed_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.2.3 Omissions with CHM and RGB why are these missing? # function to plot ortho terra_plt_ortho &lt;- function( ortho , gt_piles = NA , pred_piles = NA , boundary , title , chm = NA , maxh = 99 ) { terra::plotRGB(ortho, stretch = &quot;lin&quot;) terra::plot( boundary %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA , main = title ) if(inherits(chm,&quot;SpatRaster&quot;)){ terra::plot( chm , add = T, col = viridis::plasma(n=100), alpha = 0.5 , legend = F , range = c(0,maxh), fill_range = T ) } if(!all(is.na(gt_piles))){ terra::plot( gt_piles %&gt;% dplyr::filter(is_in_stand) %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;cyan&quot;, col = NA, lwd = 1.2 ) } if(!all(is.na(pred_piles))){ terra::plot( pred_piles %&gt;% sf::st_transform(terra::crs(ortho)) %&gt;% terra::vect() , add = T, border = &quot;magenta&quot;, col = NA, lwd = 1.2 ) } } # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ piles &lt;- slash_piles_polys[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::inner_join( dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;omission&quot;) %&gt;% dplyr::select(pile_id) , by = &quot;pile_id&quot; ) maxh &lt;- all_stand_boundary %&gt;% dplyr::filter(site_data_lab == x) %&gt;% dplyr::slice(1) %&gt;% dplyr::pull(max_ht_m) # crop, slice rast crp_chm_rast_temp &lt;- chm_rast[[x]] %&gt;% terra::crop( piles %&gt;% sf::st_transform(terra::crs(chm_rast[[x]])) %&gt;% terra::vect() , mask = T ) crp_chm_rast_temp &lt;- crp_chm_rast_temp %&gt;% # slice terra::clamp( upper = maxh , lower = 0 , values = F ) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = piles , pred_piles = NA , boundary = stand_boundary[[x]] , chm = crp_chm_rast_temp , maxh = maxh , title = paste0( &quot;Omissions: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) }) 8.4.3 commissions (False Positives) Check out the plots for the commissions (FP) # dbscan dbscan_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;commission&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;dbscan&quot;, mtchgrp = &quot;commission&quot;) ) return(pl) } ) # watershed watershed_tp_plts_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::set_names() %&gt;% purrr::map( function(x){ nn &lt;- watershed_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;commission&quot;) %&gt;% nrow() if(nn==0){return(NULL)} pl &lt;- 1:min(nn,nplts_temp) %&gt;% purrr::map( \\(r) p_fn_temp(row_n = r, site = x, method = &quot;watershed&quot;, mtchgrp = &quot;commission&quot;) ) return(pl) } ) 8.4.3.1 DBSCAN plot example commissions on the RGB with the actual pile (cyan) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(dbscan_tp_plts_temp[[x]]))){return(NULL)} l &lt;- dbscan_tp_plts_temp[[x]] %&gt;% length() dbscan_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.3.2 Watershed plot example commissions on the RGB with the actual pile (cyan) pile outlined all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ if(any(is.null(watershed_tp_plts_temp[[x]]))){return(NULL)} l &lt;- watershed_tp_plts_temp[[x]] %&gt;% length() watershed_tp_plts_temp[[x]] %&gt;% # purrr::map(1) %&gt;% # purrr::keep_at(1:4) %&gt;% patchwork::wrap_plots(ncol = min(l,4)) + patchwork::plot_annotation( title = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10, hjust = 0.5)) ) }) 8.4.3.3 Commissions with CHM and RGB why are these missing? # map over it all_stand_boundary$site_data_lab %&gt;% purrr::map( function(x){ piles &lt;- dbscan_structural_preds[[x]] %&gt;% dplyr::filter(is_in_stand) %&gt;% dplyr::inner_join( dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp == &quot;commission&quot;) %&gt;% dplyr::select(pred_id) , by = &quot;pred_id&quot; ) if(nrow(piles)==0){return(NULL)} maxh &lt;- all_stand_boundary %&gt;% dplyr::filter(site_data_lab == x) %&gt;% dplyr::slice(1) %&gt;% dplyr::pull(max_ht_m) # crop, slice rast crp_chm_rast_temp &lt;- chm_rast[[x]] %&gt;% terra::crop( piles %&gt;% sf::st_transform(terra::crs(chm_rast[[x]])) %&gt;% terra::vect() , mask = T ) crp_chm_rast_temp &lt;- crp_chm_rast_temp %&gt;% # slice terra::clamp( upper = maxh , lower = 0 , values = F ) terra_plt_ortho( ortho = rgb_rast[[x]] , gt_piles = NA , pred_piles = piles , boundary = stand_boundary[[x]] , chm = crp_chm_rast_temp , maxh = maxh , title = paste0( &quot;Commissions: &quot; , all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) }) "],["preds_quantit.html", "Section 9 Quantification Accuracy 9.1 Height and Diameter Accuracy 9.2 Area Accuracy 9.3 Volume Comparison", " Section 9 Quantification Accuracy To this point we have: Provided a data overview: here and here Processed the UAS point cloud Demonstrated our geometry-based slash pile detection methodology Demonstrated our spectral refinement (i.e. data fusion) methodology Reviewed how we will evaluate our method Made predictions using our method on four experimental sites and Evaluated the pile detection accuracy of the structural-plus-spectral data fusion methodology In this section, we’ll evaluate the effectiveness of the proposed geometric, rules-based slash pile detection methodology by assessing its quantification accuracy performance. We fully reviewed the quantification accuracy assessment workflow here, but here is a quick overview: While detection accuracy evaluates the ability of the method to correctly locate slash piles, the quantification accuracy assessment measures the precision of the physical pile form dimensions estimated for the successfully identified piles. The quantification accuracy assessment focuses exclusively on TP matches to calculate performance metrics such as Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), and Mean Error (ME) for pile form measurements height and diameter. Unlike the detection validation which includes all four study sites, this quantification accuracy evaluation is limited to the PSINF Mixed Conifer site where direct field-measured ground truth data is available. We intentionally limit the quantification accuracy reporting to measurements of height and diameter which were made directly in the field rather than derived volume. To evaluate volume, we will perform a direct comparison between the volumes calculated from our predicted segments and those calculated from field measurements using identical geometric formulas. This comparison functions as a test of measurement consistency rather than a formal accuracy assessment of the remote-sensing method itself. This approach ensures our quantification metrics reflect the actual performance of the detection method instead of a composite error involving sensor noise, field variance, and geometric assumptions. Because both the predicted and field-based volumes rely on the same simplified shape assumptions, any resulting differences are not treated as true errors. Instead, this evaluation highlights how variations in the primary inputs of height and diameter propagate through to the final volume estimate. This distinction is critical because it separates the verifiable accuracy of our sensor-derived physical pile form measurements from the subsequent modeling of three-dimensional space. 9.1 Height and Diameter Accuracy Let’s evaluate the height and diameter accuracy of our slash pile detection and quantification framework using field measurements for the PSINF site which were taken by measuring the height and diameter (longest side of pile) using a laser hypsometer We already computed the performance metrics RMSE, MAPE, and ME for pile form measurements height and diameter at the study site and detection methodology level in the prior section using our agg_ground_truth_match() function that we defined earlier let’s check out what we got df_temp &lt;- agg_ground_truth_match_ans %&gt;% dplyr::mutate( ref_trees = tp_n+fn_n , det_trees = tp_n+fp_n ) %&gt;% dplyr::select( site, method # , site_area_m2 # detection , ref_trees , det_trees , tp_n , omission_rate,commission_rate,recall,precision,f_score # quantification , tidyselect::ends_with(&quot;_mean&quot;) , tidyselect::ends_with(&quot;_rmse&quot;) , tidyselect::ends_with(&quot;_mape&quot;) ) %&gt;% # second select to arrange pile_metric dplyr::select( site, method # , site_area_m2 # detection , ref_trees , det_trees , tp_n , omission_rate,commission_rate,recall,precision,f_score # quantification # , c(tidyselect::contains(&quot;volume&quot;) &amp; !tidyselect::contains(&quot;paraboloid&quot;)) , tidyselect::contains(&quot;area&quot;) , tidyselect::contains(&quot;height&quot;) , tidyselect::contains(&quot;diameter&quot;) ) %&gt;% # names() dplyr::mutate( dplyr::across( .cols = c( f_score, recall, precision, tidyselect::ends_with(&quot;_mape&quot;) , tidyselect::ends_with(&quot;_rate&quot;) ) , .fn = ~ scales::percent(.x, accuracy = 1) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_mean&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.01) ) , dplyr::across( .cols = c(tidyselect::ends_with(&quot;_rmse&quot;)) , .fn = ~ scales::comma(.x, accuracy = 0.1) ) ) # dplyr::glimpse() ########################## adj this if want lots of cols df_temp %&gt;% dplyr::inner_join( all_stand_boundary %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(site_data_lab == &quot;psinf&quot;) %&gt;% dplyr::select(site,site_area_ha) , by = &quot;site&quot; ) %&gt;% dplyr::select( !tidyselect::contains(&quot;_area_&quot;) &amp; !tidyselect::contains(&quot;diff_diameter_&quot;) &amp; !tidyselect::ends_with(&quot;_trees&quot;) # &amp; !tidyselect::ends_with(&quot;_n&quot;) &amp; !tidyselect::ends_with(&quot;_rate&quot;) ) %&gt;% dplyr::select( -c(recall,precision,f_score) ) %&gt;% ########################## adj this if want lots of cols # dplyr::glimpse() dplyr::relocate(site,method,tp_n) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Quantification Accuracy&quot; , col.names = c( &quot;site&quot;, &quot;method&quot;, &quot;TP predictions&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 2) ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=3 # , &quot;Detection&quot; = 3 # , &quot;Area&quot; = 3 , &quot;Height (m)&quot; = 3 , &quot;Diameter (m)&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(3,9,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% # kableExtra::column_spec( # column = 3:9 # , extra_css = &quot;font-size: 10px;&quot; # , include_thead = T # ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.1: Quantification Accuracy Height (m) Diameter (m) site method TP predictions ME RMSE MAPE ME RMSE MAPE PSINF Mixed Conifer Site DBSCAN 115 -0.07 0.7 19% 0.19 0.5 10% Watershed 115 -0.07 0.7 19% 0.19 0.5 10% These results demonstrate that the two segmentation methods, DBSCAN and Watershed, show no significant difference in their ability to represent the physical form of correctly identified piles. Because the quantification of pile form is derived directly from the underlying structural CHM data, the two methods naturally yield similar results once a pile is successfully detected. Since both algorithms operate on the same input data to generate measurements for a given location, major differences in quantification accuracy are only expected if there are significant disparities in detection performance. Our detection accuracy evaluation confirmed that both methods performed similarly, and as a result, they produced nearly identical representations of physical pile attributes. before we compare the measurements in aggregate, let’s look at the distributions dplyr::bind_rows( dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) , watershed_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(method = &quot;watershed&quot;) ) %&gt;% dplyr::select(pile_id,method,field_height_m,pred_height_m,field_diameter_m,pred_diameter_m) %&gt;% tidyr::pivot_longer( cols = -c(pile_id,method) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;field_&quot;) ~ &quot;field&quot; , stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;image-annotated&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; ) ) ) %&gt;% # dplyr::glimpse() dplyr::mutate( method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% # plot dist ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = which_data, fill = which_data)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid( rows = dplyr::vars(method) , cols = dplyr::vars(pile_metric) , scales = &quot;free_x&quot;, axes = &quot;all_x&quot; , switch = &quot;y&quot; ) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=&quot;&quot; , subtitle = &quot;comparison of height and diameter distributions&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) 9.1.1 Stand-level Aggregation Let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory). Summarizing the predicted and ground truth pile height and diameter form measurements for all instances across the entire study area, regardless of whether individual piles were successfully matched between datasets, for comparison provides insight into the method’s aggregated performance in predicting total pile size in an area. Such totals are often required for administrative needs like submitting burn permits which do not typically focus on individual pile quantification differences. # sum_df_temp &lt;- stand_agg_fn &lt;- function( df ,which_comp = &quot;field&quot; # or &quot;gt&quot; ) { df %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-c(pred_id)) %&gt;% dplyr::summarise( dplyr::across( .cols = tidyselect::starts_with( paste0(which_comp,&quot;_&quot;) ) | tidyselect::starts_with(&quot;pred_&quot;) , ~sum(.x,na.rm=T) ) ) %&gt;% tidyr::pivot_longer( cols = dplyr::everything() , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;field_&quot;) ~ &quot;field&quot; , stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;image-annotated&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(allom_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; , &quot;allom_volume&quot; , &quot;volume&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; # , &quot;Allometric Volume (m3)&quot; # , &quot;Volume (m3)&quot; , &quot;Allometric Field vs\\nAllometric Predicted Volume (m3)&quot; , &quot;Allometric Field vs\\nIrregular Predicted Volume (m3)&quot; ) ) ) %&gt;% dplyr::group_by(pile_metric) %&gt;% dplyr::arrange(pile_metric,which_data) %&gt;% dplyr::mutate( pct_diff = (value-dplyr::lag(value))/dplyr::lag(value) ) %&gt;% dplyr::ungroup() } # do it sum_df_temp &lt;- dplyr::bind_rows( dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% stand_agg_fn() %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) , watershed_gt_pred_match[[&quot;psinf&quot;]] %&gt;% stand_agg_fn() %&gt;% dplyr::mutate(method = &quot;watershed&quot;) ) %&gt;% dplyr::filter( !stringr::str_detect(metric,&quot;volume&quot;) , !stringr::str_detect(metric,&quot;area&quot;) ) # sum_df_temp %&gt;% dplyr::glimpse() plot the aggregated, stand-level height and diameter comparison between field-measured and predicted piles # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_grid( rows = dplyr::vars(pile_metric) , cols = dplyr::vars(method) , scales = &quot;free_y&quot;, axes = &quot;all_x&quot; , switch = &quot;y&quot; ) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated measurements at the PSINF site&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table the aggregated, stand-level height and diameter comparison between field-measured and predicted piles sum_df_temp %&gt;% dplyr::mutate( pile_metric=stringr::word(pile_metric) , value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% tidyr::pivot_wider( id_cols = method , values_from = c(value,pct_diff) , names_from = c(pile_metric,which_data) ) %&gt;% dplyr::select(dplyr::where(~ !all(is.na(.x)))) %&gt;% dplyr::rename_with( .cols = dplyr::everything() , .fn = ~ dplyr::case_when( stringr::str_starts(.x,&quot;value_&quot;) ~ stringr::str_remove(.x,&quot;^value_&quot;) %&gt;% stringr::str_c(&quot;_value&quot;) , stringr::str_starts(.x,&quot;pct_diff_&quot;) ~ stringr::str_remove(.x,&quot;^pct_diff_&quot;) %&gt;% stringr::str_c(&quot;_zzpct_diff&quot;) , T ~ .x ) ) %&gt;% dplyr::select(order(colnames(.))) %&gt;% dplyr::mutate(site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==&quot;psinf&quot;) %&gt;% dplyr::pull(site)) %&gt;% dplyr::relocate(site,method) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated measurements at the PSINF site&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , rep(c(&quot;Field&quot;,&quot;Predicted&quot;,&quot;Pct Diff&quot;), times = 2) ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 # , &quot;Detection&quot; = 3 # , &quot;Area&quot; = 3 , &quot;Diameter (m)&quot; = 3 , &quot;Height (m)&quot; = 3 )) %&gt;% kableExtra::column_spec(seq(2,8,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% # kableExtra::column_spec( # column = 3:9 # , extra_css = &quot;font-size: 10px;&quot; # , include_thead = T # ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.2: Comparison of aggregated measurements at the PSINF site Diameter (m) Height (m) site method Field Predicted Pct Diff Field Predicted Pct Diff PSINF Mixed Conifer Site dbscan 417.1 433.7 4.0% 263.7 258.8 -1.9% watershed 417.1 447.2 7.2% 263.7 270.7 2.7% 9.2 Area Accuracy We could also evaluate quantification accuracy using pile areas based on the image annotations, though these are less presumptive than the “gold standard” field measurements. These annotations were occasionally limited by the difficulty of pinpointing exact pile boundaries, even when using high-resolution RGB data. Despite the potential for human error in the digitizing process, these area measurements provide additional validation data that is available across all four study sites. ########################## adj this if want lots of cols df_temp %&gt;% dplyr::select( !tidyselect::contains(&quot;_height_&quot;) &amp; !tidyselect::contains(&quot;_diameter_&quot;) &amp; !tidyselect::ends_with(&quot;_trees&quot;) # &amp; !tidyselect::ends_with(&quot;_n&quot;) &amp; !tidyselect::ends_with(&quot;_rate&quot;) ) %&gt;% dplyr::select( -c(recall,precision,f_score) ) %&gt;% ########################## adj this if want lots of cols # dplyr::glimpse() dplyr::relocate(site,method,tp_n) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Quantification Accuracy&quot; , col.names = c( &quot;site&quot;, &quot;method&quot;, &quot;TP predictions&quot; , rep(c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAPE&quot;), times = 1) ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=3 # , &quot;Detection&quot; = 3 # , &quot;Area&quot; = 3 , &quot;Area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; = 3 ), escape = F) %&gt;% kableExtra::column_spec(seq(3,6,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% # kableExtra::column_spec( # column = 3:9 # , extra_css = &quot;font-size: 10px;&quot; # , include_thead = T # ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.3: Quantification Accuracy Area (m2) site method TP predictions ME RMSE MAPE ARNF Ponderosa Pine Site DBSCAN 18 12.76 16.6 4% Watershed 18 13.33 17.0 4% BHEF Ponderosa Pine Site DBSCAN 24 -24.85 48.4 15% Watershed 24 -24.86 48.3 15% PSINF Mixed Conifer Site DBSCAN 115 -0.78 2.1 10% Watershed 115 -0.78 2.1 10% TRFO-BLM Pinyon-Juniper Site DBSCAN 246 -0.95 1.7 13% Watershed 246 -0.95 1.8 13% These results further confirm that the two segmentation methods yield similar quantification accuracies for pile area, mirroring the patterns observed for height and diameter. While the absolute area accuracy naturally varies across study sites according to the average pile size, the MAPE remains decently low, ranging between 3.5% and 14.9% across all locations. These metrics suggest that both DBSCAN and Watershed are capable of delineating pile boundaries with acceptable precision. before we compare the measurements in aggregate, let’s look at the distributions all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) dplyr::bind_rows( dbscan_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,gt_area_m2,pred_area_m2) %&gt;% dplyr::mutate( method = &quot;dbscan&quot; , site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) , watershed_gt_pred_match[[x]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,gt_area_m2,pred_area_m2) %&gt;% dplyr::mutate( method = &quot;watershed&quot; , site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) ) %&gt;% dplyr::bind_rows() %&gt;% tidyr::pivot_longer( cols = -c(site,pile_id,method) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;field_&quot;) ~ &quot;field&quot; , stringr::str_starts(metric,&quot;gt_&quot;) ~ &quot;image-annotated&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;height&quot; , &quot;diameter&quot; , &quot;area&quot; ) , labels = c( &quot;Height (m)&quot; , &quot;Diameter (m)&quot; , &quot;Area (m2)&quot; ) ) ) %&gt;% # dplyr::glimpse() dplyr::mutate( site = stringr::word(site) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% # plot dist ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = which_data, fill = which_data)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + ggplot2::facet_grid( rows = dplyr::vars(method) , cols = dplyr::vars(site) , scales = &quot;free_x&quot;, axes = &quot;all_x&quot; , switch = &quot;y&quot; ) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot; , x=latex2exp::TeX(&quot;area $m^2$&quot;) , subtitle = latex2exp::TeX(&quot;Comparison of pile Area ($m^2$) distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) 9.2.1 Stand-level Aggregation Let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory). Summarizing the predicted and ground truth pile height and diameter form measurements for all instances across the entire study area, regardless of whether individual piles were successfully matched between datasets, for comparison provides insight into the method’s aggregated performance in predicting total pile size in an area. Such totals are often required for administrative needs like submitting burn permits which do not typically focus on individual pile quantification differences. # do it sum_df_temp &lt;- all_stand_boundary$site_data_lab %&gt;% purrr::map( \\(x) dplyr::bind_rows( dbscan_gt_pred_match[[x]] %&gt;% stand_agg_fn(which_comp = &quot;gt&quot;) %&gt;% dplyr::mutate( method = &quot;dbscan&quot; , site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) , watershed_gt_pred_match[[x]] %&gt;% stand_agg_fn(which_comp = &quot;gt&quot;) %&gt;% dplyr::mutate( method = &quot;watershed&quot; , site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==x) %&gt;% dplyr::pull(site) ) ) %&gt;% dplyr::filter( stringr::str_detect(metric,&quot;area&quot;) ) ) %&gt;% dplyr::bind_rows() # sum_df_temp %&gt;% dplyr::glimpse() plot the aggregated, stand-level area comparison between image-annotated and predicted piles # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) ) %&gt;% dplyr::mutate( site = stringr::word(site) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_grid( rows = dplyr::vars(site) , cols = dplyr::vars(method) , scales = &quot;free_y&quot;, axes = &quot;all_x&quot; , switch = &quot;y&quot; ) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = latex2exp::TeX(&quot;Comparison of aggregated pile Area ($m^2$) measurements for all sites&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table the aggregated, stand-level area comparison between image-annotated and predicted piles sum_df_temp %&gt;% dplyr::mutate( pile_metric=stringr::word(pile_metric) , value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% tidyr::pivot_wider( id_cols = c(site,method) , values_from = c(value,pct_diff) , names_from = c(pile_metric,which_data) ) %&gt;% dplyr::select(dplyr::where(~ !all(is.na(.x)))) %&gt;% dplyr::rename_with( .cols = dplyr::everything() , .fn = ~ dplyr::case_when( stringr::str_starts(.x,&quot;value_&quot;) ~ stringr::str_remove(.x,&quot;^value_&quot;) %&gt;% stringr::str_c(&quot;_value&quot;) , stringr::str_starts(.x,&quot;pct_diff_&quot;) ~ stringr::str_remove(.x,&quot;^pct_diff_&quot;) %&gt;% stringr::str_c(&quot;_zzpct_diff&quot;) , T ~ .x ) ) %&gt;% dplyr::select(order(colnames(.))) %&gt;% dplyr::relocate(site,method) %&gt;% # dplyr::glimpse() dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated area measurements for all sites&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , rep(c(&quot;Image-annotated&quot;,&quot;Predicted&quot;,&quot;Pct Diff&quot;), times = 1) ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 # , &quot;Detection&quot; = 3 # , &quot;Area&quot; = 3 , &quot;Area (m&lt;sup&gt;2&lt;/sup&gt;)&quot; = 3 ),escape = F) %&gt;% kableExtra::column_spec(seq(2,5,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% # kableExtra::column_spec( # column = 3:9 # , extra_css = &quot;font-size: 10px;&quot; # , include_thead = T # ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.4: Comparison of aggregated area measurements for all sites Area (m2) site method Image-annotated Predicted Pct Diff ARNF Ponderosa Pine Site dbscan 7,770.4 8,553.0 10.1% watershed 7,770.4 8,487.8 9.2% BHEF Ponderosa Pine Site dbscan 5,198.6 4,339.2 -16.5% watershed 5,198.6 4,434.4 -14.7% PSINF Mixed Conifer Site dbscan 1,185.5 1,072.5 -9.5% watershed 1,185.5 1,112.7 -6.1% TRFO-BLM Pinyon-Juniper Site dbscan 2,942.6 2,941.5 0.0% watershed 2,942.6 2,911.4 -1.1% 9.3 Volume Comparison We excluded quantification accuracy metrics for derived volume because the resulting value would not constitute a true “error”. Comparing our predicted volume to a volume that was not directly measured, but instead calculated using a geometric assumption (like assuming a perfectly circular base and paraboloid shape) would be inappropriate. This is because any resulting difference between the prediction and the ground truth would be a blend of three inseparable factors: the error of the remote-sensing prediction method, the error in the direct field measurements (diameter/height), and the error introduced by the geometric shape assumption. Reporting such combined errors would be misleading, as it would be impossible to isolate the true performance of our remote-sensing method alone. Instead, data involving derived values of volume based on field measurements and a shape assumption and its comparison to our irregularly shaped CHM-derived volume will be treated simply as data points for insight into the differences. Using geometric shape assumptions for estimating pile volume is the standard practice when implementing prescriptions or preparing for slash pile burning (Hardy 1996; Long &amp; Boston 2014). This comparison will help us understand the discrepancy between our irregularly shaped CHM-derived volume and the volume calculated assuming a perfectly circular base and paraboloid shape with field-measured height and diameter. This approach will still provide valuable context about the impact of the perfectly circular base and paraboloid geometric assumptions without falsely attributing the error of the simplified model to the remote-sensing method itself. let’s do that now field-measured piles volume assumes a paraboloid shape, with volume calculated using the field-measured diameter (as the width) and height. we’ll refer to this as “Allometric Field Volume” to indicate the field measurement is derived using a shape assumption. predicted piles volume calculated from the elevation profile of the irregular predicted pile footprint, without assuming a specific geometric shape. we’ll refer to this as “Predicted Volume” to indicate the predicted measurement is from our CHM-based detection methodology We would generally expect that the allometric field volume is larger than the predicted volume because the allometric calculation assumes a perfectly regular geometric shape (circular base and paraboloid) based on maximum field dimensions (height and diameter). this process effectively encloses the actual, irregular pile form within a simplified geometric dome which inherently neglects and sits above the actual irregularities and voids in the pile structure, likely leading to an overestimation of the volume. we already added volume measurements to the TP matches for both the ground truth and predicted piles, summary of that data dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(field_volume_m3, pred_volume_m3) %&gt;% summary() ## field_volume_m3 pred_volume_m3 ## Min. : 4.270 Min. : 1.710 ## 1st Qu.: 6.602 1st Qu.: 4.449 ## Median : 7.536 Median : 5.346 ## Mean : 15.403 Mean : 8.889 ## 3rd Qu.: 8.777 3rd Qu.: 7.341 ## Max. :183.080 Max. :89.497 those don’t really look like they match up well…let’s explore dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(diff_volume_m3 = field_volume_m3 - pred_volume_m3) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = field_volume_m3, x = pred_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + # ggplot2::geom_point(ggplot2::aes(color = diff_volume_m3)) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$pred_volume_m3,na.rm=T), max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$field_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$pred_volume_m3,na.rm=T), max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$field_volume_m3,na.rm=T) ) )) + ggplot2::labs( y = latex2exp::TeX(&quot;allometric field volume $m^3$&quot;) , x = latex2exp::TeX(&quot;predicted volume $m^3$&quot;) # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison&quot;) ) + ggplot2::theme_light() this is exactly what we expected: for true positive matches, there is a clear systematic difference with the plot showing that the volume calculated using the idealized, regular shape assumption (allometric field volume) is consistently larger than the predicted volume derived from the CHM let’s check these using lm() lm_temp &lt;- lm(field_volume_m3 ~ pred_volume_m3, data = dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;)) summary(lm_temp) ## ## Call: ## lm(formula = field_volume_m3 ~ pred_volume_m3, data = dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% ## dplyr::filter(match_grp == &quot;true positive&quot;)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -33.505 -2.876 -0.166 2.393 61.011 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.5787 1.1270 -3.175 0.00193 ** ## pred_volume_m3 2.1353 0.0725 29.453 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.915 on 113 degrees of freedom ## Multiple R-squared: 0.8847, Adjusted R-squared: 0.8837 ## F-statistic: 867.5 on 1 and 113 DF, p-value: &lt; 2.2e-16 These linear model results (intercept = -3.58, slope = 2.14) indicate a strong proportional bias that significantly increases with pile size. The high slope (2.14) coupled with the negative intercept (-3.58) indicate that the volume difference is not a simple constant offset (e.g. slope of ~1.0 and intercept of &gt;0 if our hypothesis of consistently higher allometric field volume is true), but rather a scaling issue that is driven by the largest piles. The much larger allometric field volume estimates relative to the CHM-predicted volumes for the largest piles exert a strong influence on the predicted form of the liner model, pulling the slope steeply upward and forcing the intercept below zero as a mathematical artifact. Despite the predicted negative intercept, visual inspection of the data shows that most allometric field volumes are larger than the CHM-predicted volumes, even for smaller piles. The slope value indicates that for every 1 m3 increase in predicted volume, the allometric field volume increases by nearly 2.14 m3. This data suggests that the geometric assumptions of the allometric model potentially introduce substantial scaling error which may limit its reliability (especially for larger piles) for accurately estimating the volume of real-world piles which have heterogeneous footprints and elevation profiles. before we compare the volume measurements in aggregate, let’s look at the distributions vol_df_temp &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,field_volume_m3,pred_volume_m3) %&gt;% tidyr::pivot_longer(cols = -c(pile_id)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;field_volume_m3&quot;,&quot;pred_volume_m3&quot;) , labels = c( &quot;allometric field volume&quot; , &quot;predicted volume&quot; ) ) ) # plot dist vol_df_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = name, fill = name)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=latex2exp::TeX(&quot;volume $m^3$&quot;) , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison of distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) slope plots are neat too vol_df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) what if we only look at the smaller piles? vol_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(x = value &lt; quantile(vol_df_temp$value, probs = 0.90)) %&gt;% dplyr::group_by(pile_id) %&gt;% dplyr::filter( max(x) == 1 ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level for the smaller piles&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) let’s compare aggregated volume measurements for the true positive matches Mean Difference (MD): \\[\\text{MD} = \\frac{1}{N} \\sum_{i=1}^{N} (\\text{Allometric Volume}_i - \\text{Predicted Volume}_i)\\] Percent Mean Difference: \\[\\%\\text{MD} = \\frac{\\text{MD}}{\\text{Mean}(\\text{Predicted Volume})} \\times 100\\] vol_agg_df_temp &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( mean_diff = mean(field_volume_m3-pred_volume_m3) , sd_diff = sd(field_volume_m3-pred_volume_m3) , mean_field_volume_m3 = mean(field_volume_m3,na.rm = T) , mean_pred_volume_m3 = mean(pred_volume_m3,na.rm = T) ) %&gt;% dplyr::mutate( pct_mean_diff = mean_diff/mean_pred_volume_m3 ) what did we get? vol_agg_df_temp %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( value = dplyr::case_when( stringr::str_starts(name, &quot;pct_&quot;) ~ scales::percent(value, accuracy = 0.1) , T ~ scales::comma(value, accuracy = 0.1) ) ) %&gt;% kableExtra::kbl( caption = &quot;comparison of aggregated allometric field volume and predicted volume&quot; , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 9.5: comparison of aggregated allometric field volume and predicted volume metric value mean_diff 6.5 sd_diff 17.6 mean_field_volume_m3 15.4 mean_pred_volume_m3 8.9 pct_mean_diff 73.3% we’ll dig into the MD shortly but before we move on let’s focus on the percent mean difference. We calcualted a %MD of 73.3% which indicates a major systematic difference where the allometric field volume is, on average, 73.3% larger than our CHM-predicted volume. This large relative difference shows how much the geometric assumptions inflate the volume compared to the irregular volumes measured by our remote sensing-based method. let’s make a Bland-Altman plot to compare the two measurement methods. this plot uses the average of the two measurements (approximate size) on the x-axis and the difference (bias) between the two measurements on the y-axis dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( mean_vol = (field_volume_m3+pred_volume_m3)/2 , diff_vol = (field_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp , scale_diff = ifelse(diff_vol &lt; 0, -abs(diff_vol) / abs(min(diff_vol)), diff_vol / max(diff_vol)) ) %&gt;% # ggplot() + geom_point(aes(x=diff_vol,y=0, color=scale_diff)) + scale_color_gradient2(mid = &quot;gray&quot;, midpoint = 0, low = &quot;red&quot;, high = &quot;blue&quot;) # plot ggplot2::ggplot( mapping = ggplot2::aes(x = mean_vol, y = diff_vol) ) + ggplot2::geom_hline(yintercept = 0, color = &quot;black&quot;, lwd = 1.2) + # mean difference (bias) ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff , linetype = &quot;dashed&quot;, color = &quot;blue&quot;, lwd = 1 ) + # upper limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # lower limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # annotations ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff , label = latex2exp::TeX( paste0( &quot;mean difference (bias): &quot; , scales::comma(vol_agg_df_temp$mean_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;blue&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;+1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;-1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = 1.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + # points ggplot2::geom_point(mapping = ggplot2::aes(color = scale_diff), size = 1.9, alpha = 0.8) + ggplot2::scale_color_steps2(mid = &quot;gray&quot;, midpoint = 0) + ggplot2::labs( subtitle = &quot;Bland-Altman plot: allometric field volume vs predicted volume&quot; , x = latex2exp::TeX(&quot;mean volume ($m^3$)&quot;) , y = latex2exp::TeX(&quot;difference (allometric - predicted volume $m^3$)&quot;) ) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;none&quot;) That’s a lot of plotting to show that the mean difference is 6.51 m3. Points falling outside the 95% interval on the plot are instances of significant disagreement between the two volume measurements for those specific data points. These outliers indicate that, for a particular pile, the difference between the allometric field volume and the predicted volume is unusually large, suggesting a potential failure in either the CHM segmentation process, the quality of the original field measurements, the geometric shape assumption, or a combination thereof. We should investigate these extreme disagreements further to see what is happening before we do that, let’s use a paired t-test to determine if the mean difference (MD) between the allometric field volume and the predicted volume is statistically significant (i.e. significantly different from zero) # is the mean difference between the two volumes significantly different from zero ttest_temp &lt;- t.test( dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(field_volume_m3) , dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(field_volume_m3) and dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_volume_m3) ## t = 3.9741, df = 114, p-value = 0.0001243 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 3.266685 9.760398 ## sample estimates: ## mean difference ## 6.513542 that’s neat, the test gave us the same mean difference (MD) of 6.51 m3 that we calculated above. also, the p-value of 0.00012 is less than 0.05, meaning we should reject the null hypothesis that the true mean difference is zero. this confirms that the systematic difference (or bias) we observed where allometric volume is larger than our predicted volume is statistically significant and not due to random chance. 9.3.1 Extreme Volume Disagreements let’s investigate the extreme disagreements further to see what is happening bad_vol_df_temp &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( diff_vol = (field_volume_m3-pred_volume_m3) # match the order used in vol_agg_df_temp ) %&gt;% dplyr::filter( diff_vol &lt; (vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff) | diff_vol &gt; (vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff) ) %&gt;% dplyr::left_join( slash_piles_polys[[&quot;psinf&quot;]] %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(pile_id, comment) %&gt;% dplyr::rename(pile_type = comment) , by = &quot;pile_id&quot; ) # what are the differences? bad_vol_df_temp %&gt;% dplyr::select( pile_id, pile_type , field_height_m, pred_height_m, diff_field_height_m , field_diameter_m, pred_diameter_m, diff_field_diameter_m , field_volume_m3, pred_volume_m3 ) %&gt;% dplyr::mutate( dplyr::across( .cols = -c(pile_id,pile_type) , .fns = ~ scales::comma(.x,accuracy=0.01) ) ) %&gt;% kableExtra::kbl( caption = &quot;Volume measurement outliers: comparison of ground truth and predicted piles&quot; # , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling(font_size = 9.8) Table 9.6: Volume measurement outliers: comparison of ground truth and predicted piles pile_id pile_type field_height_m pred_height_m diff_field_height_m field_diameter_m pred_diameter_m diff_field_diameter_m field_volume_m3 pred_volume_m3 190 Mechanical Pile 4.42 3.25 -1.17 8.96 8.68 -0.28 139.37 59.11 194 Mechanical Pile 6.40 3.65 -2.75 8.53 8.48 -0.06 183.08 62.97 195 Mechanical Pile 5.79 4.01 -1.78 8.23 8.99 0.76 154.02 89.50 82 Mechanical Pile 4.27 3.40 -0.87 7.62 7.56 -0.06 97.30 52.95 197 Mechanical Pile 5.18 3.21 -1.97 7.32 7.84 0.53 108.89 47.61 8 Mechanical Pile 4.27 3.00 -1.27 6.71 7.38 0.67 75.35 32.67 76 Mechanical Pile 4.72 1.73 -2.99 7.01 5.68 -1.33 91.18 15.80 All of the extreme volume discrepancies at the PSINF site occur for mechanical piles, where field-measured heights exceed the predicted, CHM-derived heights. One possible cause of this height discrepancy is that the max_ht_m parameter was set too low to capture the upper extent of these taller structures. If this is the case, then the predicted height would be right at the maximum height allowed by max_ht_m. However, we set the max_ht_m parameter to 5.0 m and the maximum predicted height of these piles was 4.0 m which means that it is not likely that the height-filtered CHM removed the top of the pile from the unfiltered CHM. Instead, the under-prediction appears to stem from artifacts in height normalization during point cloud processing. If we go back to look at the DTM of this site we can see slight vertical variations within the pile footprints, suggesting that the ground classification algorithm incorrectly identified the lower portions of these larger piles as terrain. Because the DTM was incorrectly inflated within the pile footprint the height-normalized CHM slightly underestimates the true height of the piles. bad_vol_df_temp %&gt;% dplyr::select( pile_id , field_height_m, pred_height_m , field_diameter_m, pred_diameter_m , field_volume_m3, pred_volume_m3 ) %&gt;% tidyr::pivot_longer( cols = -c(pile_id) , names_to = &quot;metric&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate( which_data = dplyr::case_when( stringr::str_starts(metric,&quot;field_&quot;) ~ &quot;field&quot; , stringr::str_starts(metric,&quot;pred_&quot;) ~ &quot;prediction&quot; , T ~ &quot;error&quot; ) %&gt;% ordered() , pile_metric = metric %&gt;% stringr::str_remove(&quot;(_rmse|_rrmse|_mean|_mape)$&quot;) %&gt;% stringr::str_extract(&quot;(paraboloid_volume|volume|area|height|diameter)&quot;) %&gt;% factor( ordered = T , levels = c( &quot;volume&quot; , &quot;area&quot; , &quot;height&quot; , &quot;diameter&quot; ) , labels = c( &quot;Volume (m3)&quot; , &quot;Area (m2)&quot; , &quot;Height (m)&quot; , &quot;Diameter (m)&quot; ) ) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = which_data, y = value, label = scales::comma(value,accuracy=0.1), group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = which_data), alpha = 0.8, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + # harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::geom_text( vjust = -0.25 , show.legend = FALSE ) + ggplot2::facet_grid(rows = dplyr::vars(pile_metric), scales = &quot;free_y&quot;) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0.05,.32))) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot;, color = &quot;&quot; , subtitle = &quot;Volume measurement outliers: comparison of measurements&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , strip.text = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) ) RGB with the predicted piles (magenta) and the ground-truth piles (cyan) overlaid with the CHM # cloud2raster_ans$chm_rast %&gt;% # terra::clamp(upper = structural_params_settings$max_ht_m, lower = 0, values = F) %&gt;% # terra::plot() # bad_vol_df_temp %&gt;% dplyr::glimpse() # plot RGB + CHM # plot RGB plts_temp &lt;- 1:nrow(bad_vol_df_temp) %&gt;% # sample(1) %&gt;% purrr::map(function(x){ dta &lt;- bad_vol_df_temp %&gt;% dplyr::slice(x) gt &lt;- slash_piles_polys[[&quot;psinf&quot;]] %&gt;% dplyr::filter(pile_id==dta$pile_id) pr &lt;- dbscan_spectral_preds[[&quot;psinf&quot;]] %&gt;% dplyr::filter(pred_id==dta$pred_id) #plt ortho_plt_fn( rgb_rast = rgb_rast[[&quot;psinf&quot;]] , stand = gt , add_stand = F , buffer = 7 ) + ggnewscale::new_scale_fill() + ggplot2::geom_tile( data = chm_rast[[&quot;psinf&quot;]] %&gt;% terra::crop( sf::st_union(gt,pr) %&gt;% sf::st_transform(terra::crs(chm_rast[[&quot;psinf&quot;]])) %&gt;% terra::vect() , mask = T ) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = ggplot2::aes(x=x,y=y,fill=f) , alpha = 0.5 , inherit.aes = F , show.legend = T ) + ggplot2::scale_fill_viridis_c( option = &quot;plasma&quot;, na.value = &quot;gray&quot;,name = &quot;CHM (m)&quot; , limits = c(0,all_stand_boundary %&gt;% dplyr::filter(site_data_lab==&quot;psinf&quot;) %&gt;% dplyr::pull(max_ht_m)) ) + ggplot2::geom_sf(data = gt, fill = NA, color = &quot;cyan&quot;, lwd = 0.6) + ggplot2::geom_sf(data = pr, fill = NA, color = &quot;magenta&quot;, lwd = 0.5) + ggplot2::labs( subtitle = paste0( &quot;Fld ht: &quot;, round(dta$field_height_m,1) , &quot; | Pred ht: &quot;, round(dta$pred_height_m,1) , &quot;\\nFld dia: &quot;, round(dta$field_diameter_m,1) , &quot; | Pred dia: &quot;, round(dta$pred_diameter_m,1) ) ) + ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 8) , legend.title = ggplot2::element_text(size = 8) ) }) # plts_temp # combine patchwork::wrap_plots( plts_temp , ncol = 3 , guides = &quot;collect&quot; ) + patchwork::plot_annotation( theme = ggplot2::theme( legend.position = &quot;bottom&quot; , legend.text = ggplot2::element_text(size = 8) , legend.title = ggplot2::element_text(size = 8) , legend.margin = ggplot2::margin(0,0,0,0) ) ) 9.3.2 Allometric Volume Comparison The volume comparison immediately above compared the allometric field volume using a geometric shape assumption (paraboloid) with the predicted volume based on the irregular CHM elevation profile. Thus, the volume difference included the impact of the shape assumption. In an attempt to remove the influence of comparing a regular shape (field measured) to an irregular shape (predicted volume), we’ll perform a comparison analysis where both volume calculations are based on the same paraboloid shape assumption. This should provide insight into the differences related only to the predicted versus field-measured maximum dimensions of height and diameter. In the following section, we compare volume predictions against field measured data where both volume calculations utilize the same paraboloid shape assumption. For this analysis, we’ll update the predicted volume only using the following volume definitions: field-measured piles volume assumes a paraboloid shape, with volume calculated using the field-measured diameter (as the width) and height. we’ll refer to this as “Allometric Field Volume” to indicate the field measurement is derived using a shape assumption. predicted piles volume assumes a paraboloid shape, with volume calculated using the predicted diameter (as the width) and height. we’ll refer to this as “Allometric Predicted Volume” to indicate the measurement is derived using a shape assumption. We would generally expect that the allometric field volume will not be uniformly larger or smaller than the predicted allometric volume, as the volume difference will be the net result of two competing influences: the overestimation/underestimation of diameter and the overestimation/underestimation of height propagating through the volume calculation formula. let’s first update the predicted volume to calculate the allometric predicted volume where the volume formula for a paraboloid is: \\[ V = \\frac{1}{8}\\pi \\cdot width^2 \\cdot height \\] dbscan_gt_pred_match[[&quot;psinf&quot;]] &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::mutate( pred_allom_volume_m3 = (1/8) * pi * (pred_diameter_m^2) * pred_height_m ) %&gt;% dplyr::glimpse() ## Rows: 126 ## Columns: 24 ## $ pile_id &lt;dbl&gt; 190, 194, 195, 82, 197, 77, 189, 8, 187, 76,… ## $ i_area &lt;dbl&gt; 46.420164, 44.907459, 46.605098, 36.810987, … ## $ u_area &lt;dbl&gt; 62.038111, 54.767766, 53.639576, 41.666730, … ## $ iou &lt;dbl&gt; 0.7482524, 0.8199615, 0.8688566, 0.8834624, … ## $ pred_id &lt;dbl&gt; 2064, 3161, 3597, 5659, 4086, 5234, 2190, 50… ## $ match_grp &lt;ord&gt; true positive, true positive, true positive,… ## $ gt_diameter_m &lt;dbl&gt; 10.216924, 8.966741, 9.030139, 7.892174, 8.6… ## $ gt_area_m2 &lt;dbl&gt; 59.263275, 54.040225, 50.979673, 40.292717, … ## $ field_height_m &lt;dbl&gt; 4.4196, 6.4008, 5.7912, 4.2672, 5.1816, 2.43… ## $ field_diameter_m &lt;dbl&gt; 8.96112, 8.53440, 8.22960, 7.62000, 7.31520,… ## $ field_volume_m3 &lt;dbl&gt; 139.369402, 183.079674, 154.023115, 97.29999… ## $ pred_diameter_m &lt;dbl&gt; 8.683317, 8.475848, 8.988882, 7.564390, 7.84… ## $ pred_area_m2 &lt;dbl&gt; 49.195, 45.635, 49.265, 38.185, 34.985, 27.7… ## $ pred_volume_m3 &lt;dbl&gt; 59.110490, 62.972508, 89.496626, 52.950735, … ## $ pred_height_m &lt;dbl&gt; 3.246000, 3.652000, 4.014000, 3.396000, 3.21… ## $ diff_area_m2 &lt;dbl&gt; -10.06827455, -8.40522481, -1.71467337, -2.1… ## $ pct_diff_area_m2 &lt;dbl&gt; 0.169890622, 0.155536452, 0.033634452, 0.052… ## $ diff_diameter_m &lt;dbl&gt; -1.53360713, -0.49089339, -0.04125673, -0.32… ## $ pct_diff_diameter_m &lt;dbl&gt; 0.150104577, 0.054746018, 0.004568782, 0.041… ## $ diff_field_diameter_m &lt;dbl&gt; -0.27780266, -0.05855196, 0.75928202, -0.055… ## $ pct_diff_field_diameter_m &lt;dbl&gt; 0.031000886, 0.006860700, -0.092262324, 0.00… ## $ diff_field_height_m &lt;dbl&gt; -1.17359995, -2.74880005, -1.77720006, -0.87… ## $ pct_diff_field_height_m &lt;dbl&gt; 0.26554438, 0.42944633, 0.30687941, 0.204162… ## $ pred_allom_volume_m3 &lt;dbl&gt; 96.112473, 103.028404, 127.364562, 76.308938… # summarize it dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(field_volume_m3, pred_volume_m3, pred_allom_volume_m3) %&gt;% summary() ## field_volume_m3 pred_volume_m3 pred_allom_volume_m3 ## Min. : 4.270 Min. : 1.710 Min. : 2.822 ## 1st Qu.: 6.602 1st Qu.: 4.449 1st Qu.: 6.912 ## Median : 7.536 Median : 5.346 Median : 8.201 ## Mean : 15.403 Mean : 8.889 Mean : 14.445 ## 3rd Qu.: 8.777 3rd Qu.: 7.341 3rd Qu.: 12.133 ## Max. :183.080 Max. :89.497 Max. :127.365 nice, the allometric predicted volume is larger than the predicted volume calculated based on the irregular elevation profile in the CHM dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::mutate(diff_volume_m3 = field_volume_m3 - pred_allom_volume_m3) %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(y = field_volume_m3, x = pred_allom_volume_m3)) + ggplot2::geom_abline(lwd = 1.5) + ggplot2::geom_point(color = &quot;navy&quot;) + ggplot2::geom_smooth(method = &quot;lm&quot;, se=F, color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + ggplot2::scale_color_viridis_c(option = &quot;mako&quot;, direction = -1, alpha = 0.8) + ggplot2::scale_x_continuous(limits = c(0, max( max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$pred_allom_volume_m3,na.rm=T), max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$field_volume_m3,na.rm=T) ) )) + ggplot2::scale_y_continuous(limits = c(0, max( max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$pred_allom_volume_m3,na.rm=T), max(dbscan_gt_pred_match[[&quot;psinf&quot;]]$field_volume_m3,na.rm=T) ) )) + ggplot2::labs( y = latex2exp::TeX(&quot;allometric field volume $m^3$&quot;) , x = latex2exp::TeX(&quot;allometric predicted volume $m^3$&quot;) # , color = &quot;image-field\\ndiameter diff.&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison&quot;) ) + ggplot2::theme_light() the differences between the predictions for the larger field measured piles are pulling the slope of the line upwards but for the smaller piles, the volume differences are clustered around the line of equality before we compare the volume measurements in aggregate, let’s look at the distributions vol_df_temp &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::select(pile_id,field_volume_m3,pred_allom_volume_m3) %&gt;% tidyr::pivot_longer(cols = -c(pile_id)) %&gt;% dplyr::mutate( name = factor( name , ordered = T , levels = c(&quot;field_volume_m3&quot;,&quot;pred_allom_volume_m3&quot;) , labels = c( &quot;allometric field volume&quot; , &quot;allometric predicted volume&quot; ) ) ) # plot dist vol_df_temp %&gt;% ggplot2::ggplot(mapping = ggplot2::aes(x = value, color = name, fill = name)) + ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.7) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::scale_y_continuous(NULL,breaks=NULL) + ggplot2::labs( color=&quot;&quot;,fill=&quot;&quot;,x=latex2exp::TeX(&quot;allometric volume $m^3$&quot;) , subtitle = latex2exp::TeX(&quot;Allometric bulk volume ($m^3$) comparison of distributions&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;top&quot; ) nice, the distributions overlap much more than the volume comparison between the allometric field value and the irregular, CHM-derived prediction slope plots are neat too vol_df_temp %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;allometric volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;Allometric bulk volume ($m^3$) comparison at the pile level&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) what if we only look at the smaller piles? vol_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(x = value &lt; quantile(vol_df_temp$value, probs = 0.90)) %&gt;% dplyr::group_by(pile_id) %&gt;% dplyr::filter( max(x) == 1 ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes(x = name, y = value, group = pile_id) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_point(mapping = ggplot2::aes(color = name), alpha = 0.7, size = 2.5) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::labs( color=&quot;&quot; , y = latex2exp::TeX(&quot;volume $m^3$&quot;) , x = &quot;&quot; , subtitle = latex2exp::TeX(&quot;bulk volume ($m^3$) comparison at the pile level for the smaller piles&quot;) ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.title = ggplot2::element_text(size = 10) , axis.text = ggplot2::element_text(size = 10) ) there is much more variability in this slope plot than the volume comparison between the allometric field value and the irregular, CHM-derived prediction let’s compare aggregated volume measurements for the true positive matches vol_agg_df_temp &lt;- dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% dplyr::summarise( mean_diff = mean(field_volume_m3-pred_allom_volume_m3) , sd_diff = sd(field_volume_m3-pred_allom_volume_m3) , mean_field_volume_m3 = mean(field_volume_m3,na.rm = T) , mean_pred_allom_volume_m3 = mean(pred_allom_volume_m3,na.rm = T) ) %&gt;% dplyr::mutate( pct_mean_diff = mean_diff/mean_pred_allom_volume_m3 ) what did we get? vol_agg_df_temp %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% dplyr::mutate( value = dplyr::case_when( stringr::str_starts(name, &quot;pct_&quot;) ~ scales::percent(value, accuracy = 0.1) , T ~ scales::comma(value, accuracy = 0.1) ) ) %&gt;% kableExtra::kbl( caption = &quot;comparison of aggregated allometric field volume and allometric predicted volume&quot; , col.names = c(&quot;metric&quot;, &quot;value&quot;) ) %&gt;% kableExtra::kable_styling() Table 9.7: comparison of aggregated allometric field volume and allometric predicted volume metric value mean_diff 1.0 sd_diff 12.4 mean_field_volume_m3 15.4 mean_pred_allom_volume_m3 14.4 pct_mean_diff 6.6% we’ll dig into the MD shortly but before we move on let’s focus on the percent mean difference. We calcualted a %MD of 6.6% which indicates a slight systematic difference where the allometric field volume is, on average, 6.6% larger than our predicted allometric volume. let’s make a Bland-Altman plot to compare the two measurement methods. this plot uses the average of the two measurements (approximate size) on the x-axis and the difference (bias) between the two measurements on the y-axis dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # calc needed metrics dplyr::mutate( mean_vol = (field_volume_m3+pred_allom_volume_m3)/2 , diff_vol = (field_volume_m3-pred_allom_volume_m3) # match the order used in vol_agg_df_temp , scale_diff = ifelse(diff_vol &lt; 0, -abs(diff_vol) / abs(min(diff_vol)), diff_vol / max(diff_vol)) ) %&gt;% # ggplot() + geom_point(aes(x=diff_vol,y=0, color=scale_diff)) + scale_color_gradient2(mid = &quot;gray&quot;, midpoint = 0, low = &quot;red&quot;, high = &quot;blue&quot;) # plot ggplot2::ggplot( mapping = ggplot2::aes(x = mean_vol, y = diff_vol) ) + ggplot2::geom_hline(yintercept = 0, color = &quot;black&quot;, lwd = 1.2) + # mean difference (bias) ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff , linetype = &quot;dashed&quot;, color = &quot;blue&quot;, lwd = 1 ) + # upper limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # lower limit ggplot2::geom_hline( yintercept = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , linetype = &quot;dotted&quot;, color = &quot;red&quot;, lwd = 1 ) + # annotations ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff , label = latex2exp::TeX( paste0( &quot;mean difference (bias): &quot; , scales::comma(vol_agg_df_temp$mean_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;blue&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;+1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff+1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = -0.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + ggplot2::annotate( &quot;text&quot; , x = Inf , y = vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff , label = latex2exp::TeX( paste0( &quot;-1.96 SD: &quot; , scales::comma(vol_agg_df_temp$mean_diff-1.96*vol_agg_df_temp$sd_diff, accuracy = 0.01) , &quot; $m^3$&quot; ) , output = &quot;character&quot; ) , vjust = 1.5 , hjust = 1 , color = &quot;red&quot; , size = 4 , parse = TRUE ) + # points ggplot2::geom_point(mapping = ggplot2::aes(color = scale_diff), size = 1.9, alpha = 0.8) + ggplot2::scale_color_steps2(mid = &quot;gray&quot;, midpoint = 0) + ggplot2::labs( subtitle = &quot;Bland-Altman plot: allometric field volume vs allometric predicted volume&quot; , x = latex2exp::TeX(&quot;mean allometric volume ($m^3$)&quot;) , y = latex2exp::TeX(&quot;difference (allometric field - allometric predicted volume $m^3$)&quot;) ) + ggplot2::theme_light() + ggplot2::theme(legend.position = &quot;none&quot;) That’s a lot of plotting to show that the mean difference is 0.96 m3. This is a significant improvement over our comparison between the allometric field value and the irregular, CHM-derived prediction let’s use a paired t-test to determine if the mean difference (MD) between the allometric field volume and the allometric predicted volume is statistically significant (i.e. significantly different from zero) # is the mean difference between the two volumes significantly different from zero ttest_temp &lt;- t.test( dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(field_volume_m3) , dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_allom_volume_m3) , paired = TRUE ) ttest_temp ## ## Paired t-test ## ## data: dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(field_volume_m3) and dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::filter(match_grp == &quot;true positive&quot;) %&gt;% dplyr::pull(pred_allom_volume_m3) ## t = 0.82545, df = 114, p-value = 0.4108 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -1.340997 3.256869 ## sample estimates: ## mean difference ## 0.9579359 Wow, the p-value of 0.411 is greater than 0.05 (even 0.10), meaning we fail to reject the null hypothesis that the true mean difference is zero. That is, the mean difference between the field-measured volume and the predicted volume is not different than zero when both are forced to use the same paraboloid shape assumption. This contrasts sharply with the previously observed major systematic difference between the allometric field volume and the predicted irregular, CHM-derived volume. The non-significant difference strongly suggests that the major volume discrepancy noted earlier was primarily due to the geometric irregularity of the actual piles, and not to systematic prediction bias in our CHM-derived height and diameter measurements. 9.3.3 Stand-level Aggregation Let’s summarize the measurement values of the predictions (true positive and false positive) and the ground truth data (true positive and false negative) over the entire stand (this is similar to a basal area comparison in a forest inventory). Summarizing the predicted and ground truth pile height and diameter form measurements for all instances across the entire study area, regardless of whether individual piles were successfully matched between datasets, for comparison provides insight into the method’s aggregated performance in predicting total pile size in an area. Such totals are often required for administrative needs like submitting burn permits which do not typically focus on individual pile quantification differences. # do it sum_df_temp &lt;- dplyr::bind_rows( dbscan_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::mutate( pred_allom_volume_m3 = (1/8) * pi * (pred_diameter_m^2) * pred_height_m , field_allom_volume_m3 = field_volume_m3 ) %&gt;% stand_agg_fn() %&gt;% dplyr::mutate(method = &quot;dbscan&quot;) , watershed_gt_pred_match[[&quot;psinf&quot;]] %&gt;% dplyr::mutate( pred_allom_volume_m3 = (1/8) * pi * (pred_diameter_m^2) * pred_height_m , field_allom_volume_m3 = field_volume_m3 ) %&gt;% stand_agg_fn() %&gt;% dplyr::mutate(method = &quot;watershed&quot;) ) %&gt;% dplyr::filter( stringr::str_detect(metric,&quot;volume&quot;) ) # sum_df_temp %&gt;% dplyr::glimpse() plot the aggregated, stand-level volume comparison between field-measured and predicted piles # plot it sum_df_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( stand_id=1 , lab = paste0( scales::comma(value,accuracy=0.1) , dplyr::case_when( is.na(pct_diff) ~ &quot;&quot; , T ~ paste0( &quot;\\n&quot; , ifelse(pct_diff&lt;0,&quot;-&quot;,&quot;+&quot;) ,scales::percent(abs(pct_diff),accuracy=0.1) ) ) ) , method = method %&gt;% factor(ordered = T) %&gt;% forcats::fct_recode(&quot;DBSCAN&quot; = &quot;dbscan&quot;, &quot;Watershed&quot; = &quot;watershed&quot;) ) %&gt;% ggplot2::ggplot( mapping = ggplot2::aes( x = which_data , y = value , label = lab , group = stand_id ) ) + ggplot2::geom_line(key_glyph = &quot;point&quot;, alpha = 0.7, color = &quot;gray&quot;, lwd = 1.1) + ggplot2::geom_col(mapping = ggplot2::aes(fill = which_data), alpha = 1, width = 0.4) + harrypotter::scale_color_hp_d(option = &quot;lunalovegood&quot;) + harrypotter::scale_fill_hp_d(option = &quot;lunalovegood&quot;) + ggplot2::geom_text( vjust = -0.25 ) + ggplot2::facet_grid( rows = dplyr::vars(pile_metric) , cols = dplyr::vars(method) , scales = &quot;free_y&quot;, axes = &quot;all_x&quot; , switch = &quot;y&quot; # , labeller = ggplot2::label_wrap_gen(width = 20) ) + ggplot2::scale_y_continuous(labels = scales::comma, expand = ggplot2::expansion(mult = c(0,.3)), breaks = NULL) + ggplot2::labs( x = &quot;&quot;, y = &quot;&quot; , subtitle = &quot;Comparison of aggregated volume estimates at the PSINF site&quot; ) + ggplot2::theme_light() + ggplot2::theme( legend.position = &quot;none&quot; , axis.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.x = ggplot2::element_text(size = 11, color = &quot;black&quot;, face = &quot;bold&quot;) , strip.text.y = ggplot2::element_text(size = 9, color = &quot;black&quot;, face = &quot;bold&quot;) , panel.grid = ggplot2::element_blank() ) table the aggregated, stand-level volume comparison between field-measured and predicted piles sum_df_temp %&gt;% dplyr::mutate( pile_metric=dplyr::case_when( stringr::str_detect(metric,&quot;_allom_&quot;) ~ &quot;allometric&quot; , T ~ &quot;irregular&quot; ) , value = scales::comma(value,accuracy=0.1) , pct_diff = scales::percent(pct_diff,accuracy=0.1) ) %&gt;% tidyr::pivot_wider( id_cols = method , values_from = c(value,pct_diff) , names_from = c(pile_metric,which_data) ) %&gt;% dplyr::select(dplyr::where(~ !all(is.na(.x)))) %&gt;% dplyr::rename_with( .cols = dplyr::everything() , .fn = ~ dplyr::case_when( stringr::str_starts(.x,&quot;value_&quot;) ~ stringr::str_remove(.x,&quot;^value_&quot;) %&gt;% stringr::str_c(&quot;_value&quot;) , stringr::str_starts(.x,&quot;pct_diff_&quot;) ~ stringr::str_remove(.x,&quot;^pct_diff_&quot;) %&gt;% stringr::str_c(&quot;_zzpct_diff&quot;) , T ~ .x ) ) %&gt;% dplyr::select(order(colnames(.))) %&gt;% dplyr::mutate(site = all_stand_boundary %&gt;% dplyr::filter(site_data_lab==&quot;psinf&quot;) %&gt;% dplyr::pull(site)) %&gt;% dplyr::relocate(site,method) %&gt;% dplyr::arrange(site,method) %&gt;% kableExtra::kbl( caption = &quot;Comparison of aggregated volume estimates at the PSINF site&quot; , col.names = c( &quot;site&quot;, &quot;method&quot; , rep(c(&quot;Field&quot;,&quot;Predicted&quot;,&quot;Pct Diff&quot;), times = 2) ) , escape = F # , digits = 2 ) %&gt;% kableExtra::kable_styling(font_size = 11.5) %&gt;% kableExtra::add_header_above(c( &quot; &quot;=2 , &quot;Allometric Field vs Allometric Predicted Volume (m&lt;sup&gt;3&lt;/sup&gt;)&quot; = 3 , &quot;Allometric Field vs Irregular Predicted Volume (m&lt;sup&gt;3&lt;/sup&gt;)&quot; = 3 ),escape = F) %&gt;% kableExtra::column_spec(seq(2,8,by=3), border_right = TRUE, include_thead = TRUE) %&gt;% # kableExtra::column_spec( # column = 2:8 # , extra_css = &quot;font-size: 10px;&quot; # , include_thead = T # ) %&gt;% kableExtra::collapse_rows(columns = 1, valign = &quot;top&quot;) Table 9.8: Comparison of aggregated volume estimates at the PSINF site Allometric Field vs Allometric Predicted Volume (m3) Allometric Field vs Irregular Predicted Volume (m3) site method Field Predicted Pct Diff Field Predicted Pct Diff PSINF Mixed Conifer Site dbscan 1,813.8 1,698.8 -6.3% 1,813.8 1,053.6 -41.9% watershed 1,813.8 1,794.4 -1.1% 1,813.8 1,111.1 -38.7% "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
