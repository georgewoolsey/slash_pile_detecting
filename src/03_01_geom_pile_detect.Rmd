# Geometry-based Slash Pile Detection{#raster_watershed}

In this section, we will demonstrate the geometry-based slash pile detection method which relies upon user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-DAP point cloud data. Since this is only a demonstration of the method, we will work with only a sample area from one of the study sites which we know includes slash piles. Full evaluation of the methodology will be performed later in the analysis.

We'll attempt to detect slash piles using raster-based methods with the CHM. These raster-based approaches are simple and efficient but rasterization simplifies/removes some of the rich 3D information in the point cloud. However, raster-based approaches for detecting individual trees in forest stands and coarse woody debris are common.

Here is a section from the draft manuscript:

>These geometry-based approaches are supported by the demonstrated successes of object segmentation frameworks for both CWD and individual trees, which consistently provide high detection and quantification accuracy by utilizing rules to define expected target object morphology. Beyond their technical performance, the geometry-based methods utilizing a set of rules offer some key advantages. The inherent traceability of these methods ensures that reporting for regulatory oversight is more transparent and easier to describe compared to the "black box" nature of many model-based approaches. Geometry-based frameworks also do not rely on training datasets and can directly align with the explicit pile construction parameters which are generally known by land managers through silvicultural prescriptions. To address the current lack of automated methods for simultaneously detecting and quantifying slash piles from aerial remote sensing data, our objective in this work is to present a geometry-based approach that uses rules and user-defined thresholds applied to geometric features (such as area, shape, and height) to identify and quantify slash piles from UAS-DAP point cloud data.

Geometric, rules-based object detection methods offer advantages over model-based approaches, primarily because they eliminate the need for extensive training data which might be limited in it's transferrability to unseen conditions. Models are often considered "black boxes" but rules-based methods rely on the inherent physical properties of the target objects themselves. This transparency allows for a high degree of interpretability as every segmentation result can be traced back to specific geometric constraints. Furthermore, this approach aligns perfectly with the expertise of land managers, as the input parameters like minimum height and area thresholds are the physical metrics commonly used in forest inventories and silvicultural prescriptions. By using these intuitive thresholds, the method becomes accessible to managers who possess a good understanding of the landscape they manage.

To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation or DBSCAN (Density-Based Spatial Clustering of Applications with Noise). Both of these methods are common in segmenting individual trees and coarse woody debris from CHM data.

## Demonstration Area

we'll focus on a 2,000 square meter example area

```{r, include = F, eval = F}
mapview::mapview(psinf_stand_boundary, color = "black", lwd = 1, alpha.regions = 0, label = FALSE, popup = FALSE) +
  mapview::mapview(psinf_slash_piles_polys)
```

```{r}
# boundary
aoi_boundary <- 
  psinf_slash_piles_polys %>% 
  # dplyr::filter(pile_id == 195) %>% # machine
  # dplyr::filter(pile_id == 74) %>% # hand
  dplyr::filter(pile_id == 71) %>% # hand
  # arnf_slash_piles_polys %>% 
  # dplyr::filter(pile_id == 14) %>%
  sf::st_centroid() %>% 
  sf::st_buffer(
    # sqrt(9600/4) ## numerator = desired plot size in m2
    sqrt(4500/4) ## numerator = desired plot size in m2
    , endCapStyle = "SQUARE"
  ) %>%
  dplyr::mutate(dummy=1)
# rgb
aoi_rgb_rast <- psinf_rgb_rast %>% 
  terra::crop(
    aoi_boundary %>% 
      sf::st_buffer(3*2) %>% 
      sf::st_transform(terra::crs(psinf_rgb_rast)) %>% 
      terra::vect()
    , mask = T
  )
# chm
aoi_chm_rast <- psinf_chm_rast %>% 
  terra::crop(
    aoi_boundary %>% 
      sf::st_buffer(3) %>% 
      sf::st_transform(terra::crs(psinf_chm_rast)) %>% 
      terra::vect()
    , mask = T
  )
# piles
aoi_slash_piles_polys <- psinf_slash_piles_polys %>% 
  dplyr::inner_join(
    psinf_slash_piles_polys %>% 
      sf::st_intersection(aoi_boundary) %>% 
      sf::st_drop_geometry() %>% 
      dplyr::select(pile_id)
    , by = "pile_id"
  )
# ggplot base
aoi_plt_ortho <- ortho_plt_fn(rgb_rast = aoi_rgb_rast, stand = aoi_boundary, buffer = 3)
# aoi_plt_ortho
```

look at the demonstration area (plots using `ggplot2` for maximum customization)

here is the CHM of the example area. can you pick out the slash piles?

```{r}
plt_aoi_chm <- function(chm) {
  chm %>% 
    terra::as.data.frame(xy=T) %>% 
    dplyr::rename(f=3) %>% 
    ggplot2::ggplot() +
    ggplot2::geom_tile(mapping = ggplot2::aes(x=x,y=y,fill=f)) +
    ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
    ggplot2::scale_fill_viridis_c(option = "plasma") +
    ggplot2::labs(fill = "CHM (m)") +
    ggplot2::scale_x_continuous(expand = c(0, 0)) +
    ggplot2::scale_y_continuous(expand = c(0, 0)) +
    ggplot2::theme_void() +
    ggplot2::theme(legend.position = "top") 
}
plt_aoi_chm(aoi_chm_rast)
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_01_chm.jpg", height = 8, width = 8)
p_temp <- plt_aoi_chm(aoi_chm_rast) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  )
ggplot2::ggsave(plot = p_temp, filename = "../data/workflow_ex_011_chm_piles.jpg", height = 8, width = 8)
p_temp <- plt_aoi_chm(aoi_chm_rast) +
  ggplot2::theme(legend.position = "none")
ggplot2::ggsave(plot = p_temp, filename = "../data/workflow_ex_012_chm_noleg.jpg", height = 8, width = 8)
```

here is the RGB of the example area. can you pick out the slash piles?

```{r,eval=F}
aoi_plt_ortho + 
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8)
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_02_rgb.jpg", height = 8, width = 8)
```

we'll add on the ground truth piles in blue on the RGB. how many did you find? be honest.

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_03_rgb.jpg", height = 8, width = 8)
```

would you have done better if you had both the CHM and RGB data?

```{r,eval=F}
plt_aoi_chm_rgb <- function(chm) {
 aoi_plt_ortho +
    ggnewscale::new_scale_fill() +
    ggplot2::geom_tile(
      data = chm %>%
        terra::as.data.frame(xy=T) %>%
        dplyr::rename(f=3)
      , mapping = ggplot2::aes(x=x,y=y,fill=f)
      , alpha = 0.4
      , inherit.aes = F
    ) +
    ggplot2::scale_fill_viridis_c(option = "plasma") +
    ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
    ggplot2::theme(legend.position = "none") 
}
plt_aoi_chm_rgb(aoi_chm_rast) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  )
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_03_rgb_chm.jpg", height = 8, width = 8)
```

## Segmentation Methods

Our slash pile detection approach will align with the land manager knowledge of physical metrics of slash pile form which are commonly used in forest inventories and silvicultural prescriptions. We'll start with input parameters like height and area thresholds.

the first step in this approach is to isolate the lower "slice" of the CHM based on a maximum height threshold defined by the upper limit of the expected slash pile height. the expected height range to search for slash piles should be based on the pile construction prescription and potentially adjusted based on a sample of field-measured values after treatment completion

we'll set a maximum height threshold (`max_ht_m`) which filters the CHM to only include raster cells lower than this threshold. we'll also set a lower height limit (`min_ht_m`) based on the expected slash pile height for use later in removing candidate segments that are shorter than this lower limit.

```{r}
# set the max and min expected pile height
max_ht_m <- 4
min_ht_m <- 0.5
# lower CHM slice
aoi_chm_rast_slice <- terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F)
```

plot the lower slice, notice how the CHM height scale has changed

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_04_chm.jpg", height = 8, width = 8)
```

already, it looks like the piles should be distinguishable objects from this data

our rules-based pile detection methodology will also rely on area thresholds to define a search space and filter candidate segments. like height, we'll also set a minimum (`min_area_m2`) and maximum (`max_area_m2`) pile 2D area (in square meters) to search and filter for valid candidate objects. As with the height, these thresholds should be set based on the pile construction prescription or estimates or sample measurements from field visits.

```{r}
# set the max and min expected pile area
min_area_m2 <- 2
# Two standard US parking spaces, typically measuring 9 feet by 18 feet, 
# are roughly equivalent to 30.25 square meters. Each space is approximately 15.125 square meters.
# 15.125*3
max_area_m2 <- 50
```

to summarize, the size-based thresholds of our geometric, rules-based approach for detecting slash piles from CHM data are:

* `max_ht_m` : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific "slice" of the data, ignoring anything taller than a typical pile.
* `min_ht_m` : numeric. The minimum height (in meters) a detected pile must reach to be considered valid.
* `min_area_m2` : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid.
* `max_area_m2` : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid.

### Overview of Methods

The two primary segmentation methods we'll test are watershed segmentation and DBSCAN. Watershed segmentation, which we'll implement with `lidR::watershed()`, is a raster-based technique that treats a CHM as a topographic surface where height values are inverted to create basins. The algorithm identifies local maxima as "seeds" and expands them until they reach a boundary or "watershed" line. This method requires a tolerance parameter (`tol`) which defines "the minimum height of the object...between its highest point (seed) and the point where it contacts another object...If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest. Tolerance should be chosen according to the range of x." An extent parameter (`ext`) is used to define the search window for object seeds.

The DBSCAN algorithm, which we'll implement with `dbscan::dbscan()`, is typically a point-based clustering algorithm that groups points based on their spatial density but DBSCAN can also be applied to raster data by converting the raster cells into a 2D point set using the cell centroids. The algorithm relies on an epsilon parameter (`eps`), which defines the search radius around a point, and a minimum points parameter (`minPts`), which sets the threshold for how many neighbors must exist within that radius to form a core cluster.

Dynamically defining these parameters is critical for the usability and scalability of the method because it removes the guesswork typically required when moving between different datasets. For example, point clouds can vary in point density depending on the flight altitude or sensor, and rasters can vary in resolution. If parameters are kept static, a model tuned for a specific data structure or target object will be suboptimal for different data. We can link the segmentation algorithm parameters directly to the input data structure and the expected target object size so that the method automatically recalibrates itself.

In applying a similar, rules-based methodology for coarse woody debris detection from point cloud data, [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) recommend setting algorithm parameters based on minimum expected object size to be detected and point density.

We developed dynamic logic to automatically bridge the gap between the expectation of the target object form (height and area thresholds) and the representation of the object in the data by using geometric ratios. For watershed segmentation, the tolerance (`tol`) is scaled to the height range of the target objects to ensure sensitivity to the vertical variability. The extent (`ext`) is calculated by converting the physical radius of the smallest expected object into a pixel count based on the raster resolution. For DBSCAN, the epsilon parameter (`eps`) is calculated to bridge the average gap between points (or the distance between raster cell centroids) but is capped to prevent the merging of adjacent objects. The minimum points (`minPts`) parameter is scaled by the ratio of the search area (`eps`) to the total object area, ensuring that a cluster only forms if the local point density is representative of a valid target object.

| Method | Parameter | Parameter Description | Our Dynamic Logic (R-style pseudo-code) | Logic Explanation | Why our dynamic logic works |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Watershed** | `tol` | Minimum height difference to distinguish objects. | `(max_ht_m - min_ht_m) * 0.50` | Subtract the min height from the max height and take 50% of that total range. | Adapts vertical sensitivity to the "range of x," preventing minor height fluctuations from creating false objects. |
| **Watershed** | `ext` | Radius of the search window for detecting seeds. | `max(1, round((sqrt(min_area_m2 / pi) * 0.5) / res))` | Calculate the target's radius, halve it, then divide by the pixel size to get a pixel count (minimum of 1). | Uses half the target radius to increase local sensitivity, allowing the algorithm to find distinct seeds in crowded areas. |
| **DBSCAN** | `eps` | Maximum distance to consider points as neighbors. | `min(1.5 * (1/sqrt(density)), (sqrt(min_area_m2 / pi) * 0.50))` | Take the smaller of: 1.5 the average point spacing OR 50% of the target's physical radius. | Bridges gaps between points while capping the radius at 50% of the target diameter to ensure objects remain spatially separated. |
| **DBSCAN** | `minPts` | Minimum points required to form a cluster core. | `round((min_area_m2 * density) * (eps^2 / (min_area_m2 / pi)))` | Multiply total expected points by the ratio of the search circle area to the total target area. | Adjusts the minimum point threshold to ensure that core points are only identified where the local cluster is as dense as the actual target object is expected to be. |

let's define a function to get these parameters based on the user-defined size thresholds and the input data description

```{r}
# function to get segmentation parameters
get_segmentation_params <- function(
  max_ht_m
  , min_ht_m
  , min_area_m2
  , max_area_m2
  , pts_per_m2 = NULL
  , rast_res_m = NULL
){
  
  # check for missing required values
  if (missing(max_ht_m) || missing(min_ht_m) || 
      missing(min_area_m2) || missing(max_area_m2)) {
    stop("all geometric constraints (max_ht_m, min_ht_m, min_area_m2, max_area_m2) must be defined.")
  }
  
  # geometric param validation
  if (max_ht_m <= min_ht_m) {
    stop("max_ht_m must be greater than min_ht_m.")
  }
  if (max_area_m2 <= min_area_m2) {
    stop("max_area_m2 must be greater than min_area_m2.")
  }
  if (min_ht_m < 0 || min_area_m2 < 0) {
    stop("height and area constraints must be positive values.")
  }
  
  # data structure validation and calculation
  if (is.null(pts_per_m2) && is.null(rast_res_m)) {
    stop("must provide either 'pts_per_m2' (pts/m2) or 'rast_res_m' (m/pixel).")
  }
  
  # calculate and validate data str values
  if (is.null(pts_per_m2)) {
    if (rast_res_m <= 0) stop("rast_res_m must be a positive value.")
    pts_per_m2 <- 1 / (rast_res_m^2)
  }
  if (is.null(rast_res_m)) {
    if (pts_per_m2 <= 0) stop("pts_per_m2 must be a positive value.")
    rast_res_m <- 1 / sqrt(pts_per_m2)
  }
  ################################################
  # lidR::watershed / EBImage::watershed
  ################################################
  # lidR::watershed `tol`
  # set based on the height range
  height_range <- max_ht_m - min_ht_m
  # scale it to increase the sensitivity to distinguish smaller objects
  tol_val <- height_range * 0.5
  
  # lidR::watershed `ext`
  # use half the radius of the minimum object to increase sensitivity
  # this helps prevent merging nearby objects (under-segmentation)
  target_radius_m <- sqrt(min_area_m2 / pi)
  effective_radius_m <- target_radius_m * 0.5
  ext_val <- max(1, round(effective_radius_m / rast_res_m))
  
  ################################################
  # dbscan::dbscan
  ################################################
  # dbscan::dbscan `eps` (epsilon)
  # [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) recommended to set this value based:
    # "on the minimum cluster size to be detected and point density"
  
  # start by scaling based on point spacing (1.5x average distance between points).
  spacing <- 1 / sqrt(pts_per_m2)
  connectivity_eps <- 1.5 * spacing
  # eps should not exceed 50% of the minimum object radius 
    # to avoid merging separate objects into one cluster.
  max_allowable_eps <- effective_radius_m * 0.5
  # cap eps by the object size constraint
  eps_val <- min(connectivity_eps, max_allowable_eps)
  
  # dbscan::dbscan `minPts`
  # based on expected points within the epsilon neighborhood area
  
  # get expected number of points in an object of min_area_m2
  expected_pts_in_min_object <- min_area_m2 * pts_per_m2
  
  # ensure a core point is surrounded by a density of points based on min_area_m2 size at point density
  # scale the total expected points of the minimum object 
    # by the ratio of the epsilon-neighborhood area to the total minimum object area
    # to ensure a core point meets the expected density of the target object
  pts_ratio_calc <- expected_pts_in_min_object * (eps_val^2 / target_radius_m^2)
  min_pts_val <- max(
    5 # don't go any lower than the dbscan::dbscan() default
    , round(pts_ratio_calc)
  )
  
  # return
  return(list(
    data_summary = list(pts_per_m2 = pts_per_m2, rast_res_m = rast_res_m),
    watershed = list(tol = tol_val, ext = ext_val),
    dbscan = list(eps = eps_val, minPts = min_pts_val)
  ))
}
```

let's test our `get_segmentation_params()` function using the size threshold parameters we defined above: `max_ht_m`, `min_ht_m`, `min_area_m2`, `max_area_m2` and we can get the raster resolution directly from our input CHM

```{r}
# get_segmentation_params
get_segmentation_params_ans <- get_segmentation_params(
    max_ht_m = max_ht_m
    , min_ht_m = min_ht_m
    , min_area_m2 = min_area_m2
    , max_area_m2 = max_area_m2
    # , pts_per_m2 = NULL
    , rast_res_m = terra::res(aoi_chm_rast_slice)[1]
  )
# huh?
dplyr::glimpse(get_segmentation_params_ans)
```

we can see how these parameters change if the CHM resolution changes

```{r}
get_segmentation_params(
    max_ht_m = max_ht_m
    , min_ht_m = min_ht_m
    , min_area_m2 = min_area_m2
    , max_area_m2 = max_area_m2
    # , pts_per_m2 = NULL
    , rast_res_m = 0.5
  ) %>% 
  dplyr::glimpse()
```

and we can see how these parameters change using our CHM data but change the expected minimum pile 2D area

```{r}
get_segmentation_params(
    max_ht_m = max_ht_m
    , min_ht_m = min_ht_m
    , min_area_m2 = 22
    , max_area_m2 = max_area_m2
    # , pts_per_m2 = NULL
    , rast_res_m = terra::res(aoi_chm_rast_slice)[1]
  ) %>% 
  dplyr::glimpse()
```

the table summarizes how our rules-based approach creates dynamic parameters for use in watershed and DBSCAN segmentation. The height parameters manage vertical noise, the area parameters manage horizontal separation, and the data resolution parameters ensure the math stays consistent regardless of data density (raster resolution or point cloud point density).

| Dynamic Parameter | Impact of Height (`max_ht_m` / `min_ht_m`) | Impact of Target Area (`min_area_m`) | Impact of Data Resolution (`res` / `density`) |
| :--- | :--- | :--- | :--- |
| **Watershed `tol`** | **Direct Driver:** Sets the vertical threshold at 50% of the target's height range. | **None:** Vertical tolerance is independent of horizontal footprint. | **None:** Vertical sensitivity is independent of horizontal resolution. |
| **Watershed `ext`** | **None:** Horizontal search window is independent of vertical range. | **Geometric Baseline:** Defines the physical radius used to scale the search window. | **Spatial Divider:** Converts the physical radius into a specific pixel count for the image matrix. |
| **DBSCAN `eps`** | **None:** Point-to-point connectivity is independent of height. | **Physical Cap:** Provides a half-radius limit to prevent clusters from merging across objects. | **Connectivity Anchor:** Sets the search radius based on the average distance between points/raster cell centroids |
| **DBSCAN `minPts`** | **None:** Required point mass is independent of vertical range. | **Total Mass Baseline:** Defines the total expected points for the smallest valid target. | **Density Multiplier:** Calculates the local point count requirement relative to the data density. |

```{r}
sim_df_temp <-
  tidyr::crossing(
    rast_res_m = seq(0.1, 1.3, by = 0.1)
    , min_area_m2 = seq(1, 50, length.out = 33)
  ) %>% 
  dplyr::mutate(
    # Call the pre-defined function directly to ensure logic alignment
    params = purrr::map2(
      rast_res_m, min_area_m2, ~ get_segmentation_params(
        max_ht_m = max_ht_m
        , min_ht_m = min_ht_m
        , min_area_m2 = .y
        , max_area_m2 = .y * 5
        , rast_res_m = .x
      )
    )
    
    # Extract values into individual columns for plotting
    , ext = purrr::map_dbl(params, ~ .x$watershed$ext)
    , eps = purrr::map_dbl(params, ~ .x$dbscan$eps)
    , min_pts = purrr::map_dbl(params, ~ .x$dbscan$minPts)
  )
  # # Pivot to long format for faceted plotting
  # tidyr::pivot_longer(
  #   cols = c(ext, eps, min_pts),
  #   names_to = "parameter",
  #   values_to = "value"
  # )
# sim_df_temp %>% dplyr::glimpse()

# plot
p1_temp <-
  ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = ext)) +
  ggplot2::geom_tile(col = "gray") +
  ggplot2::scale_fill_viridis_c(option = "magma") +
  ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::labs(title = "Watershed: `ext` (pixels)", fill = "pixels") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom", plot.title = ggplot2::element_text(size = 9))

p2_temp <-
  ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = eps)) +
  ggplot2::geom_tile(col = "gray") +
  ggplot2::scale_fill_viridis_c(option = "magma") +
  ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::labs(title = "DBSCAN: `eps` (meters)", fill = "meters") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom", plot.title = ggplot2::element_text(size = 9))

p3_temp <-
  ggplot2::ggplot(sim_df_temp, ggplot2::aes(x = rast_res_m, y = min_area_m2, fill = min_pts)) +
  ggplot2::geom_tile(col = "gray") +
  ggplot2::scale_fill_viridis_c(option = "magma") +
  ggplot2::scale_x_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::scale_y_continuous(expand = c(0, 0), breaks = scales::breaks_extended(n=10)) +
  ggplot2::labs(title = "DBSCAN: `minPts` (count)", fill = "count") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom", plot.title = ggplot2::element_text(size = 9))

# 5. Combine using patchwork
(p1_temp + p2_temp + p3_temp) + 
  patchwork::plot_annotation(
    title = "Dynamic Watershed and DBSCAN Parameter Definition"
    , subtitle = "across raster resolution and minimum target area gradients"
    , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 10),plot.subtitle = ggplot2::element_text(size = 8))
  ) +
  patchwork::plot_layout(ncol = 3)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### Watershed Segmentation Demonstration

let's go through the watershed segmentation process using `lidR::watershed()` which is based on the bioconductor package `EBIimage`

```{r}
# ?EBImage::watershed
watershed_segs <- lidR::watershed(
    chm = aoi_chm_rast_slice
    # th_tree = Threshold below which a pixel cannot be a tree. Default is 2.
    , th_tree = 0.01
    # tol = minimum height of the object in the units of image intensity between its highest point (seed) 
      # and the point where it contacts another object (checked for every contact pixel). 
      # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest.
      # Tolerance should be chosen according to the range of x
    , tol = get_segmentation_params_ans$watershed$tol # max_ht_m-min_ht_m
    # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. 
      # Higher value smoothes out small objects.
    , ext = get_segmentation_params_ans$watershed$ext # 1
  )()
```

the result is a raster with cells segmented and given a unique identifier

```{r}
# this is a raster
watershed_segs
```

each value should be a unique "segment" which we can refine based on rules of expected size and shape of piles

```{r}
terra::freq(watershed_segs) %>% 
  dplyr::slice_sample(n = 10)
```

where the "value" is the segment identifier and the count is the number of raster cells assigned to that segment

how many predicted segments are there?

```{r}
terra::freq(watershed_segs) %>% dplyr::filter(!is.na(value)) %>% nrow()
```

let's plot the raster return from the watershed segmentation

```{r}
watershed_segs %>% 
  terra::as.factor() %>% 
  terra::plot(
    col = c(
      viridis::turbo(n = terra::minmax(watershed_segs)[2])
      # , viridis::viridis(n = floor(terra::minmax(watershed_segs)[2]/3))
      # , viridis::cividis(n = floor(terra::minmax(watershed_segs)[2]/3))
    ) %>% sample()
    , legend = F
    , axes = F
  )
```

plot the watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs %>% 
      terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
      setNames("pred_id") %>%
      sf::st_as_sf() %>% 
      sf::st_simplify() %>% 
      sf::st_make_valid() %>% 
      dplyr::filter(sf::st_is_valid(.))
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_05_rgb_wshed_cnddts.jpg", height = 8, width = 8)
```

plot the watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs %>% 
      terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
      setNames("pred_id") %>%
      sf::st_as_sf() %>% 
      sf::st_simplify() %>% 
      sf::st_make_valid() %>% 
      dplyr::filter(sf::st_is_valid(.))
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_05_chm_wshed_cnddts.jpg", height = 8, width = 8)
```

nice...we are getting close.

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### DBSCAN Segmentation Demonstration

```{r, include=FALSE, eval=FALSE}
# set the dbscan parameters based on minimum expected object size and point density
# min_area_m2 <- 2.5
# the minimum cluster size to be detected based on the minimum object area expected (min_area_m2)
# circular radius = epsilon = sqrt(min_area_m2/pi)
(epsilon <- sqrt(min_area_m2/pi)*1.1) # *1.01 # could make this slightly larger to avoid over-segmenting
# depends on the point density and expected size of WD objects
# could do math based on input point cloud density and expected minimum size
# expected points in the smallest object size expected = 
  # minPts = avg_pts_per_m2 * min_area_m2
# las_planar # check this point density
# las_planar %>% lidR::filter_poi(planar==F) # check this point density
# ( nrow(est_wd_pts_sf) / (lidR::st_bbox(las) %>% sf::st_as_sfc() %>% sf::st_as_sf() %>% sf::st_area() %>% as.numeric()) ) # check this point density
# !!!!! for rasters...points/m2 = 1 m2 / cell area m2 = points
avg_pts_per_m2 <- 1/prod(terra::res(aoi_chm_rast_slice)[1:2])
# avg_pts_per_m2
minPts <- max( # don't go any lower than the dbscan::dbscan() default
  5 # the dbscan::dbscan() default
  , ceiling(avg_pts_per_m2 * min_area_m2)
)
## XY df
xy_df <- terra::as.data.frame(aoi_chm_rast_slice, xy = T) %>% 
  dplyr::rename(
    X=x,Y=y
    , f=3
  ) %>% 
  dplyr::filter(!is.na(f)) %>% 
  dplyr::select(X,Y)
# xy_df %>% dplyr::glimpse()
# ggplot2::ggplot(data = xy_df, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=".")

epsilon
# ?dbscan::dbscan
db <- dbscan::dbscan(
  x = xy_df
    # est_wd_pts_sf %>% sf::st_drop_geometry() %>% dplyr::select(X,Y)
  # eps primarily controls the spatial extent of a cluster, 
  # as it defines how far points can be from each other to be considered part of the same dense region.
  , eps = epsilon
  # minPts primarily controls the minimum density of a cluster, 
  # as it dictates how many points must be packed together within that eps radius.
  , minPts = minPts
)
# # huh?
# db$cluster %>% length()
# nrow(xy_df)

# add the cluster to the data
xy_df$cluster <- db$cluster
summary(db$cluster)
# xy_df %>% dplyr::glimpse()

# xy_df %>% 
#   sf::st_as_sf(coords = c("X", "Y"), crs = terra::crs(aoi_chm_rast_slice), remove = F) %>%
#   sf::st_intersection(aoi_slash_piles_polys %>% dplyr::slice(1)) %>% 
#   ggplot2::ggplot(mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=".")

# fill the rast with the cluster values
dbscan_ans <- terra::rasterize(
    x = xy_df %>% 
      sf::st_as_sf(coords = c("X", "Y"), crs = terra::crs(aoi_chm_rast_slice), remove = F) %>%
      dplyr::ungroup() %>% 
      dplyr::select(cluster) %>% 
      terra::vect()
    , y = aoi_chm_rast_slice
    , field = "cluster"
  )
dbscan_ans %>% terra::as.factor() %>% terra::plot()
# "0" clusters are noise which should be dropped
# convert to vector
dbscan_ans_poly <- 
  dbscan_ans %>% 
  terra::subst(from = 0, to = NA) %>% 
  terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
  setNames("pred_id") %>%
  sf::st_as_sf() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
dbscan_ans_poly %>% dplyr::glimpse()
dbscan_ans_poly %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = as.factor(pred_id)), color = NA) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  )


watershed_ans %>% 
  terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
  sf::st_as_sf() %>% 
  dplyr::mutate(area = sf::st_area(.) %>% as.numeric()) %>% 
  dplyr::filter(area>3) %>% 
  # dplyr::filter(focal_mean==25) %>% 
  ggplot2::ggplot() + ggplot2::geom_sf(mapping = ggplot2::aes(fill=as.factor(focal_mean)), color = NA)
```

let's go through the DBSCAN segmentation process using `dbscan::dbscan()` which uses a kd-tree for efficient processing. As an aside, the `RANN` [package](https://jefferislab.github.io/RANN/) enables KD-tree searching/processing using the X and Y coordinates of the entire point cloud to build the tree which is a super-fast way to find the `x` number of near neighbors for each point in an input dataset (see `RANN::nn2()`).

because the DBSCAN process is a point-based clustering algorithm that groups points based on their spatial density we need to convert the raster cells into a 2D point set using the cell centroids first

```{r}
## XY df
xy_df_temp <- 
  aoi_chm_rast_slice %>% 
  # na.rm = T ensures we only process cells with CHM data
  terra::as.data.frame(xy = T, na.rm = T) %>% 
  dplyr::rename(
    X=x,Y=y
    , f=3
  ) %>% 
  dplyr::select(X,Y)
# huh?
xy_df_temp %>% dplyr::glimpse()
# ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=".")
```

now, we can apply the `dbscan::dbscan()` function using the parameters we identified using our dynamic process defined in `get_segmentation_params()` 

```{r}
# get_segmentation_params_ans %>% dplyr::glimpse()
# ?dbscan::dbscan
dbscan_ans_temp <- dbscan::dbscan(
  x = xy_df_temp
  # eps primarily controls the spatial extent of a cluster, 
  # as it defines how far points can be from each other to be considered part of the same dense region.
  , eps = get_segmentation_params_ans$dbscan$eps
  # minPts primarily controls the minimum density of a cluster, 
  # as it dictates how many points must be packed together within that eps radius.
  , minPts = get_segmentation_params_ans$dbscan$minPts
)
# huh?
dbscan_ans_temp %>% str()
```

the result is a vector with a `cluster` identifier for each point we provided to the algorithm

```{r}
identical(
  length(dbscan_ans_temp$cluster)
  , nrow(xy_df_temp)
)
```

add the cluster identifier to the XY point data

```{r}
# add the cluster to the data
xy_df_temp$cluster <- dbscan_ans_temp$cluster
# what?
xy_df_temp %>% 
  dplyr::count(cluster) %>% 
  dplyr::arrange(desc(n)) %>% 
  head()
```

to maintain processing consistency with the watershed result, we'll rasterize the XY data back to the original CHM grid. this will result in a raster with cells segmented and given the unique identifier. 

*Note*: the cells/segments classified as noise from the `dbscan::dbscan()` algorithm are marked with a cluster identifier as "0"...we'll remove these prior to rasterizing

```{r}
# fill the rast with the cluster values
dbscan_segs <- terra::rasterize(
  x = xy_df_temp %>% 
    dplyr::filter(cluster!=0) %>% 
    sf::st_as_sf(coords = c("X", "Y"), crs = terra::crs(aoi_chm_rast_slice), remove = F) %>%
    dplyr::ungroup() %>% 
    dplyr::select(cluster) %>% 
    terra::vect()
  , y = aoi_chm_rast_slice
  , field = "cluster"
)
```

the result is a raster with cells segmented and given a unique identifier

```{r}
# this is a raster
dbscan_segs
```

each value should be a unique "segment" which we can refine based on rules of expected size and shape of piles

```{r}
terra::freq(dbscan_segs) %>% 
  dplyr::arrange(desc(count)) %>% 
  head()
```

where the "value" is the segment identifier and the count is the number of raster cells assigned to that segment (compare to the count of the segmented points above ;)

how many predicted segments are there?

```{r}
terra::freq(dbscan_segs) %>% dplyr::filter(!is.na(value)) %>% nrow()
```

let's plot the raster of the dbscan segmentation

```{r}
dbscan_segs %>% 
  terra::as.factor() %>% 
  terra::plot(
    col = c(
      viridis::turbo(n = terra::minmax(dbscan_segs)[2])
    ) %>% sample()
    , legend = F
    , axes = F
  )
```

plot the watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs %>% 
      terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
      setNames("pred_id") %>%
      sf::st_as_sf() %>% 
      sf::st_simplify() %>% 
      sf::st_make_valid() %>% 
      dplyr::filter(sf::st_is_valid(.))
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_05_rgb_dbscan_cnddts.jpg", height = 8, width = 8)
```

plot the watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs %>% 
      terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
      setNames("pred_id") %>%
      sf::st_as_sf() %>% 
      sf::st_simplify() %>% 
      sf::st_make_valid() %>% 
      dplyr::filter(sf::st_is_valid(.))
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_05_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

nice...we are getting close.

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### Comparison of Candidate Segments

we'll start by converting the candidate segments to polygons

```{r}
# watershed_segs
watershed_segs_poly <-
  watershed_segs %>% 
  terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
  setNames("pred_id") %>%
  sf::st_as_sf() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>%
  dplyr::filter(sf::st_is_valid(.))
# dbscan_segs
dbscan_segs_poly <- 
  dbscan_segs %>% 
  terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
  setNames("pred_id") %>%
  sf::st_as_sf() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
```

count the number of unique candidate segments from each method and summarize the area covered by all segments

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , segments = c(
      terra::freq(watershed_segs) %>% nrow()
      , terra::freq(dbscan_segs) %>% nrow()
    )
    , area = c(
      watershed_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
      , dbscan_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    segments = scales::comma(segments,accuracy=1)
    , area = scales::comma(area,accuracy=0.01)
  ) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method"
    , col.names = c(
      "method", "candidate segments", "area (m<sup>2</sup>)"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

notice the dbscan segments cover a smaller area because noise points are identified and removed as part of the algorithm. in the next stage of our method, we'll include additional noise removal applied to both methodologies. In fact, all processing will be the same from here forward for both segementation methodologies.

### Segmentation Function

let's make a function to perform either the watershed (`lidR::watershed()`) or DBSCAN (`dbscan::dbscan()`) segmentation given an input CHM raster, target height range, and target area range. the output will include a raster and `sf` polygons of the candidate segments

```{r}
############################################################################
# DBSCAN function
# to align input of raster and output of raster as in lidR::watershed()
# this enables dbscan, typically a point-based method, 
# to be implemented with raster input data by using cell centroids
############################################################################
get_segs_dbscan <- function(
  chm_rast
  , eps
  , minPts
) {
  ########################
  # check raster
  ########################
  # convert to SpatRaster if input is from 'raster' package
  if(
    inherits(chm_rast, "RasterStack") 
    || inherits(chm_rast, "RasterBrick")
  ){
    chm_rast <- terra::rast(chm_rast)
  }else if(!inherits(chm_rast, "SpatRaster")){
    stop("Input 'chm_rast' must be a SpatRaster from the `terra` package")
  }
  # first layer only
  if(terra::nlyr(chm_rast)>1){warning("...only using first layer of raster stack for segmentation")}
  chm_rast <- chm_rast %>% terra::subset(subset = 1)
  # na check
  if(
    as.numeric(terra::global(chm_rast, fun = "isNA")) == terra::ncell(chm_rast) 
    # || as.numeric(terra::global(chm_rast, fun = "isNA")) >= round(terra::ncell(chm_rast)*0.98)
  ){
    stop("Input 'chm_rast' has all missing values")
  }
  
  ########################
  # get cell centroids as points
  ########################
  ## XY df
  xy_df_temp <- 
    chm_rast %>% 
    # na.rm = T ensures we only process cells with CHM data
    terra::as.data.frame(xy = T, na.rm = T) %>% 
    dplyr::rename(
      X=x,Y=y
      , f=3
    ) %>% 
    dplyr::select(X,Y)
  # huh?
  # xy_df_temp %>% dplyr::glimpse()
  # ggplot2::ggplot(data = xy_df_temp, mapping = ggplot2::aes(x=X,y=Y)) + ggplot2::geom_point(shape=".")
  
  if(nrow(xy_df_temp)==0){stop("Input 'chm_rast' has all missing values")}
  
  ########################
  # dbscan::dbscan()
  ########################
  # ?dbscan::dbscan
  dbscan_ans_temp <- dbscan::dbscan(
    x = xy_df_temp
    # eps primarily controls the spatial extent of a cluster, 
    # as it defines how far points can be from each other to be considered part of the same dense region.
    , eps = eps
    # minPts primarily controls the minimum density of a cluster, 
    # as it dictates how many points must be packed together within that eps radius.
    , minPts = minPts
  )
  # ensure the result is a vector with a `cluster` identifier for each point we provided to the algorithm
  if(
    !identical(
      length(dbscan_ans_temp$cluster)
      , nrow(xy_df_temp)
    )
  ){
    stop("dbscan::dbscan() length mismatch")
  }
  # add the cluster identifier to the XY point data
  xy_df_temp$cluster <- dbscan_ans_temp$cluster
  # # what?
  # xy_df_temp %>% 
  #   dplyr::count(cluster) %>% 
  #   dplyr::arrange(desc(n)) %>% 
  #   head()
  
  if(
    nrow( xy_df_temp %>% dplyr::filter(cluster!=0) ) == 0
  ){
    stop("dbscan::dbscan() result is all noise based on 'eps' and 'minPts'. try adjusting these parameters.")
  }
  
  ########################
  # back to raster data
  ########################
  # to maintain processing consistency with the watershed result
    # we'll rasterize the XY data back to the original CHM grid
    # this will result in a raster with cells segmented and given the unique identifier. 
    # *Note*: the cells/segments classified as noise from the `dbscan::dbscan()` 
    # algorithm are marked with a cluster identifier as "0"...we'll remove these prior to rasterizing
  # fill the rast with the cluster values
  dbscan_segs <- terra::rasterize(
    x = xy_df_temp %>% 
      dplyr::filter(cluster!=0) %>% 
      sf::st_as_sf(coords = c("X", "Y"), crs = terra::crs(chm_rast), remove = F) %>%
      dplyr::ungroup() %>% 
      dplyr::select(cluster) %>% 
      terra::vect()
    , y = chm_rast
    , field = "cluster"
  ) %>% 
  setNames("cluster")
  # the result is a raster with cells segmented and given a unique identifier
  # this is a raster
  # dbscan_segs
  return(dbscan_segs)
}
# # ?dbscan::dbscan
# get_segs_dbscan(aoi_chm_rast_slice, minPts = 5, eps = 1) %>% 
#   terra::as.factor() %>% 
#   terra::plot(legend = F, col = grDevices::rainbow(n=111) %>% sample() )

############################################################################
# intermediate function to check string method
############################################################################
  # check the `method` argument
  check_segmentation_method <- function(method) {
    if(!inherits(method,"character")){stop("no method")}
      # clean method
      method <- dplyr::coalesce(method, "") %>%
        tolower() %>%
        stringr::str_squish() %>% 
        unique()
      # potential methods
      pot_methods <- c("watershed", "dbscan") %>% unique()
      find_method <- paste(pot_methods, collapse="|")
      # can i find one?
      which_methods <- stringr::str_extract_all(string = method, pattern = find_method) %>%
        unlist() %>%
        unique()
      # make sure at least one is selected
      n_methods_not <- base::setdiff(
          pot_methods
          , which_methods
        ) %>% 
        length()
      
      if(n_methods_not>=length(pot_methods)){
        stop(paste0(
          "`method` parameter must be one of:\n"
          , "    "
          , paste(pot_methods, collapse=", ")
        ))
      }else{
        return(which_methods)
      }
  }
# check_segmentation_method(c("watershed", "dbscn", "dbsca"))
# check_segmentation_method("dbscn")

############################################################################
# intermediate function to convert rast to polygon
############################################################################
rast_to_poly <- function(rast){
  # ?terra::as.polygons
  rast %>% 
    terra::subset(1) %>% 
    terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
    setNames("pred_id") %>%
    sf::st_as_sf() %>% 
    sf::st_simplify() %>% 
    sf::st_make_valid() %>%
    dplyr::filter(sf::st_is_valid(.))  
}
############################################################################
# full segmentation function
# given an input CHM raster, target height range, and target area range. 
# the output will include a raster and `sf` polygons of the candidate segments
# automatically adjusts segmentation method parameters using get_segmentation_params()
############################################################################
get_segmentation_candidates <- function(
  chm_rast
  , method = "watershed" # "watershed" or "dbscan"
  , max_ht_m
  , min_ht_m
  , min_area_m2
  , max_area_m2
){
  ########################
  # threshold checks
  ########################
  max_ht_m <- max_ht_m[1] 
  min_ht_m <- min_ht_m[1] 
  min_area_m2 <- min_area_m2[1] 
  max_area_m2 <- max_area_m2[1] 
  if(
    (is.na(tryCatch(as.numeric(max_ht_m), error = function(e) NA)) || 
     identical(as.numeric(max_ht_m), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(max_ht_m), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(min_ht_m), error = function(e) NA)) || 
     identical(as.numeric(min_ht_m), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(min_ht_m), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || 
     identical(as.numeric(max_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || 
     identical(as.numeric(min_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) ||
    !(as.numeric(max_ht_m) > as.numeric(min_ht_m)) ||
    !(as.numeric(max_area_m2) > as.numeric(min_area_m2)) ||
    as.numeric(max_ht_m)<0 ||
    as.numeric(min_ht_m)<0 ||
    as.numeric(min_area_m2)<0 ||
    as.numeric(max_area_m2)<0
  ){
    # Code to execute if any condition is met (e.g., print an error message)
    stop("Error: One or more of `max_ht_m`,`min_ht_m`,`min_area_m2`,`max_area_m2` are not valid numbers, or the conditions max_area_m2>min_area_m2 or max_ht_m>min_ht_m are not met.")
  }else{
    max_ht_m <- as.numeric(max_ht_m)[1] 
    min_ht_m <- as.numeric(min_ht_m)[1] 
    min_area_m2 <- as.numeric(min_area_m2)[1] 
    max_area_m2 <- as.numeric(max_area_m2)[1] 
  }
  
  ########################
  # check raster
  ########################
  # convert to SpatRaster if input is from 'raster' package
  if(
    inherits(chm_rast, "RasterStack") 
    || inherits(chm_rast, "RasterBrick")
  ){
    chm_rast <- terra::rast(chm_rast)
  }else if(!inherits(chm_rast, "SpatRaster")){
    stop("Input 'chm_rast' must be a SpatRaster from the `terra` package")
  }
  # first layer only
  if(terra::nlyr(chm_rast)>1){warning("...only using first layer of raster stack for segmentation")}
  chm_rast <- chm_rast %>% terra::subset(subset = 1)
  # na check
  if(
    as.numeric(terra::global(chm_rast, fun = "isNA")) == terra::ncell(chm_rast) 
    # || as.numeric(terra::global(chm_rast, fun = "isNA")) >= round(terra::ncell(chm_rast)*0.98)
  ){
    stop("Input 'chm_rast' has all missing values")
  }
  
  ########################
  # check method
  ########################
  check_segmentation_method_ans <- check_segmentation_method(method = method)
  if(length(check_segmentation_method_ans)>1){
    warning(
      paste0( "...using only ", check_segmentation_method_ans[1], " method for segmentation")
    )
  }
  check_segmentation_method_ans <- check_segmentation_method_ans[1]
  
  ########################
  # slice CHM
  ########################
  # lower CHM slice
  slice_chm_rast <- terra::clamp(aoi_chm_rast, upper = max_ht_m, lower = 0, values = F)
  # na check
  if(
    as.numeric(terra::global(slice_chm_rast, fun = "isNA")) == terra::ncell(slice_chm_rast) 
  ){
    stop("Input 'chm_rast' has no values at or below 'max_ht_m' value")
  }
  
  ########################
  # get_segmentation_params
  ########################
  # get_segmentation_params
  seg_params_ans <- get_segmentation_params(
      max_ht_m = max_ht_m
      , min_ht_m = min_ht_m
      , min_area_m2 = min_area_m2
      , max_area_m2 = max_area_m2
      # , pts_per_m2 = NULL
      , rast_res_m = terra::res(slice_chm_rast)[1]
    )
  # # huh?
  # dplyr::glimpse(seg_params_ans)
  
  ########################
  # segmentation
  ########################
  if(check_segmentation_method_ans=="watershed"){
    # ?EBImage::watershed
    segs_rast <- lidR::watershed(
      chm = slice_chm_rast
      # th_tree = Threshold below which a pixel cannot be a tree. Default is 2.
      , th_tree = 0.01
      # tol = minimum height of the object in the units of image intensity between its highest point (seed) 
        # and the point where it contacts another object (checked for every contact pixel). 
        # If the height is smaller than the tolerance, the object will be combined with one of its neighbors, which is the highest.
        # Tolerance should be chosen according to the range of x
      , tol = seg_params_ans$watershed$tol # max_ht_m-min_ht_m
      # ext = Radius of the neighborhood in pixels for the detection of neighboring objects. 
        # Higher value smoothes out small objects.
      , ext = seg_params_ans$watershed$ext # 1
    )()
    # match names of get_segs_dbscan()
    names(segs_rast) <- "cluster"
  }else if(check_segmentation_method_ans=="dbscan"){
    segs_rast <- get_segs_dbscan(
      chm_rast = slice_chm_rast
      , eps = seg_params_ans$dbscan$eps
      , minPts = seg_params_ans$dbscan$minPts
    )
  }else{
    stop("incorrect method selected")
  }
  
  # na check
  if(
    as.numeric(terra::global(segs_rast, fun = "isNA")) == terra::ncell(segs_rast) 
  ){
    warning("no segmentation candidates detected")
  }
  
  ########################
  # rast to poly
  ########################
  segs_sf <- rast_to_poly(segs_rast)
  
  ########################
  # return
  ########################
  return(list(
    segs_rast = segs_rast
    , segs_sf = segs_sf
  ))
}

# get_segmentation_candidates(
#   chm_rast = aoi_chm_rast
#   , method = "dbscan"
#   , min_ht_m = 1
#   , max_ht_m = 4
#   , min_area_m2 = 1.5^2
#   , max_area_m2 = 55
# )
```


## Candidate Shape Refinement and Area filtering

to better align the segmentation results with real-world pile construction we'll now simplify candidate segments composed of multiple separate parts representing a single identified feature (i.e. "multi-polygon" candidate segments. We'll simplify these segments by retaining only the largest contiguous portion using `cloud2trees` functionality. Because slash piles are constructed as distinct, isolated objects to prevent tree mortality during burning, this refinement step isolates the primary candidate body to eliminate detached noise and ensure each segment represents a discrete physical object before area-based filtering

using the candidate segment polygons, apply the `cloud2trees::simplify_multipolygon_crowns()` function which keeps only the largest part of multi-polygon geometries and works for all `sf` polygon data (even though the term "crowns" is in the name)

```{r}
# watershed_segs
watershed_segs_poly <-
  watershed_segs_poly %>% 
  # simplify multipolygons by keeping only the largest portion
  dplyr::mutate(treeID = pred_id) %>% 
  cloud2trees::simplify_multipolygon_crowns() %>% 
  dplyr::select(-treeID)
# dbscan_segs
dbscan_segs_poly <- 
  dbscan_segs_poly %>% 
  # simplify multipolygons by keeping only the largest portion
  dplyr::mutate(treeID = pred_id) %>% 
  cloud2trees::simplify_multipolygon_crowns() %>% 
  dplyr::select(-treeID)
```

we'll have the same number of unique candidate segments from each method but the area covered by those segments will now be smaller

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , segments = c(
      nrow(watershed_segs_poly)
      , nrow(dbscan_segs_poly)
    )
    , area = c(
      watershed_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
      , dbscan_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    segments = scales::comma(segments,accuracy=1)
    , area = scales::comma(area,accuracy=0.01)
  ) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method after removing noise polygon parts"
    , col.names = c(
      "method", "candidate segments", "area (m<sup>2</sup>)"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

now we'll remove all candidate segments that do not meet the area criteria based on the user-defined minimum and maximum area thresholds

```{r}
st_filter_area <- function(sf_data, min_area_m2, max_area_m2) {
  # check input data
  if(!inherits(sf_data, "sf")){stop("must pass `sf` data object")}
  if( !all(sf::st_is(sf_data, type = c("POLYGON", "MULTIPOLYGON"))) ){
    stop(paste0(
      "`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])"
    ))
  }  
  # check thresholds
  min_area_m2 <- min_area_m2[1] 
  max_area_m2 <- max_area_m2[1] 
  if(
    (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || 
     identical(as.numeric(max_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || 
     identical(as.numeric(min_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) ||
    !(as.numeric(max_area_m2) > as.numeric(min_area_m2)) ||
    as.numeric(min_area_m2)<0 ||
    as.numeric(max_area_m2)<0
  ){
    # Code to execute if any condition is met (e.g., print an error message)
    stop("Error: One or more of `min_area_m2`,`max_area_m2` are not valid numbers, or the condition max_area_m2>min_area_m2 not met.")
  }else{
    min_area_m2 <- as.numeric(min_area_m2)[1] 
    max_area_m2 <- as.numeric(max_area_m2)[1] 
  }
  # return
  return(
    sf_data %>% 
      dplyr::ungroup() %>% 
      # area filter
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      # filter out the segments that don't meet the size thresholds
      dplyr::filter(
        dplyr::coalesce(area_xxxx,0) >= min_area_m2
        & dplyr::coalesce(area_xxxx,0) <= max_area_m2
      ) %>% 
      dplyr::select(-c(area_xxxx))
  )
  
}
```

apply our `st_filter_area()` function

```{r}
# watershed_segs_poly
watershed_segs_poly <- 
  watershed_segs_poly %>% 
  st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2)
# dbscan_segs_poly
dbscan_segs_poly <- 
  dbscan_segs_poly %>% 
  st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2)
```

how many candidate segments were removed?

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , old_segments = c(
      terra::freq(watershed_segs) %>% nrow()
      , terra::freq(dbscan_segs) %>% nrow()
    )
    , new_segments = c(
      nrow(watershed_segs_poly)
      , nrow(dbscan_segs_poly)
    )
    , area = c(
      watershed_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
      , dbscan_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1)
    , dplyr::across(tidyselect::ends_with("segments"), ~scales::comma(.x,accuracy=1))
    , area = scales::comma(area,accuracy=0.01)
  ) %>% 
  dplyr::relocate(method,pct_removed) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method<br>filtered by segment area"
    , col.names = c(
      "method", "% removed"
      , "orig. candidate segments"
      , "filtered candidate segments"
      , "remaining candidate area (m<sup>2</sup>)"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

### Watershed Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_06_rgb_wshed_cnddts.jpg", height = 8, width = 8)
```

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_06_chm_wshed_cnddts.jpg", height = 8, width = 8)
```

nice...we are getting closer.

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### DBSCAN Segmentation

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_06_rgb_dbscan_cnddts.jpg", height = 8, width = 8)
```

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_06_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

nice...we are getting closer.

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### Quick methods comparison

let's quickly look at the watershed and dbscan segments on the same plot

```{r}
ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(color="watershed")
    , fill = NA, lwd = 2
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(color="dbscan")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("gray33", "aquamarine3"),name="") +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "top")
```

interesting.

## Candidate Geometric filtering

slash piles are man-made objects typically constructed into common geometric forms in 2D (e.g. circular base) and 3D space (e.g. paraboloid) to facilitate efficient construction and burning [Hardy 1996](https://permanent.fdlp.gov/gpo45282/index.htm). Our method leverages these traits by applying independent geometric filters to refine candidate segments. 

First, we apply a regularity filter to remove candidates with irregularly-shaped bases. Then, an independent circularity filter removes candidates that do not meet expectations for round bases (typical of hand piles). By keeping these filters independent, the our method is flexible and allows users to prioritize generally regular shapes (e.g. circular or rectangular) or apply the circularity filter as an additional filtering step when circular pile bases are expected.

### Shape Irregularity: Convexity

Our first shape irregularity filter compares the convex hull of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the convexity ratio or "solidity" of the shape ([Glasbey and Horgan 1995](https://doi.org/10.2307/2533987)) by:

$$\frac{\text{Area of Polygon}}{\text{Area of Convex Hull}}$$

This approach is effective for identifying polygons with deep indents, holes, or branching. A perfectly convex shape like a circle, square, or triangle will have a convexity of 1.0 (because they have no indents) and as shapes become more irregular (or concave) the convexity drops toward 0. Convexity is is not sensitive to the overall elongation of a shape as a long, thin rectangle is technically convex and would have a ratio of 1.0, despite being irregular in its proportions.

let's create a convex hull of the candidate segments for comparison and convexity calculation

```{r}
# convex hulls of segments
# watershed_segs_poly
watershed_segs_poly_chull <-
  watershed_segs_poly %>% 
  sf::st_convex_hull() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
# dbscan_segs_poly
dbscan_segs_poly_chull <-
  dbscan_segs_poly %>% 
  sf::st_convex_hull() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
```

compare the convex hull shape to the raw polygons

```{r}
p1_temp <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly_chull, mapping=ggplot2::aes(color="convex hull")
    , fill = NA, lwd = 2
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(color="raw polygons")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("orangered", "brown"),name="") +
  ggplot2::labs(subtitle = "watershed") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "top"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
  )
p2_temp <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_chull, mapping=ggplot2::aes(color="convex hull")
    , fill = NA, lwd = 2
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(color="raw polygons")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("orangered", "brown"),name="") +
  ggplot2::labs(subtitle = "dbscan") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "top"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
  )
patchwork::wrap_plots(list(p1_temp,p2_temp))
```

```{r,eval=F, include=FALSE}
### !!!!!!!!!!!!!!!!!!!!!! plots for potential use in publication...not shown in analysis site
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly_chull
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")

ggplot2::ggsave(filename = "../data/workflow_ex_07_rgb_watershed_cnddts.jpg", height = 8, width = 8)

# plot the filtered watershed candidate segments (brown) and convex hull of the segments (orange) and the actual piles (blue) on the CHM

plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly_chull
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
ggplot2::ggsave(filename = "../data/workflow_ex_07_chm_watershed_cnddts.jpg", height = 8, width = 8)

### !!!!!!!!!!!!!!!!!!!!!! plots for potential use in publication...not shown in analysis site
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_chull
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")

ggplot2::ggsave(filename = "../data/workflow_ex_07_rgb_dbscan_cnddts.jpg", height = 8, width = 8)

# plot the filtered dbscan candidate segments (brown) and convex hull of the segments (orange) and the actual piles (blue) on the CHM

plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_chull
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
ggplot2::ggsave(filename = "../data/workflow_ex_07_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

now, we'll calculate the convexity ratio for each remaining candidate segment

```{r}
# watershed_segs_poly
watershed_segs_poly <- 
  watershed_segs_poly %>% 
  dplyr::mutate(poly_area_m2 = sf::st_area(.) %>% as.numeric()) %>% 
  dplyr::inner_join(
    watershed_segs_poly_chull %>% 
      dplyr::mutate(chull_area_m2 = sf::st_area(.) %>% as.numeric()) %>%
      sf::st_drop_geometry() %>% 
      dplyr::select(pred_id, chull_area_m2)
    , by = "pred_id"
  ) %>% 
  dplyr::mutate(
    convexity_ratio = poly_area_m2/chull_area_m2
  )
# dbscan_segs_poly
dbscan_segs_poly <- 
  dbscan_segs_poly %>% 
  dplyr::mutate(poly_area_m2 = sf::st_area(.) %>% as.numeric()) %>% 
  dplyr::inner_join(
    dbscan_segs_poly_chull %>% 
      dplyr::mutate(chull_area_m2 = sf::st_area(.) %>% as.numeric()) %>%
      sf::st_drop_geometry() %>% 
      dplyr::select(pred_id, chull_area_m2)
    , by = "pred_id"
  ) %>% 
  dplyr::mutate(
    convexity_ratio = poly_area_m2/chull_area_m2
  )
```

what is the convexity ratio for the remaining candidate segments in our demonstration area?

```{r}
# watershed_segs_poly
watershed_segs_poly$convexity_ratio %>% summary()
# dbscan_segs_poly
dbscan_segs_poly$convexity_ratio %>% summary()
```

plot the convexity of the candidate segments using the raw polygons

```{r}
p1_temp <-
  ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio)
    , color = NA
  ) + 
  ggplot2::geom_sf_text(
    data = watershed_segs_poly
    , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1))
    , vjust = 1, hjust = 0, size = 3.5
  ) + 
  ggplot2::scale_fill_fermenter(
    n.breaks = 10, palette = "PuOr"
    , direction = 1
    , limits = c(0,1)
    , labels = scales::percent
    , breaks = seq(0, 1, by = 0.2)
    , name = ""
  ) +
  ggplot2::labs(subtitle = "watershed") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "bottom"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
    , legend.text = ggplot2::element_text(size = 7)
  )
p2_temp <-
  ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(fill=convexity_ratio)
    , color = NA
  ) + 
  ggplot2::geom_sf_text(
    data = dbscan_segs_poly
    , mapping=ggplot2::aes(label=scales::percent(convexity_ratio, accuracy=0.1))
    , vjust = 1, hjust = 0, size = 3.5
  ) + 
  ggplot2::scale_fill_fermenter(
    n.breaks = 10, palette = "PuOr"
    , direction = 1
    , limits = c(0,1)
    , labels = scales::percent
    , breaks = seq(0, 1, by = 0.2)
    , name = ""
  ) +
  ggplot2::labs(subtitle = "dbscan") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "bottom"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
    , legend.text = ggplot2::element_text(size = 7)
  )
patchwork::wrap_plots(
  list(p1_temp,p2_temp)
  , guides = "collect"
  , 
) &
ggplot2::theme(
    legend.position = "bottom"
    , legend.text = ggplot2::element_text(size = 7)
  )
```

finally, let's filter the candidate segments with a user-defined expectation of shape irregularity on the 0-100% scale applied to the convexity ratio

```{r}
# # min required overlap between the predicted pile and the convex hull of the predicted pile
min_convexity_ratio <- 0.8
```

what proportion of the remaining segments were filtered using this shape irregularity filter

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , old_segments = c(
      watershed_segs_poly %>% nrow()
      , dbscan_segs_poly %>% nrow()
    )
    , new_segments = c(
      watershed_segs_poly %>% dplyr::filter(convexity_ratio>=min_convexity_ratio) %>% nrow()
      , dbscan_segs_poly %>% dplyr::filter(convexity_ratio>=min_convexity_ratio) %>% nrow()
    )
    , area = c(
      watershed_segs_poly %>% 
        dplyr::filter(convexity_ratio>=min_convexity_ratio) %>% 
        sf::st_union() %>% 
        sf::st_area() %>% 
        as.numeric()
      , dbscan_segs_poly %>% 
        dplyr::filter(convexity_ratio>=min_convexity_ratio) %>% 
        sf::st_union() %>% 
        sf::st_area() %>% 
        as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1)
    , dplyr::across(tidyselect::ends_with("segments"), ~scales::comma(.x,accuracy=1))
    , area = scales::comma(area,accuracy=0.01)
  ) %>% 
  dplyr::relocate(method,pct_removed) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method<br>filtered by segment convexity"
    , col.names = c(
      "method", "% removed"
      , "orig. candidate segments"
      , "filtered candidate segments"
      , "remaining candidate area (m<sup>2</sup>)"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

actually apply the filter ;)

```{r}
# watershed_segs_poly
watershed_segs_poly <- watershed_segs_poly %>% 
  dplyr::filter(convexity_ratio>=min_convexity_ratio)
# dbscan_segs_poly
dbscan_segs_poly <- dbscan_segs_poly %>% 
  dplyr::filter(convexity_ratio>=min_convexity_ratio)
```

#### Watershed Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_0701_rgb_watershed_cnddts.jpg", height = 8, width = 8)
```

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_0701_chm_watershed_cnddts.jpg", height = 8, width = 8)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

#### DBSCAN Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_0701_rgb_dbscan_cnddts.jpg", height = 8, width = 8)
```

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_0701_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

#### Convexity Filter Function

let's make a function to ingest a spatial data frame and return polygons filtered for irregularity using this convex hull process

```{r}
st_convexity_filter <- function(
  sf_data
  # min required overlap between the polygon and the convex hull of the polygon
  , min_convexity_ratio = 0.7
) {
  if(!inherits(sf_data, "sf")){stop("must pass `sf` data object")}
  # if not polygons
  if( !all(sf::st_is(sf_data, type = c("POLYGON", "MULTIPOLYGON"))) ){
    stop(paste0(
      "`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])"
    ))
  }
  # convex hulls of segments
  poly_chull <-
    sf_data %>% 
    sf::st_convex_hull() %>% 
    sf::st_simplify() %>% 
    sf::st_make_valid()
    # dplyr::filter(sf::st_is_valid(.))
  # compare areas
  if(nrow(poly_chull)!=nrow(sf_data)){
    stop("could not make valid convex hulls from provided polygon data")
  }else{
    area_comp <- sf_data %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::bind_cols(
        poly_chull %>% 
          dplyr::mutate(chull_area_xxxx = sf::st_area(.) %>% as.numeric()) %>%
          dplyr::select(chull_area_xxxx) %>% 
          sf::st_drop_geometry()
      ) %>% 
      dplyr::mutate(
        convexity_ratio = area_xxxx/chull_area_xxxx
      ) %>% 
      dplyr::filter(
        convexity_ratio >= min_convexity_ratio
      ) %>% 
      dplyr::select(-c(area_xxxx,chull_area_xxxx))
    return(area_comp)
  }
}
# dbscan_segs_poly$convexity_ratio %>% summary()
# dbscan_segs_poly %>% 
#   st_convexity_filter(min_convexity_ratio = 0.9) %>%
#   dplyr::pull(convexity_ratio) %>% 
#   summary()
```

### Shape Irregularity: Circularity

Our second shape irregularity filter compares the minimum bounding circle of the candidate segment to the raw polygon of the candidate segment. Specifically, we calculate the circularity ratio sometimes referred to as the Reock Compactness Score ([Reock 1961](https://doi.org/10.2307/2109043)) of the shape by:

$$\frac{\text{Area of Polygon}}{\text{Area of Minumum Bounding Circle}}$$

This approach is used to measure how closely a shape is spread around its central point (dispersion) with a perfect circle receiving a score of 1.0 while long, thin shapes (like downed tree boles) will have low values approaching the lower limit of 0. This metric penalizes any shape that does not fill it's circumcircle (i.e. the smallest circle that contains the polygon). For context, a perfect square has a circularity ratio of $\frac{2}{\pi}\approx 0.637$ while an equilateral triangle has a ratio of $\frac{3\sqrt{3}}{4\pi}\approx 0.414$

let's create the minimum bounding circle of the candidate segments using `lwgeom::st_minimum_bounding_circle()`

```{r}
# MBC of segments
# watershed_segs_poly
watershed_segs_poly_mbc <-
  watershed_segs_poly %>% 
  lwgeom::st_minimum_bounding_circle() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
# dbscan_segs_poly
dbscan_segs_poly_mbc <-
  dbscan_segs_poly %>% 
  lwgeom::st_minimum_bounding_circle() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
```

compare the MBC shape to the raw polygons

```{r}
p1_temp <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly_mbc, mapping=ggplot2::aes(color="min. bounding circle")
    , fill = NA, lwd = 1.5
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(color="raw polygons")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("orangered", "brown"),name="") +
  ggplot2::labs(subtitle = "watershed") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "top"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
  )
p2_temp <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_mbc, mapping=ggplot2::aes(color="min. bounding circle")
    , fill = NA, lwd = 1.5
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(color="raw polygons")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("orangered", "brown"),name="") +
  ggplot2::labs(subtitle = "dbscan") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "top"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
  )
patchwork::wrap_plots(list(p1_temp,p2_temp))
```

```{r,eval=F, include=FALSE}
### !!!!!!!!!!!!!!!!!!!!!! plots for potential use in publication...not shown in analysis site
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly_mbc
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")

ggplot2::ggsave(filename = "../data/workflow_ex_08_rgb_watershed_cnddts.jpg", height = 8, width = 8)

# plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM

plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly_mbc
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
ggplot2::ggsave(filename = "../data/workflow_ex_08_chm_watershed_cnddts.jpg", height = 8, width = 8)

### !!!!!!!!!!!!!!!!!!!!!! plots for potential use in publication...not shown in analysis site
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_mbc
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")

ggplot2::ggsave(filename = "../data/workflow_ex_08_rgb_dbscan_cnddts.jpg", height = 8, width = 8)

# plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM

plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly_mbc
    , fill = NA, color = "orangered", lwd = 1
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
ggplot2::ggsave(filename = "../data/workflow_ex_08_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

now, we'll calculate the circularity ratio for each remaining candidate segment

```{r}
# watershed_segs_poly
watershed_segs_poly <- 
  watershed_segs_poly %>% 
  dplyr::inner_join(
    watershed_segs_poly_mbc %>% 
      dplyr::mutate(mbc_area_m2 = sf::st_area(.) %>% as.numeric()) %>%
      sf::st_drop_geometry() %>% 
      dplyr::select(pred_id, mbc_area_m2)
    , by = "pred_id"
  ) %>% 
  dplyr::mutate(
    circularity_ratio = poly_area_m2/mbc_area_m2
  )
# dbscan_segs_poly
dbscan_segs_poly <- 
  dbscan_segs_poly %>% 
  dplyr::inner_join(
    dbscan_segs_poly_mbc %>% 
      dplyr::mutate(mbc_area_m2 = sf::st_area(.) %>% as.numeric()) %>%
      sf::st_drop_geometry() %>% 
      dplyr::select(pred_id, mbc_area_m2)
    , by = "pred_id"
  ) %>% 
  dplyr::mutate(
    circularity_ratio = poly_area_m2/mbc_area_m2
  )
```

what is the circularity ratio for the remaining candidate segments in our demonstration area?

```{r}
# watershed_segs_poly
watershed_segs_poly$circularity_ratio %>% summary()
# dbscan_segs_poly
dbscan_segs_poly$circularity_ratio %>% summary()
```

plot the circularity of the candidate segments using the raw polygons

```{r}
p1_temp <-
  ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio)
    , color = NA
  ) + 
  ggplot2::geom_sf_text(
    data = watershed_segs_poly
    , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1))
    , vjust = 1, hjust = 0, size = 3.5
  ) + 
  ggplot2::scale_fill_fermenter(
    n.breaks = 10, palette = "PuOr"
    , direction = 1
    , limits = c(0,1)
    , labels = scales::percent
    , breaks = seq(0, 1, by = 0.2)
    , name = ""
  ) +
  ggplot2::labs(subtitle = "watershed") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "bottom"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
    , legend.text = ggplot2::element_text(size = 7)
  )
p2_temp <-
  ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(fill=circularity_ratio)
    , color = NA
  ) + 
  ggplot2::geom_sf_text(
    data = dbscan_segs_poly
    , mapping=ggplot2::aes(label=scales::percent(circularity_ratio, accuracy=0.1))
    , vjust = 1, hjust = 0, size = 3.5
  ) + 
  ggplot2::scale_fill_fermenter(
    n.breaks = 10, palette = "PuOr"
    , direction = 1
    , limits = c(0,1)
    , labels = scales::percent
    , breaks = seq(0, 1, by = 0.2)
    , name = ""
  ) +
  ggplot2::labs(subtitle = "dbscan") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "bottom"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
    , legend.text = ggplot2::element_text(size = 7)
  )
patchwork::wrap_plots(
  list(p1_temp,p2_temp)
  , guides = "collect"
  , 
) &
ggplot2::theme(
    legend.position = "bottom"
    , legend.text = ggplot2::element_text(size = 7)
  )
```

finally, let's filter the candidate segments with a user-defined expectation of shape circularity on the 0-100% scale applied to the circularity ratio

```{r}
# # min required overlap between the predicted pile and the MBC of the predicted pile
min_circularity_ratio <- 0.6
```

what proportion of the remaining segments were filtered using this shape circularity filter

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , old_segments = c(
      watershed_segs_poly %>% nrow()
      , dbscan_segs_poly %>% nrow()
    )
    , new_segments = c(
      watershed_segs_poly %>% dplyr::filter(circularity_ratio>=min_circularity_ratio) %>% nrow()
      , dbscan_segs_poly %>% dplyr::filter(circularity_ratio>=min_circularity_ratio) %>% nrow()
    )
    , area = c(
      watershed_segs_poly %>% 
        dplyr::filter(circularity_ratio>=min_circularity_ratio) %>% 
        sf::st_union() %>% 
        sf::st_area() %>% 
        as.numeric()
      , dbscan_segs_poly %>% 
        dplyr::filter(circularity_ratio>=min_circularity_ratio) %>% 
        sf::st_union() %>% 
        sf::st_area() %>% 
        as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1)
    , dplyr::across(tidyselect::ends_with("segments"), ~scales::comma(.x,accuracy=1))
    , area = scales::comma(area,accuracy=0.01)
  ) %>% 
  dplyr::relocate(method,pct_removed) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method<br>filtered by segment circularity"
    , col.names = c(
      "method", "% removed"
      , "orig. candidate segments"
      , "filtered candidate segments"
      , "remaining candidate area (m<sup>2</sup>)"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

actually apply the filter ;)

```{r}
# watershed_segs_poly
watershed_segs_poly <- watershed_segs_poly %>% 
  dplyr::filter(circularity_ratio>=min_circularity_ratio)
# dbscan_segs_poly
dbscan_segs_poly <- dbscan_segs_poly %>% 
  dplyr::filter(circularity_ratio>=min_circularity_ratio)
```

#### Watershed Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_0801_rgb_watershed_cnddts.jpg", height = 8, width = 8)
```

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_0801_chm_watershed_cnddts.jpg", height = 8, width = 8)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

#### DBSCAN Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_0801_rgb_dbscan_cnddts.jpg", height = 8, width = 8)
```

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_0801_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

#### Circularity Filter Function

let's make a function to ingest a spatial data frame and return polygons filtered for irregularity using this minimum bounding circle process

```{r}
st_circularity_filter <- function(
  sf_data
  # min required overlap between the polygon and the minimum bounding circle of the polygon
  , min_circularity_ratio = 0.6
) {
  if(!inherits(sf_data, "sf")){stop("must pass `sf` data object")}
  # if not polygons
  if( !all(sf::st_is(sf_data, type = c("POLYGON", "MULTIPOLYGON"))) ){
    stop(paste0(
      "`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])"
    ))
  }
  # minimum bounding circle of segments
  poly_mbc <-
    sf_data %>% 
    lwgeom::st_minimum_bounding_circle() %>% 
    sf::st_simplify() %>% 
    sf::st_make_valid()
    # dplyr::filter(sf::st_is_valid(.))
  # compare areas
  if(nrow(poly_mbc)!=nrow(sf_data)){
    stop("could not make valid minimum bounding circle from provided polygon data")
  }else{
    area_comp <- sf_data %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::bind_cols(
        poly_mbc %>% 
          dplyr::mutate(mbc_area_xxxx = sf::st_area(.) %>% as.numeric()) %>%
          dplyr::select(mbc_area_xxxx) %>% 
          sf::st_drop_geometry()
      ) %>% 
      dplyr::mutate(
        circularity_ratio = area_xxxx/mbc_area_xxxx
      ) %>% 
      dplyr::filter(
        circularity_ratio >= min_circularity_ratio
      ) %>% 
      dplyr::select(-c(area_xxxx,mbc_area_xxxx))
    return(area_comp)
  }
}
# dbscan_segs_poly$circularity_ratio %>% summary()
# dbscan_segs_poly %>%
#   st_circularity_filter(min_circularity_ratio = 0.7) %>%
#   dplyr::pull(circularity_ratio) %>%
#   summary()
```

```{r, include = F, eval = F}
### !!!!!!!!!!!!!!!!!!!! COULD ALSO INCLUDE:
# Polsby-Popper Score (Isoperimetric Quotient)
# Unique Function: Measures boundary complexity or "jaggedness". It is an isoperimetric measure that evaluates how much area is enclosed relative to the perimeter length.
# Intuition: It compares the shape's area to the area of a circle with the same perimeter. This is the most sensitive metric to high-frequency "noise" or "wiggles" in a boundary; a circle with a "saw-tooth" edge will have a very low score even if it is not elongated or indented.
# Range: [0,1]. A smooth-edged circle scores 1.0.
# Formula:\(PP=\frac{4\pi \times Area_{Polygon}}{Perimeter_{Polygon}^{2}}\)
```

#### Quick methods comparison

let's quickly look at the watershed and dbscan segments on the same plot now that we have removed candidate segments that 1) do not meet the area thresholds; 2) do not meet the convexity ratio threshold; and 3) do not meet the circularity ratio threshold

```{r}
# watershed_segs_poly %>% dplyr::glimpse()
# dbscan_segs_poly %>% dplyr::glimpse()
ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(color="watershed")
    , fill = NA, lwd = 2
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(color="dbscan")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("gray33", "aquamarine3"),name="") +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "top")
```

after all of that, the results of the two methods are the same for this particular demonstration area

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Structural Metrics from CHM

We'll use the CHM raster to calculate area, height, and volume for each candidate pile to reflect the irregular pile footprints and elevation profiles that better represent real-world objects than assuming perfect geometric shapes like traditional pile measurement methods ([Long and Boston, 2014](https://doi.org/10.5849/forsci.13-501); [Trofymow et al., 2014](https://doi.org/10.1139/cjfr-2013-0281); [Guth et al., 2025](https://doi.org/10.3389/ffgc.2025.1663753))

Candidate slash pile structural metrics are derived from the CHM raster using zonal statistics to aggregate cell-level raster data within the boundaries of each pile. To ensure geodetic accuracy, an area raster is generated (`terra::cellSize()`) which accounts for minute variations in pixel area caused by the curvature of the Earth and the coordinate reference system. This area raster is then used as input for volume calculation, where it is multiplied by the CHM height values to create a volume raster. Summing the individual volume of every pixel within the candidate pile footprint yields the total pile volume with each cell in the volume raster treated as a rectangular prism with height from the CHM and base area from the area raster. Pile area is calculated by summing the area raster values within the candidate pile boundary and pile height is determined by the maximum CHM pixel value.

we'll make a function to use polygon `sf` data and an input CHM raster to perform these calculations and return the data with metrics attached

```{r}
########################################################################################
## calculate raster-based area, height, and volume using zonal stats
########################################################################################
get_structural_metrics <- function(
    sf_data
    , chm_rast
    # , sf_id = NA
) {
  # check polygons
  if(!inherits(sf_data, "sf")){stop("must include `sf` data object in 'sf_data'")}
  if( !all(sf::st_is(sf_data, type = c("POLYGON", "MULTIPOLYGON"))) ){
    stop(paste0(
      "`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])"
    ))
  }
  sf_data <- sf_data %>% dplyr::ungroup()
  
  # check raster
  # convert to SpatRaster if input is from 'raster' package
  if(
    inherits(chm_rast, "RasterStack") 
    || inherits(chm_rast, "RasterBrick")
  ){
    chm_rast <- terra::rast(chm_rast)
  }else if(!inherits(chm_rast, "SpatRaster")){
    stop("Input 'chm_rast' must be a SpatRaster from the `terra` package")
  }
  chm_rast <- chm_rast %>% terra::subset(subset = 1)
  if(
    as.numeric(terra::global(chm_rast, fun = "isNA")) == terra::ncell(chm_rast) 
    # || as.numeric(terra::global(chm_rast, fun = "isNA")) >= round(terra::ncell(chm_rast)*0.98)
  ){
    stop("Input 'chm_rast' has all missing values")
  }
  
  # # check id
  # if(!inherits(sf_id, "character")){
  #   # stop("must include 'sf_id' as the unique identifier")
  #   sf_data <- sf_data %>% 
  #     dplyr::mutate(idxxxxx = dplyr::row_number())
  #   sf_id <- "idxxxxx"
  # }else{
  #   if( !any( stringr::str_equal(names(sf_data), sf_id) ) ){
  #     stop(paste0("could not locate '",sf_id,"' in sf_data"))
  #   }
  # }
  
  # check overlap
  # Returns TRUE if any part of the vector geometry intersects the raster extent
  if(
    !any(terra::is.related(
      x = sf_data %>% 
        sf::st_transform(terra::crs(chm_rast)) %>% 
        terra::vect()
      , y = terra::ext(chm_rast)
      , relation = "intersects"
    ))
  ){
    stop("Input 'sf_data' does not overlap with 'chm_rast'")
  }
  #################################
  # area, volume of each cell
  #################################
  area_rast_temp <- terra::cellSize(chm_rast)
  names(area_rast_temp) <- "area_m2"
  # area_rast_temp %>% terra::plot()
  # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes
  vol_rast_temp <- area_rast_temp*chm_rast
  names(vol_rast_temp) <- "volume_m3"
  # vol_rast_temp %>% terra::plot()
  #################################
  # zonal stats
  #################################
  # sum area within each segment to get the total area
  area_df_temp <- terra::zonal(
      x = area_rast_temp
      , z = sf_data %>% 
        sf::st_transform(terra::crs(chm_rast)) %>% 
        terra::vect()
      , fun = "sum", na.rm = T
    ) %>% 
    setNames("area_m2") %>% 
    dplyr::mutate(area_m2 = dplyr::na_if(area_m2, NaN))
  # area_df_temp %>% dplyr::glimpse()
  # sum volume within each segment to get the total volume
  vol_df_temp <- terra::zonal(
      x = vol_rast_temp
      , z = sf_data %>% 
        sf::st_transform(terra::crs(chm_rast)) %>% 
        terra::vect()
      , fun = "sum", na.rm = T
    ) %>% 
    setNames("volume_m3") %>% 
    dplyr::mutate(volume_m3 = dplyr::na_if(volume_m3, NaN))
  # vol_df_temp %>% dplyr::glimpse()
  # max ht within each segment to get the max ht
  ht_df_temp <- terra::zonal(
      x = chm_rast
      , z = sf_data %>% 
        sf::st_transform(terra::crs(chm_rast)) %>% 
        terra::vect()
      , fun = "max", na.rm = T
    ) %>% 
    setNames("max_height_m") %>% 
    dplyr::mutate(max_height_m = dplyr::na_if(max_height_m, NaN))
  #################################
  # attach to sf
  #################################
  if(
    !identical(
      nrow(sf_data)
      , nrow(area_df_temp)
      , nrow(vol_df_temp)
      , nrow(ht_df_temp)
    )
  ){
    stop("unable to find data in raster for given vectors")
  }
  
  ret_dta <- sf_data %>%
    dplyr::select( -dplyr::any_of(c(
      "hey_xxxxxxxxxx"
      , "area_m2"
      , "volume_m3"
      , "max_height_m"
      , "volume_per_area"
    ))) %>% 
    dplyr::bind_cols(
      area_df_temp
      , vol_df_temp
      , ht_df_temp
    ) %>% 
    dplyr::mutate(
      volume_per_area = volume_m3/area_m2
    )
  # ret_dta <- sf_data %>%
  #   purrr::reduce(
  #     list(sf_data, area_df_temp, vol_df_temp, ht_df_temp)
  #     , dplyr::left_join
  #     , by = sf_id
  #   ) %>% 
  #   dplyr::mutate(
  #     volume_per_area = volume_m3/area_m2
  #   )
  
  return(
    list(
      sf_data = ret_dta
      , area_rast = area_rast_temp
      , volume_rast = vol_rast_temp
    )
  )
}

# get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %>% 
#   dplyr::glimpse()
# get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = arnf_chm_rast) %>% 
#   dplyr::glimpse()
```

### Structural Rasters

we can quickly look at the area raster that was used for the volume calculation

```{r}
get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %>% 
  purrr::pluck("area_rast") %>% 
  terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = "area (m2)")
```

and we can quickly look at the volume raster

```{r}
get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %>% 
  purrr::pluck("volume_rast") %>% 
  terra::plot(axes = F, col = grDevices::gray.colors(n=100), main = "volume (m3)")
# terra::plot(
#   aoi_slash_piles_polys %>% 
#     sf::st_transform(terra::crs(aoi_chm_rast_slice)) %>% 
#     terra::vect()
#   , add = T, border = "blue", col = NA, lwd = 1.2
# )
```

the volume raster mirrors the CHM but with volume as the cell value instead of height

```{r}
aoi_chm_rast_slice %>% 
  terra::plot(axes = F, col = viridis::plasma(100), main = "CHM (m)")
```

### Demonstration Candidate Segment Metrics

we'll use our `get_structural_metrics()` with the height-filtered CHM to compute the structural metrics for the candidate piles

```{r}
# watershed_segs_poly
watershed_segs_poly <- get_structural_metrics(sf_data = watershed_segs_poly, chm_rast = aoi_chm_rast_slice) %>% 
  purrr::pluck("sf_data") %>% 
  # we already have area so we'll drop the value from this function
  dplyr::select( -dplyr::any_of(c(
    "hey_xxxxxxxxxx"
    , "poly_area_m2"
  )))
# dbscan_segs_poly
dbscan_segs_poly <- get_structural_metrics(sf_data = dbscan_segs_poly, chm_rast = aoi_chm_rast_slice) %>% 
  purrr::pluck("sf_data") %>% 
  # we already have area so we'll drop the value from this function
  dplyr::select( -dplyr::any_of(c(
    "hey_xxxxxxxxxx"
    , "poly_area_m2"
  )))

```

what did we get back?

```{r}
watershed_segs_poly %>% dplyr::glimpse()
```

plot the metrics of pile area, height, and volume

```{r}
# p1_temp <-
p_fn_temp <- function(dta,fill_col,col_nm=latex2exp::TeX("area $\\textrm{m}^2$"),pal="Oranges"){
  ggplot2::ggplot(data = dta) +
  ggplot2::geom_sf(
    mapping=ggplot2::aes(fill=.data[[fill_col]])
    # mapping=ggplot2::aes(fill={{fill_col}})
    , color = NA
  ) + 
  ggplot2::geom_sf_text(
    # mapping=ggplot2::aes(label=scales::comma({{fill_col}}, accuracy=0.1))
    mapping=ggplot2::aes(label=scales::comma(.data[[fill_col]], accuracy=0.1))
    , vjust = 1, hjust = -1.3, size = 2.5
  ) + 
  ggplot2::scale_fill_distiller(palette = pal, name = col_nm, direction = 1) +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "top", legend.direction = "horizontal"
    , plot.subtitle = ggplot2::element_text(hjust = 0.5)
    , panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 1)
    , legend.text = ggplot2::element_text(size = 7)
  )
}
# lists
pal_temp <- c("Blues","Purples","Greens")
nm_temp <- c(
  latex2exp::TeX("area $\\textrm{m}^2$")
  , latex2exp::TeX("volume $\\textrm{m}^3$")
  , "height m"
)
col_temp <- c(
  "area_m2"
  , "volume_m3"
  , "max_height_m"
)
# watershed
ws_p_temp <- 1:length(col_temp) %>% 
  purrr::map(
    \(x)
    p_fn_temp(
      watershed_segs_poly
      , fill_col = col_temp[x]
      , col_nm = nm_temp[x]
      , pal = pal_temp[x]
    )
  )
# dbscan
db_p_temp <- 1:length(col_temp) %>% 
  purrr::map(
    \(x)
    p_fn_temp(
      dbscan_segs_poly
      , fill_col = col_temp[x]
      , col_nm = nm_temp[x]
      , pal = pal_temp[x]
    )
  )
p1_temp <- patchwork::wrap_plots(
    ws_p_temp
  ) + 
  patchwork::plot_annotation(
    title = "watershed"
    , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14))
  )
p2_temp <- patchwork::wrap_plots(
    db_p_temp
  ) + 
  patchwork::plot_annotation(
    title = "dbscan"
    , theme = ggplot2::theme(plot.title = ggplot2::element_text(size = 14))
  )

patchwork::wrap_plots(
  list(
    patchwork::wrap_elements( p1_temp )
    , patchwork::wrap_elements( p2_temp )
  )
  , nrow = 2
)
```

after all of that, the results of the two methods are the same for this particular demonstration area

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Final Shape Refinement

In the final stage, we generate convex hulls for the segments to smooth the blocky, pixelated edges inherent in raster data (which can look like they were generated in Minecraft). Any segments with overlapping convex hulls are then removed to help filter out false detections which may be groups of small trees or shrubs. This step is intended to reflect real-world conditions where distinct slash piles are constructed with enough spacing to remain spatially independent rather than overlapping. Finally, we'll apply one more filter for the area and height thresholds.

```{r, include = F, eval = F}
### !!!!!!!!!!!!!!!! IF WE WANT TO COMBINE POLYGONS THAT SHARE A COMMON BORDER BUT DON'T OVERLAP
### !!!!!!!!!!!!!!!! st_dissolve_and_combine()
###############################################################################
# dissolve groups of touching or overlapping polygons using st_union and st_cast
###############################################################################
st_combine_touching <- function(polygons_sf) {
  # check if the input is an sf data frame
  if (!inherits(polygons_sf, "sf")) {
    stop("Input 'polygons_sf' must be an sf data frame.")
  }
  
  # check if the geometry type is either polygon or multipolygon
  geometry_types <- sf::st_geometry_type(polygons_sf)
  if (!all(geometry_types %in% c("POLYGON", "MULTIPOLYGON"))) {
    stop("Input 'polygons_sf' must contain only POLYGON or MULTIPOLYGON geometries.")
  }
  
  # union then pull out separate polys
  dissolved_sf <- 
    polygons_sf %>% 
    # 1. perform a full union to dissolve all contiguous polygons into a multipolygon.
    sf::st_union(by_feature = F) %>% 
    # 2. cast the multipolygon back to individual polygons, one for each component.
    sf::st_cast("POLYGON") %>% 
    # 3. return a new sf data frame with the dissolved components.
    sf::st_sf() %>% 
    # 4. ensure valid polygons
    sf::st_simplify() %>% 
    sf::st_make_valid() %>% 
    dplyr::filter(sf::st_is_valid(.)) %>% 
    # make id
    dplyr::mutate(id = dplyr::row_number())
  
  return(dissolved_sf)
}
###############################################################################
# dissolve only contiguous, non-overlapping polygons and combine with others.
###############################################################################
st_dissolve_and_combine <- function(polygons_sf) {
  # Input checks
  if (!inherits(polygons_sf, "sf")) stop("Input 'polygons_sf' must be an sf data frame.")
  if (!all(sf::st_geometry_type(polygons_sf) %in% c("POLYGON", "MULTIPOLYGON"))) {
    stop("Input 'polygons_sf' must contain only POLYGON or MULTIPOLYGON geometries.")
  }
  
  # Identify touching and overlapping polygons using matrix operations
  touches_matrix <- sf::st_touches(polygons_sf, polygons_sf, sparse = FALSE)
  overlaps_matrix <- sf::st_overlaps(polygons_sf, polygons_sf, sparse = FALSE)
  
  # Exclude self-touching and self-overlapping relationships
  diag(touches_matrix) <- FALSE
  diag(overlaps_matrix) <- FALSE
  
  # Polygons that are part of a touching group (i.e., touch another polygon)
  touching_ids <- which(rowSums(touches_matrix) > 0)
  
  # Polygons that are part of an overlapping group (i.e., overlap another polygon)
  overlapping_ids <- which(rowSums(overlaps_matrix) > 0)
  
  # Polygons to be dissolved: only those that touch but do not overlap
  to_dissolve_ids <- touching_ids[!touching_ids %in% overlapping_ids]
  
  # Polygons to remain as-is: isolated polygons and overlapping polygons
  to_keep_ids <- unique(c(which(rowSums(touches_matrix) == 0 & rowSums(overlaps_matrix) == 0), overlapping_ids))
  
  # Separate the datasets
  to_dissolve_sf <- polygons_sf[to_dissolve_ids, ]
  to_keep_sf <- polygons_sf[to_keep_ids, ]
  
  # # Dissolve the contiguous, non-overlapping polygons
  # dissolved_sf <- sf::st_union(to_dissolve_sf)
  # dissolved_cast <- sf::st_cast(dissolved_sf, "POLYGON")
  # dissolved_final <- sf::st_sf(geometry = dissolved_cast)
  dissolved_final <- st_combine_touching(to_dissolve_sf)
  
  # Combine the dissolved polygons with the remaining polygons
  final_result <- 
    dissolved_final %>% 
    dplyr::bind_rows(
      to_keep_sf %>% 
        dplyr::mutate(id = dplyr::row_number()) %>% 
        dplyr::select(id)
    ) %>% 
    sf::st_simplify() %>% 
    sf::st_make_valid() %>% 
    dplyr::filter(sf::st_is_valid(.)) %>% 
    # make id
    dplyr::mutate(id = dplyr::row_number())
  
  return(final_result)
}
```

```{r}
###############################################################################
# make a function to remove overlapping polygons from a sf data frame
###############################################################################
st_remove_overlaps <- function(sf_data) {
  if(!inherits(sf_data, "sf")){stop("must pass `sf` data object")}
  # if not polygons
  if( !all(sf::st_is(sf_data, type = c("POLYGON", "MULTIPOLYGON"))) ){
    stop(paste0(
      "`sf_data` data must be an `sf` class object with POLYGON geometry (see [sf::st_geometry_type()])"
    ))
  }
  if(nrow(sf_data)<=1){return(sf_data)}
  # combine all touching polygons and keep the ones that overlap multiple from the original polygons
  comb_temp <- sf_data %>% 
    dplyr::ungroup() %>% 
    sf::st_union(by_feature = F) %>% 
    sf::st_cast("POLYGON") %>% 
    sf::st_as_sf() %>% 
    sf::st_set_geometry("geometry") %>% 
    sf::st_set_crs(sf::st_crs(sf_data)) %>% 
    dplyr::mutate(new_id = dplyr::row_number()) %>% 
    dplyr::select(new_id) 
  # identify overlaps
  overlap_temp <- comb_temp %>% 
    sf::st_intersection(sf_data) %>% 
    sf::st_drop_geometry() %>% 
    dplyr::group_by(new_id) %>% 
    dplyr::summarise(n_orig = dplyr::n()) %>% 
    dplyr::ungroup() %>% 
    dplyr::filter(n_orig>=2) %>% 
    dplyr::pull(new_id)
  if(length(overlap_temp)==0){return(sf_data)}
  # just get the overlaps
  comb_temp <- comb_temp %>% 
    dplyr::filter(new_id %in% overlap_temp) %>% 
    sf::st_union()
  # remove all input polygons from the original data that have any overlaps
  return(sf::st_difference(sf_data,comb_temp))
}
```

take the convex hull and apply our `st_remove_overlaps()` function to the remaining candidate segments. Finally, we filter for area based on the smoothed shape 

```{r}
# watershed_segs_poly
watershed_segs_poly <-
  watershed_segs_poly %>% 
  sf::st_convex_hull() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.)) %>% 
  st_remove_overlaps() %>%
  # now we need to re-do the volume and area calculations
  dplyr::mutate(
    area_m2 = sf::st_area(.) %>% as.numeric()
    , volume_m3 = area_m2*volume_per_area
  ) %>% 
  st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %>% 
  # filter for height
  dplyr::filter(
    max_height_m >= min_ht_m
    & max_height_m <= max_ht_m
  )
# dbscan_segs_poly
dbscan_segs_poly <-
  dbscan_segs_poly %>% 
  sf::st_convex_hull() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.)) %>% 
  st_remove_overlaps() %>%
  # now we need to re-do the volume and area calculations
  dplyr::mutate(
    area_m2 = sf::st_area(.) %>% as.numeric()
    , volume_m3 = area_m2*volume_per_area
  ) %>% 
  st_filter_area(min_area_m2 = min_area_m2, max_area_m2 = max_area_m2) %>% 
  # filter for height
  dplyr::filter(
    max_height_m >= min_ht_m
    & max_height_m <= max_ht_m
  )
# dbscan_segs_poly %>% dplyr::glimpse()
```

### Watershed Segmentation

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_09_rgb_wshed_cnddts.jpg", height = 8, width = 8)
```

plot the filtered watershed candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = watershed_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_09_chm_wshed_cnddts.jpg", height = 8, width = 8)
```

nice

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### DBSCAN Segmentation

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the RGB

```{r,eval=F}
aoi_plt_ortho +
  ggplot2::geom_sf(data = aoi_boundary, fill = NA, color = "black", lwd = 0.8) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  ) +
  ggplot2::theme(legend.position = "none")
```

```{r,eval=F, include=FALSE}
ggplot2::ggsave(filename = "../data/workflow_ex_09_rgb_dbscan_cnddts.jpg", height = 8, width = 8)
```

plot the filtered dbscan candidate segments (brown) and the actual piles (blue) on the CHM

```{r}
plt_aoi_chm(aoi_chm_rast_slice) +
  ggplot2::geom_sf(
    data = aoi_slash_piles_polys
    , fill = NA, color = "blue", lwd = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_segs_poly
    , fill = NA, color = "brown", lwd = 0.8
  )
```

```{r, include=FALSE,eval=TRUE}
ggplot2::ggsave(filename = "../data/workflow_ex_09_chm_dbscan_cnddts.jpg", height = 8, width = 8)
```

nice

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### Quick methods comparison

let's quickly look at the watershed and dbscan segments on the same plot

```{r}
ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = watershed_segs_poly, mapping=ggplot2::aes(color="watershed")
    , fill = NA, lwd = 2
  ) + 
  ggplot2::geom_sf(
    data = dbscan_segs_poly, mapping=ggplot2::aes(color="dbscan")
    , fill = NA, lwd = 1
  ) + 
  ggplot2::scale_color_manual(values = c("gray33", "aquamarine3"),name="") +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "top")
```

exactly the same

let's see how many segments were originally detected using each method and how many we are left with after our filtering for shape irregularity, pile area and height expectations, circularity, and potential overlaps after smoothing?

```{r}
dplyr::tibble(
    method = c("watershed", "DBSCAN")
    , old_segments = c(
      terra::freq(watershed_segs) %>% nrow()
      , terra::freq(dbscan_segs) %>% nrow()
    )
    , new_segments = c(
      nrow(watershed_segs_poly)
      , nrow(dbscan_segs_poly)
    )
    # area
    , old_area = c(
      terra::cellSize(watershed_segs) %>% 
        terra::crop(watershed_segs,mask=T) %>% 
        terra::global(fun="sum", na.rm=T) %>% 
        as.numeric()
      , terra::cellSize(dbscan_segs) %>% 
        terra::crop(dbscan_segs,mask=T) %>% 
        terra::global(fun="sum", na.rm=T) %>% 
        as.numeric()
    )
    , new_area = c(
      watershed_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
      , dbscan_segs_poly %>% sf::st_union() %>% sf::st_area() %>% as.numeric()
    )
  ) %>% 
  dplyr::mutate(
    segments_pct_removed = scales::percent((new_segments-old_segments)/old_segments, accuracy = 0.1)
    , dplyr::across(tidyselect::ends_with("segments"), ~scales::comma(.x,accuracy=1))
    , area_pct_removed = scales::percent((new_area-old_area)/old_area, accuracy = 0.1)
    , dplyr::across(tidyselect::ends_with("area"), ~scales::comma(.x,accuracy=0.1))
  ) %>% 
  dplyr::select(
    method
    ,tidyselect::ends_with("_segments"), segments_pct_removed
    ,tidyselect::ends_with("_area"), area_pct_removed
  ) %>% 
  kableExtra::kbl(
    caption = "Demonstration area candidate segments by method<br>final candidate segments fully filtered for size and geometric expectations"
    , col.names = c(
      "method"
      , "orig. candidate<br>segments", "final<br>segments", "% candidates<br>removed"
      , "orig. candidate<br>area (m<sup>2</sup>)", "final<br>area (m<sup>2</sup>)", "% area<br>removed"
    )
    , escape = F
  ) %>% 
  kableExtra::kable_styling()
```

wow that is a lot of filtering, but it looks like the result for this demonstration area is decently accurate (we'll perform full validation of the method later). That is, there are no false positive predictions (commission errors) and few false negative predictions (omission errors)

## Pile Detection Function{#slash_pile_detect_watershed}

The rule-based method for slash pile detection using CHM raster data we reviewed above generally follows this outline:

* *CHM Generation*: A Canopy Height Model (CHM) is generated from the point cloud data. The CHM is generated by removing the ground surface effectively representing a Digital Surface Model (DSM) without ground, ensuring all values are heights above bare earth.
* *CHM Height Filtering*: A maximum height filter is applied to the CHM to retaining only raster cells below a maximum expected slash pile height (e.g. 4 m), isolating a "slice" of the CHM. A final step includes filtering candidate segments based on an expected minimum height threshold as well to remove any piles shorter than this expectation.
* *Candidate Segmentation*: Watershed segmentation is performed on the filtered CHM raster to identify and delineate initial candidate piles based on their structural form.
* *First Irregularity Filtering*: Candidate pile locations are initially filtered to remove highly irregular shapes by assessing their overlap with their convex hull (e.g. >70% overlap). This step helps exclude lower tree branches (objects with holes in the lower CHM slice) and unorganized coarse woody debris.
* *Area Filtering*: A filter is applied based on the minimum and maximum expected pile areas.
* *Circularity Filtering*: A final geometric screen uses least squares circle fitting on each candidate pile, removing any that do not have a strong overlap (based on an Intersection over Union, or IoU, threshold) with the best-fit circle (e.g., >50%). This removes non-circular features such as rectangular boulders and downed tree stems.
* *Shape Refinement & Overlap Removal*: Lastly, segments are smoothed using their convex hull to remove the "blocky" raster edges (like they were made in Minecraft). Overlapping convex hull shapes are then removed to prevent false positives from clustered small trees or shrubs, ensuring singular pile detections.

Let's package all of the steps we demonstrated when [formulating the methodology](#raster_watershed) into a single function which can possibly be integrated into the `cloud2trees` package.

The parameters are defined as follows:

* `max_ht_m` : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific "slice" of the data, ignoring anything taller than a typical pile.
* `min_ht_m` : numeric. The minimum height (in meters) a detected pile must reach to be considered valid.
* `min_area_m2` : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid.
* `max_area_m2` : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid.
* `convexity_pct` : numeric. A value between 0 and 1 that controls how strict the filtering is for regularly shaped piles. A value of 1 means only piles that are perfectly smooth and rounded, with no dents or inward curves are kept. A value of 0 allows for both perfectly regular and very irregular shapes. This filter works alongside `circle_fit_iou_pct` to refine the pile's overall shape.
* `circle_fit_iou_pct` : numeric. A value between 0 and 1 that controls how the filtering is for circular pile shapes. Setting it to 1 means only piles that are perfectly circular are kept. A value of 0 allows for a wide range of shapes, including very circular and non-circular ones (like long, straight lines).
* `smooth_segs` :  logical. Setting this option to TRUE will: 1) smooth out the "blocky" edges of detected piles (which can look like they were made in Minecraft) by using their overall shape; and 2) remove any detected piles that overlap significantly with other smoothed piles to help ensure each detection is a single slash pile, not a cluster of small trees or shrubs.

```{r}
# detect funciton
slash_pile_detect_watershed <- function(
  chm_rast
  #### height and area thresholds for the detected piles
  # these should be based on data from the literature or expectations based on the prescription
  , max_ht_m = 4 # set the max expected pile height
  , min_ht_m = 0.5 # set the min expected pile height
  , min_area_m2 = 2 # set the min expected pile area
  , max_area_m2 = 50 # set the max expected pile area
  #### irregularity filtering
  # 1 = perfectly convex (no inward angles); 0 = so many inward angles
  # values closer to 1 remove more irregular segments; 
    # values closer to 0 keep more irregular segments (and also regular segments)
  # these will all be further filtered for their circularity and later smoothed to remove blocky edges
  # and most inward angles by applying a convex hull to the original detected segment
  , convexity_pct = 0.7 # min required overlap between the predicted pile and the convex hull of the predicted pile
  #### circularity filtering
  # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular
  # min required IoU between the predicted pile and the best fit circle of the predicted pile
  , circle_fit_iou_pct = 0.5
  #### shape refinement & overlap removal
  ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed
  ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules
  , smooth_segs = T
) {
  # checks
  if(!inherits(chm_rast,"SpatRaster")){stop("`chm_rast` must be raster data with the class `SpatRaster` ")}
  max_ht_m <- max_ht_m[1] 
  min_ht_m <- min_ht_m[1] 
  min_area_m2 <- min_area_m2[1] 
  max_area_m2 <- max_area_m2[1] 
  if(
    (is.na(tryCatch(as.numeric(max_ht_m), error = function(e) NA)) || 
     identical(as.numeric(max_ht_m), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(max_ht_m), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(min_ht_m), error = function(e) NA)) || 
     identical(as.numeric(min_ht_m), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(min_ht_m), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(max_area_m2), error = function(e) NA)) || 
     identical(as.numeric(max_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(max_area_m2), error = function(e) NA))) ||
    (is.na(tryCatch(as.numeric(min_area_m2), error = function(e) NA)) || 
     identical(as.numeric(min_area_m2), numeric(0)) || 
     !is.numeric(tryCatch(as.numeric(min_area_m2), error = function(e) NA))) ||
    !(as.numeric(max_ht_m) > as.numeric(min_ht_m)) ||
    !(as.numeric(max_area_m2) > as.numeric(min_area_m2)) ||
    as.numeric(max_ht_m)<0 ||
    as.numeric(min_ht_m)<0 ||
    as.numeric(min_area_m2)<0 ||
    as.numeric(max_area_m2)<0
  ){
    # Code to execute if any condition is met (e.g., print an error message)
    stop("Error: One or more of `max_ht_m`,`min_ht_m`,`min_area_m2`,`max_area_m2` are not valid numbers, or the conditions max_area_m2>min_area_m2 or max_ht_m>min_ht_m are not met.")
  }else{
    max_ht_m <- as.numeric(max_ht_m)[1] 
    min_ht_m <- as.numeric(min_ht_m)[1] 
    min_area_m2 <- as.numeric(min_area_m2)[1] 
    max_area_m2 <- as.numeric(max_area_m2)[1] 
  }
  # just get the first layer and "slice" the raster based on the height threshold
  chm_rast <- chm_rast %>% 
    terra::subset(subset = 1) %>% 
    terra::clamp(upper = max_ht_m, lower = 0, values = F)
  
  ########################################################################################
  ## 1) Segmentation
  ########################################################################################
    

  ########################################################################################
  ## 2) irregularity filtering
  ########################################################################################
    # let's first filter out segments that have holes in them 
    # or are very irregularly shaped by comparing the area of the polygon and convex hull

    # convexity_pct = min required overlap between the predicted pile and the convex hull of the predicted pile
    if(convexity_pct>0){
      # apply the irregularity filtering on the polygons
      watershed_ans_poly <- watershed_ans_poly %>% 
        st_convexity_filter(pct_chull_overlap = convexity_pct)
    }

    # check return
    if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){
      stop(paste0(
        "no segments detected using the given CHM and irregularity expectations"
        , "\n     try adjusting `convexity_pct` "
      ))
    }

  ########################################################################################
  ## 3) area filtering
  ########################################################################################
    # filter out the segments that don't meet the size thresholds
    watershed_ans_poly <- watershed_ans_poly %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::filter(
        dplyr::coalesce(area_xxxx,0) >= min_area_m2
        & dplyr::coalesce(area_xxxx,0) <= max_area_m2
      ) %>% 
      dplyr::select(-c(area_xxxx))
   
  ########################################################################################
  ## 4) circularity filtering
  ########################################################################################
    # let's apply a circle-fitting algorithm to remove non-circular segments from the remaining segments
    # let's apply the `sf_data_circle_fit()` function that
    # fits the best circle using `lidR::fit_circle()` to each watershed detected segment 
    # to get a spatial data frame with the best fitting circle for each segment
    if(circle_fit_iou_pct==0){
        watershed_keep_circle_fit_pred_id <- unique(watershed_ans_poly$pred_id)
    }else{
      # apply the sf_data_circle_fit() which takes each segment polygon, transforms it to points, and the fits the best circle
      watershed_ans_poly_circle_fit <- sf_data_circle_fit(watershed_ans_poly)
      
      # filter using the intersection over union (IoU) between the circle and the predicted segment. 
      # we'll use the IoU function we defined 
      # we map over this to only compare the segment to it's own best circle fit...not all
      # we should consider doing this in bulk.....another day
      watershed_circle_fit_iou <- 
        watershed_ans_poly$pred_id %>% 
        unique() %>% 
        purrr::map(\(x)
          ground_truth_single_match(
            gt_inst = watershed_ans_poly %>% 
              dplyr::filter(pred_id == x)
            , gt_id = "pred_id"
            , predictions = watershed_ans_poly_circle_fit %>% 
              dplyr::filter(pred_id == x) %>% 
              dplyr::select(pred_id) %>% # keeping other columns causes error?
              dplyr::rename(circ_pred_id = pred_id)
            , pred_id = "circ_pred_id"
            , min_iou_pct = 0 # set to 0 just to return pct
          )    
        ) %>% 
        dplyr::bind_rows()
      
      # threshold for the minimum IoU to further filter for segments that are approximately round, 
      # this filter should remove linear objects from the watershed detections
        # compare iou
        watershed_keep_circle_fit_pred_id <- watershed_circle_fit_iou %>% 
          dplyr::filter(iou>=circle_fit_iou_pct) %>% 
          dplyr::pull(pred_id) 
    }
      
    if(
      identical(watershed_keep_circle_fit_pred_id, numeric(0))
      || any(is.null(watershed_keep_circle_fit_pred_id))
      || any(is.na(watershed_keep_circle_fit_pred_id))
      || length(watershed_keep_circle_fit_pred_id)<1
    ){
      stop(paste0(
        "no segments detected using the given CHM and circularity expectations"
        , "\n     try adjusting `circle_fit_iou_pct` "
      ))
    }
  
  ########################################################################################
  ## 5) raster smoothing
  ########################################################################################
    ########################################
    # use the remaining segments that meet the geometric and area filtering
    # to smooth the watershed raster
    ########################################
    smooth_watershed_ans <- watershed_ans %>% 
      terra::mask(
        watershed_ans_poly %>% #these are irregularity and area filtered already
          dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %>% 
          terra::vect()
        , updatevalue=NA
      )
    if(dplyr::coalesce(ws_for_smooth,0)>=3){
      # smooths the raster using the majority value
      smooth_watershed_ans <- smooth_watershed_ans %>% 
        terra::focal(w = ws_for_smooth, fun = "modal", na.rm = T, na.policy = "only") # only fill NA cells  
    }
    
    names(smooth_watershed_ans) <- "pred_id"

    ########################################
    # mask the chm rast to these remaining segments and smooth to match the smoothing for the segments
    ########################################
    smooth_chm_rast <- chm_rast %>% 
      terra::mask(smooth_watershed_ans)
    
    if(dplyr::coalesce(ws_for_smooth,0)>=3){
      # smooths the raster to match the smoothing in the watershed segments
      smooth_chm_rast <- smooth_chm_rast %>% 
        terra::focal(w = ws_for_smooth, fun = "mean", na.rm = T, na.policy = "only") #only for cells that are NA
    }

    # now mask the watershed_ans raster to only keep cells that are in the originating CHM
    smooth_watershed_ans <- smooth_watershed_ans %>% 
      terra::mask(smooth_chm_rast)

  ########################################################################################
  ## calculate raster-based area and volume 
  ########################################################################################
    # first, calculate the area of each cell
    area_rast <- terra::cellSize(smooth_chm_rast)
    names(area_rast) <- "area_m2"
    # area_rast %>% terra::plot()
    # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes
    vol_rast <- area_rast*smooth_chm_rast
    names(vol_rast) <- "volume_m3"
    # vol_rast %>% terra::plot()
    # sum area within each segment to get the total area
    area_df <- terra::zonal(x = area_rast, z = smooth_watershed_ans, fun = "sum", na.rm = T)
    # sum volume within each segment to get the total volume
    vol_df <- terra::zonal(x = vol_rast, z = smooth_watershed_ans, fun = "sum", na.rm = T)
    # max ht within each segment to get the max ht
    ht_df <- terra::zonal(x = smooth_chm_rast, z = smooth_watershed_ans, fun = "max", na.rm = T) %>% 
      dplyr::rename(max_height_m=2)
      
    # let's convert the smoothed and filtered watershed-detected segments from raster to vector data 
    # vectors of segments
    watershed_ans_poly <-
      smooth_watershed_ans %>% 
      terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
      sf::st_as_sf() %>% 
      sf::st_simplify() %>% 
      sf::st_make_valid() %>% 
      dplyr::filter(sf::st_is_valid(.)) %>% 
      dplyr::mutate(treeID=pred_id) %>% 
      cloud2trees::simplify_multipolygon_crowns() %>% 
      dplyr::select(-treeID)

    # add area and volume to our vector data  
    # we'll do this with a slick trick to perform multiple joins succinctly using purrr::reduce
    watershed_ans_poly <- 
      purrr::reduce(
        list(watershed_ans_poly, area_df, vol_df, ht_df)
        , dplyr::left_join
        , by = 'pred_id'
      ) %>% 
      dplyr::mutate(
        volume_per_area = volume_m3/area_m2
      ) %>% 
      # filter out the segments that don't meet the size thresholds
      dplyr::filter(
        dplyr::coalesce(area_m2,0) >= min_area_m2
        & dplyr::coalesce(area_m2,0) <= max_area_m2
        & dplyr::coalesce(max_height_m,0) >= min_ht_m
      ) %>% 
      # do one more pass of the irregularity filtering
      st_convexity_filter(pct_chull_overlap = convexity_pct)
      
      if(dplyr::coalesce(nrow(watershed_ans_poly),0)==0){
        stop(paste0(
          "no segments detected using the given CHM and expected size thresholds"
          , "\n     try adjusting `max_ht_m`, `min_area_m2`, `max_area_m2` "
        ))
      }
   

  ########################################################################################
  ## 4) shape refinement & overlap removal
  ########################################################################################
    # use the convex hull shapes of our remaining segments. 
    # This helps to smooth out the often 'blocky' edges of raster-based segments
    # , which can look like they were generated in Minecraft. 
    # Additionally, by removing any segments with overlapping convex hull shapes, 
    # we can likely reduce false detections that are actually groups of small trees or shrubs, 
    # ensuring our results represent singular slash piles.
    
    if(smooth_segs){
      ### ORIGINAL didn't combine touching segments first
      # return_dta <- watershed_ans_poly %>% 
      #   sf::st_convex_hull() %>% 
      #   sf::st_simplify() %>% 
      #   sf::st_make_valid() %>% 
      #   dplyr::filter(sf::st_is_valid(.)) %>% 
      #   dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %>% 
      #   st_remove_overlaps() %>% 
      #   # now we need to re-do the volume and area calculations
      #   dplyr::mutate(
      #     area_m2 = sf::st_area(.) %>% as.numeric()
      #     , volume_m3 = area_m2*volume_per_area
      #   ) %>% 
      #   dplyr::filter(
      #     dplyr::coalesce(area_m2,0) >= min_area_m2
      #     & dplyr::coalesce(area_m2,0) <= max_area_m2
      #   )
      
      # combine polygons that share a common border but don't overlap
        comb_watershed_ans_poly <- watershed_ans_poly %>% 
          dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id) %>% 
          st_dissolve_and_combine() %>% 
          dplyr::rename(id_comb_xxx = id) 
      # recalculate metrics
        agg_comb_watershed_ans_poly <- comb_watershed_ans_poly %>% 
          sf::st_intersection(
            watershed_ans_poly %>% 
              dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id)
          ) %>% 
          sf::st_drop_geometry() %>% 
          dplyr::group_by(id_comb_xxx) %>% 
          dplyr::summarise(
            area_m2 = sum(area_m2, na.rm = T)
            , volume_m3 = sum(volume_m3, na.rm = T)
            , max_height_m = max(max_height_m, na.rm = T)
          ) %>% 
          dplyr::mutate(
            volume_per_area = volume_m3/area_m2
          )
      # bring together
        comb_watershed_ans_poly <- 
          comb_watershed_ans_poly %>% 
          dplyr::inner_join(agg_comb_watershed_ans_poly, by = "id_comb_xxx") %>% 
          dplyr::rename(pred_id = id_comb_xxx) %>% 
          # filter out the segments that don't meet the size thresholds
          dplyr::filter(
            dplyr::coalesce(area_m2,0) >= min_area_m2
            & dplyr::coalesce(area_m2,0) <= max_area_m2
            & dplyr::coalesce(max_height_m,0) >= min_ht_m
          ) %>% 
          # do one more pass of the irregularity filtering
          st_convexity_filter(pct_chull_overlap = convexity_pct) %>% 
          # simplify multipolygons
          dplyr::mutate(treeID=dplyr::row_number()) %>% 
          cloud2trees::simplify_multipolygon_crowns() %>% 
          dplyr::select(-treeID)
        
        # watershed_ans_poly %>% dplyr::glimpse()
        # comb_watershed_ans_poly %>% dplyr::glimpse()
      
      # apply st_convex_hull
        return_dta <- comb_watershed_ans_poly %>% 
          sf::st_convex_hull() %>% 
          sf::st_simplify() %>% 
          sf::st_make_valid() %>% 
          dplyr::filter(sf::st_is_valid(.)) %>% 
          st_remove_overlaps() %>% 
          # now we need to re-do the volume and area calculations
          dplyr::mutate(
            area_m2 = sf::st_area(.) %>% as.numeric()
            , volume_m3 = area_m2*volume_per_area
          ) %>% 
          dplyr::filter(
            dplyr::coalesce(area_m2,0) >= min_area_m2
            & dplyr::coalesce(area_m2,0) <= max_area_m2
          )
      
    }else{
      return_dta <- watershed_ans_poly %>% 
        dplyr::filter(pred_id %in% watershed_keep_circle_fit_pred_id)
    }
    
    # calculate diameter
    return_dta <- st_calculate_diameter(return_dta)
      
  # return
    return(return_dta)
}
#################################################
# intermediat functions
#################################################
# rounds to nearest odd since ws for terra::focal() only takes odd
round_to_nearest_odd <- function(x) {
  rounded_int <- round(x)

  # step 2: check if the rounded integer is already odd
  is_odd <- (rounded_int %% 2 != 0)

  # step 3: for numbers that rounded to an even integer, find the nearest odd
  odd_down <- rounded_int - 1
  odd_up <- rounded_int + 1

  # calculate the absolute distances from the original number 'x'
  dist_down <- abs(x - odd_down)
  dist_up <- abs(x - odd_up)

  # step 4: use ifelse for vectorized conditional logic
  result <- ifelse(
    is_odd
    , rounded_int # if the initially rounded integer is odd, use it
    , ifelse(
      dist_down < dist_up
      , odd_down # if odd_down is strictly closer
      , odd_up # if odd_up is closer or equidistant
    )
  )

  return(result)
}
# round_to_nearest_odd(c(2,2.2,1.5,0))

# find window size given res and min expected area
ws_for_smooth_fn <- function(chm_res,min_area_m2){
  if(length(min_area_m2)>1){stop("min_area_m2 must be a single numeric value")}
  # return
  dplyr::case_when( 
    T ~ 0 ## all will be 0 so smoothing won't happen
    ###!!!!!! original attempt down here...just remove T ~ 0 !!!!!!###
    , (chm_res*3) > (min_area_m2/2) ~ 0 # the minimum ws of 3 exceeds half of the expected area (coarse)
    , T ~ round( (min_area_m2/4) / chm_res ) %>% round_to_nearest_odd() %>% max(3) # has to be odd and at least 3
  )
}
# dplyr::tibble(res = seq(0.01,0.5,by=0.01)) %>% 
#   dplyr::rowwise() %>% 
#   dplyr::mutate(
#     ws = ws_for_smooth_fn(res, 2) # min_area_m2=2
#     , area = ifelse(ws==0, res*res,
#       (res^2) * (ws^2))
#     , area_prop = area/2 # min_area_m2=2
#   ) %>% 
# ggplot() +
#   # geom_line(aes(x=res,y=ws)) +
#   # geom_line(aes(x=res,y=area)) +
#   geom_line(aes(x=res,y=area_prop)) +
#   # scale_y_continuous(breaks = scales::breaks_extended(n=22)) +
#   scale_y_continuous(breaks = scales::breaks_extended(n=22), labels = scales::percent) +
#   scale_x_continuous(breaks = scales::breaks_extended(n=20))
```

let's test this real quick on our example area

```{r}
# terra::plot(example_aoi_chm, axes = F, legend = F)
# terra::plot(
#   example_aoi %>% sf::st_transform(sf::st_crs(example_aoi_chm)) %>% terra::vect()
#   , add = T, border = "black", col = NA, lwd = 1.2
# )
slash_pile_detect_watershed_ans_temp <- slash_pile_detect_watershed(
  chm_rast = example_aoi_chm
  , max_ht_m = 4.5
  , min_ht_m = 0.5
  , min_area_m2 = 2
  , max_area_m2 = 50
  , convexity_pct = 0.8
  , circle_fit_iou_pct = 0.5
)
# what did we get?
slash_pile_detect_watershed_ans_temp %>% dplyr::glimpse()
```

how does it look overlaid on the CHM?

```{r}
terra::plot(example_aoi_chm, col = viridis::plasma(100), axes = F)
terra::plot(slash_pile_detect_watershed_ans_temp %>% terra::vect(),add = T, border = "brown", col = NA, lwd = 3)
```

how do the form quantification measurements look?

```{r}
p1_temp <- slash_pile_detect_watershed_ans_temp %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = area_m2)) +
  ggplot2::scale_fill_distiller(palette = "Blues", direction = 1) +
  ggplot2::labs(x="",y="") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "top", axis.text = ggplot2::element_blank())
p2_temp <- slash_pile_detect_watershed_ans_temp %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = volume_m3)) +
  ggplot2::scale_fill_distiller(palette = "BuGn", direction = 1) +
  ggplot2::labs(x="",y="") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "top", axis.text = ggplot2::element_blank())
p3_temp <- slash_pile_detect_watershed_ans_temp %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = max_height_m)) +
  ggplot2::scale_fill_distiller(palette = "YlOrBr", direction = 1) +
  ggplot2::labs(x="",y="") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "top", axis.text = ggplot2::element_blank())
p4_temp <- slash_pile_detect_watershed_ans_temp %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = diameter_m)) +
  ggplot2::scale_fill_distiller(palette = "PuRd", direction = 1) +
  ggplot2::labs(x="",y="") +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "top", axis.text = ggplot2::element_blank())
(p1_temp + p2_temp) / (p3_temp + p4_temp)
```

the volume per area ratio (`volume_per_area`) quantifies the "effective" height or depth of that volume relative to the area it occupies; this ratio may not be very useful for anything other than scaling estimates to relate a three-dimensional quantity (volume) to a two-dimensional quantity (area)

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
remove(
  max_ht_m, min_area_m2, max_area_m2, watershed_ans
  , watershed_ans_poly, watershed_ans_poly_chull
  , pct_chull_overlap, watershed_keep_overlaps_chull_pred_id
  , watershed_ans_poly_circle_fit, watershed_circle_fit_iou
  , pct_iou_circle_fit, watershed_keep_circle_fit_pred_id
  , ht_df, area_df, area_rast, ground_truth_prediction_match_ans
  , plt_ortho_example, predicted_watershed_piles_sf, smooth_chm_rast
  , vol_df, vol_rast, min_ht_m, smooth_watershed_ans
)
gc()
```
