--- 
title: "Aerial Imagery and Point Cloud Data for Slash Pile Quantification"
author: "George Woolsey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    includes:
      in_header: header.html
documentclass: book
book_filename: "manitou_slash_piles"
output_dir: "../docs"
language:
  ui:
    chapter_name: "Section "
delete_merged_file: true
bibliography: [packages.bib]
biblio-style: apalike
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/research-institute-for-nature-and-forest.csl
suppress-bibliography: true
lang: en-US
zotero: true
link-citations: true
description: "Using the bookdown package to write a book of data exploration. The output format for this example is bookdown::gitbook."
---

# Introduction

Code in support of "Aerial Imagery and Point Cloud Data for Slash Pile Quantification"

## Objective

The objective of this study is to present a training-free, rules-based methodology for identifying slash piles from UAS data. The presented approach aims to enable high transferability by using user-defined geometric and size thresholds to identify pile candidates from aerial point cloud data, which can then be refined through a data fusion process incorporating spectral (i.e. RGB) data when available.

## Data{#data_desc}

We have remote sensing data acquired from a UAS platform and accompanying ground truth data for four different study sites. For all study sites we have:

* Aerial RGB imagery captured by a UAS platform
* Aerial point cloud data generated by processing the UAS imagery using structure from motion (SfM) photogrammetry techniques
* Image-annotated slash pile perimeters digitized in a Geographic Information System (GIS) using field-collected point locations as a guide overlaid on the UAS-collected RGB imagery

For the training study site only we have: 
* Field-collected slash pile point locations with height and diameter measurements

Data from the training study site will be used to build and test the slash pile detection and quantification framework. Data from the other study sites will be used to validate the method based on learnings from the training data testing and analysis.

The following table provides an overview of the four sites utilized in this study, detailing the unique characteristics of each location and how the data was collected. We structured the validation effort to compare performance across a wide spectrum of data collection platforms, pile sizes, construction methods, and surrounding vegetation types, which required specific parameter adaptations for each site. This summary highlights the distinct ecological and structural challenges inherent to each evaluation site.

| Site Name | Pile Type | Data Use | Unique Features & Ecology | Data Collection |
| :--- | :--- | :--- | :--- | :--- |
| **PSINF Ponderosa Pine Training Site** | Mostly Hand Piles (some smaller machine piles) | Training | Located in the Pike and San Isabel National Forest (PSINF). Ponderosa pine stand with mixed ground cover and varying canopy density. | *insert data collection summary* |
| **TRFO-BLM Pinyon-Juniper Validation Site** | Hand Piles | Validation | Located on Bureau of Land Management (BLM) land in the Colorado Southwest District managed by the Tres Rios Field Office (TRFO-BLM). Arid environment with dry vegetation appearing less green including standing dead pinyon-juniper vegetation. Piles are smaller, simpler, and hand-stacked. | *insert data collection summary* |
| **BHEF Ponderosa Pine Validation Site** | Massive Machine Piles | Validation | Located in the Black Hills Experimental Forest (BHEF). Piles are massive, mechanically built, and irregularly shaped (e.g. not necessarily circular). Tree regeneration is expected based on local precipitation and typical regrowth response. | *insert data collection summary* |
| **ARNF Ponderosa Pine Validation Site** | Massive Machine Piles | Validation | Located in the Arapahoe and Roosevelt National Forest (ARNF). Ponderosa pine forest with a climate similar to the training site and drier than BHEF. Piles are massive but more circular and regular. Less regeneration is expected due to more recent treatment and drier climate. | *insert data collection summary* |

## Updated Analysis Plan

We aim to present a geometry-based approach that uses rules and user-defined thresholds applied to geometric features (such as area, shape, and height) to identify slash pile candidates from UAS-SfM point cloud data. To refine these initial candidates and improve detection accuracy, a data fusion approach is also presented which incorporates spectral data (RGB) as an additional filtering step when available. This structure allows the geometry-based method to be implemented in a standalone mode if the necessary spectral data is not present. 

Similar geometry-based approaches have been successfully used to detected coarse woody debris from aerial point cloud and CHM data (Nystr√∂m et al. 2014; Richardson and Moskal 2016; Jarron et al. 2021; dos Santos et al. 2025). Other methods used to detect coarse woody debris include manual inspection of the point cloud (Joyce et al. 2019) or the use of deep learning (Windrim et al. 2019) and machine learning (Heinaro et al. 2021; Shokirov et al. 2021) models trained on specific data. However, Heinaro et al. (2023) caution that these model-based approaches may not be transferrable outside of unseen areas or conditions not represented in the training data. As such, we chose to utilize a geometry-based, rules-based system to enable transferability across different conditions and align the method with the explicit pile construction parameters generally known by land managers through silvicultural treatment prescriptions.

We will follow the general analysis outline in five distinct sections:

1. **Geometry-based Slash Pile Detection:** We will detail the geometry-based slash pile detection method which uses user-defined thresholds applied to geometric features from a Canopy Height Model (CHM) derived from UAS-SfM point cloud data.
2. **Spectral Refinement Methodology:** We will detail the complementary spectral refinement methodology which uses RGB data to filter the structurally-detected candidate piles.
3. **Structural-Only Methodology Evaluation:** We will evaluate the accuracy of the structural-only methodology in terms of slash pile detection (F-score, Recall, Precision) across four distinct treatment units spanning unique prescriptions and forest types.
4. **Data Fusion Methodology Evaluation:** We will evaluate the accuracy of the structural-plus-spectral data fusion methodology in terms of slash pile detection (F-score, Recall, Precision) when using spectral data to refine predictions.
5. **Sensitivity Analysis:** Finally, we will perform a sensitivity analysis on the key user-defined parameters of the proposed method to systematically quantify the impact of each varied parameter on the stability and performance of the slash pile detection.

## Old Analysis Plan

This project progressed through several phases to develop and validate a rigorous rules-based methodology for slash pile detection using UAS-collected data. The following summarizes the analysis project upon completion.

**Phase 1: Methodology Development and Sensitivity Testing**
This phase involved using ground truth data to perform [sensitivity testing](#allthetests) on the rules-based detection methodology. We first demonstrated a [structural-only method](#raster_watershed), which uses a CHM raster generated from aerial point cloud data to identify candidate piles based on structural metrics like height, area, and shape. This method can be used when spectral data is unavailable. We then demonstrated a [data fusion approach](#data_fusion), which builds on the structural method by integrating spectral data as an additional filtering step. This approach takes the structurally-detected candidates and filters out potential false positive predictions by applying a set of spectral index thresholds. We then performed parameter [sensitivity testing](#allthetests) to systematically vary parameterizations on both approaches and quantify the resulting changes in detection and form quantification accuracy. This sensitivity testing provided a set of individual point estimates of detection accuracy (F-score) and quantification accuracy (e.g. RMSE and MAPE) for each parameter combination tested. These point estimates then served as the input dataset for subsequent [statistical modeling](#stats_method) to quantify the influence of parameters and input data on accuracy.

**Phase 2: Statistical Modeling**
Following sensitivity testing, a Bayesian Generalized Linear Model (GLM) was used to build a [statistical framework](#stats_method) for understanding the methodology's performance. Unlike the sensitivity testing, which generate a range of detection and quantification accuracies based on parameter combinations tested, the statistical modeling does not calculate accuracy itself but instead uses these point estimates as dependent variables to statistically model the functional relationship between the tested detection parameters and the resulting accuracy. This provided a principled way to understand uncertainty and the complex interactions between parameters by providing posterior distributions for each parameter estimate rather than simple point estimates as obtained via sensitivity testing. This statistical modeling enabled the quantification of Bayesian credible intervals, which provide a direct measure of the uncertainty in each relationship, and allowed us to explicitly model interactions between parameters (e.g., the combined effect of CHM resolution and spectral data). Understanding these relationships and their associated uncertainty is critical for making more informed and confident decisions about the method's optimal settings.

**Phase 3: Method Validation**

The [final phase](#validation_summary) of this study involves three validation sites to assess the methodology's real-world generalizability and transferability. Crucially, our detection methodology's parameter setup (i.e. size, shape, and spectral filters) will be adjusted for each validation site based on its unique treatment and pile construction prescription, mimicking real-life application where optimal settings vary by implementation and forest type.

```{r, include=FALSE, echo=FALSE}
knitr::write_bib(c(
  .packages(),
  "bookdown"
  , "knitr"
  , "rmarkdown"
  , "tidyverse"
  , "viridis"
  , "RColorBrewer"
  , "scales"
  , "latex2exp"
  , "mapview"
  , "kableExtra"
  , "patchwork"
  , "ggnewscale"
  , "terra"
  , "stars"
  , "sf"
  , "brms"
  , "tidybayes"
  , "parallel"
), 'packages.bib')
```
