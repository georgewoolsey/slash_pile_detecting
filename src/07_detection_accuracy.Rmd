# Detection Accuracy{#preds_detect}

To this point we have:

1. Provided a data overview: [here](#data_desc) and [here](#data_load)
2. [Processed the UAS point cloud](#ptcld_process)
3. [Demonstrated our geometry-based slash pile detection methodology](#geom_detect)
4. [Demonstrated our spectral refinement (i.e. data fusion) methodology](#data_fusion)
5. [Reviewed how we will evaluate our method](#meth_eval)
5. and [Made predictions using our method on our experimental sites](#meth_preds)

In this section, we'll evaluate the effectiveness of the proposed geometric, rules-based slash pile detection methodology by assessing its detection accuracy performance. We fully reviewed the detection accuracy assessment [workflow here](#detect_metrics_form), but here is a quick overview:

Detection accuracy metrics are calculated by aggregating raw TP (true positive), FP (false positive; commission), and FN (false negative; omission) counts to quantify the method's ability to find the piles. Aggregation of the instance matching allows us to evaluate omission rate (false negative rate or miss rate), commission rate (false positive rate), precision, recall (detection rate), and the F-score metric. As a reminder, true positive (TP) instances correctly match ground truth instances with a prediction, commission tree predictions do not match a ground truth tree (false positive; FP), and omissions are ground truth instances for which no predictions match (FN)

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Instance Matching

The first step in evaluating the performance of our slash pile detection methodology is to perform instance matching. Instance matching is the process of checking our predictions of slash pile presence (or absence) against the actual pile locations in real life (we use image-annotated pile outlines as ground truth) to determine if the method correctly identifies presence and absence. We use the framework established by Puliti et al. [(2023, p. 14)](https://doi.org/10.48550/arXiv.2309.01279) to validate detections based on an Intersection over Union (IoU) threshold. We set this threshold at 45% which is slightly more permissive than the 50% used by Puliti et al. (2023) for tree crowns to accommodate the fact that our target objects are located on the forest floor rather than in the canopy and are therefore subject to higher levels of occlusion from aerial data.

we reviewed this process and defined the function `ground_truth_prediction_match()` [here](#iou_match)

```{r, results=F}
# map over ground_truth_prediction_match for dbscan
  dbscan_gt_pred_match <- 
    all_stand_boundary$site_data_lab %>% 
    purrr::set_names() %>% 
    purrr::map(
      \(x)
      ground_truth_prediction_match(
          ground_truth = slash_piles_polys[[x]] %>% 
            dplyr::filter(is_in_stand) %>% 
            sf::st_transform( sf::st_crs(dbscan_spectral_preds[[x]]) ) %>% 
            dplyr::arrange(desc(image_gt_area_m2)) # this is so the algorithm starts with the largest
          , gt_id = "pile_id"
          , predictions = dbscan_spectral_preds[[x]]
          , pred_id = "pred_id"
          , min_iou_pct = 0.45
        )
      , .progress = T
    )
# map over ground_truth_prediction_match for watershed
  watershed_gt_pred_match <- 
    all_stand_boundary$site_data_lab %>% 
    purrr::set_names() %>% 
    purrr::map(
      \(x)
      ground_truth_prediction_match(
          ground_truth = slash_piles_polys[[x]] %>% 
            dplyr::filter(is_in_stand) %>% 
            sf::st_transform( sf::st_crs(watershed_spectral_preds[[x]]) ) %>% 
            dplyr::arrange(desc(image_gt_area_m2)) # this is so the algorithm starts with the largest
          , gt_id = "pile_id"
          , predictions = watershed_spectral_preds[[x]]
          , pred_id = "pred_id"
          , min_iou_pct = 0.45
        )
      , .progress = T
    )
```

let's see what the instance matching data looks like

```{r}
# what did we get?
dbscan_gt_pred_match[[1]] %>% 
  dplyr::glimpse()
```

let's quickly look at the distribution of IoU for the TP matches

```{r, fig.height=9.7}
# palette
pal_match_grp = c(
  "omission"=viridis::cividis(3)[1]
  , "commission"= viridis::cividis(3)[2]
  , "true positive"=viridis::cividis(3)[3]
)
# plot
iou_dta_temp <- 
  dplyr::bind_rows(
   dbscan_gt_pred_match %>% 
      purrr::imap(
        \(x,nm)
        x %>% 
        dplyr::filter(match_grp=="true positive") %>% 
        dplyr::mutate(
          site = all_stand_boundary %>% dplyr::filter(site_data_lab==nm) %>% dplyr::pull(site)
          , method = "dbscan"
        )
      ) %>% 
     dplyr::bind_rows()
   , watershed_gt_pred_match %>% 
      purrr::imap(
        \(x,nm)
        x %>% 
        dplyr::filter(match_grp=="true positive") %>% 
        dplyr::mutate(
          site = all_stand_boundary %>% dplyr::filter(site_data_lab==nm) %>% dplyr::pull(site)
          , method = "watershed"
        )
      ) %>% 
     dplyr::bind_rows()
  )
# plot it

iou_dta_temp %>% 
  # dplyr::glimpse()
  ggplot2::ggplot(mapping = ggplot2::aes(x = iou)) +
  ggplot2::geom_vline(xintercept = 0.45, color = "gray", linetype = "dashed", lwd = 1.5) +
  ggplot2::geom_violin(
    mapping = ggplot2::aes(y = 0, color = match_grp, fill = match_grp)
    , alpha = 0.8
  ) +
  ggplot2::geom_boxplot(width = 0.1, fill = NA, outliers = F) +
  ggplot2::scale_color_manual(values=pal_match_grp) +
  ggplot2::scale_fill_manual(values=pal_match_grp) +
  ggplot2::scale_y_continuous(NULL,breaks=NULL) +
  ggplot2::scale_x_continuous(limits = c(0,1), labels=scales::percent, breaks = scales::breaks_extended(n=6)) +
  ggplot2::facet_grid(
    rows = dplyr::vars(site)
    , cols = dplyr::vars(method)
    # , scales = "free_y"
    , switch = "y"
    , axes = "all_x"
  ) +
  ggplot2::labs(
    color="",fill="",x="IoU of correct precitions"
  ) +
  ggplot2::theme_light() +
  ggplot2::theme(
    legend.position = "none"
    , strip.text = ggplot2::element_text(size = 10, color = "black", face = "bold")
    , axis.text.x = ggplot2::element_text(size = 9)
    , axis.text.y = ggplot2::element_blank()
    , axis.ticks.y = ggplot2::element_blank()
  )
```

the majority of correct predictions had high overlap with the actual, ground truth piles with only a few piles at one site approaching the 45% minimum threshold to determine a match. let's check out the summary stats

```{r}
iou_dta_temp %>% 
  dplyr::group_by(site,method) %>% 
  dplyr::summarise(
    dplyr::across(
      c(iou)
      , .fns = list(
        mean = ~mean(.x,na.rm=T)
        , q50 = ~quantile(.x,na.rm=T,probs=0.5)
        , sd = ~sd(.x,na.rm=T)
        # , q10 = ~quantile(.x,na.rm=T,probs=0.1)
        # , q90 = ~quantile(.x,na.rm=T,probs=0.9)
        # , min = ~min(.x,na.rm=T)
        # , max = ~max(.x,na.rm=T)
        , range = ~paste0(
          scales::percent(min(.x,na.rm=T), accuracy = 0.1)
          ,"-"
          , scales::percent(max(.x,na.rm=T), accuracy = 0.1)
        )
      )
    )
    , n = dplyr::n() %>% scales::comma(accuracy = 1)
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(
    dplyr::across(
      dplyr::where(is.numeric)
      , ~scales::percent(.x,accuracy=0.1)
    )
  ) %>% 
  dplyr::relocate(site,method,n) %>% 
  dplyr::arrange(site,method) %>% 
  kableExtra::kbl(
    caption = "IoU of correct predictions (TP)"
    , col.names = c(
      "site", "method"
      , "TP predictions"
      , "IoU mean"
      , "IoU median"
      , "IoU sd"
      , "IoU range"
    )
    , escape = F
    # , digits = 2
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::collapse_rows(columns = 1, valign = "top")
```

```{r, include=FALSE, eval=FALSE}
iou_dta_temp %>% 
  # dplyr::glimpse()
  ggplot2::ggplot(mapping = ggplot2::aes(x = iou, color = match_grp, fill = match_grp)) +
  ggplot2::geom_vline(xintercept = 0.45, color = "gray", linetype = "dashed", lwd = 1.5) +
  ggplot2::geom_density(mapping = ggplot2::aes(y=ggplot2::after_stat(scaled)), alpha = 0.8) +
  ggplot2::scale_color_manual(values=pal_match_grp) +
  ggplot2::scale_fill_manual(values=pal_match_grp) +
  ggplot2::scale_y_continuous(NULL,breaks=NULL) +
  ggplot2::scale_x_continuous(limits = c(0,1), labels=scales::percent) +
  ggplot2::facet_grid(
    rows = dplyr::vars(site)
    , cols = dplyr::vars(method)
    # , scales = "free_y"
    , switch = "y"
    , axes = "all_x"
  ) +
  ggplot2::labs(
    color="",fill="",x="IoU of correct precitions"
  ) +
  ggplot2::theme_light() +
  ggplot2::theme(
    legend.position = "none"
    , strip.text = ggplot2::element_text(size = 11, color = "black", face = "bold")
    , axis.text.x = ggplot2::element_text(size = 11)
    , axis.text.y = ggplot2::element_blank()
    , axis.ticks.y = ggplot2::element_blank()
  )
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

let's look at the results spatially noting that just because a prediction overlaps with a ground truth pile does not mean that it meets the IoU threshold for determining a positive match. in these cases where the IoU was insufficient, a commission (FP) will overlap with an omission (FN).

```{r, results=F}
plt_fn_temp <- function(x, method) {
  if(tolower(method) == "dbscan"){
    preds <- dbscan_spectral_preds
    gt_pred_match <- dbscan_gt_pred_match
  }else if(tolower(method) == "watershed"){
    preds <- watershed_spectral_preds
    gt_pred_match <- watershed_gt_pred_match
  }else{return(NULL)}
  # plot it
    ggplot2::ggplot() +
      ggplot2::geom_sf(
        data = stand_boundary[[x]] %>% 
          sf::st_transform(sf::st_crs(preds[[x]]))
        , color = "black", fill = NA
      ) + 
      ggplot2::geom_sf(
        data = 
          slash_piles_polys[[x]] %>% 
            dplyr::filter(is_in_stand) %>% 
            dplyr::left_join(
              gt_pred_match[[x]] %>% 
                dplyr::select(pile_id,match_grp)
              , by = "pile_id"
            ) %>% 
            sf::st_transform(sf::st_crs(preds[[x]]))
        , mapping = ggplot2::aes(fill = match_grp)
        , color = NA ,alpha=0.7
        , show.legend = T
      ) + 
      ggplot2::geom_sf(
        data =
          preds[[x]] %>%
            dplyr::filter(is_in_stand) %>% 
            dplyr::left_join(
              gt_pred_match[[x]] %>% 
                dplyr::select(pred_id,match_grp)
              , by = "pred_id"
            )
        , mapping = ggplot2::aes(fill = match_grp, color = match_grp)
        , alpha = 0
        , lwd = 0.5
        , show.legend = T
      ) +
      ggplot2::scale_fill_manual(values = pal_match_grp, drop = F, name = "") +
      ggplot2::scale_color_manual(values = pal_match_grp, drop = F, name = "") +
      ggplot2::labs(
        subtitle = paste0(
          method
          , " predictions: "
          , slash_piles_polys[[x]] %>% 
            dplyr::slice(1) %>% 
            dplyr::pull(site)
        )
      ) +
      ggplot2::theme_void() +
      ggplot2::theme(
        plot.subtitle = ggplot2::element_text(
          size = 7, hjust = 0.5
          , vjust = 1
          , margin = margin(t = 0, r = 0, b = -2, l = 0, unit = "pt")
        )
      ) +
      ggplot2::guides(
        fill = ggplot2::guide_legend(
          override.aes = list(
            color = c(NA,pal_match_grp["commission"],NA)
            , fill = c(pal_match_grp["omission"],NA,pal_match_grp["true positive"])
          )
        )
        , color = "none"
      )
}
# do it
dbscan_plt_temp <- all_stand_boundary$site_data_lab %>% 
  purrr::set_names() %>% 
  purrr::map(
    \(xx)
    plt_fn_temp(xx,method = "DBSCAN")
  )
# dbscan_plt_temp[[1]]

watershed_plt_temp <- all_stand_boundary$site_data_lab %>% 
  purrr::set_names() %>% 
  purrr::map(
    \(xx)
    plt_fn_temp(xx,method = "Watershed")
  )
# watershed_plt_temp[[1]]

```

combine plots with `patchwork`

```{r, fig.height=10.5, fig.width=7}
# c(dbscan_plt_temp, watershed_plt_temp) %>%
#   (\(x) x[order(names(x))])() %>% 
#   names()
patchwork::wrap_plots(
  c(dbscan_plt_temp, watershed_plt_temp) %>%
    (\(x) x[order(names(x))])()
  , ncol = 2, guides = "collect"
  , byrow = T
) &
ggplot2::theme(legend.position = "bottom")
```

note the color legend...we like to see a lot of yellow :D

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Detection Accuracy Metrics

now we aggregate the pile-level data (TP, FP, FN) into a single record for each study site and segmentation method combination. Detection performance metrics include F-score, precision, and recall.

because our `agg_ground_truth_match()` function that we [defined earlier](#quant_metrics_form) includes capabilities to compute quantification metrics as well (e.g. height MAPE, RMSE, etc.), we'll add the pile sizing metrics to our instance match data so that `agg_ground_truth_match()` recognizes them.

* "diff_" columns are calculated as the predicted value minus the actual value (e.g. `pred_diameter_m - gt_diameter_m`) 
* "pct_diff_" columns are calculated as the actual value minus the predicted value divided by the actual value (e.g. `(gt_diameter_m - pred_diameter_m)/gt_diameter_m`)

```{r}
# add prediction and validation measurements for dbscan
dbscan_gt_pred_match <- 
  dbscan_gt_pred_match %>% 
  purrr::imap(
    \(x,nm)
    # because psinf has field data but no others do
    if(nm=="psinf"){
      x %>% 
      # join on gt data
      dplyr::left_join(
        slash_piles_polys[[nm]] %>% 
          dplyr::rename(field_volume_m3=field_gt_volume_m3) %>% 
          dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2, field_height_m, field_diameter_m, field_volume_m3) %>% 
          dplyr::rename_with(~ stringr::str_remove(.x, "^image_")) %>% 
          sf::st_drop_geometry()
        , by = "pile_id"
      ) %>% 
      # join on pred area data
      dplyr::left_join(
        dbscan_spectral_preds[[nm]] %>% 
          dplyr::select(
            pred_id
            , diameter_m
            , area_m2
            , volume_m3
            , max_height_m
          ) %>% 
          dplyr::rename(height_m=max_height_m) %>% 
          dplyr::rename_with(
            ~ paste0("pred_", .x, recycle0 = TRUE)
            , .cols = -c(pred_id)
          ) %>% 
          sf::st_drop_geometry()
        , by = "pred_id"
      ) %>% 
      # calculate difference columns
      dplyr::mutate(
        # area_m2
        diff_area_m2 = pred_area_m2-gt_area_m2
        , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2
        # diameter_m
        , diff_diameter_m = pred_diameter_m-gt_diameter_m
        , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m
        # field diameter_m
        , diff_field_diameter_m = pred_diameter_m-field_diameter_m
        , pct_diff_field_diameter_m = (field_diameter_m-pred_diameter_m)/field_diameter_m
        # field height_m
        , diff_field_height_m = pred_height_m-field_height_m
        , pct_diff_field_height_m = (field_height_m-pred_height_m)/field_height_m
        # # field volume_m3
        # , diff_field_volume_m3 = pred_volume_m3-field_volume_m3
        # , pct_diff_field_volume_m3 = (field_volume_m3-pred_volume_m3)/field_volume_m3
      )  
    }else{
      x %>% 
      # join on gt data
      dplyr::left_join(
        slash_piles_polys[[nm]] %>% 
          dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2) %>% 
          dplyr::rename_with(~ stringr::str_remove(.x, "^image_")) %>% 
          sf::st_drop_geometry()
        , by = "pile_id"
      ) %>% 
      # join on pred area data
      dplyr::left_join(
        dbscan_spectral_preds[[nm]] %>% 
          dplyr::select(
            pred_id
            , diameter_m
            , area_m2
            , volume_m3
            , max_height_m
          ) %>% 
          dplyr::rename(height_m=max_height_m) %>% 
          dplyr::rename_with(
            ~ paste0("pred_", .x, recycle0 = TRUE)
            , .cols = -c(pred_id)
          ) %>% 
          sf::st_drop_geometry()
        , by = "pred_id"
      ) %>% 
      # calculate difference columns
      dplyr::mutate(
        # area_m2
        diff_area_m2 = pred_area_m2-gt_area_m2
        , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2
        # diameter_m
        , diff_diameter_m = pred_diameter_m-gt_diameter_m
        , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m
      )
    }
  )
# dbscan_gt_pred_match %>% dplyr::glimpse()
# add prediction and validation measurements for watershed
watershed_gt_pred_match <- 
  watershed_gt_pred_match %>% 
  purrr::imap(
    \(x,nm)
    # because psinf has field data but no others do
    if(nm=="psinf"){
      x %>% 
      # join on gt data
      dplyr::left_join(
        slash_piles_polys[[nm]] %>% 
          dplyr::rename(field_volume_m3=field_gt_volume_m3) %>% 
          dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2, field_height_m, field_diameter_m, field_volume_m3) %>% 
          dplyr::rename_with(~ stringr::str_remove(.x, "^image_")) %>% 
          sf::st_drop_geometry()
        , by = "pile_id"
      ) %>% 
      # join on pred area data
      dplyr::left_join(
        watershed_spectral_preds[[nm]] %>% 
          dplyr::select(
            pred_id
            , diameter_m
            , area_m2
            , volume_m3
            , max_height_m
          ) %>% 
          dplyr::rename(height_m=max_height_m) %>% 
          dplyr::rename_with(
            ~ paste0("pred_", .x, recycle0 = TRUE)
            , .cols = -c(pred_id)
          ) %>% 
          sf::st_drop_geometry()
        , by = "pred_id"
      ) %>% 
      # calculate difference columns
      dplyr::mutate(
        # area_m2
        diff_area_m2 = pred_area_m2-gt_area_m2
        , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2
        # diameter_m
        , diff_diameter_m = pred_diameter_m-gt_diameter_m
        , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m
        # field diameter_m
        , diff_field_diameter_m = pred_diameter_m-field_diameter_m
        , pct_diff_field_diameter_m = (field_diameter_m-pred_diameter_m)/field_diameter_m
        # field height_m
        , diff_field_height_m = pred_height_m-field_height_m
        , pct_diff_field_height_m = (field_height_m-pred_height_m)/field_height_m
        # # field volume_m3
        # , diff_field_volume_m3 = pred_volume_m3-field_volume_m3
        # , pct_diff_field_volume_m3 = (field_volume_m3-pred_volume_m3)/field_volume_m3
      )  
    }else{
      x %>% 
      # join on gt data
      dplyr::left_join(
        slash_piles_polys[[nm]] %>% 
          dplyr::select(pile_id, image_gt_diameter_m, image_gt_area_m2) %>% 
          dplyr::rename_with(~ stringr::str_remove(.x, "^image_")) %>% 
          sf::st_drop_geometry()
        , by = "pile_id"
      ) %>% 
      # join on pred area data
      dplyr::left_join(
        watershed_spectral_preds[[nm]] %>% 
          dplyr::select(
            pred_id
            , diameter_m
            , area_m2
            , volume_m3
            , max_height_m
          ) %>% 
          dplyr::rename(height_m=max_height_m) %>% 
          dplyr::rename_with(
            ~ paste0("pred_", .x, recycle0 = TRUE)
            , .cols = -c(pred_id)
          ) %>% 
          sf::st_drop_geometry()
        , by = "pred_id"
      ) %>% 
      # calculate difference columns
      dplyr::mutate(
        # area_m2
        diff_area_m2 = pred_area_m2-gt_area_m2
        , pct_diff_area_m2 = (gt_area_m2-pred_area_m2)/gt_area_m2
        # diameter_m
        , diff_diameter_m = pred_diameter_m-gt_diameter_m
        , pct_diff_diameter_m = (gt_diameter_m-pred_diameter_m)/gt_diameter_m
      )
    }
  )
# watershed_gt_pred_match %>% dplyr::glimpse()
# agg_ground_truth_match(watershed_gt_pred_match[[1]]) %>% dplyr::glimpse()
```

apply our `agg_ground_truth_match()` function

```{r}
agg_ground_truth_match_ans <- 
  dplyr::bind_rows(
    dbscan_gt_pred_match %>% 
      purrr::map_dfr(agg_ground_truth_match, .id = "site_data_lab") %>% 
      dplyr::mutate(method = "dbscan") %>% 
      dplyr::bind_rows()
    , watershed_gt_pred_match %>% 
      purrr::map_dfr(agg_ground_truth_match, .id = "site_data_lab") %>% 
      dplyr::mutate(method = "watershed") %>% 
      dplyr::bind_rows()
  ) %>% 
  dplyr::inner_join(
    all_stand_boundary %>% 
      dplyr::select(site_data_lab, site) %>% 
      sf::st_drop_geometry()
    , by = "site_data_lab"
  )
```

what did we get?

```{r}
agg_ground_truth_match_ans %>% 
  dplyr::glimpse()
```

let's make a nice table of the detection accuracy metrics by study site and segmentation method

```{r}
agg_ground_truth_match_ans %>% 
  dplyr::select(
    site, method
    , tidyselect::ends_with("_n")
    , precision, recall, f_score
  ) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::ends_with("_n")
      , ~scales::comma(.x,accuracy=1)
    )
    , dplyr::across(
      dplyr::where(is.numeric)
      , ~scales::percent(.x,accuracy=0.1)
    )
  ) %>% 
  dplyr::arrange(site,method) %>% 
  kableExtra::kbl(
    caption = "Detection Accuracy"
    , col.names = c(
      "site", "method"
      , "TP predictions", "FP predictions", "FN predictions"
      , "Precision", "Recall", "F-score"
    )
    , escape = F
    # , digits = 2
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::collapse_rows(columns = 1, valign = "top")  
```

check those recall rates :)

```{r}

```

