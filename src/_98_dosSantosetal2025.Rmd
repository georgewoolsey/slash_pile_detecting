# Test

Attempt to integrate approach for woody debris (WD) detection proposed by [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651). This approach is presented as:

>...a general and adaptive morphological WD detection strategy that requires only a few intuitive thresholds, making it suitable for multi-platform LiDAR datasets in both plantation and natural forests. The conceptual basis of the strategy is that WD LiDAR points exhibit non-planar characteristics and a distinct intensity and comprise clusters that exceed a minimum size...(presented is a) WD detection approach based on morphological characteristics of debris is proposed that does not require rasterization of the LiDAR data and time-consuming training data curation (pp. 1-2)

The workflow of the proposed strategy is comprised of ~~four~~ three main steps: 

1) point cloud pre-processing to isolate portions including WD 
2) geometry- and intensity-based WD detection (using intensity is an optional step)
3) WD clustering and refinement

because there was no WD detection benefit from including the intensity step and because UAS-SfM point clouds generally don't have intensity values, we will attempt to build the proposed process without the intensity-based workflow.

>...the incorporation of either the original or normalized intensity did not lead to significant performance improvements when compared to WD detection using planarity only (p. 22) 

Load the standard libraries we use to do work

```{r, warning=FALSE, message=FALSE}
# bread-and-butter
library(tidyverse) # the tidyverse
library(viridis) # viridis colors
library(harrypotter) # hp colors
library(RColorBrewer) # brewer colors
library(scales) # work with number and plot scales
library(latex2exp)

# visualization
library(mapview) # interactive html maps
library(kableExtra) # tables
library(patchwork) # combine plots
library(corrplot) # correlation plots
library(ggnewscale) # new scale

# spatial analysis
library(terra) # raster
library(sf) # simple features
library(lidR) # lidar data
library(rgl) # 3d plots
library(cloud2trees) # the cloud2trees

# modelling
library(brms)
library(tidybayes)

# point cloud-based detection
library(RANN) #kd-tree
library(dbscan) #dbscan
```

the analysis below will roughly follow the [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) proposed workflow for the WD detection strategy in Figure 4

## Isolate possible WD points

load a normalized point cloud tile to test with

```{r}
nlas_fpath <- "../data/Dawson_Data/point_cloud_processing_temp/02_normalize/"
# list.files(nlas_fpath, pattern = ".*\\.(laz|las)$", full.names = T)
# list.files(nlas_fpath, pattern = ".*\\.(laz|las)$", full.names = T) %>% lidR::readLAScatalog() %>% lidR::plot()
las <- lidR::readLAS(
  list.files(nlas_fpath, pattern = ".*\\.(laz|las)$", full.names = T)[10] #15
  , select = "xyzic"
  , filter = "-drop_class 2 7 9 18" # ground = 2, noise = 7,18, water = 9
  # , filter = "-drop_class 7 9 18" # dos Santos keep ground
)
# las@data %>% dplyr::glimpse()
# las@data$Classification %>% table()
```

load in image-annotated piles

```{r}
piles <- sf::st_read("../data/Dawson_Data/piles/pj_pile_polys.shp",quiet=T) %>% 
  sf::st_transform(lidR::st_crs(las)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(pile_id = dplyr::row_number())
```

where is the tile in the pile space?

```{r}
lidR::st_bbox(las) %>% 
  sf::st_as_sfc() %>% 
  sf::st_as_sf() %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(fill = NA, lwd = 2) +
  ggplot2::geom_sf(data = piles, fill = NA, color = "blue")
```

plot the point cloud real quick

```{r}
lidR::plot(las, color = "Z", pal = harrypotter::hp(n=100,option = "gryffindor"))
```

## Planarity estimation

let's test out `lidR::segment_shapes()` which...

>computes, for each point, the eigenvalues of the covariance matrix of the neighboring points. The eigenvalues are later used either to segment linear/planar points or to compute derived metrics. The points that meet a given criterion based on the eigenvalue are labelled as approximately coplanar/colinear or any other shape supported.

in defining planarity, we only work with an "isolated point cloud" with points filtered by...

>...a user-defined height threshold (th) is used to remove the canopy, branches, and upper part of trunks. The remaining points correspond to the ground, bushes, WD, and lower parts of trunks (p.7)

for our purposes, we'll filter out ground points prior to defining planarity to speed data processing and because the point cloud is normalized, so by definition each ground point is expected to be part of a flat planar surface

additionally, we'll want to set the `th` height threshold used to remove the canopy, branches, and upper part of trunks equal to the maximum expected slash pile height `max_ht_m`

```{r}
th <- 2.3
las_planar <- lidR::segment_shapes(
  # MUST filter out ground and isolate low points in las arg as "filter" arg not doing it
  las = las %>% lidR::filter_poi(Classification != 2L & Z<=th) 
  , algorithm = lidR::shp_plane(
    k = 8 # default = 8
    , th1 = 25 # default = 25
    , th2 = 6 # default = 6
  )
  , attribute = "planar"
  , filter = ~(Classification != 2L & Z<=th)
)
```

huh?

```{r}
las_planar@data %>% dplyr::count(planar)
```

did it filter heights?

```{r}
las_planar@data$Z %>% summary()
```

```{r, include=F,eval=FALSE}
las_planar %>% 
  lidR::clip_roi(
    piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
        sf::st_as_sfc() %>% 
        sf::st_as_sf()
      ) %>% 
      sf::st_union()
  ) %>% 
  # lidR::plot(color = "planar", pal = c("FALSE"="red","TRUE"="gray"))
  lidR::filter_poi(planar==F) %>%
  lidR::npoints()
```

plot planar estimate where non-planar (red) would be considered potential WD points

```{r}
lidR::plot(las_planar, color = "planar", pal = c("FALSE"="red","TRUE"="gray"))
```

plot just non-planar following [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651):

>...a WD point cloud cluster is hypothesized to exhibit a non-planar composition (p. 8)

```{r}
las_planar %>% 
  lidR::filter_poi(planar==F) %>% 
  lidR::plot(color = "Z", pal = harrypotter::hp(n=100,option = "gryffindor"))
```

what if we look at just non-planar points within the known pile locations?

```{r}
las_planar %>% 
  lidR::filter_poi(planar==F) %>% 
  lidR::clip_roi(
    piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
        sf::st_as_sfc() %>% 
        sf::st_as_sf()
      ) %>% 
      sf::st_union()
  ) %>% 
  lidR::plot(color = "Z", pal = harrypotter::hp(n=100,option = "gryffindor"))
```

ok, so some piles will potentially be missed with all of the points that were defined as planar within the actual pile footprints. it is possible that the piles constructed at this site were more sprawling than vertical and the wide and short nature of these piles is what was defined as "messy"

note, that, in addition to not considering ground points which are planar by definition, we already distinguished planar and non-planar points using `lidR::shp_plane()` which uses the criteria defined by [Limberger & Oliveira (2015)](https://doi.org/10.1016/j.patcog.2014.12.020) to determine planarity. as such, we do not need to implement the Gaussian Mixture Model (GMM) for class separation used by [dos Santos et al. (2025, p.9-10)](https://doi.org/10.3390/rs17040651). we could test this GMM method out later if needed

## Define tree trunks locations

*the majority of this section works through the tree trunk detection method presented by [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738)*

>Then, a user-defined 2D distance threshold (tdist) is adopted for the removal of hypothesized WD (points) near to tree trunk locations where trunk locations are established using a height-difference-based strategy (Zhou et al. 2022)

now, we need to look at how [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738) defined this "height-difference-based strategy" which is based on the hypothesis that point cloud points belonging to a tree trunk exhibit large height differences in a local neighborhood...machine slash piles would exhibit these same large height differences, so, not sure how that will work out...

>...tree geometry is used in this approach by assuming that the tree trunk grows vertically and high local height differences correspond to trunk locations. Using the partitioned normalized height point cloud as input, tree detection and localization are performed in three main steps: estimation of maximum local height difference within a local neighborhood, trunk candidate selection, and trunk detection/localization...The maximum local height difference estimation starts with the creation of uniformly distributed seed points with a spacing of "dseed" along the XY plane over the hypothesized trunk portion. For each seed point, a vertical cylinder centered at this point with radius "rcyl" and infinite height was created. The maximum local height difference value of this seed point was computed using the largest/smallest height from the points within this cylinder. To speed up the search process for finding LiDAR points within a cylinder, a KD-Tree was created for the partitioned point cloud. In case the maximum local height difference value of a given seed point was larger than a predefined threshold "h_dif_min", this point was considered a trunk candidate point. By doing this, several candidate points can be identified for a single tree trunk. In the next step, all candidate points are sorted based on the computed height different values. The candidate point with the largest value is regarded as the detected tree location. Then, neighboring candidate points with a planimetric distance from this tree location that is smaller than a user-defined threshold "d_trunk_min" are removed. The same steps are conducted on the remaining candidate points to derive all tree locations (p.13)

this process seems like it will be very computationally intensive and rely on many manually defined parameters. perhaps we can modify this process to isolate points in the expected DBH range of a tree (1.233-1.507 m = (1.37\*0.9) to (1.37\*1.1), where 1.37 m=DBH), use `TreeLS` to segment stems

[dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) use the non-height-filtered normalized point cloud for stem detection. 

We'll first attempt to detect tree stems/boles from the height normalized point cloud using `TreeLS::treeMap()` with the `TreeLS::map.hough()` algorithm

```{r, eval=FALSE}
trunk_map <- TreeLS::treeMap(
    las = las
    , method = TreeLS::map.hough(
      # height thresholds applied to filter a point cloud before processing
      # this is for detecting stems...not determining tree height
      min_h = 1
      , max_h = 3
      # height interval to perform point filtering/assignment/classification
      , h_step = (2/3)
      # pixel side length to discretize the point cloud layers
        # while performing the Hough Transform circle search
      , pixel_size = 0.025
      # largest tree diameter expected in the point cloud
      , max_d = 1.8 # 0.75m = 30in
      # minimum point density (0 to 1) within a pixel evaluated
        # on the Hough Transform - i.e. only dense point clousters will undergo circle search
        # hey google, define "clouster" ?
      , min_density = 0.1
      # minimum number of circle intersections over a pixel
        # to assign it as a circle center candidate.
      , min_votes = 3
    )
    # parameter passed down to treeMap.merge (if merge > 0)
    , merge = 0
    , positions_only = T
  )
```

*several hours later*

```{r, eval=FALSE}
trunk_map %>% dplyr::glimpse()
```

bro, what even is this?

let's read in the CHM just for this plotting

```{r}
chm_rast <- terra::rast("../data/Dawson_Data/point_cloud_processing_delivery/chm_0.1m.tif") %>% 
  terra::crop(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf() %>% 
      terra::vect()
  )
```

and plot

```{r, eval=FALSE}
# plt
chm_rast %>% terra::plot(col = viridis::plasma(n=100))
trunk_map %>% 
  sf::st_as_sf(coords = c("X", "Y"), crs = lidR::st_crs(las), remove = F) %>%
  terra::vect() %>% 
  terra::plot(add=T,col="red")
```

certainly missed some trees...and i forgot how slowwww `TreeLS` is ;/

```{r, include = F, eval=FALSE}
library(tidyverse)
# open sample plot file
file = system.file("extdata", "pine_plot.laz", package="TreeLS")

nlas_fpath <- "../data/Dawson_Data/point_cloud_processing_temp/02_normalize/"
# list.files(nlas_fpath, pattern = ".*\\.(laz|las)$", full.names = T)[1] %>% lidR::readLAS() %>% lidR::plot()
file = list.files(nlas_fpath, pattern = ".*\\.(laz|las)$", full.names = T)[1]
file
# file = system.file("extdata", "pine_plot.laz", package="TreeLS")
tls = TreeLS::readTLS(file)
table(tls@data$Classification)
summary(tls@data$Z)

# normalize the point cloud
tls = TreeLS::tlsNormalize(tls, keep_ground = F)
(x = lidR::plot(tls))
tls
# extract the tree map from a thinned point cloud
# thin = tlsSample(tls, smp.voxelize(0.02))
map = TreeLS::treeMap(tls, TreeLS::map.hough(min_density = 0.1), 0)
TreeLS::add_treeMap(x, map, color='yellow', size=2)

# classify tree regions
tls = TreeLS::treePoints(tls, map, TreeLS::trp.crop())
TreeLS::add_treePoints(x, tls, size=4)
TreeLS::add_treeIDs(x, tls, cex = 2, col='yellow')

# classify stem points
tls = TreeLS::stemPoints(tls, TreeLS::stm.hough())
TreeLS::add_stemPoints(x, tls, color='red', size=8)

# make the plot's inventory
inv = tlsInventory(tls, d_method=shapeFit(shape='circle', algorithm = 'irls'))
add_tlsInventory(x, inv)

# extract stem measures
seg = stemSegmentation(tls, sgt.ransac.circle(n = 20))
add_stemSegments(x, seg, color='white', fast=T)

# plot everything once
tlsPlot(tls, map, inv, seg, fast=T)

# check out only one tree
tlsPlot(tls, inv, seg, tree_id = 11)

#------------------------------------------#
### overview of some new methods on v2.0 ###
#------------------------------------------#

file = system.file("extdata", "pine.laz", package="TreeLS")
tls = readTLS(file) %>% tlsNormalize()

# calculate some point metrics
tls = fastPointMetrics(tls, ptm.knn())
x = plot(tls, color='Verticality')

# get its stem points
tls = stemPoints(tls, stm.eigen.knn(voxel_spacing = .02))
add_stemPoints(x, tls, size=3, color='red')

# get dbh and height
dbh_algo = shapeFit(shape='cylinder', algorithm = 'bf', n=15, inliers=.95, z_dev=10)
inv = tlsInventory(tls, hp = .95, d_method = dbh_algo)
add_tlsInventory(x, inv)

# segment the stem usind 3D cylinders and getting their directions
seg = stemSegmentation(tls, sgt.irls.cylinder(n=300))
add_stemSegments(x, seg, color='blue')

# check out a specific tree segment
tlsPlot(seg, tls, segment = 3)

```

let's go back and attempt the [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738) "height-difference-based strategy" which uses the height normalized, "partitioned" point cloud for tree detection and localization:

>...potential LiDAR points corresponding to trunks (hereafter denoted as hypothesized trunk portion) are extracted from the normalized height point cloud through user-defined minimum (hmin) and maximum (hmax) height thresholds...In this case, the majority of the canopy and shrub part is removed, leaving only the portion that is believed to correspond to trunks ([Lin et al. 2021](https://doi.org/10.3390/drones5040115)) (p.10)

**step 1:** The maximum local height difference estimation starts with the creation of uniformly distributed seed points with a spacing of "dseed" along the XY plane over the hypothesized trunk portion (i.e. the "partitioned" point cloud)

>Spacing between seed points, dseed: The spacing is determined based on the prior knowledge of average tree diameter and the level of details captured by LiDAR systems on tree trunks. This parameter should be small enough to ensure that there are several seed points for a tree trunk. However, choosing a small dseed will result in a longer processing time. (p.13)

we'll start by defining the uniformly distributed seed point grid and plot with the known pile locations

```{r}
dseed <- 1
# grid the space
seed_grid_temp <-
  lidR::st_bbox(las) %>% 
  sf::st_as_sfc() %>% 
  sf::st_as_sf() %>% 
  sf::st_make_grid(cellsize = dseed) %>% 
  sf::st_as_sf() %>% 
  sf::st_set_geometry("geometry") %>% 
  dplyr::mutate(seed_id = dplyr::row_number())
# seed_grid_temp
# plot with the known pile locations
seed_grid_temp %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(color="gray", fill = NA) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , fill = NA, color = "blue"
  ) + 
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

let's filter the grid to only include cells that contain points within the partitioned point cloud

```{r}
hmin <- 1.37*(1-0.10)
hmax <- 1.37*(1+0.80)
# get locations with points in the partitioned point clouds to filter the seed grid
las_stem_pts_temp <- las %>% 
  lidR::filter_poi(Z >= hmin & Z <= hmax) %>% 
  lidR::pixel_metrics(res = (dseed*0.9), func = .stdmetrics_z) %>% 
  terra::subset(1) %>% 
  terra::as.points(na.rm = TRUE) %>% 
  sf::st_as_sf()
# filter the seed grid
seed_pts_temp <- seed_grid_temp %>% 
  dplyr::inner_join(
    # get only seed grids with cld data
    seed_grid_temp %>% 
      sf::st_intersection(las_stem_pts_temp) %>% 
      sf::st_drop_geometry() %>% 
      dplyr::select(seed_id)
    , by = "seed_id"
  ) %>% 
  dplyr::distinct() %>% 
  sf::st_centroid() %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(
    X = sf::st_coordinates(.)[,1]
    , Y = sf::st_coordinates(.)[,2]
  )
# seed_pts_temp
# plt
seed_pts_temp %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(size=0.5,color="black") + 
  ggplot2::geom_sf(data = seed_grid_temp, color="gray", fill = NA) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

look at this on the chm?

```{r}
chm_rast %>% terra::plot(col = viridis::plasma(n=100),axes=F)
seed_pts_temp %>% 
  terra::vect() %>% 
  terra::plot(add=T,col="black")
piles %>% 
  sf::st_intersection(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
  ) %>% 
  terra::vect() %>% 
  terra::plot(add=T,col=NA,border="blue")
```

it looks like the UAS-SfM point cloud may not include points within tree crowns which makes sense for this site as pinyon-juniper have dense crowns and less defined stems (often these vegetation are considered more shrub-like than tree-like)

in addition, there are points within the known slash pile locations that are within the height threshold defined to partition the point cloud to search in the area were tree stems are expected. the inclusion of these slash pile points increases the risk that these actual piles are classified as tree stems and therefore excluded from the WD detection method used by [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651)

**step 2:**

> For each seed point, a vertical cylinder centered at this point with radius rcyl and infinite height was created. The maximum local height difference value of this seed point was computed using the largest/smallest height from the points within this cylinder. To speed up the search process for finding LiDAR points within a cylinder, a KD-Tree was created for the partitioned point cloud. In case the maximum local height difference value of a given seed point was larger than a predefined threshold h_dif_min, this point was considered a trunk candidate point. By doing this, several candidate points can be identified for a single tree trunk (p. 13).

where [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738) recommend the parameter setting guidelines:

> Cylinder radius, rcyl: This parameter also depends on the prior knowledge of average tree diameter and the level of details captured by the LiDAR system on tree trunks. More specifically, rcyl is chosen to guarantee that: (i) the cylinder radius is at a similar level to the trunk diameter and (ii) the cylinder contains an adequate number of LiDAR points. 

and 

> Minimum height difference value, h_dif_min: This height difference threshold depends on the hmax and hmin values used in the partitioning step. In general, this value can be selected as from 1/2 to 2/3 of (hmax âˆ’ hmin).

because we are primarily concerned with detecting slash piles which may have large height differences in the point cloud points in the local radius, we will want to set a relatively large `h_dif_min` parameter to ensure that we don't remove very tall slash piles (e.g. machine piles). instead, if we have RGB data available, we can use the spectral data to attempt to filter out any tress which might have passed through the height filtering stage. since it is recommended to set `h_dif_min` to 0.5-0.66 of the difference between `hmax` and `hmin`, we'll set `hmax` higher than would typically be required to capture just the tree bole and allow for the inclusion of potential crown points

*for detecting slash piles in practice, we will want to tie the `hmax` parameter to the maximum expected pile height `max_ht_m` to ensure that `hmax` is at least as large and potentially much larger while `hmin` should remain just below DBH height (1.37 m) since the objective of this step is the removal of potential tree trunks from the candidate WD points*

```{r}
# Cylinder radius
rcyl <- 1.5/2 # ?????????????
# Minimum height difference value
h_dif_min <- (hmax-hmin)*(2/3)

# convert seed points to "infinite height" cylinders
seed_cyls_temp <- seed_pts_temp %>% 
  sf::st_buffer(rcyl)
  # terra::vect() %>% terra::plot()
```

i'm not quite sure what is meant by "a KD-Tree was created for the partitioned point cloud" as there are no references but i did find this article by [Pinkham et al. (2020)](https://scholar.google.com/scholar?cluster=5468974134373213545&hl=en&as_sdt=0,6&scioq=QuickNN++Memory+and+Performance+Optimization+of+k+d%0ATree+Based+Nearest+Neighbor+Search+for+3D+Point+Clouds). in addition, it looks like the `RANN` [package](https://jefferislab.github.io/RANN/) enables KD-tree searching/processing

```{r}
# build a 2D kd-tree from the partitioned point cloud
# Use the X and Y coordinates of the entire point cloud to build the tree.
pc_coords_temp <- las %>% 
  lidR::filter_poi(Z >= hmin & Z <= hmax) %>% 
  purrr::pluck("data") %>% 
  dplyr::select(X,Y,Z)

# perform a fixed-radius search using RANN::nn2
nn_ans_temp <- RANN::nn2(
  # the point cloud xy data (builds the kd-tree on this)
  data = pc_coords_temp %>% dplyr::select(X,Y)
  # the seed point xy data (number of columns must be the same as data)
  , query = seed_pts_temp %>% sf::st_drop_geometry() %>% dplyr::select(X,Y) # seeds xy
  # maximum number of neighbors to find per query
  , k = nrow(seed_pts_temp)
  # the search radius (rcyl)
  , radius = rcyl
  , searchtype = "radius"
)
# huh?
nn_ans_temp %>% dplyr::glimpse()
# nn_ans_temp %>% class()
# nn_ans_temp %>% length()
# nn_ans_temp %>% names()
# nn_ans_temp$nn.idx %>% length()

# calculate height differences and filter
# iterate through the results to compute metrics
cyl_max_ht_diff_temp <- 
  1:nrow(seed_pts_temp) %>% 
  purrr::map(
    function(i) {
      # which seed?
      which_seed <- seed_pts_temp %>% dplyr::slice(i)
      
      # get indices of points in the current cylinder (0 means no point found)
      cyl_pts <- nn_ans_temp$nn.idx[i, ]
      cyl_pts <- cyl_pts[cyl_pts > 0] 
      
      if (dplyr::coalesce(length(cyl_pts),0) < 2) {
        return(
          which_seed %>% dplyr::mutate(max_height_diff = as.numeric(NA))
        )
      }
      
      # Extract Z values using the indices
      z_values <- pc_coords_temp$Z[cyl_pts]
      
      # Calculate max height difference
      max_diff <- max(z_values) - min(z_values)
      return(
        which_seed %>% dplyr::mutate(max_height_diff = max_diff)
      )
    }
  ) %>% 
  dplyr::bind_rows()
# huh?
# nrow(seed_pts_temp)
# nrow(cyl_max_ht_diff_temp)
# cyl_max_ht_diff_temp %>% dplyr::glimpse()
```

```{r, include=FALSE,eval=FALSE}
### !!!!!!!!!!!!!!! not a kd-tree but works.....

# define a custom function to calculate the max local height difference within the radius
lidr_height_diff <- function(Z) {
  if (length(Z) > 1) {
    max_h <- max(Z)
    min_h <- min(Z)
    return(max_h - min_h)
  } else {
    # handle cases with zero or one point in the neighborhood
    return(NA) 
  }
}

# function to map over for height difference
cyl_max_ht_diff_fn <- function(i, my_las) {
  cyl <- seed_cyls_temp %>% dplyr::slice(i)
  
  # Clip the original LAS data using the current cyl polygon
  # This performs an infinite height clip because it only considers the XY extent
  clipped_las <- lidR::clip_roi(my_las, cyl)
  
  # Check if any points were found within the cylinder
  if (lidR::is.empty(clipped_las) || lidR::npoints(clipped_las) < 2) {
    return(
      cyl %>% dplyr::mutate(max_height_diff = NA)
    )
  }
  
  # calculate max height difference (max z - min z)
  z_values <- clipped_las$Z
  max_diff <- max(z_values) - min(z_values)
  
  # return results as a data frame
  return(
    cyl %>% dplyr::mutate(max_height_diff = max_diff)
  )
}

# iterate through each cyl and apply the clipping and metric calculation
cyl_max_ht_diff_temp <- 
  1:nrow(seed_cyls_temp) %>% 
  purrr::map(
    \(x) 
    cyl_max_ht_diff_fn(
      i=x
      , my_las = las %>% lidR::filter_poi(Z >= hmin & Z <= hmax)
    )
  ) %>% 
  dplyr::bind_rows()
```

we can color the seed points by maximum local height difference as in Figure 12 of [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738)

```{r}
cyl_max_ht_diff_temp %>%
  ggplot2::ggplot() +
  ggplot2::geom_sf(
    mapping=ggplot2::aes(color = max_height_diff)
  ) +
  ggplot2::geom_sf(
    data = piles %>%
      sf::st_intersection(
        lidR::st_bbox(las) %>%
          sf::st_as_sfc() %>%
          sf::st_as_sf()
      )
    , color="blue", fill = NA
  ) +
  ggplot2::scale_color_viridis_c(option = "turbo") +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

let's compare the maximum height difference to the threshold defined by `h_dif_min`

```{r}
cyl_max_ht_diff_temp %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(
    mapping=ggplot2::aes(color = max_height_diff>h_dif_min)
  ) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA
  ) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
# filter the results based on the h_dif_min threshold
trunk_cndt_pts_temp <- cyl_max_ht_diff_temp %>%
  dplyr::filter(max_height_diff > h_dif_min) %>%
  # remove NAs that might result from points having less than 2 neighbors
  dplyr::filter(!is.na(max_height_diff)) %>% 
  # arrange it to start with the largest height diff
  dplyr::mutate(rand = rnorm(dplyr::n())) %>% 
  dplyr::arrange(desc(max_height_diff), rand) %>% 
  dplyr::select(-rand) %>% 
  dplyr::mutate(rn = dplyr::row_number())
# trunk_cndt_pts_temp
```

these plots indicate that most of the seed points in these small, hand piles do not meet the minimum height difference threshold defined by `h_dif_min` ... but this might not be the case for large machine piles...

>all candidate points are sorted based on the computed height different values. The candidate point with the largest value is regarded as the detected tree location. Then, neighboring candidate points with a planimetric distance from this tree location that is smaller than a user-defined threshold d_trunk_min are removed. The same steps are conducted on the remaining candidate points to derive all tree locations (p.13)

where

>Minimum distance between trunks, d_trunk_min: This distance is determined based on prior knowledge related to the tree spacing within the ROI

i think we would want to set this `d_trunk_min` value based on the expected spacing between residual trees and piles (for this site the minimum pile height was 1.5 m and piles should be at least twice this distance from residual trees...but it was indicated that pile construction was messy)

```{r}
d_trunk_min <- 1.5
################################################
# do it only if >1 candidate trunks found
################################################
if(nrow(trunk_cndt_pts_temp)>1){
  # use that kd-tree again
  # perform a fixed-radius search using RANN::nn2
  nn_ans_temp <- RANN::nn2(
    # the point cloud xy data (builds the kd-tree on this)
    data = trunk_cndt_pts_temp %>% sf::st_drop_geometry() %>% dplyr::select(X,Y) # seeds xy
    # the seed point xy data (number of columns must be the same as data)
    , query = trunk_cndt_pts_temp %>% sf::st_drop_geometry() %>% dplyr::select(X,Y) # seeds xy
    # maximum number of neighbors to find per query
    , k = nrow(trunk_cndt_pts_temp)
    # the search radius (rcyl)
    , radius = d_trunk_min
    , searchtype = "radius"
  )
  # start with the first and keep doing it while..
  
  # start with candidate point with the largest value is regarded as the detected tree location
  i <- 1
  # indicies of points in the current search area
  cyl_pts <- nn_ans_temp$nn.idx[i, ]
  cyl_pts <- cyl_pts[cyl_pts > 0] 
  # store the selected as the detected trunk
  final_trunks_temp <- trunk_cndt_pts_temp %>% dplyr::slice(i) # always the first since we sorted above
  # store list of candidates within d_trunk_min of selected as well as selected
  exclude_pts <- c(cyl_pts,i) %>% unique()
  
  while(length(exclude_pts)<nrow(trunk_cndt_pts_temp)){
    # get the next candidate still remaining
    i <- trunk_cndt_pts_temp %>% 
      dplyr::filter(
        !(rn %in% exclude_pts)
      ) %>% 
      dplyr::slice(1) %>% # get the new leader
      dplyr::pull(rn)
    # store the selected as the detected trunk
    final_trunks_temp <- final_trunks_temp %>% 
      dplyr::bind_rows(
        trunk_cndt_pts_temp %>% 
          dplyr::filter(rn==i)
      )
    # indicies of points in the current search area
    cyl_pts <- nn_ans_temp$nn.idx[i, ]
    cyl_pts <- cyl_pts[cyl_pts > 0] 
    # store list of candidates within d_trunk_min of selected as well as selected
    exclude_pts <- c(exclude_pts,cyl_pts,i) %>% unique()
  }
}else{ # if(nrow(trunk_cndt_pts_temp)==1){
  # store the selected as the detected trunk
  final_trunks_temp <- trunk_cndt_pts_temp
}
# huh?
final_trunks_temp %>% dplyr::glimpse()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(nn_ans_temp,cyl_pts,exclude_pts,i,pc_coords_temp)
gc()
```

now let's look at the final detected trunks plotted as having a circular radius of `d_trunk_min`

```{r}
# # check area
# final_trunks_temp %>% 
#   sf::st_buffer(d_trunk_min) %>% 
#   dplyr::mutate(
#     a = sf::st_area(.) %>% as.numeric()
#     , b = pi*(d_trunk_min^2)
#   ) %>% 
#   sf::st_drop_geometry() %>% 
#   summary()
cyl_max_ht_diff_temp %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(
    mapping=ggplot2::aes(color = max_height_diff>h_dif_min)
  ) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA
  ) +
  ggplot2::geom_sf(
    data = final_trunks_temp %>% sf::st_buffer(d_trunk_min)
    , color="black", fill = NA
  ) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

a few of these appear to overlap with areas of the known piles so those intersecting areas might get cut out of the pile detection. also, note that a single tree appears to be counted as multiple "trunks" but that is ok for our purposes as these trunk areas will be used to mask area where we do not expect piles/WD to be.

we can look at this trunk mask area on the CHM

```{r}
chm_rast %>% terra::plot(col = viridis::plasma(n=100),axes=F)
final_trunks_temp %>% 
  sf::st_buffer(d_trunk_min) %>%
  sf::st_union() %>% 
  terra::vect() %>% 
  terra::plot(add=T,col="black",alpha=0.8)
piles %>% 
  sf::st_intersection(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
  ) %>% 
  terra::vect() %>% 
  terra::plot(add=T,col=NA,border="blue")
```

it looks like we missed the tree tops. this is likely caused by limited point density within the tree crowns from the UAS-SfM point cloud generation and/or the dense crowns typical in this pinyon-juniper forest type. perhaps we need to set `hmax` much larger (potentially Inf)?

## Refinement based on trunk location

with the trunks now detected, we go back to [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651)

we'll show where we are in the process by replicating sections of Figures 6 and 7

Figure 6a "isolated point cloud" point cloud based on a maximum height threshold where points are assumed to correspond to the ground, bushes, WD, and lower parts of trees and trunks. points colored by height

```{r}
las_planar@data %>% 
  dplyr::slice_sample(prop = 0.03) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_point(
    mapping=ggplot2::aes(x=X,y=Y,color = Z)
    , alpha = 0.9
  ) + 
  ggplot2::scale_color_viridis_c(option = "turbo") +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

now let's look at only the non-planar points assumed to be WD points as in Figure 7b

```{r}
las_planar@data %>%
  dplyr::filter(planar==F) %>% 
  dplyr::slice_sample(prop = 0.03) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_point(
    mapping=ggplot2::aes(x=X,y=Y)
    , alpha = 0.9
    , color = "gray"
  ) + 
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

overlay the trunk mask

>trunk locations are established using a height-difference-based strategy...Then, these locations are used to remove the hypothesized WD points at their vicinity. Specifically, a user-defined 2D distance threshold (tdist) is adopted for the removal of hypothesized WD near to tree trunk locations (p.10)

the only recommendation for setting this `tdist` threshold is that is should be adjusted based on expected tree diameter (unclear if that means bole diameter or crown diameter)

>...different values for this threshold (i.e., 0.9 m and 0.5 m) were due to the larger tree diameters in the natural forest study areas (p.13)

we'll set `tdist = d_trunk_min` where `d_trunk_min` represents the minimum expected distance between tree trunks [Zhou et al. (2022)](https://doi.org/10.3390/rs14153738)

now, we'll plot the candidate WD points (gray), with the buffered trunk locations (black), and, since we have it, the known pile locations (blue)

```{r}
# user-defined 2D distance threshold (tdist) is adopted for the removal of hypothesized WD near to tree trunk locations
tdist <- d_trunk_min
# plot it
las_planar@data %>%
  dplyr::filter(planar==F) %>% 
  dplyr::slice_sample(prop = 0.03) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_point(
    mapping=ggplot2::aes(x=X,y=Y)
    , alpha = 0.9
    , color = "gray"
  ) + 
  ggplot2::geom_sf(
    data = final_trunks_temp %>% 
      sf::st_buffer(tdist) %>% 
      sf::st_union()
    , fill="black"
    , alpha = 0.9
  ) +
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 1.2
  ) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

that is looking decent. what if we look at all of this on the CHM? remember, the non-masked WD points (gray) are what will pass through to the final stage of WD detection

```{r}
chm_rast %>% 
  terra::plot(col = viridis::plasma(n=100),axes=F)
las_planar@data %>%
  dplyr::filter(planar==F) %>% 
  dplyr::slice_sample(prop = 0.02) %>% 
  sf::st_as_sf(coords = c("X", "Y"), crs = lidR::st_crs(las), remove = F) %>%
  terra::vect() %>% 
  terra::plot(add=T,col="gray",alpha=0.9)
final_trunks_temp %>% 
  sf::st_buffer(tdist) %>%
  sf::st_union() %>% 
  terra::vect() %>% 
  terra::plot(add=T,col="black",alpha=0.9)
piles %>% 
  sf::st_intersection(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
  ) %>% 
  terra::vect() %>% 
  terra::plot(add=T,col=NA,border="blue")
```

now let's filter our las data to include only points that are outside of the area near to predicted tree trunk locations

```{r}
# lidR::merge_spatial is slowwww
# las_planar %>% 
#   lidR::filter_poi(planar==F) %>% 
#   lidR::merge_spatial(
#     source = final_trunks_temp %>% 
#       sf::st_buffer(tdist) %>%
#       sf::st_union()
#     , attribute = "trunks"
#   ) %>% 
#   purrr::pluck("data") %>% 
#   dplyr::count(trunks)

# convert to sf and filter
est_wd_pts_sf <- las_planar@data %>%
  dplyr::filter(planar==F) %>% ## be sure to only work with non-planar
  sf::st_as_sf(coords = c("X", "Y"), crs = lidR::st_crs(las_planar), remove = F) %>%
  # anti-join trunks
  sf::st_filter(
    y = final_trunks_temp %>% 
      sf::st_buffer(tdist) %>%
      sf::st_union()
    , .predicate = sf::st_disjoint
  )
# can convert back to a lidR LAS object if needed
# est_wd_pts_las <- lidR::LAS(est_wd_pts_sf %>% sf::st_drop_geometry(), crs = sf::st_crs(est_wd_pts_sf))
```

now let's plot the final predicted WD points colored by height with the known pile locations on top

```{r}
# plot it
est_wd_pts_sf %>%  
  dplyr::slice_sample(prop = 0.1) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(
    mapping = ggplot2::aes(color = Z)
    , alpha = 0.9
    # , color = "gray"
  ) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 1.2
  ) +
  ggplot2::scale_color_viridis_c(option = "turbo") +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void()
```

looking pretty good

## DBSCAN segmentation

the final stage is to create segmented objects from the WD point cloud using DBSCAN and filter those objects based on expected size thresholds (as in our CHM-based pile detection method)

>The WD clustering step assumes that WD points would comprise clusters whose 2D spread exceeds a pre-defined threshold. Therefore, this refinement step starts with clustering WD regions using the DBSCAN algorithm. This algorithm requires two threshold values: a neighborhood distance threshold (epsilon) and a minimum number of neighboring points (minPts). The spread of a hypothesized WD cluster is defined by the maximum planimetric distance between two points in that cluster. All WD clusters with a spread less than a user-defined threshold (t_min_length) are eliminated (p.12)

[dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) used an `epsilon` value of 0.5 for all test sites but it is recommended to set this value based "on the
minimum cluster size to be detected and point density". as such, we would want to set this value based on the minimum expected slash pile size `min_area_m2`

While `minPts` varied by site:

>The larger minPts value for the plantation dataset (i.e., 500 points as opposed to 200 points for a natural forest) was due to the higher point density and larger debris resulting from the tree thinning activity at this site (p.13)

we'll use the `dbscan` package for this where the `eps` argument is the size (radius) of the epsilon neighborhood

```{r, include=FALSE,eval=FALSE}
# how many pts for minpts?
est_wd_pts_sf %>% 
  sf::st_intersection(piles) %>% 
  sf::st_drop_geometry() %>% 
  dplyr::count(pile_id) %>% 
  dplyr::arrange(n) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()

est_wd_pts_sf %>% 
  sf::st_intersection(piles) %>% 
  sf::st_drop_geometry() %>% 
  dplyr::count(pile_id) %>% 
  dplyr::pull(n) %>% 
  summary()

piles %>% 
  dplyr::left_join(
    est_wd_pts_sf %>% 
    sf::st_intersection(piles) %>% 
    sf::st_drop_geometry() %>% 
    dplyr::count(pile_id)  
  ) %>% 
  sf::st_intersection(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
  ) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(mapping = ggplot2::aes(fill = n)) +
  ggplot2::scale_fill_distiller(palette = "Blues", direction = 1) +
  ggplot2::theme_void()
```


```{r}
# set the dbscan parameters based on minimum expected object size and point density
min_area_m2 <- 2.0
# the minimum cluster size to be detected based on the minimum object area expected (min_area_m2)
# circular radius = epsilon = sqrt(min_area_m2/pi)
epsilon <- sqrt(min_area_m2/pi) # *1.01 # could make this slightly larger to avoid over-segmenting
# depends on the point density and expected size of WD objects
# could do math based on input point cloud density and expected minimum size
# expected points in the smallest object size expected = 
  # minPts = avg_pts_per_m2 * min_area_m2
# las_planar # check this point density
# las_planar %>% lidR::filter_poi(planar==F) # check this point density
# ( nrow(est_wd_pts_sf) / (lidR::st_bbox(las) %>% sf::st_as_sfc() %>% sf::st_as_sf() %>% sf::st_area() %>% as.numeric()) ) # check this point density
avg_pts_per_m2 <- ( nrow(est_wd_pts_sf) / (lidR::st_bbox(las) %>% sf::st_as_sfc() %>% sf::st_as_sf() %>% sf::st_area() %>% as.numeric()) )
# avg_pts_per_m2
minPts <- max( # don't go any lower than the dbscan::dbscan() default
  5 # the dbscan::dbscan() default
  , ceiling(avg_pts_per_m2 * min_area_m2)
)
# dbscan::dbscan
db <- dbscan::dbscan(
  x = est_wd_pts_sf %>% sf::st_drop_geometry() %>% dplyr::select(X,Y)
  # eps primarily controls the spatial extent of a cluster, 
  # as it defines how far points can be from each other to be considered part of the same dense region.
  , eps = epsilon
  # minPts primarily controls the minimum density of a cluster, 
  # as it dictates how many points must be packed together within that eps radius.
  , minPts = minPts
)
# # huh?
# db$cluster %>% length()
# nrow(est_wd_pts_sf)

# add the cluster to the data
est_wd_pts_sf$cluster <- db$cluster
# est_wd_pts_sf %>% dplyr::glimpse()
```

plot the predicted WD points colored by the resulting `dbscan::dbscan()` cluster with the known pile locations on top

```{r}
# plot it
est_wd_pts_sf %>%  
  dplyr::slice_sample(prop = 0.1) %>% 
  dplyr::mutate(cluster = as.factor(cluster)) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(
    mapping = ggplot2::aes(color = cluster)
    , alpha = 0.9
    # , color = "gray"
  ) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 1.2
  ) +
  ggplot2::scale_color_manual(
    values = viridis::turbo(n = length(unique(est_wd_pts_sf$cluster)) ) %>% sample()
  ) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

this is looking good. 

### Geometric Shape and Size Filtering

now we can roughly follow the steps outlined in our raster-based detection method to filter out detected objects based on the expected size and geometric shape of the pile objects we are attempting to identify

#### rasterization and vectorization

first, let's rasterize the point data to get discrete point locations by cluster on a fine scale and then convert to vector data to get the predicted objects as polygon data

rasterization and vectorization is a common approach to convert point cloud data to 2D representations of ecological objects

```{r}
# make a blank raster of the las data to fill
# should we set the raster resolution based on the point density?
# to find the minimum CHM resolution that could be created for a given point density (i.e. points/m2) while maintaining at least one point per cell
# , use the formula: sqrt(1/point_density)
# sqrt(1/avg_pts_per_m2)
r_temp <- lidR::st_bbox(las) %>% 
  sf::st_as_sfc() %>% 
  sf::st_as_sf() %>% 
  terra::vect() %>% 
  terra::rast(
    # res = 0.1
    res = max(
      dplyr::coalesce(sqrt(1/avg_pts_per_m2),0)
      , 0.1 # no lower than 0.1
    )
  )
# r_temp
# fill the rast with the cluster values
dbscan_ans_poly <- terra::rasterize(
    x = est_wd_pts_sf %>% 
      dplyr::ungroup() %>% 
      dplyr::select(cluster) %>% 
      terra::vect()
    , y = r_temp
    , field = "cluster"
  ) %>% 
  # convert back to vector
  terra::as.polygons(round = F, aggregate = T, values = T, extent = F, na.rm = T) %>% 
  setNames("pred_id") %>%
  sf::st_as_sf() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
```

plot of the candidate segments as vectors

```{r}
# plot it
dbscan_ans_poly %>% 
  dplyr::mutate(pred_id = as.factor(pred_id)) %>% 
  ggplot2::ggplot() + 
  ggplot2::geom_sf(
    mapping = ggplot2::aes(fill = pred_id)
    , alpha = 0.8
    , color = NA
  ) + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 1.2
  ) +
  ggplot2::scale_fill_manual(
    values = viridis::turbo(n = length(unique(dbscan_ans_poly$pred_id)) ) %>% sample()
  ) +
  ggplot2::coord_sf(expand = F) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

we also need to create a CHM based on the remaining WD points which will be used to calculate volume and height of the predictions

```{r}
# fill the rast with the max Z value
est_wd_chm_rast <- terra::rasterize(
  x = est_wd_pts_sf %>% 
    dplyr::ungroup() %>% 
    dplyr::select(Z) %>% 
    terra::vect()
  , y = r_temp
  , field = "Z"
  , fun = "max"
) %>% 
setNames("z")
```

check out our CHM raster of the WD

```{r}
est_wd_chm_rast %>% 
  terra::plot(col = viridis::plasma(n=100),axes=F)
piles %>% 
  sf::st_intersection(
    lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
  ) %>% 
  terra::vect() %>% 
  terra::plot(add=T,col=NA,border="blue")
```

#### shape irregularity filtering

now we can filter these polygons based on their overlap with a convex hull of their shape to remove highly irregular shapes, shapes with holes, or fragmented shapes. the following steps are the exact same as in our raster-based detection methodology

let's plot our example dbscan detected segments as vectors (brown) and convex hull of the segments (orange) compared with the ground truth piles (blue)

```{r}
# convex hulls of segments
dbscan_ans_poly_chull <-
  dbscan_ans_poly %>% 
  sf::st_convex_hull() %>% 
  sf::st_simplify() %>% 
  sf::st_make_valid() %>% 
  dplyr::filter(sf::st_is_valid(.))
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_chull
    , fill = NA, color = "orangered", lwd = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

notice how the most irregularly-shaped predicted segments have much less overlap with the convex hull shapes than the more regularly shaped segments

let's filter out segments that have holes in them or are very irregularly shaped by comparing the area of the polygon and convex hull

```{r}
# 1 = perfectly convex (no inward angles); 0 = so many inward angles
# values closer to 1 remove more irregular segments; 
  # values closer to 0 keep more irregular segments (and also regular segments)
# these will all be further filtered for their circularity and later smoothed to remove blocky edges
# and most inward angles by applying a convex hull to the original detected segment
convexity_pct <- 0.66
# run it
dbscan_ans_poly_chull_filtered <-
  dbscan_ans_poly %>% 
    st_irregular_remove(pct_chull_overlap = convexity_pct)
```

plot the remaining dbscan detected segments as vectors (brown) compared with the ground truth piles (blue) 

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_chull_filtered
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

#### size thresholding

filter out the segments that don't meet the size thresholds

```{r}
max_ht_m = 2.3 # set the max expected pile height
min_ht_m = 0.3 # set the min expected pile height
# min_area_m2 = 2.0 # set the min expected pile area
max_area_m2 = 18.5 # set the max expected pile area
# filter out the segments that don't meet the size thresholds
dbscan_ans_poly_size_filtered <- dbscan_ans_poly_chull_filtered %>% 
  dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
  dplyr::filter(
    dplyr::coalesce(area_xxxx,0) >= min_area_m2
    & dplyr::coalesce(area_xxxx,0) <= max_area_m2
  ) %>% 
  dplyr::select(-c(area_xxxx))
```

plot the remaining dbscan detected segments as vectors (brown) compared with the ground truth piles (blue) 

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_size_filtered
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

#### circularity filtering

let's apply a circle-fitting algorithm to remove non-circular segments from the remaining segments let's apply the `sf_data_circle_fit()` function that fits the best circle using `lidR::fit_circle()` to each detected segment to get a spatial data frame with the best fitting circle for each segment

```{r}
#### circularity filtering
# 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular
# min required IoU between the predicted pile and the best fit circle of the predicted pile
circle_fit_iou_pct = 0.30

# apply the sf_data_circle_fit() which takes each segment polygon, transforms it to points, and the fits the best circle
set.seed(9)
dbscan_ans_poly_circle_fit <- sf_data_circle_fit(dbscan_ans_poly_size_filtered)
# dbscan_ans_poly_circle_fit %>% dplyr::glimpse()

# filter using the intersection over union (IoU) between the circle and the predicted segment. 
# we'll use the IoU function we defined 
# we map over this to only compare the segment to it's own best circle fit...not all
# we should consider doing this in bulk.....another day
dbscan_circle_fit_iou <- 
  dbscan_ans_poly_size_filtered$pred_id %>%
  unique() %>%
  purrr::map(\(x)
    ground_truth_single_match(
      gt_inst = dbscan_ans_poly_size_filtered %>% 
        dplyr::filter(pred_id == x)
      , gt_id = "pred_id"
      , predictions = dbscan_ans_poly_circle_fit %>% 
        dplyr::filter(pred_id == x) %>% 
        dplyr::select(pred_id) %>% # keeping other columns causes error?
        dplyr::rename(circ_pred_id = pred_id)
      , pred_id = "circ_pred_id"
      , min_iou_pct = 0 # set to 0 just to return pct
    )    
  ) %>% 
  dplyr::bind_rows()
# dbscan_circle_fit_iou %>% dplyr::glimpse()

# threshold for the minimum IoU to further filter for segments that are approximately round, 
# this filter should remove linear objects from the watershed detections
  # compare iou
dbscan_keep_circle_fit_pred_id <- dbscan_circle_fit_iou %>% 
  dplyr::filter(iou>=circle_fit_iou_pct) %>% 
  dplyr::pull(pred_id) 
# and just keep the remaining
dbscan_ans_poly <-
  dbscan_ans_poly_size_filtered %>% 
  dplyr::inner_join(
    dbscan_circle_fit_iou %>% dplyr::filter(iou>=circle_fit_iou_pct)  
    , by = "pred_id"
  )
  
```

let's plot the regularity and size filtered dbscan detected segments as vectors colored by whether or not it meets the circularity expectation and best circle fit of the segments (orange) compared with the ground truth piles (blue)

```{r, include=FALSE,eval=FALSE}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_size_filtered %>% 
      dplyr::left_join(
        dbscan_circle_fit_iou %>% 
        sf::st_drop_geometry() %>% 
        dplyr::select(pred_id,iou)
      )
    # , fill = NA, color = "brown", lwd = 0.6
    , mapping = ggplot2::aes(fill = iou)
    , color = NA, lwd = 0, alpha = 1
  ) +
  
  ggplot2::geom_sf(
    data = dbscan_ans_poly_circle_fit %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::filter(
        dplyr::coalesce(area_xxxx,0) >= min_area_m2*0.2
        & dplyr::coalesce(area_xxxx,0) <= max_area_m2*4
      ) %>% 
      dplyr::select(-c(area_xxxx))
    
    , fill = NA, color = "orangered", lwd = 0.6
  ) +
  
  # ggplot2::geom_sf_label(
  #   data = dbscan_ans_poly_size_filtered
  #   , mapping = ggplot2::aes(label = pred_id)
  # ) +
  ggplot2::scale_fill_fermenter(
    n.breaks = 10 # 10 use 10 if can go full range 0-1
    , palette = "PuOr" # "BrBG"
    , direction = 1
    , limits = c(0,1) # use c(0,1) if can go full range 0-1
    , labels = scales::percent
    , na.value = "black"
  ) +
  ggplot2::theme_void()

# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_size_filtered %>% 
      dplyr::left_join(
        dbscan_circle_fit_iou %>% 
        sf::st_drop_geometry() %>% 
        dplyr::select(pred_id,iou)
      ) %>% 
      dplyr::mutate(iou = iou>=circle_fit_iou_pct)
    # , fill = NA, color = "brown", lwd = 0.6
    , mapping = ggplot2::aes(fill = iou)
    , color = NA, lwd = 0, alpha = 1
  ) +
  
  ggplot2::geom_sf(
    data = dbscan_ans_poly_circle_fit %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::filter(
        dplyr::coalesce(area_xxxx,0) >= min_area_m2*0.2
        & dplyr::coalesce(area_xxxx,0) <= max_area_m2*4
      ) %>% 
      dplyr::select(-c(area_xxxx))
    
    , fill = NA, color = "orangered", lwd = 0.6
  ) +
  
  ggplot2::geom_sf_label(
    data = dbscan_ans_poly_size_filtered
    , mapping = ggplot2::aes(label = pred_id)
  ) +
  ggplot2::theme_void()


poly_to_points(
  dbscan_ans_poly_size_filtered %>% 
        dplyr::filter(pred_id == 914) %>% 
    sf::st_simplify()
  , as_spatial = T, simplify_multipolygons = F) %>% 
  ggplot() + geom_sf() +
  geom_sf(
    data = dbscan_ans_poly_size_filtered %>% 
        dplyr::filter(pred_id == 914)
    , fill = NA, color = "blue"
  ) + 
  ggplot2::geom_sf(
    data = dbscan_ans_poly_circle_fit %>% 
      dplyr::filter(pred_id == 914)
    , fill = NA, color = "orangered", lwd = 0.6
  )
```

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_size_filtered %>% 
      dplyr::mutate(is_circular = (pred_id %in% dbscan_keep_circle_fit_pred_id))
    # , fill = NA, color = "brown", lwd = 0.6
    , mapping = ggplot2::aes(fill = is_circular)
    # , fill = "brown"
    , color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly_circle_fit %>% 
      dplyr::mutate(area_xxxx = sf::st_area(.) %>% as.numeric()) %>% 
      dplyr::filter(
        dplyr::coalesce(area_xxxx,0) >= min_area_m2*0.5
        & dplyr::coalesce(area_xxxx,0) <= max_area_m2*3
      ) %>% 
      dplyr::select(-c(area_xxxx))
    
    , fill = NA, color = "orangered", lwd = 0.6
  ) +
  ggplot2::theme_void()
```

notice how this is not perfect as some actual piles were removed and some false piles were kept

let's look at only the piles remaining

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

#### volume calculation and size filtering

now, we apply basic raster math to get the volume (cell area times cell height) and height of each remaining segment

```{r}
########################################
# use the remaining segments that meet the geometric and area filtering
# to create a raster for fast computation
########################################
    dbscan_ans_rast <-
      terra::rasterize(
        x = dbscan_ans_poly %>% 
          dplyr::ungroup() %>% 
          dplyr::select(pred_id) %>% 
          terra::vect()
        , y = r_temp
        , field = "pred_id"
      )
########################################################################################
## calculate raster-based area and volume 
########################################################################################
    # first, calculate the area of each cell
    area_rast <- terra::cellSize(est_wd_chm_rast)
    names(area_rast) <- "area_m2"
    # area_rast %>% terra::plot()
    # then, multiply area by the CHM (elevation) for each cell to get a raster with cell volumes
    vol_rast <- area_rast*est_wd_chm_rast
    names(vol_rast) <- "volume_m3"
    # vol_rast %>% terra::plot()
    # sum area within each segment to get the total area
    area_df <- terra::zonal(x = area_rast, z = dbscan_ans_rast, fun = "sum", na.rm = T)
    # sum volume within each segment to get the total volume
    vol_df <- terra::zonal(x = vol_rast, z = dbscan_ans_rast, fun = "sum", na.rm = T)
    # max ht within each segment to get the max ht
    ht_df <- terra::zonal(x = est_wd_chm_rast, z = dbscan_ans_rast, fun = "max", na.rm = T) %>% 
      dplyr::rename(max_height_m=2)

    # add area and volume to our vector data  
    # we'll do this with a slick trick to perform multiple joins succinctly using purrr::reduce
    dbscan_ans_poly <- 
      purrr::reduce(
        list(dbscan_ans_poly, area_df, vol_df, ht_df)
        , dplyr::left_join
        , by = 'pred_id'
      ) %>% 
      dplyr::mutate(
        volume_per_area = volume_m3/area_m2
      ) %>% 
      # filter out the segments that don't meet the size thresholds
      dplyr::filter(
        dplyr::coalesce(area_m2,0) >= min_area_m2
        & dplyr::coalesce(area_m2,0) <= max_area_m2
        & dplyr::coalesce(max_height_m,0) >= min_ht_m
      ) %>% 
      # do one more pass of the irregularity filtering
      st_irregular_remove(pct_chull_overlap = convexity_pct)
# what did we get?
dbscan_ans_poly %>% dplyr::glimpse()
```

let's look at only the piles remaining

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = dbscan_ans_poly
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

#### smooth remaining segments

use the convex hull shapes of our remaining segments. This helps to smooth out the often 'blocky' edges of raster-based segments , which can look like they were generated in Minecraft. Additionally, by removing any segments with overlapping convex hull shapes, we can likely reduce false detections that are actually groups of small trees or shrubs, ensuring our results represent singular slash piles.

```{r}
# use the convex hull shapes of our remaining segments. 
    # This helps to smooth out the often 'blocky' edges of raster-based segments
    # , which can look like they were generated in Minecraft. 
    # Additionally, by removing any segments with overlapping convex hull shapes, 
    # we can likely reduce false detections that are actually groups of small trees or shrubs, 
    # ensuring our results represent singular slash piles.
      # combine polygons that share a common border but don't overlap
        comb_dbscan_ans_poly <- dbscan_ans_poly %>% 
          st_dissolve_and_combine() %>% 
          dplyr::rename(id_comb_xxx = id) 
        # comb_dbscan_ans_poly
      # recalculate metrics
        agg_comb_dbscan_ans_poly <-
          comb_dbscan_ans_poly %>% 
          sf::st_intersection(dbscan_ans_poly) %>% 
          sf::st_drop_geometry() %>% 
          dplyr::group_by(id_comb_xxx) %>% 
          dplyr::summarise(
            area_m2 = sum(area_m2, na.rm = T)
            , volume_m3 = sum(volume_m3, na.rm = T)
            , max_height_m = max(max_height_m, na.rm = T)
          ) %>% 
          dplyr::mutate(
            volume_per_area = volume_m3/area_m2
          )
      # bring together
        comb_dbscan_ans_poly <- 
          comb_dbscan_ans_poly %>% 
          dplyr::inner_join(agg_comb_dbscan_ans_poly, by = "id_comb_xxx") %>% 
          dplyr::rename(pred_id = id_comb_xxx) %>% 
          # filter out the segments that don't meet the size thresholds
          dplyr::filter(
            dplyr::coalesce(area_m2,0) >= min_area_m2
            & dplyr::coalesce(area_m2,0) <= max_area_m2
            & dplyr::coalesce(max_height_m,0) >= min_ht_m
          ) %>% 
          # do one more pass of the irregularity filtering
          st_irregular_remove(pct_chull_overlap = convexity_pct) %>% 
          # simplify multipolygons
          dplyr::mutate(treeID=dplyr::row_number()) %>% 
          cloud2trees::simplify_multipolygon_crowns() %>% 
          dplyr::select(-treeID)
        
        # dbscan_ans_poly %>% dplyr::glimpse()
        # comb_dbscan_ans_poly %>% dplyr::glimpse()
      
      # apply st_convex_hull
        final_dbscan_pred_poly <- comb_dbscan_ans_poly %>% 
          sf::st_convex_hull() %>% 
          sf::st_simplify() %>% 
          sf::st_make_valid() %>% 
          dplyr::filter(sf::st_is_valid(.)) %>% 
          st_remove_overlaps() %>% 
          # now we need to re-do the volume and area calculations
          dplyr::mutate(
            area_m2 = sf::st_area(.) %>% as.numeric()
            , volume_m3 = area_m2*volume_per_area
          ) %>% 
          dplyr::filter(
            dplyr::coalesce(area_m2,0) >= min_area_m2
            & dplyr::coalesce(area_m2,0) <= max_area_m2
          )
```

check out the final predictions

```{r}
# plot
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = piles %>% 
      sf::st_intersection(
        lidR::st_bbox(las) %>% 
          sf::st_as_sfc() %>% 
          sf::st_as_sf()
      )
    , color="blue", fill = NA, lwd = 0.7
  ) +
  ggplot2::geom_sf(
    data = final_dbscan_pred_poly
    # , fill = NA, color = "brown", lwd = 0.6
    , fill = "brown", color = NA, lwd = 0, alpha = 0.6
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "none")
```

### Predictions on RGB

let's load in the RGB data for this area and visualize the predicted piles overlaid on the spectral data.

```{r}
###############################################################
# read/crop RGB raster
###############################################################
rgb_fnm_temp <- "../data/dawson_data/dawson_rgb.tif"
pj_rgb_rast <- terra::rast(rgb_fnm_temp)
## function to change the resolution of RGB 
change_res_fn <- function(r, my_res=1, m = "bilinear"){
  r2 <- r
  terra::res(r2) <- my_res
  r2 <- terra::resample(r, r2, method = m)
  return(r2)
}
## apply the function
pj_rgb_rast <- change_res_fn(pj_rgb_rast, my_res=0.08)
# stand boundary
pj_stand_boundary <- sf::st_read("../data/Dawson_data/units/units.shp", quiet=T) %>% 
  dplyr::rename_with(tolower) %>% 
  dplyr::rename_with(stringr::str_squish) %>% 
  dplyr::rename_with(make.names) %>% 
  dplyr::rename_with(~stringr::str_replace_all(.x, "\\.{2,}", ".")) %>% 
  dplyr::rename_with(~stringr::str_remove(.x, "\\.$")) %>% 
  dplyr::rename_with(~stringr::str_replace_all(.x, "\\.", "_")) %>% 
  sf::st_transform(sf::st_crs(las)) %>% 
  dplyr::filter(tolower(unit)=="u10") %>% 
  dplyr::slice(1)
```

plot RGB with the ground-truth piles (blue) and the predicted piles (brown)

```{r}
pj_rgb_rast %>% 
  terra::crop(
    lidR::st_bbox(las) %>% 
    sf::st_as_sfc() %>% 
    sf::st_as_sf() %>% 
    sf::st_buffer(6) %>% 
    sf::st_transform(terra::crs(pj_rgb_rast)) %>% 
    terra::vect()
  ) %>% 
  terra::mask(
    lidR::st_bbox(las) %>% 
    sf::st_as_sfc() %>% 
    sf::st_as_sf() %>% 
    sf::st_buffer(6) %>% 
    sf::st_transform(terra::crs(pj_rgb_rast)) %>% 
    terra::vect()
  ) %>% 
  terra::plotRGB(stretch="lin")
terra::plot(
  pj_stand_boundary %>% 
    sf::st_intersection(
      lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf() %>% 
      sf::st_buffer(6)
    ) %>% 
    terra::vect() %>% 
    terra::project(terra::crs(pj_rgb_rast))
  , add = T, border = "black", col = NA, lwd = 1.5
)
terra::plot(
  piles %>% 
    sf::st_intersection(
      lidR::st_bbox(las) %>% 
      sf::st_as_sfc() %>% 
      sf::st_as_sf()
    ) %>% 
    terra::vect() %>% 
    terra::project(terra::crs(pj_rgb_rast))
  , add = T, border = "blue", col = NA, lwd = 1.2
)
terra::plot(
  final_dbscan_pred_poly %>% 
    terra::vect() %>% 
    terra::project(terra::crs(pj_rgb_rast))
  , add = T, border = "brown", col = NA, lwd = 1.3
)
```

it is possible that some of these false positives, especially those outside of the treatment unit, would be removed by implementing specral filtering as many appear to be green vegetation.

## dos Santos (2025) Pile Detection Function{#slash_pile_detect_dossantos}

Let's put all of this together into a single workflow to make it easy to process height-normalized point cloud data using the [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) method for WD detection with specific application to slash piles. Because we do not exactly follow the [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651) method for WD detection, this is actually a modified (e.g. planarity definition) and augmented (e.g. slash pile geometric shape filtering) version of the proposed method but we'll still give credit to [dos Santos et al. (2025)](https://doi.org/10.3390/rs17040651).

Modifications:

* we filter out ground points prior to defining planarity to speed data processing since, by definition, each ground point is expected to be part of a flat planar surface
* dos Santos et al. (2025) require the setting of `rmin` and `rmax` parameters to identify an optimal spherical neighborhood for determining planarity of points in the point cloud, we believe this is non-intuitive for users so instead use the expected minimum and maximum expected area of objects which are sought to be identified from the point cloud to set the spherical neighborhood for determining planarity. dos Santos et al. (2025) acknowledge that these parameters should be "tuned according to rough prior knowledge of the size of the sought-after objects" (p. 8) and that the chosen `rmin` value should ensure that a sufficient number of points exist within the spherical neighborhood to describe its geometric characteristics (e.g. at least 10 points). As such, we make the following modifications based on the minimum and maximum expected area (`min_area_m2` and `max_area_m2`) and the average point cloud density per square meter (which is inherent to the point cloud data) and follow these steps to define a global radius of the neighborhood sphere for determinining planarity:
    * 1) identify the minimum radius based on the expected size: $r_{\text{min}} = \sqrt{\frac{\text{min_area_m2}}{\pi}}$
    * 2) identify the maximum radius based on the expected size: $r_{\text{max}} = \sqrt{\frac{\text{max_area_m2}}{\pi}}$
    * 3) fix the number of target points to exist in the spherical neighborhood: $K_{\text{target}} = 20$
    * 4) find a point cloud density-driven radius $r_{*}$ such that the circular footprint of the sphere captures enough points: $K_{\text{target}} = \text{avg_points_per_m2} \times \pi r_{*}^{2}$ which can be rearranged to $r_{*} = \sqrt{\frac{K_{\text{target}}}{\pi \times \text{avg_points_per_m2}}}$
    * 5) ensure that the selected spherichal radius $r_{\text{fixed}}$ respects the density and size constraints limited to a maximum spherical radius of 1 m: $r_{\text{fixed}} = \min\left(\max\left(r_{*}, r_{\text{min}}\right), r_{\text{max}}, 1\right)$
 

Let's package all of the steps  into a single function which can possibly be integrated into the `cloud2trees` package.

The parameters are defined as follows:

* `max_ht_m` : numeric. The maximum height (in meters) a slash pile is expected to be. This value helps us focus on a specific "slice" of the data, ignoring anything taller than a typical pile.
* `min_ht_m` : numeric. The minimum height (in meters) a detected pile must reach to be considered valid.
* `min_area_m2` : numeric. The smallest 2D area (in square meters) a detected pile must cover to be considered valid.
* `max_area_m2` : numeric. The largest 2D area (in square meters) a detected pile can cover to be considered valid.
* `convexity_pct` : numeric. A value between 0 and 1 that controls how strict the filtering is for regularly shaped piles. A value of 1 means only piles that are perfectly smooth and rounded, with no dents or inward curves are kept. A value of 0 allows for both perfectly regular and very irregular shapes. This filter works alongside `circle_fit_iou_pct` to refine the pile's overall shape.
* `circle_fit_iou_pct` : numeric. A value between 0 and 1 that controls how the filtering is for circular pile shapes. Setting it to 1 means only piles that are perfectly circular are kept. A value of 0 allows for a wide range of shapes, including very circular and non-circular ones (like long, straight lines).
* `smooth_segs` :  logical. Setting this option to TRUE will: 1) smooth out the "blocky" edges of detected piles (which can look like they were made in Minecraft) by using their overall shape; and 2) remove any detected piles that overlap significantly with other smoothed piles to help ensure each detection is a single slash pile, not a cluster of small trees or shrubs.

we'll start by attempting to define a `lasR` pipeline to do as much of the point cloud processing as possible

```{r}
# ...a user-defined height threshold (th) is used to remove the 
# canopy, branches, and upper part of trunks. 
# The remaining points correspond to the ground, bushes, WD, and lower parts of trunks (p.7)
max_ht_m <- 2
min_area_m2 <- 2.0 # set the min expected pile area
max_area_m2 <- 18.5 # set the max expected pile area

# function to calculate the fixed spherical search radius for determining point planarity
r_fixed_fn <- function(min_area_m2, max_area_m2, k_target=20, points_per_m2) {
  rmin <- sqrt(min_area_m2/pi)
  rmax <- sqrt(max_area_m2/pi)
  rstar <- sqrt(k_target/(pi*points_per_m2))
  rfixed <- min( max(rstar, rmin), rmax, 1)
  return(rfixed)
}
##################################
# set up filters for reading in and working with las
##################################
filter_primary <- "-drop_noise -drop_duplicates -drop_class 2 7 9 18"
filter_for_lidr_read <- paste(filter_primary, "-drop_z_above", max_ht_m)
filter_for_lasr_read <- c(
  "Classification %out% 2 7 9 18"
  , "-drop_duplicates"
  , paste(
    "Z <="
    , max_ht_m
  )
)
# filter_for_lasr_read
##################################
# ensure that norm las data exists
##################################
norm_las <- list.files("../data/Dawson_Data/point_cloud_processing_temp/02_normalize/", pattern = ".*\\.(laz|las)$", full.names = T)[c(10)] #15
nlas_ctg <- cloud2trees:::check_las_data(norm_las)
# set the lascatalog options
if(inherits(nlas_ctg, "LAScatalog")){
  lidR::opt_progress(nlas_ctg) <- F
  lidR::opt_filter(nlas_ctg) <- filter_for_lidr_read # "-drop_duplicates -drop_class 2 7 9 18" ## class 2 = ground; 9 = water; 18 = noise
  lidR::opt_select(nlas_ctg) <- "xyzic" # 0 enables all extra bytes to be loaded...possibly treeID
  lidR::opt_output_files(nlas_ctg) <- paste0(tempdir(), "/{*}_dosSantos")
}else if(inherits(nlas_ctg, "LAS")){
  stop(paste0(
    "`norm_las` should contain: a directory with nomalized las files,"
    ,"\n   the path of a single .laz|.las file,"
    , "\n   -or- an object of class `LAScatalog`"
  ))
  # nlas_ctg <- nlas_ctg %>%
  #   lidR::filter_poi(!Classification %in% c(2,9,18)) %>%
  #   lidR::filter_duplicates()
}
# get average point density
ctg_avg_pts_per_m2 <- 
  sum(nlas_ctg$Number.of.point.records, na.rm = T) /
  (nlas_ctg$geometry %>% 
    sf::st_union() %>% 
    sf::st_area() %>% 
    as.numeric())
r_fixed_temp <-
  r_fixed_fn(
    min_area_m2 = min_area_m2
    , max_area_m2 = max_area_m2
    , k_target = 20
    , points_per_m2 = ctg_avg_pts_per_m2
  )
##################################
# lasR pipeline
##################################
# read
lasr_read <- lasR::reader(
  filter = filter_for_lasr_read
  , select = "xyzic"
)
##################################
# planarity
##################################
  # get the 3 eigenvalues
  lasr_eigen <- lasR::geometry_features(
    # k,r: integer and numeric respectively for k-nearest neighbours and radius of the neighborhood sphere. 
      # If k is given and r is missing, computes with the knn
      # if r is given and k is missing computes with a sphere neighborhood
      # if k and r are given computes with the knn and a limit on the search distance.
    ## the lidR::shp_plane() default only includes k = 8
    k = 8
    , r = r_fixed_temp
    # , features = "E"
    , features = "p"
  )
  # planarity based on Limberger, F. A., & Oliveira, M. M. (2015): https://doi.org/10.1016/j.patcog.2014.12.020
  # as applied by lidR::shp_plane()
  # lasr_planar <- lasR::delete_points(c("lambda2 > (25*lambda1)", "lambda3 < (6*lambda2)")) # keep non-planar points
  
  # planarity based on Hackel, T., Wegner, J. D., & Schindler, K. (2016): https://doi.org/10.1109/CVPR.2016.178
  # with a threshold of xxx
  # Nurunnabi, A., Teferle, F., Laefer, D. F., Chen, M., & Ali, M. M. (2024): https://doi.org/10.5194/isprs-archives-XLVIII-2-2024-301-2024
  # ... used a threshold of 0.7 to define points as planar
  # Coglan, J., Gharineiat, Z., & Tarsha Kurdi, F. (2025): https://doi.org/10.3390/rs17193389
  # ... also used a threshold of 0.7 to define points as planar
  lasr_planar <- lasR::delete_points("planarity>=0.7") # keep non-planar points

##################################
# tree trunk masking
##################################
# Then, a user-defined 2D distance threshold (tdist) is adopted for the removal of hypothesized WD (points) near to tree trunk locations where trunk locations are established using a height-difference-based strategy (Zhou et al. 2022)
# this goes back to using the normalized point cloud but with a different set of height thresholds with points filtered where tree trunks are expected (e.g. 1.37*0.9 to 1.37*1.3)

### !!! this is where i will pause as coding this to work across a LASCatalog covering a broad extent will be very time consuming
### !!! this is where i will pause as coding this to work across a LASCatalog covering a broad extent will be very time consuming
### !!! this is where i will pause as coding this to work across a LASCatalog covering a broad extent will be very time consuming
### !!! this is where i will pause as coding this to work across a LASCatalog covering a broad extent will be very time consuming
### !!! this is where i will pause as coding this to work across a LASCatalog covering a broad extent will be very time consuming

# pipeline
lasr_pipeline <- lasr_read +
  lasR::summarise() +
  lasR::rasterize(res = 0.5) +
  lasr_eigen +
  lasr_planar +
  lasR::write_las() +
  lasR::summarise()
lasr_ans <- lasR::exec(lasr_pipeline, on = nlas_ctg)
lasr_ans
# lasr_ans$rasterize.1 %>% terra::plot()

# lidR::readLAS("C:\\Users\\georg\\AppData\\Local\\Temp\\RtmpW2DtOK/_708000_4193280_normalize.las") %>% 
#   lidR::filter_poi(planarity<0.5) %>% 
#   lidR::plot(color = "Z", pal = harrypotter::hp(n=100,option = "gryffindor"))
#   dplyr::select(planarity) %>%
#   ggplot() + geom_density(aes(x=planarity))
#   dplyr::glimpse()
```


```{r, include=FALSE, eval=FALSE}
wd_detect_dosSantos2025 <- function(
  # can be a sigular las already loaded, a list of las|laz files, or a LASCatalog
  norm_las
  #### height and area thresholds for the detected piles
  # these should be based on data from the literature or expectations based on the prescription
  , max_ht_m = 4 # set the max expected pile height
  , min_ht_m = 0.5 # set the min expected pile height
  , min_area_m2 = 2 # set the min expected pile area
  , max_area_m2 = 50 # set the max expected pile area
  #### irregularity filtering
  # 1 = perfectly convex (no inward angles); 0 = so many inward angles
  # values closer to 1 remove more irregular segments; 
    # values closer to 0 keep more irregular segments (and also regular segments)
  # these will all be further filtered for their circularity and later smoothed to remove blocky edges
  # and most inward angles by applying a convex hull to the original detected segment
  , convexity_pct = 0.7 # min required overlap between the predicted pile and the convex hull of the predicted pile
  #### circularity filtering
  # 1 = perfectly circular; 0 = not circular (e.g. linear) but also circular
  # min required IoU between the predicted pile and the best fit circle of the predicted pile
  , circle_fit_iou_pct = 0.5
  #### shape refinement & overlap removal
  ## smooth_segs = T ... convex hulls of raster detected segments are returned, any that overlap are removed
  ## smooth_segs = F ... raster detected segments are returned (blocky) if they meet all prior rules
  , smooth_segs = T
) {
  ##################################
  # ensure that norm las data exists
  ##################################
  nlas_ctg <- cloud2trees:::check_las_data(norm_las)
  # set the lascatalog options
  if(inherits(nlas_ctg, "LAScatalog")){
    lidR::opt_progress(nlas_ctg) <- F
    lidR::opt_filter(nlas_ctg) <- "-drop_duplicates -drop_class 2 7 9 18" ## class 2 = ground; 9 = water; 18 = noise
    lidR::opt_select(nlas_ctg) <- "xyzic" # 0 enables all extra bytes to be loaded...possibly treeID
    lidR::opt_output_files(nlas_ctg) <- paste0(tempdir(), "/{*}_dosSantos")
  }else if(inherits(nlas_ctg, "LAS")){
    stop(paste0(
      "`norm_las` should contain: a directory with nomalized las files,"
      ,"\n   the path of a single .laz|.las file,"
      , "\n   -or- an object of class `LAScatalog`"
    ))
    # nlas_ctg <- nlas_ctg %>%
    #   lidR::filter_poi(!Classification %in% c(2,9,18)) %>%
    #   lidR::filter_duplicates()
  }
  ######################################
  # execute lasR pipeline
  ######################################
    # set lasR parallel processing options as of lasR 0.10.1
      lasR::set_parallel_strategy(
        strategy = lasR::concurrent_points(
            ncores = max(lasR::ncores()-2, lasR::half_cores())
          )
      )

    # create safe function to capture error and map over
      # lasr_pipeline <- lasr_pipeline() # is this needed?
      safe_lasr_pipeline <- purrr::safely(lasr_pipeline)

    # map over processing grids
      lasr_ans_list <-
        chunk_las_catalog_ans$process_data$processing_grid %>%
        unique() %>%
        purrr::map(\(x) safe_lasr_pipeline(
          processing_grid_num = x
          , process_data = chunk_las_catalog_ans$process_data
          , keep_intrmdt = keep_intrmdt
          , dtm_res_m = dtm_res_m
          , chm_res_m = chm_res_m
          , min_height = min_height
          , max_height = max_height
          , dtm_dir = config$dtm_dir
          , chm_dir = config$chm_dir
          , classify_dir = config$las_classify_dir
          , normalize_dir = config$las_normalize_dir
        ))
}
```

